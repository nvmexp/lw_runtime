File Name,Public,File Path,Test Description,Test Config,Test Program,Test Parameters,Expected Output,Note
ldpc_BG1_K8448_SNR10_104.h5,FALSE,P4 path: //sw/gpgpu/gputelecom/test/test_vectors/LDPC/,,,lwphy_ex_ldpc,-i ldpc_BG1_K8448_SNR10_104.h5 -p 4 -n 10 -x 1,,"LDPC example program in the lwPHY repository, single precision. https://confluence.lwpu.com/display/5GV/LDPC+Error+Correction"
ldpc_BG1_K8448_SNR10_104.h5,FALSE,P4 path: //sw/gpgpu/gputelecom/test/test_vectors/LDPC/,,,lwphy_ex_ldpc,-i ldpc_BG1_K8448_SNR10_104.h5 -p 4 -n 10 -x 1 -f,,"LDPC example program in the lwPHY repository, half precision, add the -f flag. https://confluence.lwpu.com/display/5GV/LDPC+Error+Correction"
ldpc_BG1_K8448_SNR7_1.h5,FALSE,P4 path: //sw/gpgpu/gputelecom/test/test_vectors/LDPC/,,,lwphy_ex_ldpc,-i ldpc_BG1_K8448_SNR7_1.h5 -p 4 -n 10 -x 1,,"LDPC example program in the lwPHY repository, single precision. https://confluence.lwpu.com/display/5GV/LDPC+Error+Correction"
ldpc_BG1_K8448_SNR7_1.h5,FALSE,P4 path: //sw/gpgpu/gputelecom/test/test_vectors/LDPC/,,,lwphy_ex_ldpc,-i ldpc_BG1_K8448_SNR7_1.h5 -p 4 -n 10 -x 1 -f,,"LDPC example program in the lwPHY repository, half precision, add the -f flag. https://confluence.lwpu.com/display/5GV/LDPC+Error+Correction"
ldpc_BG1_K8448_SNR7_40.h5,FALSE,P4 path: //sw/gpgpu/gputelecom/test/test_vectors/LDPC/,,,lwphy_ex_ldpc,-i ldpc_BG1_K8448_SNR7_40.h5 -p 4 -n 10 -x 1,,"LDPC example program in the lwPHY repository, single precision. https://confluence.lwpu.com/display/5GV/LDPC+Error+Correction"
ldpc_BG1_K8448_SNR7_40.h5,FALSE,P4 path: //sw/gpgpu/gputelecom/test/test_vectors/LDPC/,,,lwphy_ex_ldpc,-i ldpc_BG1_K8448_SNR7_40.h5 -p 4 -n 10 -x 1 -f,,"LDPC example program in the lwPHY repository, half precision, add the -f flag. https://confluence.lwpu.com/display/5GV/LDPC+Error+Correction"
ldpc_BG1_K8448_SNR7_80.h5,FALSE,P4 path: //sw/gpgpu/gputelecom/test/test_vectors/LDPC/,,,lwphy_ex_ldpc,-i ldpc_BG1_K8448_SNR7_80.h5 -p 4 -n 10 -x 1,,"LDPC example program in the lwPHY repository, single precision. https://confluence.lwpu.com/display/5GV/LDPC+Error+Correction"
ldpc_BG1_K8448_SNR7_80.h5,FALSE,P4 path: //sw/gpgpu/gputelecom/test/test_vectors/LDPC/,,,lwphy_ex_ldpc,-i ldpc_BG1_K8448_SNR7_80.h5 -p 4 -n 10 -x 1 -f,,"LDPC example program in the lwPHY repository, half precision, add the -f flag. https://confluence.lwpu.com/display/5GV/LDPC+Error+Correction"
,,,,,,,,
ldpc_BG1_K1408_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 64, Valid Parity Range (-p option):  4 thru 46 ",,lwphy_ex_ldpc, -i ldpc_BG1_K1408_SNR7_80_p_m.h5 -n 10 -p 8,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG1_K2112_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 96, Valid Parity Range (-p option):  4 thru 46 ",,lwphy_ex_ldpc,-i ldpc_BG1_K2112_SNR7_80_p_m.h5 -n 10 -p 8,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG1_K2816_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 128, Valid Parity Range (-p option):  4 thru 46 ",,lwphy_ex_ldpc,-i ldpc_BG1_K2816_SNR7_80_p_m.h5 -n 10 -p 8,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG1_K3520_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 160, Valid Parity Range (-p option):  4 thru 46 ",,lwphy_ex_ldpc,-i ldpc_BG1_K3520_SNR7_80_p_m.h5 -n 10 -p 8,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG1_K4224_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 192, Valid Parity Range (-p option):  4 thru 46 ",,lwphy_ex_ldpc,-i ldpc_BG1_K4224_SNR7_80_p_m.h5 -n 10 -p 8,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG1_K4928_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 224, Valid Parity Range (-p option):  4 thru 46 ",,lwphy_ex_ldpc,-i ldpc_BG1_K4928_SNR7_80_p_m.h5 -n 10 -p 8,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG1_K5632_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 256, Valid Parity Range (-p option):  4 thru 46 ",,lwphy_ex_ldpc,-i ldpc_BG1_K5632_SNR7_80_p_m.h5 -n 10 -p 8,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG1_K6336_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 288, Valid Parity Range (-p option):  4 thru 46 ",,lwphy_ex_ldpc,-i ldpc_BG1_K6336_SNR7_80_p_m.h5 -n 10 -p 8,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG1_K7040_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 320, Valid Parity Range (-p option):  4 thru 46 ",,lwphy_ex_ldpc,-i ldpc_BG1_K7040_SNR7_80_p_m.h5 -n 10 -p 8,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG1_K7744_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 352, Valid Parity Range (-p option):  4 thru 46 ",,lwphy_ex_ldpc,-i ldpc_BG1_K7744_SNR7_80_p_m.h5 -n 10 -p 8,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG1_K8448_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 384, Valid Parity Range (-p option):  4 thru 46 ",,lwphy_ex_ldpc,-i ldpc_BG1_K8448_SNR7_80_p_m.h5 -n 10 -p 8,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG2_K640_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 64, Valid Parity Range (-p option):  4 thru 42",,lwphy_ex_ldpc,-i ldpc_BG2_K640_SNR7_80_p_m.h5 -n 10 -p 8 -g 2,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG2_K960_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 96, Valid Parity Range (-p option):  4 thru 42 ",,lwphy_ex_ldpc,-i ldpc_BG2_K960_SNR7_80_p_m.h5 -n 10 -p 8 -g 2,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG2_K1280_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 128, Valid Parity Range (-p option):  4 thru 42 ",,lwphy_ex_ldpc,-i ldpc_BG2_K1280_SNR7_80_p_m.h5 -n 10 -p 8 -g 2,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG2_K1600_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 160, Valid Parity Range (-p option):  4 thru 42 ",,lwphy_ex_ldpc,-i ldpc_BG2_K1600_SNR7_80_p_m.h5 -n 10 -p 8 -g 2,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG2_K1920_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 192, Valid Parity Range (-p option):  4 thru 42 ",,lwphy_ex_ldpc,-i ldpc_BG2_K1920_SNR7_80_p_m.h5 -n 10 -p 8 -g 2,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG2_K2240_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 224, Valid Parity Range (-p option):  4 thru 42 ",,lwphy_ex_ldpc,-i ldpc_BG2_K2240_SNR7_80_p_m.h5 -n 10 -p 8 -g 2,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG2_K2560_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 256, Valid Parity Range (-p option):  4 thru 42 ",,lwphy_ex_ldpc,-i ldpc_BG2_K2560_SNR7_80_p_m.h5 -n 10 -p 8 -g 2,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG2_K2880_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 288, Valid Parity Range (-p option):  4 thru 42 ",,lwphy_ex_ldpc,-i ldpc_BG2_K2880_SNR7_80_p_m.h5 -n 10 -p 8 -g 2,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG2_K3200_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 320, Valid Parity Range (-p option):  4 thru 42 ",,lwphy_ex_ldpc,-i ldpc_BG2_K3200_SNR7_80_p_m.h5 -n 10 -p 8 -g 2,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG2_K3520_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 352, Valid Parity Range (-p option):  4 thru 42 ",,lwphy_ex_ldpc,-i ldpc_BG2_K3520_SNR7_80_p_m.h5 -n 10 -p 8 -g 2,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
ldpc_BG2_K3840_SNR7_80_p_m.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/release/testVectors,"Base Gragh: 1,  Z: 384, Valid Parity Range (-p option):  4 thru 42 ",,lwphy_ex_ldpc,-i ldpc_BG2_K3840_SNR7_80_p_m.h5 -n 10 -p 8 -g 2,,"Additional options:
-p 4
Change the number of parity nodes (and thus the code rate). A reasonable subset to summarize performance might be (4, 8, 16, 32, 46).
-r 100
Time over 100 iterations instead of 1. (This is more stable - partilwlarly when running with small numbers of parity nodes, since the kernels are short.)
-g 2
Specifies that the input data is for base graph 2. (Note that base graph 2 support was added to the develop branch on 10/28. Builds before that will not decode base graph 2 inputs.)
-f
Use half precision input LLR data. (Note that as of 10/28/2019, the ""fast"" kernels are only implemented with single precision. fp16 implementations are under development, but in the meantime using half precision is not recommended.)
-n 8
Run 8 iterations of the LDPC decoder, instead of 10. (Note that some Xilinx dolwments provide timings for 8 iterations, whereas for internal tests we often use 10.)
-w 40
Limit exelwtion to a subset of the input codewords. (This can be used to, for example, compare the latency of ""1 codeword"" to ""1 codeword per SM"" (often the same), or it can be done to measure the time for a single ""wavefront"" on architectures with fewer SMs than codewords in the input file.)"
,,,,,,,,
TV_lwphy_perf-pusch-TC231_snrdb40.00_iter1_MIMO1x4_PRB104_DataSyms10_qam256.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 256 QAM, 1 Layers, 104 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC231_snrdb40.00_iter1_MIMO1x4_PRB104_DataSyms10_qam256.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_perf-pusch-TC232_snrdb40.00_iter1_MIMO1x4_PRB104_DataSyms10_qam256.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 256 QAM, 1 Layers, 104 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC232_snrdb40.00_iter1_MIMO1x4_PRB104_DataSyms10_qam256.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_perf-pusch-TC233_snrdb40.00_iter1_MIMO1x4_PRB104_DataSyms10_qam64.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 64 QAM, 1 Layers, 104 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC233_snrdb40.00_iter1_MIMO1x4_PRB104_DataSyms10_qam64.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_perf-pusch-TC234_snrdb40.00_iter1_MIMO1x4_PRB104_DataSyms10_qam64.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 64 QAM, 1 Layers, 104 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC234_snrdb40.00_iter1_MIMO1x4_PRB104_DataSyms10_qam64.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_perf-pusch-TC235_snrdb40.00_iter1_MIMO1x4_PRB104_DataSyms10_qam16.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 16 QAM, 1 Layers, 104 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC235_snrdb40.00_iter1_MIMO1x4_PRB104_DataSyms10_qam16.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_perf-pusch-TC281_snrdb40.00_iter1_MIMO8x16_PRB272_DataSyms10_qam256.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 256 QAM, 8 Layers, 272 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC281_snrdb40.00_iter1_MIMO8x16_PRB272_DataSyms10_qam256.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_perf-pusch-TC282_snrdb40.00_iter1_MIMO8x16_PRB272_DataSyms10_qam256.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 256 QAM, 8 Layers, 272 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC282_snrdb40.00_iter1_MIMO8x16_PRB272_DataSyms10_qam256.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_perf-pusch-TC283_snrdb40.00_iter1_MIMO8x16_PRB272_DataSyms10_qam64.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 64 QAM, 8 Layers, 272 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC283_snrdb40.00_iter1_MIMO8x16_PRB272_DataSyms10_qam64.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_perf-pusch-TC284_snrdb40.00_iter1_MIMO8x16_PRB272_DataSyms10_qam64.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 64 QAM, 8 Layers, 272 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC284_snrdb40.00_iter1_MIMO8x16_PRB272_DataSyms10_qam64.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_perf-pusch-TC285_snrdb40.00_iter1_MIMO8x16_PRB272_DataSyms10_qam16.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 16 QAM, 8 Layers, 272 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC285_snrdb40.00_iter1_MIMO8x16_PRB272_DataSyms10_qam16.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_pusch-TC1_snrdb40.00_iter1_MIMO4x8_PRB272_DataSyms9_qam64.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 64 QAM, 4 Layers, 272 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_pusch-TC1_snrdb40.00_iter1_MIMO4x8_PRB272_DataSyms9_qam64.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_pusch-TC2_snrdb40.00_iter1_MIMO2x8_PRB272_DataSyms9_qam64.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 64 QAM, 2 Layers, 272 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_pusch-TC2_snrdb40.00_iter1_MIMO2x8_PRB272_DataSyms9_qam64.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_pusch-TC3_snrdb40.00_iter1_MIMO1x8_PRB272_DataSyms9_qam64.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 64 QAM, 1 Layers, 272 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_pusch-TC3_snrdb40.00_iter1_MIMO1x8_PRB272_DataSyms9_qam64.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_pusch-TC4_snrdb40.00_iter1_MIMO4x8_PRB272_DataSyms9_qam16.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 16 QAM, 4 Layers, 272 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_pusch-TC4_snrdb40.00_iter1_MIMO4x8_PRB272_DataSyms9_qam16.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_pusch-TC5_snrdb40.00_iter1_MIMO2x8_PRB272_DataSyms9_qam16.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 16 QAM, 2 Layers, 272 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_pusch-TC5_snrdb40.00_iter1_MIMO2x8_PRB272_DataSyms9_qam16.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_pusch-TC6_snrdb40.00_iter1_MIMO1x8_PRB272_DataSyms9_qam16.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 16 QAM, 1 Layers, 272 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_pusch-TC6_snrdb40.00_iter1_MIMO1x8_PRB272_DataSyms9_qam16.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_pusch-TC7_snrdb40.00_iter1_MIMO2x8_PRB48_DataSyms9_qam64.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 64 QAM, 2 Layers, 48 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_pusch-TC7_snrdb40.00_iter1_MIMO2x8_PRB48_DataSyms9_qam64.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_pusch-TC8_snrdb40.00_iter1_MIMO2x8_PRB64_DataSyms9_qam16.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 16 QAM, 2 Layers, 64 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_pusch-TC8_snrdb40.00_iter1_MIMO2x8_PRB64_DataSyms9_qam16.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_pusch-TC11_snrdb40.00_iter1_MIMO4x8_PRB272_DataSyms9_qam4.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 4 QAM, 4 Layers, 272 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_pusch-TC11_snrdb40.00_iter1_MIMO4x8_PRB272_DataSyms9_qam4.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_pusch-TC12_snrdb40.00_iter1_MIMO2x8_PRB272_DataSyms9_qam4.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 4 QAM, 2 Layers, 272 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_pusch-TC12_snrdb40.00_iter1_MIMO2x8_PRB272_DataSyms9_qam4.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_pusch-TC13_snrdb40.00_iter1_MIMO1x8_PRB272_DataSyms9_qam4.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 4 QAM, 1 Layers, 272 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_pusch-TC13_snrdb40.00_iter1_MIMO1x8_PRB272_DataSyms9_qam4.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_pusch-TC14_snrdb40.00_iter1_MIMO4x8_PRB272_DataSyms9_qam256.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 256 QAM, 4 Layers, 272 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_pusch-TC14_snrdb40.00_iter1_MIMO4x8_PRB272_DataSyms9_qam256.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_pusch-TC15_snrdb40.00_iter1_MIMO2x8_PRB272_DataSyms9_qam256.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 256 QAM, 2 Layers, 272 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_pusch-TC15_snrdb40.00_iter1_MIMO2x8_PRB272_DataSyms9_qam256.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
TV_lwphy_pusch-TC16_snrdb40.00_iter1_MIMO1x8_PRB272_DataSyms9_qam256.h5,TRUE,P4 path: //sw/gpgpu/gputelecom/source_release/testVectors,"PUSCH Rx pipeline: 8 BB ports, 9 data symbols, 256 QAM, 1 Layers, 272 PRB counts",,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_pusch-TC16_snrdb40.00_iter1_MIMO1x8_PRB272_DataSyms9_qam256.h5,," scrambling enabled and the data I/Q samples are in FP16 precision, pipeline runs for 1000 iterations by default for the purposes of measuring exelwtion time.
Optionally use the -r option to change the number of run iterations.  Default is equivalent to -r 1000"
,,,,,,,,
TV_lwphy_perf-pusch-TC231_snrdb40.00_MIMO1x4_PRB104_DataSyms10_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC231_snrdb40.00_MIMO1x4_PRB104_DataSyms10_qam256.h5,,
TV_lwphy_perf-pusch-TC232_snrdb40.00_MIMO1x4_PRB104_DataSyms10_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC232_snrdb40.00_MIMO1x4_PRB104_DataSyms10_qam256.h5,,
TV_lwphy_perf-pusch-TC233_snrdb40.00_MIMO1x4_PRB104_DataSyms10_qam64.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC233_snrdb40.00_MIMO1x4_PRB104_DataSyms10_qam64.h5,,
TV_lwphy_perf-pusch-TC234_snrdb40.00_MIMO1x4_PRB104_DataSyms10_qam64.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC234_snrdb40.00_MIMO1x4_PRB104_DataSyms10_qam64.h5,,
TV_lwphy_perf-pusch-TC235_snrdb40.00_MIMO1x4_PRB104_DataSyms10_qam16.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC235_snrdb40.00_MIMO1x4_PRB104_DataSyms10_qam16.h5,,
TV_lwphy_perf-pusch-TC281_snrdb40.00_MIMO8x16_PRB272_DataSyms10_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC281_snrdb40.00_MIMO8x16_PRB272_DataSyms10_qam256.h5,,
TV_lwphy_perf-pusch-TC282_snrdb40.00_MIMO8x16_PRB272_DataSyms10_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC282_snrdb40.00_MIMO8x16_PRB272_DataSyms10_qam256.h5,,
TV_lwphy_perf-pusch-TC283_snrdb40.00_MIMO8x16_PRB272_DataSyms10_qam64.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC283_snrdb40.00_MIMO8x16_PRB272_DataSyms10_qam64.h5,,
TV_lwphy_perf-pusch-TC284_snrdb40.00_MIMO8x16_PRB272_DataSyms10_qam64.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC284_snrdb40.00_MIMO8x16_PRB272_DataSyms10_qam64.h5,,
TV_lwphy_perf-pusch-TC285_snrdb40.00_MIMO8x16_PRB272_DataSyms10_qam16.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC285_snrdb40.00_MIMO8x16_PRB272_DataSyms10_qam16.h5,,
TV_lwphy_perf-pusch-TC310_snrdb40.00_MIMO1x4_PRB272_DataSyms11_qam64.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC310_snrdb40.00_MIMO1x4_PRB272_DataSyms11_qam64.h5,,
TV_lwphy_perf-pusch-TC311_snrdb40.00_MIMO1x4_PRB272_DataSyms10_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC311_snrdb40.00_MIMO1x4_PRB272_DataSyms10_qam256.h5,,
TV_lwphy_perf-pusch-TC312_snrdb40.00_MIMO1x4_PRB272_DataSyms10_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC312_snrdb40.00_MIMO1x4_PRB272_DataSyms10_qam256.h5,,
TV_lwphy_perf-pusch-TC313_snrdb40.00_MIMO1x4_PRB272_DataSyms10_qam64.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC313_snrdb40.00_MIMO1x4_PRB272_DataSyms10_qam64.h5,,
TV_lwphy_perf-pusch-TC314_snrdb40.00_MIMO1x4_PRB272_DataSyms10_qam64.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC314_snrdb40.00_MIMO1x4_PRB272_DataSyms10_qam64.h5,,
TV_lwphy_perf-pusch-TC315_snrdb40.00_MIMO1x4_PRB272_DataSyms10_qam16.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pusch_rx_multi_pipe,-i TV_lwphy_perf-pusch-TC315_snrdb40.00_MIMO1x4_PRB272_DataSyms10_qam16.h5,,
,,,,,,,,
TV_lwphy_pucch-TC1001.h5,TRUE,Matlab generated: generate_all_TC.m,,,pucch_receiver,TV_lwphy_pucch-TC1001.h5 20,,
TV_lwphy_pucch-TC1002.h5,TRUE,Matlab generated: generate_all_TC.m,,,pucch_receiver,TV_lwphy_pucch-TC1002.h5 20,,
TV_lwphy_pucch-TC1003.h5,TRUE,Matlab generated: generate_all_TC.m,,,pucch_receiver,TV_lwphy_pucch-TC1003.h5 20,,
TV_lwphy_pucch-TC1004.h5,TRUE,Matlab generated: generate_all_TC.m,,,pucch_receiver,TV_lwphy_pucch-TC1004.h5 20,,
TV_lwphy_pucch-TC1005.h5,TRUE,Matlab generated: generate_all_TC.m,,,pucch_receiver,TV_lwphy_pucch-TC1005.h5 20,,
TV_lwphy_pucch-TC1006.h5,TRUE,Matlab generated: generate_all_TC.m,,,pucch_receiver,TV_lwphy_pucch-TC1006.h5 20,,
,,,,,,,,
TV_lwphy_pdsch-TC201_slot17_MIMO4x4_PRB104_DataSyms11_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC201_slot17_MIMO4x4_PRB104_DataSyms11_qam256.h5 20 0,,
TV_lwphy_pdsch-TC202_slot17_MIMO4x4_PRB104_DataSyms11_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC202_slot17_MIMO4x4_PRB104_DataSyms11_qam256.h5 20 0,,
TV_lwphy_pdsch-TC203_slot17_MIMO4x4_PRB104_DataSyms11_qam64.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC203_slot17_MIMO4x4_PRB104_DataSyms11_qam64.h5 20 0,,
TV_lwphy_pdsch-TC204_slot17_MIMO4x4_PRB104_DataSyms11_qam64.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC204_slot17_MIMO4x4_PRB104_DataSyms11_qam64.h5 20 0,,
TV_lwphy_pdsch-TC205_slot17_MIMO4x4_PRB104_DataSyms11_qam16.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC205_slot17_MIMO4x4_PRB104_DataSyms11_qam16.h5 20 0,,
TV_lwphy_pdsch-TC261_slot17_MIMO16x16_PRB273_DataSyms10_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC261_slot17_MIMO16x16_PRB273_DataSyms10_qam256.h5 20 0,,
TV_lwphy_pdsch-TC262_slot17_MIMO16x16_PRB273_DataSyms10_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC262_slot17_MIMO16x16_PRB273_DataSyms10_qam256.h5 20 0,,
TV_lwphy_pdsch-TC263_slot17_MIMO16x16_PRB273_DataSyms10_qam64.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC263_slot17_MIMO16x16_PRB273_DataSyms10_qam64.h5 20 0,,
TV_lwphy_pdsch-TC264_slot17_MIMO16x16_PRB273_DataSyms10_qam64.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC264_slot17_MIMO16x16_PRB273_DataSyms10_qam64.h5 20 0,,
TV_lwphy_pdsch-TC265_slot17_MIMO16x16_PRB273_DataSyms10_qam16.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC265_slot17_MIMO16x16_PRB273_DataSyms10_qam16.h5 20 0,,
,,,,,,,,
TV_lwphy_pdsch-TC301a_slot8_MIMO4x4_PRB272_DataSyms11_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx, TV_lwphy_pdsch-TC301a_slot8_MIMO4x4_PRB272_DataSyms11_qam256.h5 20 0,,
TV_lwphy_pdsch-TC301b_slot0_MIMO4x4_PRB248_DataSyms11_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx, TV_lwphy_pdsch-TC301b_slot0_MIMO4x4_PRB248_DataSyms11_qam256.h5 20 0,,
TV_lwphy_pdsch-TC302_slot17_MIMO4x4_PRB273_DataSyms11_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx, TV_lwphy_pdsch-TC302_slot17_MIMO4x4_PRB273_DataSyms11_qam256.h5 20 0,,
TV_lwphy_pdsch-TC303_slot17_MIMO4x4_PRB273_DataSyms11_qam64.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx, TV_lwphy_pdsch-TC303_slot17_MIMO4x4_PRB273_DataSyms11_qam64.h5 20 0,,
TV_lwphy_pdsch-TC304_slot17_MIMO4x4_PRB273_DataSyms11_qam64.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx, TV_lwphy_pdsch-TC304_slot17_MIMO4x4_PRB273_DataSyms11_qam64.h5 20 0,,
TV_lwphy_pdsch-TC305_slot17_MIMO4x4_PRB273_DataSyms11_qam16.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx, TV_lwphy_pdsch-TC305_slot17_MIMO4x4_PRB273_DataSyms11_qam16.h5 20 0,,
,,,,,,,,
TV_lwphy_pdsch-TC201_slot17_MIMO4x4_PRB104_DataSyms11_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC201_slot17_MIMO4x4_PRB104_DataSyms11_qam256.h5 20 1,,
TV_lwphy_pdsch-TC202_slot17_MIMO4x4_PRB104_DataSyms11_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC202_slot17_MIMO4x4_PRB104_DataSyms11_qam256.h5 20 1,,
TV_lwphy_pdsch-TC203_slot17_MIMO4x4_PRB104_DataSyms11_qam64.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC203_slot17_MIMO4x4_PRB104_DataSyms11_qam64.h5 20 1,,
TV_lwphy_pdsch-TC204_slot17_MIMO4x4_PRB104_DataSyms11_qam64.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC204_slot17_MIMO4x4_PRB104_DataSyms11_qam64.h5 20 1,,
TV_lwphy_pdsch-TC205_slot17_MIMO4x4_PRB104_DataSyms11_qam16.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC205_slot17_MIMO4x4_PRB104_DataSyms11_qam16.h5 20 1,,
TV_lwphy_pdsch-TC261_slot17_MIMO16x16_PRB273_DataSyms10_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC261_slot17_MIMO16x16_PRB273_DataSyms10_qam256.h5 20 1,,
TV_lwphy_pdsch-TC262_slot17_MIMO16x16_PRB273_DataSyms10_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC262_slot17_MIMO16x16_PRB273_DataSyms10_qam256.h5 20 1,,
TV_lwphy_pdsch-TC263_slot17_MIMO16x16_PRB273_DataSyms10_qam64.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC263_slot17_MIMO16x16_PRB273_DataSyms10_qam64.h5 20 1,,
TV_lwphy_pdsch-TC264_slot17_MIMO16x16_PRB273_DataSyms10_qam64.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC264_slot17_MIMO16x16_PRB273_DataSyms10_qam64.h5 20 1,,
TV_lwphy_pdsch-TC265_slot17_MIMO16x16_PRB273_DataSyms10_qam16.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx,TV_lwphy_pdsch-TC265_slot17_MIMO16x16_PRB273_DataSyms10_qam16.h5 20 1,,
,,,,,,,,
TV_lwphy_pdsch-TC301a_slot8_MIMO4x4_PRB272_DataSyms11_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx, TV_lwphy_pdsch-TC301a_slot8_MIMO4x4_PRB272_DataSyms11_qam256.h5 20 1,,
TV_lwphy_pdsch-TC301b_slot0_MIMO4x4_PRB248_DataSyms11_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx, TV_lwphy_pdsch-TC301b_slot0_MIMO4x4_PRB248_DataSyms11_qam256.h5 20 1,,
TV_lwphy_pdsch-TC302_slot17_MIMO4x4_PRB273_DataSyms11_qam256.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx, TV_lwphy_pdsch-TC302_slot17_MIMO4x4_PRB273_DataSyms11_qam256.h5 20 1,,
TV_lwphy_pdsch-TC303_slot17_MIMO4x4_PRB273_DataSyms11_qam64.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx, TV_lwphy_pdsch-TC303_slot17_MIMO4x4_PRB273_DataSyms11_qam64.h5 20 1,,
TV_lwphy_pdsch-TC304_slot17_MIMO4x4_PRB273_DataSyms11_qam64.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx, TV_lwphy_pdsch-TC304_slot17_MIMO4x4_PRB273_DataSyms11_qam64.h5 20 1,,
TV_lwphy_pdsch-TC305_slot17_MIMO4x4_PRB273_DataSyms11_qam16.h5,TRUE,Matlab generated: generate_all_TC.m,,,lwphy_ex_pdsch_tx, TV_lwphy_pdsch-TC305_slot17_MIMO4x4_PRB273_DataSyms11_qam16.h5 20 1,,
,,,,,,,,
TV_lwphy_DL_ctrl-TC2001_SSBlock.h5,TRUE,Matlab generated: generate_all_TC.m,,,testSS,TV_lwphy_DL_ctrl-TC2001_SSBlock.h5,,
,,,,,,,,
TV_lwphy_DL_ctrl-TC2003_pdcch_1_1.h5,TRUE,Matlab generated: generate_all_TC.m,,,embed_pdcch_tf_signal,TV_lwphy_DL_ctrl-TC2003_pdcch_1_1.h5,,
TV_lwphy_DL_ctrl-TC2004_pdcch_0_0.h5,TRUE,Matlab generated: generate_all_TC.m,,,embed_pdcch_tf_signal,TV_lwphy_DL_ctrl-TC2004_pdcch_0_0.h5,,
