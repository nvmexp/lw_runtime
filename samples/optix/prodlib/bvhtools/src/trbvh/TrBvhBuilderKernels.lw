// Copyright LWPU Corporation 2013
// TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW, THIS SOFTWARE IS PROVIDED
// *AS IS* AND LWPU AND ITS SUPPLIERS DISCLAIM ALL WARRANTIES, EITHER EXPRESS
// OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, IMPLIED WARRANTIES OF MERCHANTABILITY
// AND FITNESS FOR A PARTICULAR PURPOSE.  IN NO EVENT SHALL LWPU OR ITS SUPPLIERS
// BE LIABLE FOR ANY SPECIAL, INCIDENTAL, INDIRECT, OR CONSEQUENTIAL DAMAGES
// WHATSOEVER (INCLUDING, WITHOUT LIMITATION, DAMAGES FOR LOSS OF BUSINESS PROFITS,
// BUSINESS INTERRUPTION, LOSS OF BUSINESS INFORMATION, OR ANY OTHER PELWNIARY LOSS)
// ARISING OUT OF THE USE OF OR INABILITY TO USE THIS SOFTWARE, EVEN IF LWPU HAS
// BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES

#include "TrBvhBuilderKernels.hpp"
#include <prodlib/bvhtools/src/common/SharedKernelFunctions.hpp>

using namespace prodlib::bvhtools;


// filters out NaNs in aabbs, since fmaxf( 0, nan) == 0
static __device__ __forceinline__ float     aabbClampedHalfArea (float sizeX, float sizeY, float sizeZ) { return fmaxf( 0.0f, sizeX * sizeY + sizeY * sizeZ + sizeZ * sizeX ); }

//------------------------------------------------------------------------

static __global__ __launch_bounds__(TRBVH_RADIXTREE_WARPS_PER_BLOCK * 32, TRBVH_RADIXTREE_BLOCKS_PER_SM)
void TrbvhRadixTree(TrbvhRadixTreeParams p)
{
    Range primRange = (p.primRange) ? *p.primRange : Range(0, p.maxPrims);
    int nodeRangeStart = *p.nodeRangeStart;
    p.nodes += nodeRangeStart;
    p.nodeVisited += *p.nodeVisitedOfs;

    // Pick a node index.

    int i = threadIdx.x + 32 * (threadIdx.y + TRBVH_RADIXTREE_WARPS_PER_BLOCK * (blockIdx.x + gridDim.x * blockIdx.y));

    // First thread => write nodeParents[0] and outNodeRange.

    if (i == 0)
    {
        p.nodeParents[0] = INT_MAX;
        *p.outNodeRange = Range(nodeRangeStart, nodeRangeStart + max(primRange.span() - 1, 1));
    }

    // Out of bounds => terminate.

    if (i >= primRange.span() - 1)
        return;

    int s, d, j;
    computeInterval( i, primRange.span(), p.mortonCodes + primRange.start, s, d, j );

    // Determine children.
    // Internal node => output parent pointer.
    // Leaf node => complement index.

    int childA = i + s * d + min(d, 0);
    int childB = childA + 1;

    if (childA > min(i, j))
        p.nodeParents[childA] = i;
    else
        childA = ~childA;

    if (childB < max(i, j))
        p.nodeParents[childB] = ~i;
    else
        childB = ~childB;

    // Output child pointers and initialize nodeVisited.
    *(int2*)&p.nodes[i].tmp.c0idx = make_int2(childA, childB);
    p.nodeVisited[i] = -2;
}

//------------------------------------------------------------------------

static __global__ __launch_bounds__(32 * TRBVH_FIT_WARPS_PER_BLOCK, TRBVH_FIT_BLOCKS_PER_SM)
void TrbvhFit(TrbvhFitParams p)
{
    Range primRange = (p.primRange) ? *p.primRange : Range(0, p.maxPrims);
    Range nodeRange = *p.nodeRange;
    p.nodes += nodeRange.start;
    p.nodeVisited += *p.nodeVisitedOfs;
    const int nodeVisitedTag = -1;

    // Pick an edge in the tree.

    int edgeIdx = threadIdx.x + 32 * (threadIdx.y + TRBVH_FIT_WARPS_PER_BLOCK * (blockIdx.x + gridDim.x * blockIdx.y));
    if (edgeIdx == 0)
    {
        *p.outNodeRangeEnd = nodeRange.end;

        // Handle special case

        if (primRange.span() < 2)
        {
            // Left child.

            TrbvhNode n;
            if (primRange.span())
            {
                PrimitiveAABB pa = p.inModel.loadPrimitiveAABB(p.sortOrder[primRange.start]);
                n.tmp.c0idx = ~pa.primitiveIdx;
                n.tmp.c0lox = pa.lox, n.tmp.c0loy = pa.loy, n.tmp.c0loz = pa.loz; // true AABB
                n.tmp.c0hix = pa.hix, n.tmp.c0hiy = pa.hiy, n.tmp.c0hiz = pa.hiz;
            }
            else
            {
                n.tmp.c0idx = ~0;
                n.tmp.c0lox = n.tmp.c0loy = n.tmp.c0loz = LWDART_NAN_F; // unhittable AABB
                n.tmp.c0hix = n.tmp.c0hiy = n.tmp.c0hiz = LWDART_NAN_F;
            }

            // Right child.

            n.tmp.c1idx = n.tmp.c0idx;
            n.tmp.c1lox = n.tmp.c1loy = n.tmp.c1loz = LWDART_NAN_F; // unhittable AABB
            n.tmp.c1hix = n.tmp.c1hiy = n.tmp.c1hiz = LWDART_NAN_F;

            // Output.

            n.tmp.pad = 0.0f;
            n.tmp.area = 0.0f;
            p.nodes[0] = n;

            p.nodeVisited[0] = nodeVisitedTag;
            p.nodeCosts[0].subtreeSize = 2.0f;
            p.nodeCosts[0].subtreeCost = setLSB(0.0f);

            return;
        }
    }

    // Out of range

    if (edgeIdx >= (primRange.span() - 1) * 2)
      return;

    // Determine parent and child.

    int parentIdx = edgeIdx >> 1;
    int edgeDir = -(edgeIdx & 1); // left = 0, right = -1
    float4 p1 = p.nodes[parentIdx].f4[1]; // (c0hiy, c0hiz, c0idx, c1idx)
    int childIdx = slct(__float_as_int(p1.z), __float_as_int(p1.w), edgeDir); // (edgeDir >= 0) ? c0idx : c1idx

    // Child is an internal node => skip.

    if (childIdx >= 0)
        return;

    // Fetch child AABB.

    int primIdx = p.sortOrder[~childIdx + primRange.start];
    PrimitiveAABB primAABB = p.inModel.loadPrimitiveAABB(primIdx);
    float3 lo = make_float3(primAABB.lox, primAABB.loy, primAABB.loz);
    float3 hi = max(make_float3(primAABB.hix, primAABB.hiy, primAABB.hiz), lo);


    // Replace child index with primitive index.

    *(&p.nodes[parentIdx].tmp.c0idx - edgeDir) = ~primAABB.primitiveIdx;

    // Initialize costs.

    float subtreeSize = 1.0f;
    float subtreeCost = aabbClampedHalfArea(hi.x - lo.x, hi.y - lo.y, hi.z - lo.z) * p.sahPrimCost;

    // Accumulate AABB and costs to ancestors.

    for (;;)
    {
        TrbvhNode& node = p.nodes[parentIdx];

        // Store child AABB.

        storeCG((float4*)&node.tmp.c0lox - edgeDir * 2, make_float4(lo.x, lo.y, lo.z, hi.x));
        storeCG((float2*)&node.tmp.c0hiy - edgeDir * 4, make_float2(hi.y, hi.z));

        // Mark the node as visited.
        // Not visited before => terminate thread.

        if (atomicExch(&p.nodeVisited[parentIdx], nodeVisitedTag) != nodeVisitedTag)
            break;

        // Fetch sibling index.

        float4 n1 = p.nodes[parentIdx].f4[1]; // (c0hiy, c0hiz, c0idx, c1idx)
        int siblingIdx = slct(__float_as_int(n1.w), __float_as_int(n1.z), edgeDir); // (edgeDir >= 0) ? c1idx : c0idx

        // Fetch AABB.

        float4 sa = loadCG((const float4*)&node.tmp.c1lox + edgeDir * 2); // (lox, loy, loz, hix)
        float2 sb = loadCG((const float2*)&node.tmp.c1hiy + edgeDir * 4); // (hiy, hiz)
        float3 slo = make_float3(sa.x, sa.y, sa.z);
        float3 shi = make_float3(sa.w, sb.x, sb.y);

        // Grow AABB and costs by those of the sibling.

        if (siblingIdx < 0) // leaf
        {
            subtreeSize += 1.0f;
            subtreeCost += aabbClampedHalfArea(shi.x - slo.x, shi.y - slo.y, shi.z - slo.z) * p.sahPrimCost;
        }
        else                // internal node
        {
            float2 costs = loadCG((const float2*)&p.nodeCosts[siblingIdx]); // (subtreeSize, subtreeCost)
            subtreeSize += costs.x;
            subtreeCost += costs.y;
        }

        lo = min(lo, slo);
        hi = max(hi, shi);

        // Callwlate final SAH cost for the node.

        float area = aabbClampedHalfArea(hi.x - lo.x, hi.y - lo.y, hi.z - lo.z);
        subtreeCost = setLSB(subtreeCost + area * p.sahNodeCost);

        if (subtreeSize <= p.maxLeafSize)
        {
            float leafCost = area * subtreeSize * p.sahPrimCost;
            subtreeCost = fminf(subtreeCost, clearLSB(leafCost));
        }

        // Output results.

        storeCG((float2*)&p.nodeCosts[parentIdx], make_float2(subtreeSize, subtreeCost));
        node.tmp.area = area;

        // Advance towards the root.

        if (parentIdx == 0)
            break;

        parentIdx = LDG_OR_GLOBAL(&p.nodeParents[parentIdx]);
        edgeDir = parentIdx >> 31;
        parentIdx ^= edgeDir;
    }
}

//------------------------------------------------------------------------
// Pre-optimized schedules for restructureTreelet().
//
// A schedule is organized into sections of 32 conselwtive entries, where
// each section corresponds to one round of processing. Each individual
// entry tells which subset of the treelet leaf nodes a given lane should
// process in each round. Lanes that do not have anything useful to do
// are assigned duplicate values.

static __device__ int g_restructureTreelet_schedule_5[] =
{
      9,   3,  17,   5,  18,  10,   6,  12,  20,  24,   9,   3,  17,   5,  18,  10,   6,  12,  20,  24,   9,   3,  17,   5,  18,  10,   6,  12,  20,  24,   9,   3,
      7,  25,  11,  13,  21,  19,  26,  22,  14,  28,   7,  25,  11,  13,  21,  19,  26,  22,  14,  28,   7,  25,  11,  13,  21,  19,  26,  22,  14,  28,   7,  25,
};

static __device__ int g_restructureTreelet_schedule_6[] =
{
      9,  17,  33,   3,   5,   6,  18,  34,  10,  12,  36,  20,  24,  40,  48,   9,  17,  33,   3,   5,   6,  18,  34,  10,  12,  36,  20,  24,  40,  48,   9,  17,
     41,  37,  35,  49,   7,  25,  11,  13,  21,  19,  22,  50,  14,  26,  42,  38,  52,  44,  28,  56,  41,  37,  35,  49,   7,  25,  11,  13,  21,  19,  22,  50,
     29,  23,  39,  43,  27,  15,  45,  51,  53,  57,  46,  54,  30,  58,  60,  29,  23,  39,  43,  27,  15,  45,  51,  53,  57,  46,  54,  30,  58,  60,  29,  23,
};

static __device__ int g_restructureTreelet_schedule_7[] =
{
     20,  68,  36,  12,  24,  40,  72,  48,  80,  96,  20,  68,  36,  12,  24,  40,  72,  48,  80,  96,  20,  68,  36,  12,  24,  40,  72,  48,  80,  96,  20,  68,
     44,  28,  52, 100,  84, 104,  56,  88, 112,   9,  33,  17,  65,   5,   3,  18,  10,  34,   6,  66,  44,  28,  52, 100,  84, 104,  56,  88, 112,   9,  33,  17,
    116,  60, 120,  69,  97,  73,  81,  67,  21,  19,  35,  37,  41,  49,  13,  11,  25,   7,  98,  38,  26,  70,  14,  42,  74,  82,  50,  22,  76, 116,  60, 120,
     71,  75,  77,  57,  15,  53,  51,  83, 113,  45,  43,  89,  85,  29,  27, 101, 105,  99,  23,  39,  46, 102, 106, 114,  30,  54,  90,  78,  86,  58, 108,  92,
    103,  93,  91, 107,  87, 109,  31,  79,  47,  55,  59, 117,  61, 121, 115, 110, 118, 122,  94,  62, 124, 103,  93,  91, 107,  87, 109,  31,  79,  47,  55,  59,
};

static __device__ int g_restructureTreelet_schedule_8[] =
{
     18, 130,  34,  66,  20,  68, 132,  36,  12,  24, 136,  40,  72, 144,  48,  80,  96, 160, 192,  18, 130,  34,  66,  20,  68, 132,  36,  12,  24, 136,  40,  72,
    146,  98,  52,  28, 140, 148, 100,  44, 164, 196,  76,  84, 200, 168,  56,  88, 152, 104, 112, 176, 208, 224,   3,  17,  33,   9,   5, 129,  65,   6,  10, 146,
     81,  73,   7,  69,  67,  49, 133,  97, 137,  37,  41,  25, 145,  11,  21, 161,  19,  35,  13, 194,  82,  74,  14,  50,  42,  22,  38,  26,  70, 162, 134, 138,
    154,  30, 106, 166, 226,  46, 198, 202,  78,  86,  54, 210, 114, 178,  58, 204, 156, 116, 228, 172, 212, 108, 180,  60,  92, 232, 184, 216, 120, 240, 193, 131,
    149, 105, 113, 165, 201,  77,  75,  71, 209,  57,  83,  53,  45,  43, 225,  39,  29,  27,  23,  51,  15,  89, 101,  85,  99, 195, 197,  90, 142, 170, 150, 102,
    115,  31,  47,  94, 110, 118, 122, 242, 158, 234, 186, 206, 230, 182, 214,  62, 218, 174, 236, 220, 244, 188, 124, 248, 141, 139, 177, 153, 163, 135, 169, 147,
    203, 117,  59, 179,  61, 157, 241, 155, 213, 211, 121, 233, 199, 185, 205, 167,  79, 181,  87, 227, 151, 103, 107, 229, 109, 171,  55, 143, 173,  93, 217,  91,
    221, 231, 219, 175, 215,  63, 183, 207, 235, 125, 159, 237, 119, 187, 243, 111,  95, 245, 249, 189, 123, 238, 222, 126, 246, 190, 250, 252, 221, 231, 219, 175,
};

static __device__ const int* g_restructureTreelet_schedules[] =
{
    NULL, // 0
    NULL, // 1
    NULL, // 2
    NULL, // 3
    NULL, // 4
    g_restructureTreelet_schedule_5,
    g_restructureTreelet_schedule_6,
    g_restructureTreelet_schedule_7,
    g_restructureTreelet_schedule_8,
};

//------------------------------------------------------------------------
// Called simultaneously by a warp to collaboratively process one treelet.

template <int N, int SCHEDULE_SIZE> static INLINE
void restructureTreelet(TrbvhOptParams p, int treeletRoot, const int* schedule, volatile TrbvhOptSh& warpSh)
{
    INIT_SHUFFLE_EMULATION(TRBVH_OPT_WARPS_PER_BLOCK)
    int numSets   = 1 << N;
    int lane      = threadIdx.x;

    // Use lanes 0..N-1 for storing treelet leaves,
    // and lanes N..N*2-2 for storing treelet internal nodes.
    // Treelet root is the first internal node, stored at lane N.

    int myNode = -1;
    float3 myLo = make_float3(+LWDART_MAX_NORMAL_F, +LWDART_MAX_NORMAL_F, +LWDART_MAX_NORMAL_F);
    float3 myHi = make_float3(-LWDART_MAX_NORMAL_F, -LWDART_MAX_NORMAL_F, -LWDART_MAX_NORMAL_F);

    // Form the treelet using the first 8 lanes.

    int internalNode = treeletRoot;
    if (lane < 8)
    {
        // Assign children of treelet root to the first two lanes.

        int parentNode = treeletRoot;
        int edgeDir = 0;
        float area = 0.0f;

        if (lane < 2)
        {
            edgeDir = lane;
            myNode = *(&p.nodes[parentNode].tmp.c0idx + edgeDir);
            if (myNode >= 0)
                area = p.nodes[myNode].tmp.area;
        }

        // Expand nodes one by one.

        for (int size = 2; size < N; size++)
        {
            // Find the largest treelet leaf.
            // Note: Reinterpreting the floats as unsigned integers ensures that
            // the comparison stays robust even if the input contains NaNs/Infs.

            unsigned int areaU32 = __float_as_int(fmaxf(area, 0.0f));
            unsigned int largestAreaU32 = areaU32;
            for (int i = 4; i >= 1; i /= 2)
                largestAreaU32 = max(largestAreaU32, (unsigned int)__shfl_xor_nosync((int)largestAreaU32, i));

            unsigned int largestMask = __ballot(areaU32 == largestAreaU32 && myNode >= 0);
            int largestLeaf = __shfl_nosync(myNode, findLeadingOne(largestMask));

            // Allocate a new lane, and record the leaf as an internal node there.

            bool isNewLane = (lane == size);
            if (isNewLane)
                internalNode = largestLeaf;

            // Assign the left child to the old lane, and the right child to the new lane.
            // BVH leaf => cannot grow further => set area to negative.

            if (isNewLane | myNode == largestLeaf)
            {
                parentNode = largestLeaf;
                edgeDir = (isNewLane) ? 1 : 0;
                myNode = loadCG(&p.nodes[parentNode].tmp.c0idx + edgeDir);
                area = (myNode < 0) ? 0.0f : loadCG(&p.nodes[myNode].tmp.area);
            }
        }

        // Fetch AABBs for the resulting treelet leaves.

        if (lane < N)
        {
            float4 ca = loadCG((const float4*)&p.nodes[parentNode].tmp.c0lox + edgeDir * 2); // (lox, loy, loz, hix)
            float2 cb = loadCG((const float2*)&p.nodes[parentNode].tmp.c0hiy + edgeDir * 4); // (hiy, hiz)
            myLo = make_float3(ca.x, ca.y, ca.z);
            myHi = make_float3(ca.w, cb.x, cb.y);
        }
    }

    // Assign the internal nodes to lanes N..N*2-2.

    internalNode = __shfl_nosync(internalNode, lane - N + 1);
    if (lane >= N)
        myNode = internalNode;

    // Allocate temporary space for each possible subset of the treelet leaf nodes:
    //
    // __shared__ float setArea      [numSets]  // Surface area of the AABB of this subset.
    // __shared__ float setCost      [numSets]  // Optimal cost for this subset. Overlaid on top of setArea.
    // __device__ int   setPartition [numSets]  // Optimal partitioning for this subset.

    __shared__ volatile float s_setArea[TRBVH_OPT_WARPS_PER_BLOCK][(1 << N) + 1];
    __shared__ volatile unsigned char s_setPartition[TRBVH_OPT_WARPS_PER_BLOCK][(1 << N) + 4];
    volatile float* setArea = s_setArea[threadIdx.y];
    volatile float* setCost = setArea;
    volatile unsigned char* setPartition = s_setPartition[threadIdx.y];

    // Initialize setArea for each subset.
    // Each lane is responsible for 4 subsets in each round.

    for (int i = 0; i < (numSets - 1) / 128 + 1; i++)
    {
        int set = i * 128 + lane * 4;

        // Determine AABB of the chosen subset.

        int lane = findLeadingOne(set); // set = 0 yields lane = -1 = 31
        float3 slo = shfl(myLo, lane), shi = shfl(myHi, lane);

        for (int leaf = 2; leaf < N - 1; leaf++)
        {
            float3 tlo = shfl(myLo, leaf), thi = shfl(myHi, leaf);
            if ((set & (1 << leaf)) != 0)
                slo = min(slo, tlo), shi = max(shi, thi);
        }

        // Output setArea for set+0 .. set+3.

        if (set < numSets)
        {
            setArea[set + 0] = aabbClampedHalfArea(shi.x - slo.x, shi.y - slo.y, shi.z - slo.z);

            float3 tlo = min(slo, shfl(myLo, 0)), thi = max(shi, shfl(myHi, 0));
            setArea[set + 1] = aabbClampedHalfArea(thi.x - tlo.x, thi.y - tlo.y, thi.z - tlo.z);

            slo = min(slo, shfl(myLo, 1)), shi = max(shi, shfl(myHi, 1));
            setArea[set + 2] = aabbClampedHalfArea(shi.x - slo.x, shi.y - slo.y, shi.z - slo.z);

            slo = min(slo, tlo), shi = max(shi, thi);
            setArea[set + 3] = aabbClampedHalfArea(shi.x - slo.x, shi.y - slo.y, shi.z - slo.z);
        }

        // Only one iteration => tell the compiler that the loop is not actually a loop => better register allocation.

        if (N < 8)
            break;
    }

    // Initialize setCost for subsets of size 0..1, and
    // fetch the number of primitives represented by each treelet leaf.

    float mySubtreeSize = 1.0f;
    if (lane < N)
    {
        float mySubtreeCost;
        if (myNode < 0) // leaf
            mySubtreeCost = aabbClampedHalfArea(myHi.x - myLo.x, myHi.y - myLo.y, myHi.z - myLo.z) * p.sahPrimCost;
        else            // internal node
        {
            float2 costs = loadCG((const float2*)&p.nodeCosts[myNode]); // (subtreeSize, subtreeCost)
            mySubtreeSize = costs.x;
            mySubtreeCost = costs.y;
        }

        setCost[0] = LWDART_MAX_NORMAL_F;
        setCost[1 << lane] = mySubtreeCost;
    }

    // Find optimal partitioning for each subset of size 2..N-2.
    // The processing is done in a warp-synchronous fashion according to
    // a pre-optimized schedule (see above).

    int mySubtreeSizeInt = (int)fminf(mySubtreeSize, TRBVH_COLLAPSE_MAX_LEAF_SIZE + 1); // for __ballot() below

    for (int i = 0; i < SCHEDULE_SIZE / 32; i++)
    {
        int set = schedule[i * 32 + lane];
        float bestChildCost = LWDART_MAX_NORMAL_F;
        int bestPartition = 0;

        // Try each way of partitioning the leaves into two subsets.

        int delta = set & (set - 1);
        int partition = -delta & set;
        do
        {
            float childCost = setCost[partition] + setCost[set - partition];
            if (childCost <= bestChildCost)
            {
                bestChildCost = childCost;
                bestPartition = partition;
            }
            partition = (partition - delta) & set;
        }
        while (partition != 0);

        // Callwlate the total number of primitives in this subset.

        int setPrimsInt = 0;
        for (int bit = 0; (1 << bit) <= TRBVH_COLLAPSE_MAX_LEAF_SIZE + 1; bit++)
            setPrimsInt += __popc(__ballot((mySubtreeSizeInt >> bit) & 1) & set) << bit;
        float setPrims = (float)setPrimsInt;

        // Callwlate SAH cost for this subset.

        float area = setArea[set];
        float bestSubtreeCost = setLSB(area * p.sahNodeCost + bestChildCost);
        if (setPrims <= p.maxLeafSize)
            bestSubtreeCost = fminf(bestSubtreeCost, clearLSB(area * setPrims * p.sahPrimCost));

        // Store results.

        setCost[set] = bestSubtreeCost;
        setPartition[set] = bestPartition;
    }

    // Find optimal partitioning for each subset of size N-1.
    // Each group of 4 lanes collaborates to process one subset.

    int groupLog2 = 2;
    int missingLeaf = lane >> groupLog2;
    if (missingLeaf < N)
    {
        int maskGe = -1 << missingLeaf;
        int set = numSets - 1 + maskGe;
        int firstPartition = lane & ((1 << groupLog2) - 1);

        float bestChildCost = LWDART_MAX_NORMAL_F;
        int bestPartition = 0;

        // Try a fraction of ways of partitioning the leaves.

        for (int i = 0; i < numSets / (4 << groupLog2); i++)
        {
            int partition = firstPartition + (i << groupLog2);
            partition += partition & maskGe;
            float childCost = setCost[partition] + setCost[set - partition];
            if (childCost <= bestChildCost)
            {
                bestChildCost = childCost;
                bestPartition = partition;
            }
        }

        // Perform reduction over the group of lanes to find the absolute best partitioning for each subset.

        float finalChildCost = bestChildCost;
        for (int i = groupLog2 - 1; i >= 0; i--)
            finalChildCost = fminf(finalChildCost, __shfl_xor_nosync(finalChildCost, 1 << i));

        // Callwlate SAH cost for this subset.

        float area = setArea[set];
        float setPrims = p.nodeCosts[treeletRoot].subtreeSize - __shfl_nosync(mySubtreeSize, missingLeaf);
        float bestSubtreeCost = setLSB(area * p.sahNodeCost + finalChildCost);
        if (setPrims <= p.maxLeafSize)
            bestSubtreeCost = fminf(bestSubtreeCost, clearLSB(area * setPrims * p.sahPrimCost));

        // Store results.

        setCost[set] = bestSubtreeCost;
        if (finalChildCost == bestChildCost)
            setPartition[set] = bestPartition;
    }

    // Find optimal partitioning for the full set of leaves.
    {
        int set = numSets - 1;
        float bestChildCost = LWDART_MAX_NORMAL_F;
        int bestPartition = 0;

        for (int i = 0; i < (numSets - 1) / 64 + 1; i++)
        {
            int partition = i * 32 + lane;
            float childCost = setCost[partition] + setCost[set - partition];
            if (childCost <= bestChildCost)
            {
                bestChildCost = childCost;
                bestPartition = partition;
            }
        }

        float finalChildCost = bestChildCost;
        for (int i = 16; i >= 1; i /= 2)
            finalChildCost = fminf(finalChildCost, __shfl_xor_nosync(finalChildCost, i));

        // Callwlate SAH cost.
        // Not improved, or failed due to NaNs/Infs => skip the output part of the algorithm.

        float area = setArea[set];
        float bestRootCost = setLSB(area * p.sahNodeCost + finalChildCost);
        if (bestRootCost >= p.nodeCosts[treeletRoot].subtreeCost ||
            (unsigned int)__float_as_int(bestRootCost) >= 0x7F7FFFFEu) // NaN, Inf, < 0.0f, or >= clearLSB(LWDART_MAX_NORMAL_F)?
        {
            return;
        }

        // Store results.

        setCost[set] = bestRootCost;
        if (finalChildCost == bestChildCost)
            setPartition[set] = bestPartition;
    }

    // Reconstruct the optimal treelet.

    __shared__ volatile int s_allocSets[TRBVH_OPT_WARPS_PER_BLOCK][N / 2];
    volatile int* allocSets = s_allocSets[threadIdx.y];

    int  mySet      = numSets - 1; // treelet root
    int  childSetA  = setPartition[mySet];
    int  childSetB  = mySet - childSetA;
    int  childLaneA = findLeadingOne(childSetA); // assuming the child is a treelet leaf
    int  childLaneB = findLeadingOne(childSetB);

    for (int2 range = make_int2(N, N + 1); range.y < N * 2 - 1;) // lanes [range.x, range.y[ contain fresh internal nodes
    {
        // Determine how many child nodes we want to allocate.

        bool alloc  = (lane >= range.x & lane < range.y);
        bool allocA = (alloc & childSetA != 1 << childLaneA);
        bool allocB = (alloc & childSetB != 1 << childLaneB);

        // Warp-wide scan.

        unsigned int maskA = __ballot(allocA), maskB = __ballot(allocB);
        int allocScan = __popc(maskA & getLaneMaskLt()) + __popc(maskB & getLaneMaskLt());
        int allocTotal = __popc(maskA) + __popc(maskB);

        // Allocate the children.

        if (allocA)
        {
            childLaneA = allocScan + range.y;
            allocSets[allocScan++] = childSetA;
        }
        if (allocB)
        {
            childLaneB = allocScan + range.y;
            allocSets[allocScan++] = childSetB;
        }

        // Initialize the children.

        int idx = lane - range.y;
        if (idx >= 0 & idx < allocTotal)
        {
            mySet = allocSets[idx];
            childSetA = setPartition[mySet];
            childSetB = mySet - childSetA;
            childLaneA = findLeadingOne(childSetA); // assuming the child is a treelet leaf
            childLaneB = findLeadingOne(childSetB);
        }

        // Process the children on the next round.

        range = make_int2(range.y, range.y + allocTotal);
    }

    // Callwlate AABBs and primitive counts of the internal nodes.

    if (lane < N)
        childLaneA = childLaneB = lane; // leaf => make sure it's safe to recompute the AABB

    if (lane >= N & lane < N * 2 - 1)
        mySubtreeSize = -LWDART_MAX_NORMAL_F; // internal node => indicate that the node is not ready yet

    float3 alo, ahi, blo, bhi; // child AABBs
    do
    {
        alo = shfl(myLo, childLaneA), ahi = shfl(myHi, childLaneA);
        blo = shfl(myLo, childLaneB), bhi = shfl(myHi, childLaneB);
        myLo = min(alo, blo), myHi = max(ahi, bhi);

        float childSubtreeSize = __shfl_nosync(mySubtreeSize, childLaneA) + __shfl_nosync(mySubtreeSize, childLaneB);
        if (mySubtreeSize < 0.0f)
            mySubtreeSize = childSubtreeSize;
    }
    while (__any(mySubtreeSize < 0.0f));

    // Output the modified internal nodes.

    int childNodeA = __shfl_nosync(myNode, childLaneA);
    int childNodeB = __shfl_nosync(myNode, childLaneB);
    float area = aabbClampedHalfArea(myHi.x - myLo.x, myHi.y - myLo.y, myHi.z - myLo.z);

    if (lane >= N & lane < N * 2 - 1)
    {
        TrbvhNode& node = p.nodes[myNode];
        storeCG((float4*)&node.tmp.c0lox, make_float4(alo.x, alo.y, alo.z, ahi.x));
        storeCG((float4*)&node.tmp.c0hiy, make_float4(ahi.y, ahi.z, __int_as_float(childNodeA), __int_as_float(childNodeB)));
        storeCG((float4*)&node.tmp.c1lox, make_float4(blo.x, blo.y, blo.z, bhi.x));
        storeCG((float4*)&node.tmp.c1hiy, make_float4(bhi.y, bhi.z, 0.0f, area));

        if (childNodeA >= 0) p.nodeParents[childNodeA] = myNode;
        if (childNodeB >= 0) p.nodeParents[childNodeB] = ~myNode;
        storeCG((float2*)&p.nodeCosts[myNode], make_float2(mySubtreeSize, setCost[mySet]));
    }
}

//------------------------------------------------------------------------

template <int N, int SCHEDULE_SIZE> static __global__ __launch_bounds__(TRBVH_OPT_WARPS_PER_BLOCK * 32, TRBVH_OPT_BLOCKS_PER_SM)
void TrbvhOpt(TrbvhOptParams p)
{
    INIT_SHUFFLE_EMULATION(TRBVH_OPT_WARPS_PER_BLOCK)
    p.nodes += p.nodeRange->start;
    p.nodeVisited += *p.nodeVisitedOfs;

    // Copy the schedule to shared memory for faster access.

    __shared__ int s_schedule[SCHEDULE_SIZE];
    const int* schedulePtr = g_restructureTreelet_schedules[N];
    for (int i = 0; i < SCHEDULE_SIZE / 32; i++)
        s_schedule[i * 32 + threadIdx.x] = schedulePtr[i * 32 + threadIdx.x];

    // Allocate shared memory for register spilling.

    __shared__ TrbvhOptSh s_warpSh[TRBVH_OPT_WARPS_PER_BLOCK];
    volatile TrbvhOptSh& warpSh = s_warpSh[threadIdx.y];

    // Initialize current round.
    {
        int round = *p.lwrRound;

        int gamma = // Note: p.gamma[round] seems to confuse the compiler.
            (round == 0) ? p.gamma[0] :
            (round == 1) ? p.gamma[1] :
            (round == 2) ? p.gamma[2] :
                           p.gamma[3];

        Range nodeRange = *p.nodeRange;
        warpSh.numNodes = nodeRange.span();
        warpSh.round = round;
        warpSh.gamma = (float)gamma;
    }

    // Persistent threads.

    for (;;)
    {
        // Pick a group of 32 unprocessed internal nodes for the warp.

        int nodeIdx = 0;
        if (threadIdx.x == 0)
            nodeIdx = atomicAdd(p.workCounter, 32);
        nodeIdx = __shfl_nosync(nodeIdx, 0);

        // Out of work => terminate.
        // Last warp => initialize the next round.

        int numNodes = warpSh.numNodes;
        if (nodeIdx >= numNodes)
        {
            int numWarps = gridDim.x * TRBVH_OPT_WARPS_PER_BLOCK;
            int lastWorkCounter = ((numNodes - 1) & -32) + numWarps * 32;
            if (nodeIdx == lastWorkCounter)
            {
                *p.lwrRound = warpSh.round + 1;
                *p.workCounter = 0;
            }
            break;
        }

        // Assign one internal node for each lane.
        // At least one child is an internal node => will process later.
        // Otherwise => mark the node as visited.
        // Already visited => no need to process again.

        nodeIdx += threadIdx.x;
        {
            if( nodeIdx >= numNodes ) {
              nodeIdx = -1;
            } else {
              float4 n1 = p.nodes[nodeIdx].f4[1]; // (c0hiy, c0hiz, c0idx, c1idx)
              int c0 = __float_as_int(n1.z);
              int c1 = __float_as_int(n1.w);

              int round = warpSh.round;
              if ((c0 >= 0 | c1 >= 0) || atomicExch(&p.nodeVisited[nodeIdx], round) == round)
                  nodeIdx = -1;
              }
        }

        // Walk up the tree.

        while (__any(nodeIdx != -1))
        {
            // Which lanes want their current node to be a treelet root?

            if (nodeIdx != -1)
            {
                float subtreeSize = LDG_OR_GLOBAL(&p.nodeCosts[nodeIdx].subtreeSize);
                warpSh.activeMask = __ballot(subtreeSize >= warpSh.gamma);
            }

            // Each active lane => restructure corresponding treelet by the entire warp.

            unsigned int activeMask;
            while ((activeMask = warpSh.activeMask) != 0)
            {
                int lane = findLeadingOne(activeMask);
                warpSh.activeMask = activeMask - (1 << lane);
                restructureTreelet<N, SCHEDULE_SIZE>(p, __shfl_nosync(nodeIdx, lane), s_schedule, warpSh);
            }

            // Find the parent of the current node.

            int parentIdx = -1;
            if (nodeIdx > 0)
            {
                parentIdx = LDG_OR_GLOBAL(&p.nodeParents[nodeIdx]);
                parentIdx ^= parentIdx >> 31;
            }

            // Mark the parent as visited.
            // Parent has already been visited, or one of its children is a leaf => proceed to the parent.

            nodeIdx = -1;
            if (parentIdx != -1)
            {
                float4 p1 = p.nodes[parentIdx].f4[1]; // (c0hiy, c0hiz, c0idx, c1idx)
                int c0 = __float_as_int(p1.z);
                int c1 = __float_as_int(p1.w);

                int round = warpSh.round;
                if (atomicExch(&p.nodeVisited[parentIdx], round) == round | c0 < 0 | c1 < 0)
                    nodeIdx = parentIdx;
            }
        }
    }
}

//------------------------------------------------------------------------
// Needs at least max(numPrims*2,1) threads

static __global__ __launch_bounds__(TRBVH_COLLAPSE_WARPS_PER_BLOCK * 32, TRBVH_COLLAPSE_BLOCKS_PER_SM)
void TrbvhCollapse(TrbvhCollapseParams p)
{
    INIT_SHUFFLE_EMULATION(TRBVH_COLLAPSE_WARPS_PER_BLOCK)
    int numPrims = (p.primRange) ? p.primRange->span() : p.maxPrims;
    Range nodeRange = *p.nodeRange;
    p.nodes += nodeRange.start;

    // Pick an edge in the tree.
    // Out of range => handle special cases and terminate.

    int edgeIdx = threadIdx.x + 32 * (threadIdx.y + TRBVH_COLLAPSE_WARPS_PER_BLOCK * (blockIdx.x + gridDim.x * blockIdx.y));
    int edgeDir = edgeIdx & 1; // left = 0, right = 1
    int parentIdx = edgeIdx >> 1;

    if (edgeIdx >= (numPrims - 1) * 2)
    {
        // Less than 2 primitives => special case to match the logic in TrbvhFit().

        if (edgeIdx == 0)
        {
            int remapVal = ~p.nodes[0].tmp.c0idx;
            if (p.listLenEnc == RLLE_COMPLEMENT_LAST)
                remapVal ^= -1;
            else if (p.listLenEnc == RLLE_PACK_IN_FIRST)
                remapVal |= numPrims << RLLEPACK_LEN_SHIFT;

            int remapIdx = atomicAdd(p.remapSize, numPrims);
            p.remap[remapIdx] = remapVal;

            p.nodes[0].out.c0idx = ~remapIdx;
            p.nodes[0].out.c1idx = ~remapIdx;
            p.nodes[0].out.c0num = numPrims;
            p.nodes[0].out.c1num = 0;
        }
        return;
    }

    float4 p1 = p.nodes[parentIdx].f4[1]; // (c0hiy, c0hiz, c0idx, c1idx)
    int childIdx = slct(__float_as_int(p1.z), __float_as_int(p1.w), -edgeDir); // (edgeDir <= 0) ? c0idx : c1idx

    // Check the ancestors of the child to see whether it is supposed to exist in the first place.

    int ancestorIdx = parentIdx;
    while (ancestorIdx != 0)
    {
        float2 costs = *(const float2*)&p.nodeCosts[ancestorIdx];
        float subtreeSize = costs.x;
        float subtreeCost = costs.y;

        // Current ancestor wants to be a leaf => the child is not supposed to exist.

        if (getLSB(subtreeCost) == 0)
        {
            p.nodes[parentIdx].out.c1num = BVHNODE_NOT_IN_USE;
            return;
        }

        // Too large to be a leaf => no need to consider any more ancestors.

        if (subtreeSize > p.maxLeafSize)
            break;

        // Advance towards to the root.

        ancestorIdx = LDG_OR_GLOBAL(&p.nodeParents[ancestorIdx]);
        ancestorIdx ^= ancestorIdx >> 31;
    }

    // Child is a leaf, or wants to be a leaf => collapse.

    int leafSize = BVHNODE_CHILD_IS_INTERNAL_NODE;
    if (childIdx < 0 || getLSB(p.nodeCosts[childIdx].subtreeCost) == 0)
    {
        // Traverse subtree and collect primitives.

        int prims[TRBVH_COLLAPSE_MAX_LEAF_SIZE];
        int arraySize = TRBVH_COLLAPSE_MAX_LEAF_SIZE;
        int stackBegin = arraySize; // prims[stackTop..arraySize-1] is used as a stack of internal nodes
        leafSize = 0;

        int nodeIdx = childIdx;
        while (nodeIdx >= 0 | stackBegin < arraySize)
        {
            if (nodeIdx < 0)
            {
                prims[leafSize++] = nodeIdx;
                nodeIdx = prims[stackBegin++];
            }

            float4 n1 = p.nodes[nodeIdx].f4[1]; // (c0hiy, c0hiz, c0idx, c1idx)
            int c0 = __float_as_int(n1.z);
            int c1 = __float_as_int(n1.w);
            p.nodes[nodeIdx].out.c1num = BVHNODE_NOT_IN_USE;
            nodeIdx = c0;
            prims[(c1 >= 0) ? --stackBegin : leafSize++] = c1;
        }

        prims[leafSize++] = nodeIdx;

        // Remove duplicates.

        for (int i = leafSize - 1; i > 0; i--)
        {
            int ti = prims[i];
            bool isDuplicate = false;
            for (int j = 0; j < i; j++)
                isDuplicate = (isDuplicate || ti == prims[j]);
            if (isDuplicate)
                prims[i] = prims[--leafSize];
        }

        // Allocate space for output.

        int remapIdx = 0;
        for (int bit = 0; (1 << bit) <= TRBVH_COLLAPSE_MAX_LEAF_SIZE; bit++)
            remapIdx += __popc(__ballot((leafSize >> bit) & 1) & getLaneMaskLt()) << bit;

        int outputBase = 0;
        int highestLane = findLeadingOne(__ballot(true));
        if (threadIdx.x == highestLane)
            outputBase = atomicAdd(p.remapSize, remapIdx + leafSize);

        remapIdx += __shfl_nosync(outputBase, highestLane);
        childIdx = ~remapIdx;

        // Output the list of primitives.

        for (int i = 0; i < leafSize; i++)
        {
            int primIdx = ~prims[i];
            if (p.listLenEnc == RLLE_COMPLEMENT_LAST && i == leafSize - 1)
                primIdx = ~primIdx;
            else if( p.listLenEnc == RLLE_PACK_IN_FIRST && i==0 )
                primIdx = primIdx | (leafSize << RLLEPACK_LEN_SHIFT);

            p.remap[remapIdx] = primIdx;
            remapIdx++;
        }
    }

    // Child is an internal node => express the index as absolute wrt. the entire node buffer.

    if (childIdx >= 0)
        childIdx += nodeRange.start;

    // Write the final child reference to the parent.

    *((int2*)&p.nodes[parentIdx].out.c0idx + edgeDir * 4) = make_int2(childIdx, leafSize);
}

//------------------------------------------------------------------------

bool prodlib::bvhtools::launchTrbvhRadixTree(dim3 gridDim, dim3 blockDim, lwdaStream_t stream, const TrbvhRadixTreeParams& p)
{
    if (lwdaFuncSetCacheConfig(TrbvhRadixTree, lwdaFuncCachePreferL1) != lwdaSuccess) return false;
    TrbvhRadixTree<<<gridDim, blockDim>>>(p);
    return true;
}

//------------------------------------------------------------------------

bool prodlib::bvhtools::launchTrbvhFit(dim3 gridDim, dim3 blockDim, lwdaStream_t stream, const TrbvhFitParams& p)
{
    if (lwdaFuncSetCacheConfig(TrbvhFit, lwdaFuncCachePreferL1) != lwdaSuccess) return false;
    TrbvhFit<<<gridDim, blockDim, 0, stream>>>(p);
    return true;
}

//------------------------------------------------------------------------

bool prodlib::bvhtools::launchTrbvhOpt(dim3 gridDim, dim3 blockDim, lwdaStream_t stream, const TrbvhOptParams& p, int treeletSize)
{
    void (*kernel)(TrbvhOptParams p);
    switch (treeletSize)
    {
    case 5:     kernel = TrbvhOpt<5, sizeof(g_restructureTreelet_schedule_5) / sizeof(int)>; break;
    case 6:     kernel = TrbvhOpt<6, sizeof(g_restructureTreelet_schedule_6) / sizeof(int)>; break;
    case 7:     kernel = TrbvhOpt<7, sizeof(g_restructureTreelet_schedule_7) / sizeof(int)>; break;
    case 8:     kernel = TrbvhOpt<8, sizeof(g_restructureTreelet_schedule_8) / sizeof(int)>; break;
    default:    return false;
    }

    if (lwdaFuncSetCacheConfig(kernel, lwdaFuncCachePreferShared) != lwdaSuccess) return false;
    kernel<<<gridDim, blockDim, 0, stream>>>(p);
    return true;
}

//------------------------------------------------------------------------

bool prodlib::bvhtools::launchTrbvhCollapse(dim3 gridDim, dim3 blockDim, lwdaStream_t stream, const TrbvhCollapseParams& p)
{
    if (lwdaFuncSetCacheConfig(TrbvhCollapse, lwdaFuncCachePreferL1) != lwdaSuccess) return false;
    TrbvhCollapse<<<gridDim, blockDim, 0, stream>>>(p);
    return true;
}

//------------------------------------------------------------------------
