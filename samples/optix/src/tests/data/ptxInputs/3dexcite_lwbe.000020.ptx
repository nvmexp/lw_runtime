//
// Generated by LWPU LWVM Compiler
//
// Compiler Build ID: CL-19805474
// Lwca compilation tools, release 7.5, V7.5.16
// Based on LLVM 3.4svn
//

.version 4.3
.target sm_20
.address_size 64

	// .globl	_Z9miss_implPFN3rtt7stellar19MLCBackgroundResultEPKvNS0_11MLCRaystackENS0_7ADReal2ENS0_17MLCCameraInstanceE6float4fjfE
.visible .func  (.param .align 16 .b8 func_retval0[64]) stlr_main
(
	.param .b64 stlr_main_param_0,
	.param .align 8 .b8 stlr_main_param_1[24],
	.param .align 8 .b8 stlr_main_param_2[24],
	.param .align 8 .b8 stlr_main_param_3[24],
	.param .align 16 .b8 stlr_main_param_4[16],
	.param .b32 stlr_main_param_5,
	.param .b32 stlr_main_param_6,
	.param .b32 stlr_main_param_7
)
;
.visible .func  (.param .align 16 .b8 func_retval0[64]) stlr_ambient_occlusion
(
	.param .b64 stlr_ambient_occlusion_param_0,
	.param .align 8 .b8 stlr_ambient_occlusion_param_1[24],
	.param .align 8 .b8 stlr_ambient_occlusion_param_2[24],
	.param .align 8 .b8 stlr_ambient_occlusion_param_3[24],
	.param .align 16 .b8 stlr_ambient_occlusion_param_4[16],
	.param .b32 stlr_ambient_occlusion_param_5,
	.param .b32 stlr_ambient_occlusion_param_6,
	.param .b32 stlr_ambient_occlusion_param_7
)
;
.global .align 8 .b8 launch_index[8];
.global .align 16 .b8 ray_data[80];
.global .align 4 .b8 ray[36];
.global .align 1 .b8 render_task_data[1];
.global .align 4 .u32 render_task_id;
.global .align 8 .u64 _ZN21rti_internal_register20reg_bitness_detectorE;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail0E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail1E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail2E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail3E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail4E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail5E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail6E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail7E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail8E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail9E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail0E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail1E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail2E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail3E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail4E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail5E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail6E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail7E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail8E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail9E;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_xE;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_yE;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_zE;
.global .align 8 .b8 _ZTVSt14error_category[72];
.global .align 8 .b8 _ZTVSt23_Generic_error_category[72];
.global .align 8 .b8 _ZTVSt24_Iostream_error_category[72];
.global .align 8 .b8 _ZTVSt22_System_error_category[72];
.global .align 4 .b8 _ZN21rti_internal_typeinfo12launch_indexE[8] = {82, 97, 121, 0, 8, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo8ray_dataE[8] = {82, 97, 121, 0, 80, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo3rayE[8] = {82, 97, 121, 0, 36, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo14render_task_idE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 1 .b8 _ZN21rti_internal_typename12launch_indexE[5] = {105, 110, 116, 50, 0};
.global .align 1 .b8 _ZN21rti_internal_typename8ray_dataE[8] = {82, 97, 121, 68, 97, 116, 97, 0};
.global .align 1 .b8 _ZN21rti_internal_typename3rayE[11] = {111, 112, 116, 105, 120, 58, 58, 82, 97, 121, 0};
.global .align 1 .b8 _ZN21rti_internal_typename14render_task_idE[4] = {105, 110, 116, 0};
.global .align 4 .u32 _ZN21rti_internal_typeenum12launch_indexE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum8ray_dataE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum3rayE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum14render_task_idE = 4919;
.global .align 1 .b8 _ZN21rti_internal_semantic12launch_indexE[14] = {114, 116, 76, 97, 117, 110, 99, 104, 73, 110, 100, 101, 120, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic8ray_dataE[10] = {114, 116, 80, 97, 121, 108, 111, 97, 100, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic3rayE[13] = {114, 116, 67, 117, 114, 114, 101, 110, 116, 82, 97, 121, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic14render_task_idE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation12launch_indexE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation8ray_dataE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation3rayE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation14render_task_idE[1];

.visible .func _Z9miss_implPFN3rtt7stellar19MLCBackgroundResultEPKvNS0_11MLCRaystackENS0_7ADReal2ENS0_17MLCCameraInstanceE6float4fjfE(
	.param .b64 _Z9miss_implPFN3rtt7stellar19MLCBackgroundResultEPKvNS0_11MLCRaystackENS0_7ADReal2ENS0_17MLCCameraInstanceE6float4fjfE_param_0
)
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<23>;
	.reg .f32 	%f<70>;
	.reg .b32 	%r<21>;
	.reg .b64 	%rd<25>;


	ld.param.u64 	%rd3, [_Z9miss_implPFN3rtt7stellar19MLCBackgroundResultEPKvNS0_11MLCRaystackENS0_7ADReal2ENS0_17MLCCameraInstanceE6float4fjfE_param_0];
	ld.global.s32 	%rd6, [render_task_id];
	mov.u64 	%rd10, render_task_data;
	cvta.global.u64 	%rd5, %rd10;
	mov.u32 	%r1, 1;
	mov.u32 	%r2, 272;
	mov.u64 	%rd9, 0;
	// inline asm
	call (%rd4), _rt_buffer_get_64, (%rd5, %r1, %r2, %rd6, %rd9, %rd9, %rd9);
	// inline asm
	ld.u8 	%rs1, [%rd4+80];
	and.b16  	%rs2, %rs1, 1;
	setp.eq.b16	%p1, %rs2, 1;
	mov.f32 	%f69, 0f7F800000;
	mov.f32 	%f68, 0f3F800000;
	mov.f32 	%f67, %f68;
	mov.f32 	%f66, 0f00000000;
	mov.f32 	%f65, %f66;
	@!%p1 bra 	BB0_2;
	bra.uni 	BB0_1;

BB0_1:
	ld.u32 	%r7, [%rd4];
	ld.global.v2.u32 	{%r8, %r9}, [launch_index];
	sub.s32 	%r11, %r8, %r7;
	sub.s32 	%r13, %r9, %r7;
	cvt.rn.f32.s32	%f28, %r11;
	cvt.rn.f32.s32	%f29, %r13;
	ld.u32 	%r3, [%rd4+64];
	mov.u32 	%r6, 2;
	mov.f32 	%f31, 0f00000000;
	// inline asm
	call (%f65, %f66, %f67, %f19), _rt_texture_get_f_id, (%r3, %r6, %f28, %f29, %f31, %f31);
	// inline asm
	mov.f32 	%f32, 0f3F800000;
	sub.f32 	%f68, %f32, %f19;
	ld.u32 	%r5, [%rd4+68];
	// inline asm
	call (%f69, %f25, %f26, %f27), _rt_texture_get_f_id, (%r5, %r6, %f28, %f29, %f31, %f31);
	// inline asm

BB0_2:
	ld.u64 	%rd11, [%rd4+56];
	ld.u64 	%rd12, [%rd4+48];
	ld.v2.u32 	{%r14, %r15}, [%rd4+40];
	ld.v2.f32 	{%f33, %f34}, [%rd4+72];
	mov.b32 	 %r18, %f34;
	ld.global.u32 	%r19, [ray+24];
	mul.wide.u32 	%rd13, %r19, 8;
	add.s64 	%rd14, %rd4, %rd13;
	ld.u64 	%rd15, [%rd14+96];
	ld.global.u64 	%rd16, [ray_data+16];
	ld.u64 	%rd17, [%rd16+16];
	ld.v2.u64 	{%rd18, %rd19}, [%rd16];
	ld.global.v2.f32 	{%f37, %f38}, [ray_data+40];
	ld.global.v2.f32 	{%f41, %f42}, [ray_data+48];
	ld.global.v2.f32 	{%f45, %f46}, [ray_data+56];
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd15;
	.param .align 8 .b8 param1[24];
	st.param.b64	[param1+0], %rd18;
	st.param.b64	[param1+8], %rd19;
	st.param.b64	[param1+16], %rd17;
	.param .align 8 .b8 param2[24];
	st.param.f32	[param2+0], %f37;
	st.param.f32	[param2+4], %f38;
	st.param.f32	[param2+8], %f41;
	st.param.f32	[param2+12], %f42;
	st.param.f32	[param2+16], %f45;
	st.param.f32	[param2+20], %f46;
	.param .align 8 .b8 param3[24];
	st.param.b32	[param3+0], %r14;
	st.param.b32	[param3+4], %r15;
	st.param.b64	[param3+8], %rd12;
	st.param.b64	[param3+16], %rd11;
	.param .align 16 .b8 param4[16];
	st.param.f32	[param4+0], %f65;
	st.param.f32	[param4+4], %f66;
	st.param.f32	[param4+8], %f67;
	st.param.f32	[param4+12], %f68;
	.param .b32 param5;
	st.param.f32	[param5+0], %f69;
	.param .b32 param6;
	st.param.b32	[param6+0], %r18;
	.param .b32 param7;
	st.param.f32	[param7+0], %f33;
	.param .align 16 .b8 retval0[64];
	prototype_0 : .callprototype (.param .align 16 .b8 _[64]) _ (.param .b64 _, .param .align 8 .b8 _[24], .param .align 8 .b8 _[24], .param .align 8 .b8 _[24], .param .align 16 .b8 _[16], .param .b32 _, .param .b32 _, .param .b32 _);
	call (retval0), 
	%rd3, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4, 
	param5, 
	param6, 
	param7
	)
	, prototype_0;
	ld.param.b64	%rd22, [retval0+0];
	ld.param.b64	%rd23, [retval0+8];
	ld.param.b64	%rd24, [retval0+16];
	ld.param.b8	%rs3, [retval0+24];
	ld.param.b8	%rs4, [retval0+25];
	ld.param.b8	%rs5, [retval0+26];
	ld.param.b8	%rs6, [retval0+27];
	ld.param.b8	%rs7, [retval0+28];
	ld.param.b8	%rs8, [retval0+29];
	ld.param.b8	%rs9, [retval0+30];
	ld.param.b8	%rs10, [retval0+31];
	ld.param.f32	%f49, [retval0+32];
	ld.param.f32	%f50, [retval0+36];
	ld.param.f32	%f51, [retval0+40];
	ld.param.b32	%r20, [retval0+44];
	ld.param.f32	%f52, [retval0+48];
	ld.param.b8	%rs11, [retval0+52];
	ld.param.b8	%rs12, [retval0+53];
	ld.param.b8	%rs13, [retval0+54];
	ld.param.b8	%rs14, [retval0+55];
	ld.param.b8	%rs15, [retval0+56];
	ld.param.b8	%rs16, [retval0+57];
	ld.param.b8	%rs17, [retval0+58];
	ld.param.b8	%rs18, [retval0+59];
	ld.param.b8	%rs19, [retval0+60];
	ld.param.b8	%rs20, [retval0+61];
	ld.param.b8	%rs21, [retval0+62];
	ld.param.b8	%rs22, [retval0+63];
	
	//{
	}// Callseq End 0
	ld.global.v4.f32 	{%f53, %f54, %f55, %f56}, [ray_data];
	add.f32 	%f58, %f52, %f56;
	add.f32 	%f60, %f51, %f55;
	add.f32 	%f62, %f50, %f54;
	add.f32 	%f64, %f53, %f49;
	st.global.v4.f32 	[ray_data], {%f64, %f62, %f60, %f58};
	st.global.f32 	[ray_data+72], %f69;
	ret;
}

	// .globl	_ZNK3rtt7stellar14OptixBufferPtrIPKvE9asPointerEv
.visible .func  (.param .b64 func_retval0) _ZNK3rtt7stellar14OptixBufferPtrIPKvE9asPointerEv(
	.param .b64 _ZNK3rtt7stellar14OptixBufferPtrIPKvE9asPointerEv_param_0
)
{
	.reg .b64 	%rd<3>;


	ld.param.u64 	%rd1, [_ZNK3rtt7stellar14OptixBufferPtrIPKvE9asPointerEv_param_0];
	ld.u64 	%rd2, [%rd1];
	st.param.b64	[func_retval0+0], %rd2;
	ret;
}

	// .globl	_Z4missv
.visible .entry _Z4missv(

)
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<23>;
	.reg .f32 	%f<70>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<24>;


	ldu.global.u32 	%r3, [render_task_id];
	cvt.s64.s32	%rd5, %r3;
	mov.u64 	%rd9, render_task_data;
	cvta.global.u64 	%rd4, %rd9;
	mov.u32 	%r1, 1;
	mov.u32 	%r2, 272;
	mov.u64 	%rd8, 0;
	// inline asm
	call (%rd3), _rt_buffer_get_64, (%rd4, %r1, %r2, %rd5, %rd8, %rd8, %rd8);
	// inline asm
	ld.u8 	%rs1, [%rd3+80];
	and.b16  	%rs2, %rs1, 1;
	setp.eq.b16	%p1, %rs2, 1;
	mov.f32 	%f69, 0f7F800000;
	mov.f32 	%f68, 0f3F800000;
	mov.f32 	%f67, %f68;
	mov.f32 	%f66, 0f00000000;
	mov.f32 	%f65, %f66;
	@!%p1 bra 	BB2_2;
	bra.uni 	BB2_1;

BB2_1:
	ld.u32 	%r8, [%rd3];
	ld.global.v2.u32 	{%r9, %r10}, [launch_index];
	sub.s32 	%r12, %r9, %r8;
	sub.s32 	%r14, %r10, %r8;
	cvt.rn.f32.s32	%f28, %r12;
	cvt.rn.f32.s32	%f29, %r14;
	ld.u32 	%r4, [%rd3+64];
	mov.u32 	%r7, 2;
	mov.f32 	%f31, 0f00000000;
	// inline asm
	call (%f65, %f66, %f67, %f19), _rt_texture_get_f_id, (%r4, %r7, %f28, %f29, %f31, %f31);
	// inline asm
	mov.f32 	%f32, 0f3F800000;
	sub.f32 	%f68, %f32, %f19;
	ld.u32 	%r6, [%rd3+68];
	// inline asm
	call (%f69, %f25, %f26, %f27), _rt_texture_get_f_id, (%r6, %r7, %f28, %f29, %f31, %f31);
	// inline asm

BB2_2:
	ld.u64 	%rd10, [%rd3+56];
	ld.u64 	%rd11, [%rd3+48];
	ld.v2.u32 	{%r15, %r16}, [%rd3+40];
	ld.v2.f32 	{%f33, %f34}, [%rd3+72];
	mov.b32 	 %r19, %f34;
	ld.global.u32 	%r20, [ray+24];
	mul.wide.u32 	%rd12, %r20, 8;
	add.s64 	%rd13, %rd3, %rd12;
	ld.u64 	%rd14, [%rd13+96];
	ld.global.u64 	%rd15, [ray_data+16];
	ld.u64 	%rd16, [%rd15+16];
	ld.v2.u64 	{%rd17, %rd18}, [%rd15];
	ld.global.v2.f32 	{%f37, %f38}, [ray_data+40];
	ld.global.v2.f32 	{%f41, %f42}, [ray_data+48];
	ld.global.v2.f32 	{%f45, %f46}, [ray_data+56];
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd14;
	.param .align 8 .b8 param1[24];
	st.param.b64	[param1+0], %rd17;
	st.param.b64	[param1+8], %rd18;
	st.param.b64	[param1+16], %rd16;
	.param .align 8 .b8 param2[24];
	st.param.f32	[param2+0], %f37;
	st.param.f32	[param2+4], %f38;
	st.param.f32	[param2+8], %f41;
	st.param.f32	[param2+12], %f42;
	st.param.f32	[param2+16], %f45;
	st.param.f32	[param2+20], %f46;
	.param .align 8 .b8 param3[24];
	st.param.b32	[param3+0], %r15;
	st.param.b32	[param3+4], %r16;
	st.param.b64	[param3+8], %rd11;
	st.param.b64	[param3+16], %rd10;
	.param .align 16 .b8 param4[16];
	st.param.f32	[param4+0], %f65;
	st.param.f32	[param4+4], %f66;
	st.param.f32	[param4+8], %f67;
	st.param.f32	[param4+12], %f68;
	.param .b32 param5;
	st.param.f32	[param5+0], %f69;
	.param .b32 param6;
	st.param.b32	[param6+0], %r19;
	.param .b32 param7;
	st.param.f32	[param7+0], %f33;
	.param .align 16 .b8 retval0[64];
	call.uni (retval0), 
	stlr_main, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4, 
	param5, 
	param6, 
	param7
	);
	ld.param.b64	%rd21, [retval0+0];
	ld.param.b64	%rd22, [retval0+8];
	ld.param.b64	%rd23, [retval0+16];
	ld.param.b8	%rs3, [retval0+24];
	ld.param.b8	%rs4, [retval0+25];
	ld.param.b8	%rs5, [retval0+26];
	ld.param.b8	%rs6, [retval0+27];
	ld.param.b8	%rs7, [retval0+28];
	ld.param.b8	%rs8, [retval0+29];
	ld.param.b8	%rs9, [retval0+30];
	ld.param.b8	%rs10, [retval0+31];
	ld.param.f32	%f49, [retval0+32];
	ld.param.f32	%f50, [retval0+36];
	ld.param.f32	%f51, [retval0+40];
	ld.param.b32	%r21, [retval0+44];
	ld.param.f32	%f52, [retval0+48];
	ld.param.b8	%rs11, [retval0+52];
	ld.param.b8	%rs12, [retval0+53];
	ld.param.b8	%rs13, [retval0+54];
	ld.param.b8	%rs14, [retval0+55];
	ld.param.b8	%rs15, [retval0+56];
	ld.param.b8	%rs16, [retval0+57];
	ld.param.b8	%rs17, [retval0+58];
	ld.param.b8	%rs18, [retval0+59];
	ld.param.b8	%rs19, [retval0+60];
	ld.param.b8	%rs20, [retval0+61];
	ld.param.b8	%rs21, [retval0+62];
	ld.param.b8	%rs22, [retval0+63];
	
	//{
	}// Callseq End 1
	ld.global.v4.f32 	{%f53, %f54, %f55, %f56}, [ray_data];
	add.f32 	%f58, %f52, %f56;
	add.f32 	%f60, %f51, %f55;
	add.f32 	%f62, %f50, %f54;
	add.f32 	%f64, %f53, %f49;
	st.global.v4.f32 	[ray_data], {%f64, %f62, %f60, %f58};
	st.global.f32 	[ray_data+72], %f69;
	ret;
}

	// .globl	_Z7miss_aov
.visible .entry _Z7miss_aov(

)
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<23>;
	.reg .f32 	%f<70>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<24>;


	ldu.global.u32 	%r3, [render_task_id];
	cvt.s64.s32	%rd5, %r3;
	mov.u64 	%rd9, render_task_data;
	cvta.global.u64 	%rd4, %rd9;
	mov.u32 	%r1, 1;
	mov.u32 	%r2, 272;
	mov.u64 	%rd8, 0;
	// inline asm
	call (%rd3), _rt_buffer_get_64, (%rd4, %r1, %r2, %rd5, %rd8, %rd8, %rd8);
	// inline asm
	ld.u8 	%rs1, [%rd3+80];
	and.b16  	%rs2, %rs1, 1;
	setp.eq.b16	%p1, %rs2, 1;
	mov.f32 	%f69, 0f7F800000;
	mov.f32 	%f68, 0f3F800000;
	mov.f32 	%f67, %f68;
	mov.f32 	%f66, 0f00000000;
	mov.f32 	%f65, %f66;
	@!%p1 bra 	BB3_2;
	bra.uni 	BB3_1;

BB3_1:
	ld.u32 	%r8, [%rd3];
	ld.global.v2.u32 	{%r9, %r10}, [launch_index];
	sub.s32 	%r12, %r9, %r8;
	sub.s32 	%r14, %r10, %r8;
	cvt.rn.f32.s32	%f28, %r12;
	cvt.rn.f32.s32	%f29, %r14;
	ld.u32 	%r4, [%rd3+64];
	mov.u32 	%r7, 2;
	mov.f32 	%f31, 0f00000000;
	// inline asm
	call (%f65, %f66, %f67, %f19), _rt_texture_get_f_id, (%r4, %r7, %f28, %f29, %f31, %f31);
	// inline asm
	mov.f32 	%f32, 0f3F800000;
	sub.f32 	%f68, %f32, %f19;
	ld.u32 	%r6, [%rd3+68];
	// inline asm
	call (%f69, %f25, %f26, %f27), _rt_texture_get_f_id, (%r6, %r7, %f28, %f29, %f31, %f31);
	// inline asm

BB3_2:
	ld.u64 	%rd10, [%rd3+56];
	ld.u64 	%rd11, [%rd3+48];
	ld.v2.u32 	{%r15, %r16}, [%rd3+40];
	ld.v2.f32 	{%f33, %f34}, [%rd3+72];
	mov.b32 	 %r19, %f34;
	ld.global.u32 	%r20, [ray+24];
	mul.wide.u32 	%rd12, %r20, 8;
	add.s64 	%rd13, %rd3, %rd12;
	ld.u64 	%rd14, [%rd13+96];
	ld.global.u64 	%rd15, [ray_data+16];
	ld.u64 	%rd16, [%rd15+16];
	ld.v2.u64 	{%rd17, %rd18}, [%rd15];
	ld.global.v2.f32 	{%f37, %f38}, [ray_data+40];
	ld.global.v2.f32 	{%f41, %f42}, [ray_data+48];
	ld.global.v2.f32 	{%f45, %f46}, [ray_data+56];
	// Callseq Start 2
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd14;
	.param .align 8 .b8 param1[24];
	st.param.b64	[param1+0], %rd17;
	st.param.b64	[param1+8], %rd18;
	st.param.b64	[param1+16], %rd16;
	.param .align 8 .b8 param2[24];
	st.param.f32	[param2+0], %f37;
	st.param.f32	[param2+4], %f38;
	st.param.f32	[param2+8], %f41;
	st.param.f32	[param2+12], %f42;
	st.param.f32	[param2+16], %f45;
	st.param.f32	[param2+20], %f46;
	.param .align 8 .b8 param3[24];
	st.param.b32	[param3+0], %r15;
	st.param.b32	[param3+4], %r16;
	st.param.b64	[param3+8], %rd11;
	st.param.b64	[param3+16], %rd10;
	.param .align 16 .b8 param4[16];
	st.param.f32	[param4+0], %f65;
	st.param.f32	[param4+4], %f66;
	st.param.f32	[param4+8], %f67;
	st.param.f32	[param4+12], %f68;
	.param .b32 param5;
	st.param.f32	[param5+0], %f69;
	.param .b32 param6;
	st.param.b32	[param6+0], %r19;
	.param .b32 param7;
	st.param.f32	[param7+0], %f33;
	.param .align 16 .b8 retval0[64];
	call.uni (retval0), 
	stlr_ambient_occlusion, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4, 
	param5, 
	param6, 
	param7
	);
	ld.param.b64	%rd21, [retval0+0];
	ld.param.b64	%rd22, [retval0+8];
	ld.param.b64	%rd23, [retval0+16];
	ld.param.b8	%rs3, [retval0+24];
	ld.param.b8	%rs4, [retval0+25];
	ld.param.b8	%rs5, [retval0+26];
	ld.param.b8	%rs6, [retval0+27];
	ld.param.b8	%rs7, [retval0+28];
	ld.param.b8	%rs8, [retval0+29];
	ld.param.b8	%rs9, [retval0+30];
	ld.param.b8	%rs10, [retval0+31];
	ld.param.f32	%f49, [retval0+32];
	ld.param.f32	%f50, [retval0+36];
	ld.param.f32	%f51, [retval0+40];
	ld.param.b32	%r21, [retval0+44];
	ld.param.f32	%f52, [retval0+48];
	ld.param.b8	%rs11, [retval0+52];
	ld.param.b8	%rs12, [retval0+53];
	ld.param.b8	%rs13, [retval0+54];
	ld.param.b8	%rs14, [retval0+55];
	ld.param.b8	%rs15, [retval0+56];
	ld.param.b8	%rs16, [retval0+57];
	ld.param.b8	%rs17, [retval0+58];
	ld.param.b8	%rs18, [retval0+59];
	ld.param.b8	%rs19, [retval0+60];
	ld.param.b8	%rs20, [retval0+61];
	ld.param.b8	%rs21, [retval0+62];
	ld.param.b8	%rs22, [retval0+63];
	
	//{
	}// Callseq End 2
	ld.global.v4.f32 	{%f53, %f54, %f55, %f56}, [ray_data];
	add.f32 	%f58, %f52, %f56;
	add.f32 	%f60, %f51, %f55;
	add.f32 	%f62, %f50, %f54;
	add.f32 	%f64, %f53, %f49;
	st.global.v4.f32 	[ray_data], {%f64, %f62, %f60, %f58};
	st.global.f32 	[ray_data+72], %f69;
	ret;
}


//
// Generated by LLVM LWPTX Back-End
//





	// .globl	stlr_create_for_stellarcheck

.visible .func  (.param .b32 func_retval0) stlr_create_for_stellarcheck(
	.param .b64 stlr_create_for_stellarcheck_param_0,
	.param .b32 stlr_create_for_stellarcheck_param_1
)
{
	.reg .s32 	%r<2>;

	ld.param.u32 	%r1, [stlr_create_for_stellarcheck_param_1];
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .globl	stlr_light_closures_type
.visible .func  (.param .align 8 .b8 func_retval0[80]) stlr_light_closures_type(
	.param .b64 stlr_light_closures_type_param_0,
	.param .align 8 .b8 stlr_light_closures_type_param_1[80]
)
{
	.reg .s64 	%rd<11>;

	ld.param.u64 	%rd1, [stlr_light_closures_type_param_1];
	st.param.b64	[func_retval0+0], %rd1;
	ld.param.u64 	%rd2, [stlr_light_closures_type_param_1+8];
	st.param.b64	[func_retval0+8], %rd2;
	ld.param.u64 	%rd3, [stlr_light_closures_type_param_1+16];
	st.param.b64	[func_retval0+16], %rd3;
	ld.param.u64 	%rd4, [stlr_light_closures_type_param_1+24];
	st.param.b64	[func_retval0+24], %rd4;
	ld.param.u64 	%rd5, [stlr_light_closures_type_param_1+32];
	st.param.b64	[func_retval0+32], %rd5;
	ld.param.u64 	%rd6, [stlr_light_closures_type_param_1+40];
	st.param.b64	[func_retval0+40], %rd6;
	ld.param.u64 	%rd7, [stlr_light_closures_type_param_1+48];
	st.param.b64	[func_retval0+48], %rd7;
	ld.param.u64 	%rd8, [stlr_light_closures_type_param_1+56];
	st.param.b64	[func_retval0+56], %rd8;
	ld.param.u64 	%rd9, [stlr_light_closures_type_param_1+64];
	st.param.b64	[func_retval0+64], %rd9;
	ld.param.u64 	%rd10, [stlr_light_closures_type_param_1+72];
	st.param.b64	[func_retval0+72], %rd10;
	ret;
}

	// .globl	stlr_main
.visible .func  (.param .align 16 .b8 func_retval0[64]) stlr_main(
	.param .b64 stlr_main_param_0,
	.param .align 8 .b8 stlr_main_param_1[24],
	.param .align 8 .b8 stlr_main_param_2[24],
	.param .align 8 .b8 stlr_main_param_3[24],
	.param .align 16 .b8 stlr_main_param_4[16],
	.param .b32 stlr_main_param_5,
	.param .b32 stlr_main_param_6,
	.param .b32 stlr_main_param_7
)
{
	.reg .pred 	%p<76>;
	.reg .f32 	%f<324>;
	.reg .s32 	%r<478>;
	.reg .s64 	%rd<491>;

	ld.param.u64 	%rd39, [stlr_main_param_3+16];
	ld.param.u64 	%rd57, [stlr_main_param_3+8];
	ld.param.u32 	%r78, [stlr_main_param_3+4];
	ld.param.u32 	%r77, [stlr_main_param_3];
	ld.param.f32 	%f303, [stlr_main_param_2+20];
	ld.param.f32 	%f302, [stlr_main_param_2+16];
	ld.param.f32 	%f301, [stlr_main_param_2+12];
	ld.param.f32 	%f300, [stlr_main_param_2+8];
	ld.param.f32 	%f299, [stlr_main_param_2+4];
	ld.param.f32 	%f298, [stlr_main_param_2];
	ld.param.u64 	%rd37, [stlr_main_param_1+16];
	ld.param.u64 	%rd36, [stlr_main_param_1+8];
	ld.param.u64 	%rd35, [stlr_main_param_1];
	ld.param.u64 	%rd34, [stlr_main_param_0];
	ld.u32 	%r87, [%rd35];
	add.s32 	%r88, %r87, -1;
	mul.wide.s32 	%rd52, %r88, 112;
	add.s64 	%rd53, %rd36, %rd52;
	ld.f32 	%f18, [%rd53+88];
	ld.f32 	%f17, [%rd53+84];
	ld.f32 	%f16, [%rd53+80];
	ld.f32 	%f15, [%rd53+72];
	ld.f32 	%f14, [%rd53+68];
	ld.f32 	%f13, [%rd53+64];
	ld.f32 	%f12, [%rd53+56];
	ld.f32 	%f11, [%rd53+52];
	ld.f32 	%f10, [%rd53+48];
	ld.f32 	%f9, [%rd53+40];
	ld.f32 	%f8, [%rd53+36];
	ld.f32 	%f7, [%rd53+32];
	ld.f32 	%f6, [%rd53+24];
	ld.f32 	%f5, [%rd53+20];
	ld.f32 	%f4, [%rd53+16];
	ld.f32 	%f3, [%rd53+8];
	ld.f32 	%f2, [%rd53+4];
	ld.f32 	%f1, [%rd53];
	add.s64 	%rd54, %rd37, %rd52;
	ld.u32 	%r6, [%rd54+108];
	ld.f32 	%f36, [%rd54+104];
	ld.f32 	%f35, [%rd54+100];
	ld.u32 	%r4, [%rd54+40];
	ld.f32 	%f323, [%rd54+32];
	ld.f32 	%f39, [%rd54+24];
	ld.f32 	%f38, [%rd54+20];
	ld.f32 	%f37, [%rd54+16];
	ld.u32 	%r2, [%rd54+4];
	ld.u32 	%r1, [%rd54];
	ld.u32 	%r8, [%rd54+8];
	st.u32 	[%rd35], %r88;
	// inline asm
	mov.b64 {_,%r79}, %rd34;
	// inline asm
	mov.u32 	%r86, 1;
	mov.u64 	%rd51, 0;
	// inline asm
	call (%rd41), _rt_buffer_get_id_64, (%r79, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd46, [%rd41+568];
	mul.wide.s32 	%rd55, %r78, 112;
	// inline asm
	mov.b64 {_,%r83}, %rd46;
	// inline asm
	// inline asm
	call (%rd47), _rt_buffer_get_id_64, (%r83, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd56, %rd55, %rd47;
	ld.u32 	%r7, [%rd56+512];
	bfe.s32 	%r9, %r8, 2, 1;
	shr.u32 	%r89, %r8, 3;
	or.b32  	%r90, %r9, %r89;
	and.b32  	%r91, %r90, %r7;
	and.b32  	%r92, %r91, 1;
	setp.eq.b32	%p1, %r92, 1;
	mov.f32 	%f306, 0f00000000;
	mov.f32 	%f307, %f306;
	mov.f32 	%f308, %f306;
	mov.f32 	%f309, %f306;
	@!%p1 bra 	LBB2_17;
	bra.uni 	LBB2_1;
LBB2_1:
	and.b32  	%r93, %r9, 1;
	setp.eq.b32	%p2, %r93, 1;
	@%p2 bra 	LBB2_3;
	// inline asm
	mov.b64 {_,%r95}, %rd57;
	// inline asm
	// inline asm
	call (%rd58), _rt_callable_program_from_id_64, (%r95);
	// inline asm
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd39;
	.param .b32 param1;
	st.param.b32	[param1+0], %r77;
	.param .align 16 .b8 param2[48];
	st.param.f32	[param2+0], %f1;
	st.param.f32	[param2+4], %f2;
	st.param.f32	[param2+8], %f3;
	st.param.f32	[param2+16], %f4;
	st.param.f32	[param2+20], %f5;
	st.param.f32	[param2+24], %f6;
	st.param.f32	[param2+32], %f7;
	st.param.f32	[param2+36], %f8;
	st.param.f32	[param2+40], %f9;
	.param .align 16 .b8 param3[48];
	st.param.f32	[param3+0], %f10;
	st.param.f32	[param3+4], %f11;
	st.param.f32	[param3+8], %f12;
	st.param.f32	[param3+16], %f13;
	st.param.f32	[param3+20], %f14;
	st.param.f32	[param3+24], %f15;
	st.param.f32	[param3+32], %f16;
	st.param.f32	[param3+36], %f17;
	st.param.f32	[param3+40], %f18;
	.param .align 8 .b8 retval0[32];
	prototype_0 : .callprototype (.param .align 8 .b8 _[32]) _ (.param .b64 _, .param .b32 _, .param .align 16 .b8 _[48], .param .align 16 .b8 _[48]);
	call (retval0), 
	%rd58, 
	(
	param0, 
	param1, 
	param2, 
	param3
	)
	, prototype_0;
	ld.param.f32	%f298, [retval0+0];
	ld.param.f32	%f299, [retval0+4];
	ld.param.f32	%f300, [retval0+8];
	ld.param.f32	%f301, [retval0+12];
	ld.param.f32	%f302, [retval0+16];
	ld.param.f32	%f303, [retval0+20];
	ld.param.b32	%r96, [retval0+24];
	
	//{
	}// Callseq End 0
LBB2_3:
	shr.u32 	%r97, %r1, 11;
	add.s32 	%r98, %r97, 1;
	shr.u32 	%r99, %r1, 15;
	not.b32 	%r100, %r99;
	and.b32  	%r101, %r100, %r98;
	and.b32  	%r102, %r101, 1;
	setp.eq.b32	%p3, %r102, 1;
	mov.f32 	%f306, 0f00000000;
	mov.f32 	%f307, %f306;
	mov.f32 	%f308, %f306;
	mov.f32 	%f309, %f306;
	@!%p3 bra 	LBB2_17;
	bra.uni 	LBB2_4;
LBB2_4:
	abs.s32 	%r111, %r2;
	// inline asm
	mov.b64 {_,%r103}, %rd34;
	// inline asm
	// inline asm
	call (%rd60), _rt_buffer_get_id_64, (%r103, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd65, [%rd60+520];
	// inline asm
	mov.b64 {_,%r107}, %rd65;
	// inline asm
	// inline asm
	call (%rd66), _rt_buffer_get_id_64, (%r107, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u32 	%r112, [%rd66+508];
	add.s32 	%r460, %r112, -1;
	mul.wide.s32 	%rd71, %r111, 8;
	add.s64 	%rd72, %rd66, %rd71;
	ld.u32 	%r13, [%rd72+512];
	ld.u32 	%r14, [%rd72+516];
	setp.ge.s32	%p4, %r13, %r14;
	@%p4 bra 	LBB2_74;
	// inline asm
	mov.b64 {_,%r114}, %rd34;
	// inline asm
	// inline asm
	call (%rd74), _rt_buffer_get_id_64, (%r114, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd79, [%rd74+528];
	// inline asm
	mov.b64 {_,%r118}, %rd79;
	// inline asm
	// inline asm
	call (%rd80), _rt_buffer_get_id_64, (%r118, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	sub.s32 	%r458, %r14, %r13;
	mul.wide.s32 	%rd85, %r13, 8;
	or.b64  	%rd486, %rd85, 4;
	add.s64 	%rd5, %rd80, 512;
LBB2_6:
	add.s64 	%rd86, %rd486, %rd5;
	ld.u32 	%r121, [%rd86+-4];
	and.b32  	%r122, %r121, 1025;
	setp.ne.s32	%p5, %r122, 1025;
	@%p5 bra 	LBB2_8;
	add.s64 	%rd87, %rd5, %rd486;
	ld.u32 	%r460, [%rd87];
LBB2_8:
	add.s32 	%r458, %r458, -1;
	add.s64 	%rd486, %rd486, 8;
	setp.ne.s32	%p6, %r458, 0;
	@%p6 bra 	LBB2_6;
	bra.uni 	LBB2_9;
LBB2_74:
LBB2_9:
	shr.u32 	%r131, %r460, 31;
	// inline asm
	mov.b64 {_,%r123}, %rd34;
	// inline asm
	// inline asm
	call (%rd89), _rt_buffer_get_id_64, (%r123, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd94, [%rd89+536];
	// inline asm
	mov.b64 {_,%r127}, %rd94;
	// inline asm
	// inline asm
	call (%rd95), _rt_buffer_get_id_64, (%r127, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u32 	%r132, [%rd95+512];
	and.b32  	%r133, %r132, 1;
	setp.eq.s32	%p7, %r133, %r131;
	and.b32  	%r134, %r7, 1;
	setp.eq.b32	%p8, %r134, 1;
	not.pred 	%p9, %p8;
	or.pred  	%p10, %p9, %p7;
	@%p10 bra 	LBB2_10;
	bra.uni 	LBB2_11;
LBB2_10:
	mov.f32 	%f306, 0f00000000;
	mov.f32 	%f307, %f306;
	mov.f32 	%f308, %f306;
	mov.f32 	%f309, %f306;
	bra.uni 	LBB2_17;
LBB2_11:
	cvt.s64.s32	%rd1, %r78;
	// inline asm
	mov.b64 {_,%r135}, %rd34;
	// inline asm
	// inline asm
	call (%rd101), _rt_buffer_get_id_64, (%r135, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd106, [%rd101+568];
	mul.lo.s64 	%rd137, %rd1, 112;
	// inline asm
	mov.b64 {_,%r139}, %rd106;
	// inline asm
	// inline asm
	call (%rd107), _rt_buffer_get_id_64, (%r139, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd138, %rd107, 512;
	add.s64 	%rd139, %rd137, %rd138;
	ld.v2.f32 	{%f170, %f171}, [%rd139+88];
	ld.v2.f32 	{%f172, %f173}, [%rd139+96];
	sub.ftz.f32 	%f174, %f172, %f170;
	sub.ftz.f32 	%f175, %f173, %f171;
	mul.ftz.f32 	%f176, %f301, %f175;
	mul.ftz.f32 	%f177, %f300, %f174;
	mul.ftz.f32 	%f178, %f303, %f175;
	mul.ftz.f32 	%f179, %f302, %f174;
	fma.rn.ftz.f32 	%f165, %f298, %f174, %f170;
	fma.rn.ftz.f32 	%f166, %f299, %f175, %f171;
	add.s64 	%rd140, %rd137, 16;
	add.s64 	%rd141, %rd138, %rd140;
	ld.f32 	%f58, [%rd141+32];
	ld.f32 	%f59, [%rd141+36];
	ld.f32 	%f60, [%rd141+40];
	ld.f32 	%f61, [%rd141+48];
	ld.u32 	%r163, [%rd141];
	ld.u64 	%rd118, [%rd141+8];
	ld.u64 	%rd112, [%rd101+512];
	mul.wide.s32 	%rd142, %r163, 32;
	// inline asm
	mov.b64 {_,%r143}, %rd112;
	// inline asm
	// inline asm
	call (%rd113), _rt_buffer_get_id_64, (%r143, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd143, %rd142, %rd113;
	ld.v2.u32 	{%r22, %r23}, [%rd143+528];
	cvt.rn.f32.s32	%f180, %r23;
	cvt.rn.f32.s32	%f181, %r22;
	mul.ftz.f32 	%f182, %f177, %f181;
	mul.ftz.f32 	%f183, %f176, %f180;
	mul.ftz.f32 	%f184, %f183, %f183;
	fma.rn.ftz.f32 	%f185, %f182, %f182, %f184;
	sqrt.approx.ftz.f32 	%f186, %f185;
	mul.ftz.f32 	%f187, %f179, %f181;
	mul.ftz.f32 	%f188, %f178, %f180;
	mul.ftz.f32 	%f189, %f188, %f188;
	fma.rn.ftz.f32 	%f190, %f187, %f187, %f189;
	sqrt.approx.ftz.f32 	%f191, %f190;
	max.ftz.f32 	%f192, %f186, %f191;
	mov.f32 	%f193, 0f3F800000;
	max.ftz.f32 	%f194, %f192, %f193;
	mov.f32 	%f195, 0f47000000;
	min.ftz.f32 	%f196, %f194, %f195;
	lg2.approx.ftz.f32 	%f168, %f196;
	// inline asm
	mov.b64 {%r147,_}, %rd118;
	// inline asm
	mov.u32 	%r149, 2;
	mov.f32 	%f305, 0f00000000;
	mov.u32 	%r150, 0;
	// inline asm
	call (%f161,%f162,%f163,%f164), _rt_texture_get_level_id, (%r147, %r149, %f165, %f166, %f305, %r150, %f168);
	// inline asm
	// inline asm
	mov.b64 {_,%r151}, %rd34;
	// inline asm
	// inline asm
	call (%rd120), _rt_buffer_get_id_64, (%r151, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd125, [%rd120+512];
	// inline asm
	mov.b64 {_,%r155}, %rd125;
	// inline asm
	// inline asm
	call (%rd126), _rt_buffer_get_id_64, (%r155, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd144, %rd126, %rd142;
	ld.u32 	%r164, [%rd144+512];
	setp.lt.s32	%p11, %r164, 4;
	ld.u64 	%rd131, [%rd120+568];
	// inline asm
	mov.b64 {_,%r159}, %rd131;
	// inline asm
	// inline asm
	call (%rd132), _rt_buffer_get_id_64, (%r159, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd145, %rd140, %rd132;
	ld.u32 	%r165, [%rd145+528];
	setp.ne.s32	%p12, %r165, 1;
	mov.f32 	%f304, %f305;
	@%p12 bra 	LBB2_13;
	mov.f32 	%f198, 0f3F000000;
	div.approx.ftz.f32 	%f199, %f198, %f181;
	sub.ftz.f32 	%f201, %f193, %f199;
	max.ftz.f32 	%f202, %f165, %f199;
	min.ftz.f32 	%f203, %f202, %f201;
	sub.ftz.f32 	%f204, %f165, %f203;
	abs.ftz.f32 	%f205, %f204;
	mul.ftz.f32 	%f206, %f181, %f205;
	mov.f32 	%f207, 0f00000000;
	max.ftz.f32 	%f208, %f206, %f207;
	min.ftz.f32 	%f304, %f208, %f193;
LBB2_13:
	selp.f32	%f67, 0f3F800000, %f164, %p11;
	selp.f32	%f66, %f161, %f163, %p11;
	selp.f32	%f65, %f161, %f162, %p11;
	// inline asm
	mov.b64 {_,%r166}, %rd34;
	// inline asm
	// inline asm
	call (%rd147), _rt_buffer_get_id_64, (%r166, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd152, [%rd147+568];
	// inline asm
	mov.b64 {_,%r170}, %rd152;
	// inline asm
	// inline asm
	call (%rd153), _rt_buffer_get_id_64, (%r170, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd159, %rd137, %rd153;
	ld.u32 	%r174, [%rd159+548];
	setp.ne.s32	%p13, %r174, 1;
	@%p13 bra 	LBB2_15;
	mov.f32 	%f211, 0f3F000000;
	div.approx.ftz.f32 	%f212, %f211, %f180;
	sub.ftz.f32 	%f214, %f193, %f212;
	max.ftz.f32 	%f215, %f166, %f212;
	min.ftz.f32 	%f216, %f215, %f214;
	sub.ftz.f32 	%f217, %f166, %f216;
	abs.ftz.f32 	%f218, %f217;
	mul.ftz.f32 	%f219, %f180, %f218;
	mov.f32 	%f220, 0f00000000;
	max.ftz.f32 	%f221, %f219, %f220;
	min.ftz.f32 	%f305, %f221, %f193;
LBB2_15:
	sub.ftz.f32 	%f222, %f58, %f161;
	fma.rn.ftz.f32 	%f223, %f304, %f222, %f161;
	sub.ftz.f32 	%f224, %f59, %f65;
	fma.rn.ftz.f32 	%f225, %f304, %f224, %f65;
	sub.ftz.f32 	%f226, %f60, %f66;
	fma.rn.ftz.f32 	%f227, %f304, %f226, %f66;
	sub.ftz.f32 	%f228, %f61, %f67;
	fma.rn.ftz.f32 	%f229, %f304, %f228, %f67;
	sub.ftz.f32 	%f230, %f58, %f223;
	fma.rn.ftz.f32 	%f231, %f305, %f230, %f223;
	sub.ftz.f32 	%f232, %f59, %f225;
	fma.rn.ftz.f32 	%f233, %f305, %f232, %f225;
	sub.ftz.f32 	%f234, %f60, %f227;
	fma.rn.ftz.f32 	%f235, %f305, %f234, %f227;
	sub.ftz.f32 	%f236, %f61, %f229;
	fma.rn.ftz.f32 	%f309, %f305, %f236, %f229;
	// inline asm
	mov.b64 {_,%r175}, %rd34;
	// inline asm
	// inline asm
	call (%rd161), _rt_buffer_get_id_64, (%r175, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd166, [%rd161+568];
	// inline asm
	mov.b64 {_,%r179}, %rd166;
	// inline asm
	// inline asm
	call (%rd167), _rt_buffer_get_id_64, (%r179, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd173, %rd137, %rd167;
	ld.f32 	%f237, [%rd173+592];
	mul.ftz.f32 	%f308, %f235, %f237;
	mul.ftz.f32 	%f307, %f233, %f237;
	mul.ftz.f32 	%f306, %f231, %f237;
	setp.ltu.ftz.f32	%p14, %f309, 0f3F800000;
	@%p14 bra 	LBB2_75;
	bra.uni 	LBB2_16;
LBB2_75:
LBB2_17:
	and.b32  	%r183, %r8, 32;
	setp.eq.s32	%p15, %r183, 0;
	and.b32  	%r24, %r8, 1;
	@%p15 bra 	LBB2_19;
	setp.eq.s32	%p16, %r24, 0;
	selp.f32	%f321, 0f00000000, %f38, %p16;
	selp.f32	%f320, 0f00000000, %f37, %p16;
	selp.f32	%f322, 0f00000000, %f39, %p16;
	selp.f32	%f323, 0f00000000, %f323, %p16;
	bra.uni 	LBB2_73;
LBB2_19:
	setp.eq.s32	%p17, %r24, 0;
	@%p17 bra 	LBB2_38;
	// inline asm
	mov.b64 {_,%r184}, %rd34;
	// inline asm
	// inline asm
	call (%rd175), _rt_buffer_get_id_64, (%r184, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd180, [%rd175+560];
	cvt.s64.s32	%rd7, %r6;
	mul.wide.s32 	%rd186, %r6, 16;
	// inline asm
	mov.b64 {_,%r188}, %rd180;
	// inline asm
	// inline asm
	call (%rd181), _rt_buffer_get_id_64, (%r188, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd187, %rd186, %rd181;
	ld.f32 	%f88, [%rd187+516];
	setp.eq.ftz.f32	%p18, %f88, 0f00000000;
	@%p18 bra 	LBB2_21;
	bra.uni 	LBB2_22;
LBB2_21:
	mov.u32 	%r462, 8;
	bra.uni 	LBB2_23;
LBB2_38:
	setp.ne.s32	%p40, %r6, -1;
	@%p40 bra 	LBB2_40;
	bra.uni 	LBB2_39;
LBB2_40:
	// inline asm
	mov.b64 {_,%r279}, %rd34;
	// inline asm
	// inline asm
	call (%rd488), _rt_buffer_get_id_64, (%r279, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	setp.lt.s32	%p41, %r4, 1;
	@%p41 bra 	LBB2_77;
	ld.u64 	%rd273, [%rd488+584];
	mul.wide.s32 	%rd279, %r6, 8;
	// inline asm
	mov.b64 {_,%r284}, %rd273;
	// inline asm
	// inline asm
	call (%rd274), _rt_buffer_get_id_64, (%r284, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd280, %rd279, %rd274;
	add.s64 	%rd489, %rd280, 512;
	bra.uni 	LBB2_43;
LBB2_16:
	mul.ftz.f32 	%f320, %f37, %f306;
	mul.ftz.f32 	%f321, %f38, %f307;
	mul.ftz.f32 	%f322, %f39, %f308;
	bra.uni 	LBB2_73;
LBB2_22:
	setp.eq.ftz.f32	%p19, %f88, 0f7F800000;
	selp.b32	%r462, 10, 9, %p19;
LBB2_23:
	// inline asm
	mov.b64 {_,%r193}, %rd34;
	// inline asm
	// inline asm
	call (%rd189), _rt_buffer_get_id_64, (%r193, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd194, [%rd189+560];
	shl.b64 	%rd200, %rd7, 4;
	// inline asm
	mov.b64 {_,%r197}, %rd194;
	// inline asm
	// inline asm
	call (%rd195), _rt_buffer_get_id_64, (%r197, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd201, %rd200, %rd195;
	ld.f32 	%f89, [%rd201+512];
	setp.eq.ftz.f32	%p20, %f89, 0f00000000;
	@%p20 bra 	LBB2_24;
	bra.uni 	LBB2_25;
LBB2_24:
	mov.u32 	%r463, 2;
	bra.uni 	LBB2_26;
LBB2_25:
	setp.neu.ftz.f32	%p21, %f89, 0f40C90FDB;
	selp.u32	%r463, 1, 0, %p21;
LBB2_26:
	// inline asm
	mov.b64 {_,%r202}, %rd34;
	// inline asm
	// inline asm
	call (%rd203), _rt_buffer_get_id_64, (%r202, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd208, [%rd203+544];
	mul.lo.s64 	%rd214, %rd7, 24;
	// inline asm
	mov.b64 {_,%r206}, %rd208;
	// inline asm
	// inline asm
	call (%rd209), _rt_buffer_get_id_64, (%r206, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd8, %rd209, 512;
	add.s64 	%rd215, %rd214, %rd8;
	ld.u32 	%r210, [%rd215];
	shl.b32 	%r211, %r210, 1;
	and.b32  	%r212, %r211, 2;
	ld.u32 	%r213, [%rd215+4];
	setp.eq.s32	%p22, %r213, 1;
	selp.b32	%r214, 4, 0, %p22;
	ld.u32 	%r215, [%rd215+8];
	setp.eq.s32	%p23, %r215, 1;
	selp.b32	%r216, 8, 0, %p23;
	ld.u32 	%r217, [%rd215+12];
	setp.eq.s32	%p24, %r217, 1;
	selp.b32	%r218, 16, 0, %p24;
	setp.eq.s32	%p25, %r213, 2;
	selp.b32	%r219, 64, 0, %p25;
	setp.eq.s32	%p26, %r215, 2;
	selp.b32	%r220, 128, 0, %p26;
	setp.eq.s32	%p27, %r217, 2;
	selp.b32	%r221, 256, 0, %p27;
	or.b32  	%r222, %r212, %r214;
	or.b32  	%r223, %r222, %r219;
	or.b32  	%r224, %r223, %r216;
	or.b32  	%r225, %r224, %r220;
	or.b32  	%r226, %r225, %r218;
	or.b32  	%r227, %r226, %r221;
	or.b32  	%r228, %r227, 1;
	and.b32  	%r229, %r228, %r1;
	setp.gt.s32	%p28, %r229, 0;
	and.b32  	%r230, %r1, 34816;
	setp.eq.s32	%p29, %r230, 0;
	and.pred  	%p30, %p29, %p28;
	mov.f32 	%f320, 0f00000000;
	mov.f32 	%f321, %f320;
	mov.f32 	%f322, %f320;
	mov.f32 	%f323, %f320;
	@!%p30 bra 	LBB2_73;
	bra.uni 	LBB2_27;
LBB2_27:
	and.b32  	%r231, %r1, 65536;
	setp.eq.s32	%p31, %r231, 0;
	@%p31 bra 	LBB2_29;
	ld.u32 	%r232, [%rd215+16];
	and.b32  	%r233, %r232, 1;
	setp.eq.b32	%p32, %r233, 1;
	mov.f32 	%f320, 0f00000000;
	mov.f32 	%f321, %f320;
	mov.f32 	%f322, %f320;
	mov.f32 	%f323, %f320;
	@!%p32 bra 	LBB2_73;
	bra.uni 	LBB2_29;
LBB2_29:
	// inline asm
	mov.b64 {_,%r234}, %rd34;
	// inline asm
	// inline asm
	call (%rd219), _rt_buffer_get_id_64, (%r234, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd224, [%rd219+544];
	// inline asm
	mov.b64 {_,%r238}, %rd224;
	// inline asm
	// inline asm
	call (%rd225), _rt_buffer_get_id_64, (%r238, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd231, %rd214, %rd225;
	ld.u32 	%r242, [%rd231+532];
	not.b32 	%r243, %r242;
	shr.u32 	%r244, %r1, 19;
	and.b32  	%r245, %r244, %r243;
	and.b32  	%r246, %r245, 1;
	setp.eq.b32	%p33, %r246, 1;
	not.pred 	%p34, %p33;
	mov.f32 	%f320, 0f00000000;
	mov.f32 	%f321, %f320;
	mov.f32 	%f322, %f320;
	mov.f32 	%f323, %f320;
	@!%p34 bra 	LBB2_73;
	bra.uni 	LBB2_30;
LBB2_30:
	add.s64 	%rd9, %rd219, 512;
	abs.s32 	%r253, %r2;
	ld.u64 	%rd232, [%rd9+8];
	// inline asm
	mov.b64 {_,%r247}, %rd232;
	// inline asm
	// inline asm
	call (%rd233), _rt_buffer_get_id_64, (%r247, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u32 	%r254, [%rd233+508];
	add.s32 	%r466, %r254, -1;
	mul.wide.s32 	%rd238, %r253, 8;
	add.s64 	%rd239, %rd233, %rd238;
	ld.u32 	%r34, [%rd239+512];
	ld.u32 	%r35, [%rd239+516];
	setp.ge.s32	%p35, %r34, %r35;
	@%p35 bra 	LBB2_76;
	shl.b32 	%r251, %r86, %r462;
	shl.b32 	%r252, %r86, %r463;
	or.b32  	%r32, %r252, %r251;
	// inline asm
	mov.b64 {_,%r256}, %rd34;
	// inline asm
	// inline asm
	call (%rd241), _rt_buffer_get_id_64, (%r256, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd246, [%rd241+528];
	// inline asm
	mov.b64 {_,%r260}, %rd246;
	// inline asm
	// inline asm
	call (%rd247), _rt_buffer_get_id_64, (%r260, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	sub.s32 	%r464, %r35, %r34;
	mul.wide.s32 	%rd252, %r34, 8;
	or.b64  	%rd487, %rd252, 4;
	add.s64 	%rd13, %rd247, 512;
LBB2_32:
	add.s64 	%rd253, %rd487, %rd13;
	ld.u32 	%r263, [%rd253+-4];
	and.b32  	%r264, %r263, %r32;
	setp.ne.s32	%p36, %r264, %r32;
	@%p36 bra 	LBB2_34;
	add.s64 	%rd254, %rd13, %rd487;
	ld.u32 	%r466, [%rd254];
LBB2_34:
	add.s32 	%r464, %r464, -1;
	add.s64 	%rd487, %rd487, 8;
	setp.ne.s32	%p37, %r464, 0;
	@%p37 bra 	LBB2_32;
	bra.uni 	LBB2_35;
LBB2_39:
	// inline asm
	mov.b64 {_,%r288}, %rd34;
	// inline asm
	mov.u32 	%r289, 1;
	// inline asm
	call (%rd488), _rt_buffer_get_id_64, (%r288, %r289, %r289, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	bra.uni 	LBB2_42;
LBB2_77:
LBB2_42:
	ld.u64 	%rd287, [%rd488+576];
	// inline asm
	mov.b64 {_,%r292}, %rd287;
	// inline asm
	mov.u32 	%r293, 1;
	// inline asm
	call (%rd288), _rt_buffer_get_id_64, (%r292, %r293, %r293, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd489, %rd288, 512;
LBB2_43:
	ld.u64 	%rd21, [%rd489];
	// inline asm
	mov.b64 {_,%r295}, %rd21;
	// inline asm
	// inline asm
	call (%rd294), _rt_buffer_get_id_64, (%r295, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u32 	%r44, [%rd294+508];
	setp.lt.s32	%p42, %r44, 2;
	@%p42 bra 	LBB2_44;
	and.b32  	%r46, %r1, 34816;
	and.b32  	%r47, %r1, 65536;
	shr.u32 	%r300, %r1, 19;
	not.b32 	%r301, %r300;
	and.b32  	%r48, %r301, 1;
	and.b32  	%r50, %r8, 16;
	mul.wide.s32 	%rd22, %r6, 8;
	mov.f32 	%f314, 0f00000000;
	abs.s32 	%r376, %r2;
	lg2.approx.ftz.f32 	%f279, %f35;
	mul.ftz.f32 	%f280, %f279, 0f3FC00000;
	ex2.approx.ftz.f32 	%f281, %f280;
	mov.u32 	%r468, %r86;
	mov.f32 	%f315, %f314;
	mov.f32 	%f316, %f314;
LBB2_46:
	mul.wide.s32 	%rd317, %r468, 20;
	// inline asm
	mov.b64 {_,%r302}, %rd21;
	// inline asm
	// inline asm
	call (%rd300), _rt_buffer_get_id_64, (%r302, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd318, %rd317, %rd300;
	ld.u32 	%r52, [%rd318+516];
	// inline asm
	mov.b64 {_,%r306}, %rd34;
	// inline asm
	// inline asm
	call (%rd306), _rt_buffer_get_id_64, (%r306, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd311, [%rd306+560];
	cvt.s64.s32	%rd24, %r52;
	mul.wide.s32 	%rd319, %r52, 16;
	// inline asm
	mov.b64 {_,%r310}, %rd311;
	// inline asm
	// inline asm
	call (%rd312), _rt_buffer_get_id_64, (%r310, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd320, %rd319, %rd312;
	ld.f32 	%f116, [%rd320+516];
	setp.eq.ftz.f32	%p43, %f116, 0f00000000;
	@%p43 bra 	LBB2_47;
	bra.uni 	LBB2_48;
LBB2_47:
	mov.u32 	%r54, 0;
	bra.uni 	LBB2_49;
LBB2_48:
	setp.eq.ftz.f32	%p44, %f116, 0f7F800000;
	selp.b32	%r54, 2, 1, %p44;
LBB2_49:
	// inline asm
	mov.b64 {_,%r315}, %rd34;
	// inline asm
	mov.u32 	%r322, 1;
	// inline asm
	call (%rd322), _rt_buffer_get_id_64, (%r315, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd327, [%rd322+560];
	shl.b64 	%rd333, %rd24, 4;
	// inline asm
	mov.b64 {_,%r319}, %rd327;
	// inline asm
	// inline asm
	call (%rd328), _rt_buffer_get_id_64, (%r319, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd334, %rd333, %rd328;
	ld.f32 	%f117, [%rd334+512];
	setp.eq.ftz.f32	%p45, %f117, 0f00000000;
	@%p45 bra 	LBB2_50;
	bra.uni 	LBB2_51;
LBB2_50:
	mov.u32 	%r56, 2;
	bra.uni 	LBB2_52;
LBB2_51:
	setp.neu.ftz.f32	%p46, %f117, 0f40C90FDB;
	selp.u32	%r56, 1, 0, %p46;
LBB2_52:
	setp.eq.s32	%p47, %r46, 0;
	// inline asm
	mov.b64 {_,%r324}, %rd34;
	// inline asm
	// inline asm
	call (%rd336), _rt_buffer_get_id_64, (%r324, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd341, [%rd336+544];
	mul.lo.s64 	%rd347, %rd24, 24;
	// inline asm
	mov.b64 {_,%r328}, %rd341;
	// inline asm
	// inline asm
	call (%rd342), _rt_buffer_get_id_64, (%r328, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd25, %rd342, 512;
	add.s64 	%rd348, %rd347, %rd25;
	ld.u32 	%r332, [%rd348];
	shl.b32 	%r333, %r332, 1;
	and.b32  	%r334, %r333, 2;
	ld.u32 	%r335, [%rd348+4];
	setp.eq.s32	%p48, %r335, 1;
	selp.b32	%r336, 4, 0, %p48;
	ld.u32 	%r337, [%rd348+8];
	setp.eq.s32	%p49, %r337, 1;
	selp.b32	%r338, 8, 0, %p49;
	ld.u32 	%r339, [%rd348+12];
	setp.eq.s32	%p50, %r339, 1;
	selp.b32	%r340, 16, 0, %p50;
	setp.eq.s32	%p51, %r335, 2;
	selp.b32	%r341, 64, 0, %p51;
	setp.eq.s32	%p52, %r337, 2;
	selp.b32	%r342, 128, 0, %p52;
	setp.eq.s32	%p53, %r339, 2;
	selp.b32	%r343, 256, 0, %p53;
	or.b32  	%r344, %r334, %r336;
	or.b32  	%r345, %r344, %r341;
	or.b32  	%r346, %r345, %r338;
	or.b32  	%r347, %r346, %r342;
	or.b32  	%r348, %r347, %r340;
	or.b32  	%r349, %r348, %r343;
	or.b32  	%r350, %r349, 1;
	and.b32  	%r351, %r350, %r1;
	setp.gt.s32	%p54, %r351, 0;
	and.pred  	%p55, %p47, %p54;
	@!%p55 bra 	LBB2_71;
	bra.uni 	LBB2_53;
LBB2_53:
	setp.eq.s32	%p56, %r47, 0;
	@%p56 bra 	LBB2_55;
	ld.u32 	%r352, [%rd348+16];
	and.b32  	%r353, %r352, 1;
	setp.eq.b32	%p57, %r353, 1;
	@!%p57 bra 	LBB2_71;
	bra.uni 	LBB2_55;
LBB2_55:
	// inline asm
	mov.b64 {_,%r354}, %rd34;
	// inline asm
	// inline asm
	call (%rd352), _rt_buffer_get_id_64, (%r354, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd357, [%rd352+544];
	// inline asm
	mov.b64 {_,%r358}, %rd357;
	// inline asm
	// inline asm
	call (%rd358), _rt_buffer_get_id_64, (%r358, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd364, %rd347, %rd358;
	ld.u32 	%r362, [%rd364+532];
	and.b32  	%r363, %r362, 1;
	or.b32  	%r364, %r363, %r48;
	setp.eq.s32	%p58, %r364, 0;
	@%p58 bra 	LBB2_80;
	// inline asm
	mov.b64 {_,%r365}, %rd34;
	// inline asm
	// inline asm
	call (%rd366), _rt_buffer_get_id_64, (%r365, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd371, [%rd366+520];
	// inline asm
	mov.b64 {_,%r369}, %rd371;
	// inline asm
	// inline asm
	call (%rd372), _rt_buffer_get_id_64, (%r369, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u32 	%r377, [%rd372+508];
	add.s32 	%r473, %r377, -1;
	mul.wide.s32 	%rd377, %r376, 8;
	add.s64 	%rd378, %rd372, %rd377;
	ld.u32 	%r59, [%rd378+512];
	ld.u32 	%r60, [%rd378+516];
	setp.ge.s32	%p59, %r59, %r60;
	@%p59 bra 	LBB2_78;
	or.b32  	%r373, %r54, 8;
	shl.b32 	%r374, %r322, %r373;
	shl.b32 	%r375, %r322, %r56;
	or.b32  	%r57, %r375, %r374;
	// inline asm
	mov.b64 {_,%r379}, %rd34;
	// inline asm
	// inline asm
	call (%rd380), _rt_buffer_get_id_64, (%r379, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd385, [%rd380+528];
	// inline asm
	mov.b64 {_,%r383}, %rd385;
	// inline asm
	// inline asm
	call (%rd386), _rt_buffer_get_id_64, (%r383, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	sub.s32 	%r471, %r60, %r59;
	mul.wide.s32 	%rd391, %r59, 8;
	or.b64  	%rd490, %rd391, 4;
LBB2_58:
	add.s64 	%rd29, %rd386, 512;
	add.s64 	%rd392, %rd490, %rd29;
	ld.u32 	%r386, [%rd392+-4];
	and.b32  	%r387, %r386, %r57;
	setp.ne.s32	%p60, %r387, %r57;
	@%p60 bra 	LBB2_60;
	add.s64 	%rd393, %rd29, %rd490;
	ld.u32 	%r473, [%rd393];
LBB2_60:
	add.s32 	%r471, %r471, -1;
	add.s64 	%rd490, %rd490, 8;
	setp.ne.s32	%p61, %r471, 0;
	@%p61 bra 	LBB2_58;
	bra.uni 	LBB2_61;
LBB2_80:
	bra.uni 	LBB2_71;
LBB2_78:
LBB2_61:
	shr.u32 	%r396, %r473, 31;
	// inline asm
	mov.b64 {_,%r388}, %rd34;
	// inline asm
	// inline asm
	call (%rd395), _rt_buffer_get_id_64, (%r388, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd400, [%rd395+536];
	// inline asm
	mov.b64 {_,%r392}, %rd400;
	// inline asm
	// inline asm
	call (%rd401), _rt_buffer_get_id_64, (%r392, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u32 	%r397, [%rd401+512];
	and.b32  	%r398, %r397, 1;
	setp.eq.s32	%p62, %r398, %r396;
	@%p62 bra 	LBB2_81;
	bra.uni 	LBB2_62;
LBB2_81:
	bra.uni 	LBB2_71;
LBB2_62:
	cvt.s64.s32	%rd23, %r468;
	mul.lo.s64 	%rd426, %rd23, 20;
	// inline asm
	mov.b64 {_,%r399}, %rd21;
	// inline asm
	// inline asm
	call (%rd407), _rt_buffer_get_id_64, (%r399, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd427, %rd407, %rd426;
	ld.u32 	%r413, [%rd427+528];
	// inline asm
	mov.b64 {_,%r403}, %rd34;
	// inline asm
	// inline asm
	call (%rd413), _rt_buffer_get_id_64, (%r403, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd418, [%rd413+552];
	mul.wide.s32 	%rd428, %r413, 80;
	// inline asm
	mov.b64 {_,%r407}, %rd418;
	// inline asm
	// inline asm
	call (%rd419), _rt_buffer_get_id_64, (%r407, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd429, %rd428, %rd419;
	ld.u64 	%rd430, [%rd429+520];
	ld.u64 	%rd424, [%rd429+512];
	ld.u32 	%r68, [%rd427+520];
	// inline asm
	mov.b64 {_,%r411}, %rd424;
	// inline asm
	// inline asm
	call (%rd425), _rt_callable_program_from_id_64, (%r411);
	// inline asm
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd430;
	.param .b32 param1;
	st.param.b32	[param1+0], %r68;
	.param .align 16 .b8 param2[48];
	st.param.f32	[param2+0], %f1;
	st.param.f32	[param2+4], %f2;
	st.param.f32	[param2+8], %f3;
	st.param.f32	[param2+16], %f4;
	st.param.f32	[param2+20], %f5;
	st.param.f32	[param2+24], %f6;
	st.param.f32	[param2+32], %f7;
	st.param.f32	[param2+36], %f8;
	st.param.f32	[param2+40], %f9;
	.param .align 16 .b8 param3[48];
	st.param.f32	[param3+0], %f10;
	st.param.f32	[param3+4], %f11;
	st.param.f32	[param3+8], %f12;
	st.param.f32	[param3+16], %f13;
	st.param.f32	[param3+20], %f14;
	st.param.f32	[param3+24], %f15;
	st.param.f32	[param3+32], %f16;
	st.param.f32	[param3+36], %f17;
	st.param.f32	[param3+40], %f18;
	.param .align 16 .b8 retval0[32];
	prototype_1 : .callprototype (.param .align 16 .b8 _[32]) _ (.param .b64 _, .param .b32 _, .param .align 16 .b8 _[48], .param .align 16 .b8 _[48]);
	call (retval0), 
	%rd425, 
	(
	param0, 
	param1, 
	param2, 
	param3
	)
	, prototype_1;
	ld.param.f32	%f118, [retval0+0];
	ld.param.f32	%f119, [retval0+4];
	ld.param.f32	%f120, [retval0+8];
	ld.param.f32	%f262, [retval0+16];
	ld.param.f32	%f263, [retval0+20];
	ld.param.f32	%f264, [retval0+24];
	
	//{
	}// Callseq End 1
	setp.ne.s32	%p63, %r50, 0;
	@%p63 bra 	LBB2_64;
	bra.uni 	LBB2_63;
LBB2_64:
	mul.ftz.f32 	%f265, %f120, 0f3D93D07D;
	mov.f32 	%f266, 0f3F371437;
	fma.rn.ftz.f32 	%f267, %f266, %f119, %f265;
	mov.f32 	%f268, 0f3E59C6ED;
	fma.rn.ftz.f32 	%f269, %f268, %f118, %f267;
	setp.leu.ftz.f32	%p64, %f269, 0f00000000;
	@%p64 bra 	LBB2_82;
	cvt.s64.s32	%rd31, %r413;
	// inline asm
	mov.b64 {_,%r414}, %rd34;
	// inline asm
	// inline asm
	call (%rd432), _rt_buffer_get_id_64, (%r414, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd437, [%rd432+592];
	// inline asm
	mov.b64 {_,%r418}, %rd437;
	// inline asm
	// inline asm
	call (%rd438), _rt_buffer_get_id_64, (%r418, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd449, %rd438, %rd22;
	ld.u64 	%rd32, [%rd449+512];
	// inline asm
	mov.b64 {_,%r422}, %rd32;
	// inline asm
	// inline asm
	call (%rd444), _rt_buffer_get_id_64, (%r422, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u32 	%r426, [%rd444+508];
	add.s32 	%r476, %r426, -1;
	mov.f32 	%f313, 0f00000000;
	setp.lt.s32	%p65, %r476, 0;
	@%p65 bra 	LBB2_79;
	// inline asm
	mov.b64 {_,%r428}, %rd32;
	// inline asm
	// inline asm
	call (%rd451), _rt_buffer_get_id_64, (%r428, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	mov.u32 	%r477, 0;
	mov.u32 	%r475, -1;
LBB2_67:
	add.s32 	%r433, %r477, %r476;
	shr.u32 	%r434, %r433, 31;
	add.s32 	%r435, %r433, %r434;
	shr.s32 	%r436, %r435, 1;
	mul.wide.s32 	%rd456, %r436, 20;
	add.s64 	%rd457, %rd456, %rd451;
	ld.u32 	%r437, [%rd457+516];
	setp.eq.s32	%p66, %r437, %r52;
	add.s32 	%r438, %r476, 1;
	setp.gt.s32	%p67, %r437, %r52;
	add.s32 	%r439, %r436, -1;
	add.s32 	%r440, %r436, 1;
	selp.b32	%r441, %r439, %r476, %p67;
	selp.b32	%r442, %r477, %r440, %p67;
	selp.b32	%r475, %r436, %r475, %p66;
	selp.b32	%r476, %r476, %r441, %p66;
	selp.b32	%r477, %r438, %r442, %p66;
	setp.le.s32	%p68, %r477, %r476;
	@%p68 bra 	LBB2_67;
	setp.eq.s32	%p69, %r475, -1;
	@%p69 bra 	LBB2_70;
	mul.wide.s32 	%rd464, %r475, 20;
	// inline asm
	mov.b64 {_,%r444}, %rd32;
	// inline asm
	// inline asm
	call (%rd459), _rt_buffer_get_id_64, (%r444, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd465, %rd459, 512;
	add.s32 	%r447, %r475, -1;
	mul.wide.s32 	%rd466, %r447, 20;
	add.s64 	%rd467, %rd466, %rd465;
	add.s64 	%rd468, %rd464, %rd465;
	ld.f32 	%f272, [%rd468];
	ld.f32 	%f273, [%rd467];
	sub.ftz.f32 	%f313, %f272, %f273;
	bra.uni 	LBB2_70;
LBB2_63:
	add.ftz.f32 	%f314, %f314, %f118;
	add.ftz.f32 	%f315, %f315, %f119;
	add.ftz.f32 	%f316, %f316, %f120;
	bra.uni 	LBB2_71;
LBB2_82:
	bra.uni 	LBB2_71;
LBB2_79:
LBB2_70:
	// inline asm
	mov.b64 {_,%r449}, %rd34;
	// inline asm
	// inline asm
	call (%rd470), _rt_buffer_get_id_64, (%r449, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd475, [%rd470+552];
	mul.lo.s64 	%rd483, %rd31, 80;
	// inline asm
	mov.b64 {_,%r453}, %rd475;
	// inline asm
	// inline asm
	call (%rd476), _rt_buffer_get_id_64, (%r453, %r322, %r322, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	add.s64 	%rd484, %rd483, %rd476;
	ld.u64 	%rd485, [%rd484+552];
	ld.u64 	%rd481, [%rd484+544];
	// inline asm
	mov.b64 {_,%r457}, %rd481;
	// inline asm
	// inline asm
	call (%rd482), _rt_callable_program_from_id_64, (%r457);
	// inline asm
	// Callseq Start 2
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd485;
	.param .b32 param1;
	st.param.b32	[param1+0], %r68;
	.param .align 16 .b8 param2[48];
	st.param.f32	[param2+0], %f1;
	st.param.f32	[param2+4], %f2;
	st.param.f32	[param2+8], %f3;
	st.param.f32	[param2+16], %f4;
	st.param.f32	[param2+20], %f5;
	st.param.f32	[param2+24], %f6;
	st.param.f32	[param2+32], %f7;
	st.param.f32	[param2+36], %f8;
	st.param.f32	[param2+40], %f9;
	.param .align 16 .b8 param3[48];
	st.param.f32	[param3+0], %f10;
	st.param.f32	[param3+4], %f11;
	st.param.f32	[param3+8], %f12;
	st.param.f32	[param3+16], %f13;
	st.param.f32	[param3+20], %f14;
	st.param.f32	[param3+24], %f15;
	st.param.f32	[param3+32], %f16;
	st.param.f32	[param3+36], %f17;
	st.param.f32	[param3+40], %f18;
	.param .align 4 .b8 retval0[12];
	prototype_2 : .callprototype (.param .align 4 .b8 _[12]) _ (.param .b64 _, .param .b32 _, .param .align 16 .b8 _[48], .param .align 16 .b8 _[48]);
	call (retval0), 
	%rd482, 
	(
	param0, 
	param1, 
	param2, 
	param3
	)
	, prototype_2;
	ld.param.f32	%f274, [retval0+0];
	ld.param.f32	%f275, [retval0+4];
	ld.param.f32	%f276, [retval0+8];
	
	//{
	}// Callseq End 2
	mul.ftz.f32 	%f277, %f313, %f274;
	mul.ftz.f32 	%f278, %f36, %f277;
	lg2.approx.ftz.f32 	%f282, %f278;
	mul.ftz.f32 	%f283, %f282, 0f3FC00000;
	ex2.approx.ftz.f32 	%f284, %f283;
	add.ftz.f32 	%f285, %f281, %f284;
	div.approx.ftz.f32 	%f286, %f281, %f285;
	setp.lt.ftz.f32	%p70, %f286, 0f7F800000;
	selp.f32	%f287, %f286, 0f00000000, %p70;
	fma.rn.ftz.f32 	%f316, %f120, %f287, %f316;
	fma.rn.ftz.f32 	%f315, %f119, %f287, %f315;
	fma.rn.ftz.f32 	%f314, %f118, %f287, %f314;
LBB2_71:
	add.s32 	%r468, %r468, 1;
	setp.ne.s32	%p71, %r468, %r44;
	@%p71 bra 	LBB2_46;
	bra.uni 	LBB2_72;
LBB2_44:
	mov.f32 	%f314, 0f00000000;
	mov.f32 	%f315, %f314;
	mov.f32 	%f316, %f314;
LBB2_72:
	sub.ftz.f32 	%f288, %f306, %f314;
	sub.ftz.f32 	%f289, %f307, %f315;
	sub.ftz.f32 	%f290, %f308, %f316;
	fma.rn.ftz.f32 	%f291, %f309, %f290, %f316;
	fma.rn.ftz.f32 	%f292, %f309, %f289, %f315;
	fma.rn.ftz.f32 	%f293, %f309, %f288, %f314;
	mul.ftz.f32 	%f320, %f37, %f293;
	mul.ftz.f32 	%f321, %f38, %f292;
	mul.ftz.f32 	%f322, %f39, %f291;
LBB2_73:
	setp.nan.ftz.f32	%p72, %f320, %f321;
	setp.nan.ftz.f32	%p73, %f322, %f322;
	or.pred  	%p74, %p72, %p73;
	selp.f32	%f294, 0f00000000, %f322, %p74;
	selp.f32	%f295, 0f00000000, %f321, %p74;
	selp.f32	%f296, 0f00000000, %f320, %p74;
	setp.nan.ftz.f32	%p75, %f323, %f323;
	selp.f32	%f297, 0f3F800000, %f323, %p75;
	st.param.b64	[func_retval0+0], %rd35;
	st.param.b64	[func_retval0+8], %rd36;
	st.param.b64	[func_retval0+16], %rd37;
	st.param.f32	[func_retval0+32], %f296;
	st.param.f32	[func_retval0+36], %f295;
	st.param.f32	[func_retval0+40], %f294;
	st.param.f32	[func_retval0+48], %f297;
	ret;
LBB2_76:
LBB2_35:
	shr.u32 	%r273, %r466, 31;
	// inline asm
	mov.b64 {_,%r265}, %rd34;
	// inline asm
	// inline asm
	call (%rd256), _rt_buffer_get_id_64, (%r265, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u64 	%rd261, [%rd256+536];
	// inline asm
	mov.b64 {_,%r269}, %rd261;
	// inline asm
	// inline asm
	call (%rd262), _rt_buffer_get_id_64, (%r269, %r86, %r86, %rd51, %rd51, %rd51, %rd51);
	// inline asm
	ld.u32 	%r274, [%rd262+512];
	and.b32  	%r275, %r274, 1;
	setp.eq.s32	%p38, %r275, %r273;
	mov.f32 	%f323, 0f00000000;
	@%p38 bra 	LBB2_36;
	bra.uni 	LBB2_37;
LBB2_36:
	mov.f32 	%f320, %f323;
	mov.f32 	%f321, %f323;
	mov.f32 	%f322, %f323;
	bra.uni 	LBB2_73;
LBB2_37:
	shl.b32 	%r276, %r1, 19;
	shl.b32 	%r277, %r1, 18;
	or.b32  	%r278, %r276, %r277;
	setp.lt.s32	%p39, %r278, 0;
	selp.f32	%f255, 0f3F800000, %f35, %p39;
	mul.ftz.f32 	%f322, %f39, %f255;
	mul.ftz.f32 	%f321, %f38, %f255;
	mul.ftz.f32 	%f320, %f37, %f255;
	bra.uni 	LBB2_73;
}

	// .globl	stlr_ambient_occlusion
.visible .func  (.param .align 16 .b8 func_retval0[64]) stlr_ambient_occlusion(
	.param .b64 stlr_ambient_occlusion_param_0,
	.param .align 8 .b8 stlr_ambient_occlusion_param_1[24],
	.param .align 8 .b8 stlr_ambient_occlusion_param_2[24],
	.param .align 8 .b8 stlr_ambient_occlusion_param_3[24],
	.param .align 16 .b8 stlr_ambient_occlusion_param_4[16],
	.param .b32 stlr_ambient_occlusion_param_5,
	.param .b32 stlr_ambient_occlusion_param_6,
	.param .b32 stlr_ambient_occlusion_param_7
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<13>;
	.reg .s32 	%r<7>;
	.reg .s64 	%rd<6>;

	ld.param.u64 	%rd1, [stlr_ambient_occlusion_param_1+8];
	ld.param.u64 	%rd2, [stlr_ambient_occlusion_param_1+16];
	ld.param.u64 	%rd3, [stlr_ambient_occlusion_param_1];
	ld.u32 	%r1, [%rd3];
	add.s32 	%r2, %r1, -1;
	mul.wide.s32 	%rd4, %r2, 112;
	add.s64 	%rd5, %rd2, %rd4;
	ld.param.u32 	%r3, [stlr_ambient_occlusion_param_6];
	ld.f32 	%f1, [%rd5+16];
	ld.f32 	%f2, [%rd5+20];
	ld.f32 	%f3, [%rd5+24];
	ld.u32 	%r4, [%rd5+8];
	st.u32 	[%rd3], %r2;
	shr.u32 	%r5, %r4, 8;
	and.b32  	%r6, %r5, 1;
	setp.eq.b32	%p1, %r6, 1;
	cvt.rn.f32.s32	%f4, %r3;
	rcp.approx.ftz.f32 	%f5, %f4;
	selp.f32	%f6, %f5, 0f3F800000, %p1;
	mul.ftz.f32 	%f7, %f3, %f6;
	mul.ftz.f32 	%f8, %f2, %f6;
	mul.ftz.f32 	%f9, %f1, %f6;
	max.ftz.f32 	%f10, %f9, %f8;
	max.ftz.f32 	%f11, %f10, %f7;
	st.param.b64	[func_retval0+0], %rd3;
	st.param.b64	[func_retval0+8], %rd1;
	st.param.b64	[func_retval0+16], %rd2;
	st.param.f32	[func_retval0+32], %f11;
	st.param.f32	[func_retval0+36], %f11;
	st.param.f32	[func_retval0+40], %f11;
	mov.f32 	%f12, 0f00000000;
	st.param.f32	[func_retval0+48], %f12;
	ret;
}


