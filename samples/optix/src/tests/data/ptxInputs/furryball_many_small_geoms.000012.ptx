//

// Generated by LWPU LWVM Compiler

//

// Compiler Build ID: CL-19324574

// Lwca compilation tools, release 7.0, V7.0.27

// Based on LLVM 3.4svn

//



.version 4.2

.target sm_20

.address_size 64



	// .globl	_Z9TexSampleib6float2

.global .align 4 .f32 materialGamma;

.global .align 4 .f32 lightsGamma;

.global .align 1 .b8 textureSampleBuff[1];

.global .align 4 .b8 opt_ray[36];

.global .align 16 .b8 opt_prdShadow[144];

.global .align 4 .f32 opt_intersectionDistance;

.global .align 4 .b8 rt_objects[4];

.global .align 4 .b8 in_attributes[204];

.global .texref noise_texture;

.global .align 16 .b8 matData[944];

.global .align 8 .u64 _ZN21rti_internal_register20reg_bitness_detectorE;

.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail0E;

.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail1E;

.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail2E;

.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail3E;

.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail4E;

.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail5E;

.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail6E;

.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail7E;

.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail8E;

.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail9E;

.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail0E;

.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail1E;

.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail2E;

.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail3E;

.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail4E;

.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail5E;

.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail6E;

.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail7E;

.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail8E;

.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail9E;

.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_xE;

.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_yE;

.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_zE;

.global .align 4 .b8 _ZN21rti_internal_typeinfo13materialGammaE[8] = {82, 97, 121, 0, 4, 0, 0, 0};

.global .align 4 .b8 _ZN21rti_internal_typeinfo11lightsGammaE[8] = {82, 97, 121, 0, 4, 0, 0, 0};

.global .align 4 .b8 _ZN21rti_internal_typeinfo7opt_rayE[8] = {82, 97, 121, 0, 36, 0, 0, 0};

.global .align 4 .b8 _ZN21rti_internal_typeinfo13opt_prdShadowE[8] = {82, 97, 121, 0, 144, 0, 0, 0};

.global .align 4 .b8 _ZN21rti_internal_typeinfo24opt_intersectionDistanceE[8] = {82, 97, 121, 0, 4, 0, 0, 0};

.global .align 4 .b8 _ZN21rti_internal_typeinfo10rt_objectsE[8] = {82, 97, 121, 0, 4, 0, 0, 0};

.global .align 4 .b8 _ZN21rti_internal_typeinfo13in_attributesE[8] = {82, 97, 121, 0, 204, 0, 0, 0};

.global .align 4 .b8 _ZN21rti_internal_typeinfo7matDataE[8] = {82, 97, 121, 0, 176, 3, 0, 0};

.global .align 1 .b8 _ZN21rti_internal_typename13materialGammaE[6] = {102, 108, 111, 97, 116, 0};

.global .align 1 .b8 _ZN21rti_internal_typename11lightsGammaE[6] = {102, 108, 111, 97, 116, 0};

.global .align 1 .b8 _ZN21rti_internal_typename7opt_rayE[11] = {111, 112, 116, 105, 120, 58, 58, 82, 97, 121, 0};

.global .align 1 .b8 _ZN21rti_internal_typename13opt_prdShadowE[17] = {80, 101, 114, 83, 104, 97, 100, 111, 119, 82, 97, 121, 68, 97, 116, 97, 0};

.global .align 1 .b8 _ZN21rti_internal_typename24opt_intersectionDistanceE[6] = {102, 108, 111, 97, 116, 0};

.global .align 1 .b8 _ZN21rti_internal_typename10rt_objectsE[9] = {114, 116, 79, 98, 106, 101, 99, 116, 0};

.global .align 1 .b8 _ZN21rti_internal_typename13in_attributesE[25] = {67, 111, 109, 109, 111, 110, 71, 101, 111, 109, 101, 116, 114, 121, 65, 116, 116, 114, 105, 98, 117, 116, 101, 115, 0};

.global .align 1 .b8 _ZN21rti_internal_typename7matDataE[18] = {66, 97, 115, 105, 99, 77, 97, 116, 101, 114, 105, 97, 108, 68, 97, 116, 97, 0};

.global .align 4 .u32 _ZN21rti_internal_typeenum13materialGammaE = 4919;

.global .align 4 .u32 _ZN21rti_internal_typeenum11lightsGammaE = 4919;

.global .align 4 .u32 _ZN21rti_internal_typeenum7opt_rayE = 4919;

.global .align 4 .u32 _ZN21rti_internal_typeenum13opt_prdShadowE = 4919;

.global .align 4 .u32 _ZN21rti_internal_typeenum24opt_intersectionDistanceE = 4919;

.global .align 4 .u32 _ZN21rti_internal_typeenum10rt_objectsE = 4919;

.global .align 4 .u32 _ZN21rti_internal_typeenum13in_attributesE = 4919;

.global .align 4 .u32 _ZN21rti_internal_typeenum7matDataE = 4919;

.global .align 1 .b8 _ZN21rti_internal_semantic13materialGammaE[1];

.global .align 1 .b8 _ZN21rti_internal_semantic11lightsGammaE[1];

.global .align 1 .b8 _ZN21rti_internal_semantic7opt_rayE[13] = {114, 116, 67, 117, 114, 114, 101, 110, 116, 82, 97, 121, 0};

.global .align 1 .b8 _ZN21rti_internal_semantic13opt_prdShadowE[10] = {114, 116, 80, 97, 121, 108, 111, 97, 100, 0};

.global .align 1 .b8 _ZN21rti_internal_semantic24opt_intersectionDistanceE[23] = {114, 116, 73, 110, 116, 101, 114, 115, 101, 99, 116, 105, 111, 110, 68, 105, 115, 116, 97, 110, 99, 101, 0};

.global .align 1 .b8 _ZN21rti_internal_semantic10rt_objectsE[1];

.global .align 1 .b8 _ZN21rti_internal_semantic13in_attributesE[25] = {97, 116, 116, 114, 105, 98, 117, 116, 101, 32, 97, 116, 116, 95, 97, 116, 116, 114, 105, 98, 117, 116, 101, 115, 0};

.global .align 1 .b8 _ZN21rti_internal_semantic7matDataE[1];

.global .align 1 .b8 _ZN23rti_internal_annotation13materialGammaE[1];

.global .align 1 .b8 _ZN23rti_internal_annotation11lightsGammaE[1];

.global .align 1 .b8 _ZN23rti_internal_annotation7opt_rayE[1];

.global .align 1 .b8 _ZN23rti_internal_annotation13opt_prdShadowE[1];

.global .align 1 .b8 _ZN23rti_internal_annotation24opt_intersectionDistanceE[1];

.global .align 1 .b8 _ZN23rti_internal_annotation10rt_objectsE[1];

.global .align 1 .b8 _ZN23rti_internal_annotation13in_attributesE[1];

.global .align 1 .b8 _ZN23rti_internal_annotation7matDataE[1];



.visible .func  (.param .align 16 .b8 func_retval0[16]) _Z9TexSampleib6float2(

	.param .b32 _Z9TexSampleib6float2_param_0,

	.param .b32 _Z9TexSampleib6float2_param_1,

	.param .align 8 .b8 _Z9TexSampleib6float2_param_2[8]

)

{

	.reg .pred 	%p<2>;

	.reg .s16 	%rs<7>;

	.reg .f32 	%f<33>;

	.reg .s32 	%r<10>;





	ld.param.u32 	%r1, [_Z9TexSampleib6float2_param_0];

	ld.param.f32 	%f1, [_Z9TexSampleib6float2_param_2];

	ld.param.f32 	%f15, [_Z9TexSampleib6float2_param_2+4];

	mov.f32 	%f16, 0f3F800000;

	sub.ftz.f32 	%f2, %f16, %f15;

	ld.param.s8 	%rs1, [_Z9TexSampleib6float2_param_1];

	and.b16  	%rs2, %rs1, 255;

	setp.eq.s16	%p1, %rs2, 0;

	@%p1 bra 	BB0_2;



	mov.u32 	%r7, 2;

	mov.f32 	%f20, 0f00000000;

	// inline asm

	call (%r2, %r3, %r4, %r5), _rt_texture_get_u_id, (%r1, %r7, %f1, %f2, %f20, %f20);

	// inline asm

	cvt.u16.u32	%rs3, %r2;

	cvt.u16.u32	%rs4, %r3;

	cvt.u16.u32	%rs5, %r4;

	cvt.u16.u32	%rs6, %r5;

	{

	.reg .b16 %temp;

	mov.b16 	%temp, %rs3;

	cvt.f32.f16 	%f29, %temp;

	}

	{

	.reg .b16 %temp;

	mov.b16 	%temp, %rs4;

	cvt.f32.f16 	%f30, %temp;

	}

	{

	.reg .b16 %temp;

	mov.b16 	%temp, %rs5;

	cvt.f32.f16 	%f31, %temp;

	}

	{

	.reg .b16 %temp;

	mov.b16 	%temp, %rs6;

	cvt.f32.f16 	%f32, %temp;

	}

	bra.uni 	BB0_3;



BB0_2:

	mov.u32 	%r9, 2;

	mov.f32 	%f28, 0f00000000;

	// inline asm

	call (%f21, %f22, %f23, %f24), _rt_texture_get_f_id, (%r1, %r9, %f1, %f2, %f28, %f28);

	// inline asm

	mov.f32 	%f32, %f24;

	mov.f32 	%f31, %f23;

	mov.f32 	%f30, %f22;

	mov.f32 	%f29, %f21;



BB0_3:

	st.param.f32	[func_retval0+0], %f29;

	st.param.f32	[func_retval0+4], %f30;

	st.param.f32	[func_retval0+8], %f31;

	st.param.f32	[func_retval0+12], %f32;

	ret;

}



	// .globl	_ZN5optix19rt_texture_get_u_idEiiffff

.visible .func  (.param .align 16 .b8 func_retval0[16]) _ZN5optix19rt_texture_get_u_idEiiffff(

	.param .b32 _ZN5optix19rt_texture_get_u_idEiiffff_param_0,

	.param .b32 _ZN5optix19rt_texture_get_u_idEiiffff_param_1,

	.param .b32 _ZN5optix19rt_texture_get_u_idEiiffff_param_2,

	.param .b32 _ZN5optix19rt_texture_get_u_idEiiffff_param_3,

	.param .b32 _ZN5optix19rt_texture_get_u_idEiiffff_param_4,

	.param .b32 _ZN5optix19rt_texture_get_u_idEiiffff_param_5

)

{

	.reg .f32 	%f<5>;

	.reg .s32 	%r<7>;





	ld.param.u32 	%r5, [_ZN5optix19rt_texture_get_u_idEiiffff_param_0];

	ld.param.u32 	%r6, [_ZN5optix19rt_texture_get_u_idEiiffff_param_1];

	ld.param.f32 	%f1, [_ZN5optix19rt_texture_get_u_idEiiffff_param_2];

	ld.param.f32 	%f2, [_ZN5optix19rt_texture_get_u_idEiiffff_param_3];

	ld.param.f32 	%f3, [_ZN5optix19rt_texture_get_u_idEiiffff_param_4];

	ld.param.f32 	%f4, [_ZN5optix19rt_texture_get_u_idEiiffff_param_5];

	// inline asm

	call (%r1, %r2, %r3, %r4), _rt_texture_get_u_id, (%r5, %r6, %f1, %f2, %f3, %f4);

	// inline asm

	st.param.b32	[func_retval0+0], %r1;

	st.param.b32	[func_retval0+4], %r2;

	st.param.b32	[func_retval0+8], %r3;

	st.param.b32	[func_retval0+12], %r4;

	ret;

}



	// .globl	_ZN5optix19rt_texture_get_f_idEiiffff

.visible .func  (.param .align 16 .b8 func_retval0[16]) _ZN5optix19rt_texture_get_f_idEiiffff(

	.param .b32 _ZN5optix19rt_texture_get_f_idEiiffff_param_0,

	.param .b32 _ZN5optix19rt_texture_get_f_idEiiffff_param_1,

	.param .b32 _ZN5optix19rt_texture_get_f_idEiiffff_param_2,

	.param .b32 _ZN5optix19rt_texture_get_f_idEiiffff_param_3,

	.param .b32 _ZN5optix19rt_texture_get_f_idEiiffff_param_4,

	.param .b32 _ZN5optix19rt_texture_get_f_idEiiffff_param_5

)

{

	.reg .f32 	%f<9>;

	.reg .s32 	%r<3>;





	ld.param.u32 	%r1, [_ZN5optix19rt_texture_get_f_idEiiffff_param_0];

	ld.param.u32 	%r2, [_ZN5optix19rt_texture_get_f_idEiiffff_param_1];

	ld.param.f32 	%f5, [_ZN5optix19rt_texture_get_f_idEiiffff_param_2];

	ld.param.f32 	%f6, [_ZN5optix19rt_texture_get_f_idEiiffff_param_3];

	ld.param.f32 	%f7, [_ZN5optix19rt_texture_get_f_idEiiffff_param_4];

	ld.param.f32 	%f8, [_ZN5optix19rt_texture_get_f_idEiiffff_param_5];

	// inline asm

	call (%f1, %f2, %f3, %f4), _rt_texture_get_f_id, (%r1, %r2, %f5, %f6, %f7, %f8);

	// inline asm

	st.param.f32	[func_retval0+0], %f1;

	st.param.f32	[func_retval0+4], %f2;

	st.param.f32	[func_retval0+8], %f3;

	st.param.f32	[func_retval0+12], %f4;

	ret;

}



	// .globl	_Z11TexSample3Dib6float3

.visible .func  (.param .align 16 .b8 func_retval0[16]) _Z11TexSample3Dib6float3(

	.param .b32 _Z11TexSample3Dib6float3_param_0,

	.param .b32 _Z11TexSample3Dib6float3_param_1,

	.param .align 4 .b8 _Z11TexSample3Dib6float3_param_2[12]

)

{

	.reg .pred 	%p<2>;

	.reg .s16 	%rs<7>;

	.reg .f32 	%f<32>;

	.reg .s32 	%r<10>;





	ld.param.u32 	%r1, [_Z11TexSample3Dib6float3_param_0];

	ld.param.f32 	%f1, [_Z11TexSample3Dib6float3_param_2];

	ld.param.f32 	%f2, [_Z11TexSample3Dib6float3_param_2+4];

	ld.param.f32 	%f3, [_Z11TexSample3Dib6float3_param_2+8];

	ld.param.s8 	%rs1, [_Z11TexSample3Dib6float3_param_1];

	and.b16  	%rs2, %rs1, 255;

	setp.eq.s16	%p1, %rs2, 0;

	@%p1 bra 	BB3_2;



	mov.u32 	%r7, 3;

	mov.f32 	%f19, 0f00000000;

	// inline asm

	call (%r2, %r3, %r4, %r5), _rt_texture_get_u_id, (%r1, %r7, %f1, %f2, %f3, %f19);

	// inline asm

	cvt.u16.u32	%rs3, %r2;

	cvt.u16.u32	%rs4, %r3;

	cvt.u16.u32	%rs5, %r4;

	cvt.u16.u32	%rs6, %r5;

	{

	.reg .b16 %temp;

	mov.b16 	%temp, %rs3;

	cvt.f32.f16 	%f28, %temp;

	}

	{

	.reg .b16 %temp;

	mov.b16 	%temp, %rs4;

	cvt.f32.f16 	%f29, %temp;

	}

	{

	.reg .b16 %temp;

	mov.b16 	%temp, %rs5;

	cvt.f32.f16 	%f30, %temp;

	}

	{

	.reg .b16 %temp;

	mov.b16 	%temp, %rs6;

	cvt.f32.f16 	%f31, %temp;

	}

	bra.uni 	BB3_3;



BB3_2:

	mov.u32 	%r9, 3;

	mov.f32 	%f27, 0f00000000;

	// inline asm

	call (%f20, %f21, %f22, %f23), _rt_texture_get_f_id, (%r1, %r9, %f1, %f2, %f3, %f27);

	// inline asm

	mov.f32 	%f31, %f23;

	mov.f32 	%f30, %f22;

	mov.f32 	%f29, %f21;

	mov.f32 	%f28, %f20;



BB3_3:

	st.param.f32	[func_retval0+0], %f28;

	st.param.f32	[func_retval0+4], %f29;

	st.param.f32	[func_retval0+8], %f30;

	st.param.f32	[func_retval0+12], %f31;

	ret;

}



	// .globl	_Z12ColorBalance6float4S_S_ifbf

.visible .func  (.param .align 16 .b8 func_retval0[16]) _Z12ColorBalance6float4S_S_ifbf(

	.param .align 16 .b8 _Z12ColorBalance6float4S_S_ifbf_param_0[16],

	.param .align 16 .b8 _Z12ColorBalance6float4S_S_ifbf_param_1[16],

	.param .align 16 .b8 _Z12ColorBalance6float4S_S_ifbf_param_2[16],

	.param .b32 _Z12ColorBalance6float4S_S_ifbf_param_3,

	.param .b32 _Z12ColorBalance6float4S_S_ifbf_param_4,

	.param .b32 _Z12ColorBalance6float4S_S_ifbf_param_5,

	.param .b32 _Z12ColorBalance6float4S_S_ifbf_param_6

)

{

	.reg .pred 	%p<4>;

	.reg .s16 	%rs<3>;

	.reg .f32 	%f<55>;

	.reg .s32 	%r<2>;





	ld.param.f32 	%f28, [_Z12ColorBalance6float4S_S_ifbf_param_0+12];

	ld.param.f32 	%f50, [_Z12ColorBalance6float4S_S_ifbf_param_0+8];

	ld.param.f32 	%f49, [_Z12ColorBalance6float4S_S_ifbf_param_0+4];

	ld.param.f32 	%f48, [_Z12ColorBalance6float4S_S_ifbf_param_0];

	ld.param.f32 	%f32, [_Z12ColorBalance6float4S_S_ifbf_param_1+12];

	ld.param.f32 	%f31, [_Z12ColorBalance6float4S_S_ifbf_param_1+8];

	ld.param.f32 	%f30, [_Z12ColorBalance6float4S_S_ifbf_param_1+4];

	ld.param.f32 	%f29, [_Z12ColorBalance6float4S_S_ifbf_param_1];

	ld.param.f32 	%f36, [_Z12ColorBalance6float4S_S_ifbf_param_2+12];

	ld.param.f32 	%f35, [_Z12ColorBalance6float4S_S_ifbf_param_2+8];

	ld.param.f32 	%f34, [_Z12ColorBalance6float4S_S_ifbf_param_2+4];

	ld.param.f32 	%f33, [_Z12ColorBalance6float4S_S_ifbf_param_2];

	ld.param.u32 	%r1, [_Z12ColorBalance6float4S_S_ifbf_param_3];

	ld.param.f32 	%f37, [_Z12ColorBalance6float4S_S_ifbf_param_4];

	ld.param.f32 	%f38, [_Z12ColorBalance6float4S_S_ifbf_param_6];

	ld.param.s8 	%rs1, [_Z12ColorBalance6float4S_S_ifbf_param_5];

	setp.eq.s32	%p1, %r1, 0;

	@%p1 bra 	BB4_3;

	bra.uni 	BB4_1;



BB4_3:

	cvt.ftz.sat.f32.f32	%f48, %f48;

	cvt.ftz.sat.f32.f32	%f49, %f49;

	cvt.ftz.sat.f32.f32	%f50, %f50;

	bra.uni 	BB4_4;



BB4_1:

	setp.ne.s32	%p2, %r1, 2;

	@%p2 bra 	BB4_4;



	mov.f32 	%f39, 0f40000000;

	lg2.approx.ftz.f32 	%f40, %f39;

	mul.ftz.f32 	%f41, %f40, %f37;

	ex2.approx.ftz.f32 	%f42, %f41;

	mul.ftz.f32 	%f48, %f48, %f42;

	mul.ftz.f32 	%f49, %f49, %f42;

	mul.ftz.f32 	%f50, %f50, %f42;



BB4_4:

	fma.rn.ftz.f32 	%f51, %f29, %f48, %f33;

	fma.rn.ftz.f32 	%f52, %f30, %f49, %f34;

	fma.rn.ftz.f32 	%f53, %f31, %f50, %f35;

	fma.rn.ftz.f32 	%f54, %f28, %f32, %f36;

	and.b16  	%rs2, %rs1, 255;

	setp.eq.s16	%p3, %rs2, 0;

	@%p3 bra 	BB4_6;



	mov.f32 	%f43, 0f3F800000;

	sub.ftz.f32 	%f51, %f43, %f51;

	sub.ftz.f32 	%f52, %f43, %f52;

	sub.ftz.f32 	%f53, %f43, %f53;

	sub.ftz.f32 	%f54, %f43, %f54;



BB4_6:

	max.ftz.f32 	%f44, %f38, %f51;

	max.ftz.f32 	%f45, %f38, %f52;

	max.ftz.f32 	%f46, %f38, %f53;

	max.ftz.f32 	%f47, %f38, %f54;

	st.param.f32	[func_retval0+0], %f44;

	st.param.f32	[func_retval0+4], %f45;

	st.param.f32	[func_retval0+8], %f46;

	st.param.f32	[func_retval0+12], %f47;

	ret;

}



	// .globl	_Z11TransformUV6float2N5optix6MatrixILj4ELj4EEE

.visible .func  (.param .align 8 .b8 func_retval0[8]) _Z11TransformUV6float2N5optix6MatrixILj4ELj4EEE(

	.param .align 8 .b8 _Z11TransformUV6float2N5optix6MatrixILj4ELj4EEE_param_0[8],

	.param .b64 _Z11TransformUV6float2N5optix6MatrixILj4ELj4EEE_param_1

)

{

	.reg .f32 	%f<19>;

	.reg .s64 	%rd<2>;





	ld.param.f32 	%f1, [_Z11TransformUV6float2N5optix6MatrixILj4ELj4EEE_param_0+4];

	ld.param.f32 	%f2, [_Z11TransformUV6float2N5optix6MatrixILj4ELj4EEE_param_0];

	ld.param.u64 	%rd1, [_Z11TransformUV6float2N5optix6MatrixILj4ELj4EEE_param_1];

	ld.f32 	%f3, [%rd1];

	fma.rn.ftz.f32 	%f4, %f2, %f3, 0f00000000;

	ld.f32 	%f5, [%rd1+16];

	fma.rn.ftz.f32 	%f6, %f1, %f5, %f4;

	ld.f32 	%f7, [%rd1+32];

	fma.rn.ftz.f32 	%f8, %f7, 0f00000000, %f6;

	ld.f32 	%f9, [%rd1+48];

	add.ftz.f32 	%f10, %f8, %f9;

	ld.f32 	%f11, [%rd1+4];

	fma.rn.ftz.f32 	%f12, %f2, %f11, 0f00000000;

	ld.f32 	%f13, [%rd1+20];

	fma.rn.ftz.f32 	%f14, %f1, %f13, %f12;

	ld.f32 	%f15, [%rd1+36];

	fma.rn.ftz.f32 	%f16, %f15, 0f00000000, %f14;

	ld.f32 	%f17, [%rd1+52];

	add.ftz.f32 	%f18, %f16, %f17;

	st.param.f32	[func_retval0+0], %f10;

	st.param.f32	[func_retval0+4], %f18;

	ret;

}



	// .globl	_Z9WrapCoordfb

.visible .func  (.param .b32 func_retval0) _Z9WrapCoordfb(

	.param .b32 _Z9WrapCoordfb_param_0,

	.param .b32 _Z9WrapCoordfb_param_1

)

{

	.reg .pred 	%p<10>;

	.reg .s16 	%rs<3>;

	.reg .f32 	%f<9>;

	.reg .s32 	%r<3>;





	ld.param.f32 	%f4, [_Z9WrapCoordfb_param_0];

	cvt.rmi.ftz.f32.f32	%f5, %f4;

	sub.ftz.f32 	%f8, %f4, %f5;

	ld.param.s8 	%rs1, [_Z9WrapCoordfb_param_1];

	and.b16  	%rs2, %rs1, 255;

	setp.eq.s16	%p2, %rs2, 0;

	@%p2 bra 	BB6_5;



	cvt.rzi.ftz.s32.f32	%r1, %f4;

	mov.pred 	%p3, -1;

	and.b32  	%r2, %r1, 1;

	setp.eq.b32	%p4, %r2, 1;

	mov.pred 	%p9, %p3;

	@%p4 bra 	BB6_4;



	mov.pred 	%p5, 0;

	setp.geu.ftz.f32	%p6, %f4, 0f00000000;

	mov.pred 	%p9, %p5;

	@%p6 bra 	BB6_4;



	mov.pred 	%p9, %p3;



BB6_4:

	mov.f32 	%f6, 0f3F800000;

	sub.ftz.f32 	%f7, %f6, %f8;

	selp.f32	%f8, %f7, %f8, %p9;



BB6_5:

	st.param.f32	[func_retval0+0], %f8;

	ret;

}



	// .globl	_Z8getPhongRK6float3S1_S1_f

.visible .func  (.param .b32 func_retval0) _Z8getPhongRK6float3S1_S1_f(

	.param .b64 _Z8getPhongRK6float3S1_S1_f_param_0,

	.param .b64 _Z8getPhongRK6float3S1_S1_f_param_1,

	.param .b64 _Z8getPhongRK6float3S1_S1_f_param_2,

	.param .b32 _Z8getPhongRK6float3S1_S1_f_param_3

)

{

	.reg .f32 	%f<39>;

	.reg .s64 	%rd<4>;





	ld.param.u64 	%rd1, [_Z8getPhongRK6float3S1_S1_f_param_0];

	ld.param.u64 	%rd2, [_Z8getPhongRK6float3S1_S1_f_param_1];

	ld.param.u64 	%rd3, [_Z8getPhongRK6float3S1_S1_f_param_2];

	ld.param.f32 	%f1, [_Z8getPhongRK6float3S1_S1_f_param_3];

	ld.f32 	%f2, [%rd2];

	neg.ftz.f32 	%f3, %f2;

	ld.f32 	%f4, [%rd2+4];

	neg.ftz.f32 	%f5, %f4;

	ld.f32 	%f6, [%rd2+8];

	neg.ftz.f32 	%f7, %f6;

	ld.f32 	%f8, [%rd1];

	add.ftz.f32 	%f9, %f8, %f8;

	ld.f32 	%f10, [%rd1+4];

	add.ftz.f32 	%f11, %f10, %f10;

	ld.f32 	%f12, [%rd1+8];

	add.ftz.f32 	%f13, %f12, %f12;

	mul.ftz.f32 	%f14, %f8, %f3;

	mul.ftz.f32 	%f15, %f10, %f4;

	sub.ftz.f32 	%f16, %f14, %f15;

	mul.ftz.f32 	%f17, %f12, %f6;

	sub.ftz.f32 	%f18, %f16, %f17;

	mul.ftz.f32 	%f19, %f9, %f18;

	mul.ftz.f32 	%f20, %f11, %f18;

	mul.ftz.f32 	%f21, %f13, %f18;

	sub.ftz.f32 	%f22, %f3, %f19;

	sub.ftz.f32 	%f23, %f5, %f20;

	sub.ftz.f32 	%f24, %f7, %f21;

	ld.f32 	%f25, [%rd3];

	ld.f32 	%f26, [%rd3+4];

	mul.ftz.f32 	%f27, %f26, %f23;

	fma.rn.ftz.f32 	%f28, %f25, %f22, %f27;

	ld.f32 	%f29, [%rd3+8];

	fma.rn.ftz.f32 	%f30, %f29, %f24, %f28;

	cvt.ftz.sat.f32.f32	%f31, %f30;

	lg2.approx.ftz.f32 	%f32, %f31;

	mul.ftz.f32 	%f33, %f32, %f1;

	ex2.approx.ftz.f32 	%f34, %f33;

	add.ftz.f32 	%f35, %f1, 0f40000000;

	mov.f32 	%f36, 0f40C90FDB;

	div.approx.ftz.f32 	%f37, %f35, %f36;

	mul.ftz.f32 	%f38, %f34, %f37;

	st.param.f32	[func_retval0+0], %f38;

	ret;

}



	// .globl	_Z11getPhongPdfRK6float3S1_S1_f

.visible .func  (.param .b32 func_retval0) _Z11getPhongPdfRK6float3S1_S1_f(

	.param .b64 _Z11getPhongPdfRK6float3S1_S1_f_param_0,

	.param .b64 _Z11getPhongPdfRK6float3S1_S1_f_param_1,

	.param .b64 _Z11getPhongPdfRK6float3S1_S1_f_param_2,

	.param .b32 _Z11getPhongPdfRK6float3S1_S1_f_param_3

)

{

	.reg .f32 	%f<39>;

	.reg .s64 	%rd<4>;





	ld.param.u64 	%rd1, [_Z11getPhongPdfRK6float3S1_S1_f_param_0];

	ld.param.u64 	%rd2, [_Z11getPhongPdfRK6float3S1_S1_f_param_1];

	ld.param.u64 	%rd3, [_Z11getPhongPdfRK6float3S1_S1_f_param_2];

	ld.param.f32 	%f1, [_Z11getPhongPdfRK6float3S1_S1_f_param_3];

	ld.f32 	%f2, [%rd2];

	neg.ftz.f32 	%f3, %f2;

	ld.f32 	%f4, [%rd2+4];

	neg.ftz.f32 	%f5, %f4;

	ld.f32 	%f6, [%rd2+8];

	neg.ftz.f32 	%f7, %f6;

	ld.f32 	%f8, [%rd1];

	add.ftz.f32 	%f9, %f8, %f8;

	ld.f32 	%f10, [%rd1+4];

	add.ftz.f32 	%f11, %f10, %f10;

	ld.f32 	%f12, [%rd1+8];

	add.ftz.f32 	%f13, %f12, %f12;

	mul.ftz.f32 	%f14, %f8, %f3;

	mul.ftz.f32 	%f15, %f10, %f4;

	sub.ftz.f32 	%f16, %f14, %f15;

	mul.ftz.f32 	%f17, %f12, %f6;

	sub.ftz.f32 	%f18, %f16, %f17;

	mul.ftz.f32 	%f19, %f9, %f18;

	mul.ftz.f32 	%f20, %f11, %f18;

	mul.ftz.f32 	%f21, %f13, %f18;

	sub.ftz.f32 	%f22, %f3, %f19;

	sub.ftz.f32 	%f23, %f5, %f20;

	sub.ftz.f32 	%f24, %f7, %f21;

	ld.f32 	%f25, [%rd3];

	ld.f32 	%f26, [%rd3+4];

	mul.ftz.f32 	%f27, %f26, %f23;

	fma.rn.ftz.f32 	%f28, %f25, %f22, %f27;

	ld.f32 	%f29, [%rd3+8];

	fma.rn.ftz.f32 	%f30, %f29, %f24, %f28;

	abs.ftz.f32 	%f31, %f30;

	lg2.approx.ftz.f32 	%f32, %f31;

	mul.ftz.f32 	%f33, %f32, %f1;

	ex2.approx.ftz.f32 	%f34, %f33;

	add.ftz.f32 	%f35, %f1, 0f3F800000;

	mov.f32 	%f36, 0f40C90FDB;

	div.approx.ftz.f32 	%f37, %f35, %f36;

	mul.ftz.f32 	%f38, %f34, %f37;

	st.param.f32	[func_retval0+0], %f38;

	ret;

}



	// .globl	_Z11getGaussianff

.visible .func  (.param .b32 func_retval0) _Z11getGaussianff(

	.param .b32 _Z11getGaussianff_param_0,

	.param .b32 _Z11getGaussianff_param_1

)

{

	.reg .pred 	%p<5>;

	.reg .f32 	%f<12>;





	ld.param.f32 	%f6, [_Z11getGaussianff_param_0];

	ld.param.f32 	%f4, [_Z11getGaussianff_param_1];

	rcp.approx.ftz.f32 	%f7, %f6;

	mov.f32 	%f11, 0f3F800000;

	sub.ftz.f32 	%f8, %f11, %f7;

	div.approx.ftz.f32 	%f1, %f8, %f4;

	setp.gt.ftz.f32	%p1, %f8, 0fB727C5AC;

	@%p1 bra 	BB9_3;



	setp.gt.ftz.f32	%p2, %f4, 0f00000000;

	setp.gt.ftz.f32	%p3, %f1, 0fC3960000;

	and.pred  	%p4, %p2, %p3;

	mov.f32 	%f11, 0f00000000;

	@!%p4 bra 	BB9_3;

	bra.uni 	BB9_2;



BB9_2:

	mul.ftz.f32 	%f10, %f1, 0f3FB8AA3B;

	ex2.approx.ftz.f32 	%f11, %f10;



BB9_3:

	st.param.f32	[func_retval0+0], %f11;

	ret;

}



	// .globl	_Z11getGaussianRK6float3S1_S_f

.visible .func  (.param .b32 func_retval0) _Z11getGaussianRK6float3S1_S_f(

	.param .b64 _Z11getGaussianRK6float3S1_S_f_param_0,

	.param .b64 _Z11getGaussianRK6float3S1_S_f_param_1,

	.param .align 4 .b8 _Z11getGaussianRK6float3S1_S_f_param_2[12],

	.param .b32 _Z11getGaussianRK6float3S1_S_f_param_3

)

{

	.reg .pred 	%p<5>;

	.reg .f32 	%f<36>;

	.reg .s64 	%rd<3>;





	ld.param.u64 	%rd1, [_Z11getGaussianRK6float3S1_S_f_param_0];

	ld.param.u64 	%rd2, [_Z11getGaussianRK6float3S1_S_f_param_1];

	ld.param.f32 	%f6, [_Z11getGaussianRK6float3S1_S_f_param_2+8];

	ld.param.f32 	%f7, [_Z11getGaussianRK6float3S1_S_f_param_2];

	ld.param.f32 	%f8, [_Z11getGaussianRK6float3S1_S_f_param_2+4];

	ld.param.f32 	%f9, [_Z11getGaussianRK6float3S1_S_f_param_3];

	ld.f32 	%f10, [%rd1];

	ld.f32 	%f11, [%rd2];

	add.ftz.f32 	%f12, %f11, %f10;

	ld.f32 	%f13, [%rd1+4];

	ld.f32 	%f14, [%rd2+4];

	add.ftz.f32 	%f15, %f14, %f13;

	ld.f32 	%f16, [%rd1+8];

	ld.f32 	%f17, [%rd2+8];

	add.ftz.f32 	%f18, %f17, %f16;

	mul.ftz.f32 	%f19, %f15, %f15;

	fma.rn.ftz.f32 	%f20, %f12, %f12, %f19;

	fma.rn.ftz.f32 	%f21, %f18, %f18, %f20;

	sqrt.approx.ftz.f32 	%f22, %f21;

	rcp.approx.ftz.f32 	%f23, %f22;

	mul.ftz.f32 	%f24, %f12, %f23;

	mul.ftz.f32 	%f25, %f15, %f23;

	mul.ftz.f32 	%f26, %f18, %f23;

	mul.ftz.f32 	%f27, %f8, %f25;

	fma.rn.ftz.f32 	%f28, %f7, %f24, %f27;

	fma.rn.ftz.f32 	%f29, %f6, %f26, %f28;

	mul.ftz.f32 	%f30, %f29, %f29;

	rcp.approx.ftz.f32 	%f31, %f30;

	mov.f32 	%f35, 0f3F800000;

	sub.ftz.f32 	%f32, %f35, %f31;

	mul.ftz.f32 	%f1, %f9, %f9;

	div.approx.ftz.f32 	%f2, %f32, %f1;

	setp.gt.ftz.f32	%p1, %f32, 0fB727C5AC;

	@%p1 bra 	BB10_3;



	setp.gt.ftz.f32	%p2, %f1, 0f00000000;

	setp.gt.ftz.f32	%p3, %f2, 0fC3960000;

	and.pred  	%p4, %p2, %p3;

	mov.f32 	%f35, 0f00000000;

	@!%p4 bra 	BB10_3;

	bra.uni 	BB10_2;



BB10_2:

	mul.ftz.f32 	%f34, %f2, 0f3FB8AA3B;

	ex2.approx.ftz.f32 	%f35, %f34;



BB10_3:

	st.param.f32	[func_retval0+0], %f35;

	ret;

}



	// .globl	_Z12getGaussianGRK6float3S1_S1_f

.visible .func  (.param .b32 func_retval0) _Z12getGaussianGRK6float3S1_S1_f(

	.param .b64 _Z12getGaussianGRK6float3S1_S1_f_param_0,

	.param .b64 _Z12getGaussianGRK6float3S1_S1_f_param_1,

	.param .b64 _Z12getGaussianGRK6float3S1_S1_f_param_2,

	.param .b32 _Z12getGaussianGRK6float3S1_S1_f_param_3

)

{

	.reg .pred 	%p<5>;

	.reg .f32 	%f<45>;

	.reg .s64 	%rd<4>;





	ld.param.u64 	%rd1, [_Z12getGaussianGRK6float3S1_S1_f_param_0];

	ld.param.u64 	%rd2, [_Z12getGaussianGRK6float3S1_S1_f_param_1];

	ld.param.u64 	%rd3, [_Z12getGaussianGRK6float3S1_S1_f_param_2];

	ld.param.f32 	%f6, [_Z12getGaussianGRK6float3S1_S1_f_param_3];

	ld.f32 	%f7, [%rd3+8];

	ld.f32 	%f8, [%rd3];

	ld.f32 	%f9, [%rd3+4];

	ld.f32 	%f10, [%rd1];

	ld.f32 	%f11, [%rd2];

	add.ftz.f32 	%f12, %f11, %f10;

	ld.f32 	%f13, [%rd1+4];

	ld.f32 	%f14, [%rd2+4];

	add.ftz.f32 	%f15, %f14, %f13;

	ld.f32 	%f16, [%rd1+8];

	ld.f32 	%f17, [%rd2+8];

	add.ftz.f32 	%f18, %f17, %f16;

	mul.ftz.f32 	%f19, %f15, %f15;

	fma.rn.ftz.f32 	%f20, %f12, %f12, %f19;

	fma.rn.ftz.f32 	%f21, %f18, %f18, %f20;

	sqrt.approx.ftz.f32 	%f22, %f21;

	rcp.approx.ftz.f32 	%f23, %f22;

	mul.ftz.f32 	%f24, %f12, %f23;

	mul.ftz.f32 	%f25, %f15, %f23;

	mul.ftz.f32 	%f26, %f18, %f23;

	mul.ftz.f32 	%f27, %f9, %f25;

	fma.rn.ftz.f32 	%f28, %f8, %f24, %f27;

	fma.rn.ftz.f32 	%f29, %f7, %f26, %f28;

	mul.ftz.f32 	%f30, %f29, %f29;

	rcp.approx.ftz.f32 	%f31, %f30;

	mov.f32 	%f5, 0f3F800000;

	sub.ftz.f32 	%f32, %f5, %f31;

	mul.ftz.f32 	%f1, %f6, %f6;

	div.approx.ftz.f32 	%f2, %f32, %f1;

	setp.gt.ftz.f32	%p1, %f32, 0fB727C5AC;

	mov.f32 	%f44, %f5;

	@%p1 bra 	BB11_3;



	setp.gt.ftz.f32	%p2, %f1, 0f00000000;

	setp.gt.ftz.f32	%p3, %f2, 0fC3960000;

	and.pred  	%p4, %p2, %p3;

	mov.f32 	%f33, 0f00000000;

	mov.f32 	%f44, %f33;

	@!%p4 bra 	BB11_3;

	bra.uni 	BB11_2;



BB11_2:

	mul.ftz.f32 	%f34, %f2, 0f3FB8AA3B;

	ex2.approx.ftz.f32 	%f3, %f34;

	mov.f32 	%f44, %f3;



BB11_3:

	mov.f32 	%f4, %f44;

	mov.f32 	%f35, 0f3EAAA64C;

	div.approx.ftz.f32 	%f36, %f4, %f35;

	min.ftz.f32 	%f38, %f36, %f5;

	mov.f32 	%f39, 0f00000000;

	max.ftz.f32 	%f40, %f39, %f38;

	mul.ftz.f32 	%f41, %f40, %f40;

	fma.rn.ftz.f32 	%f42, %f40, 0fC0000000, 0f40400000;

	mul.ftz.f32 	%f43, %f41, %f42;

	st.param.f32	[func_retval0+0], %f43;

	ret;

}



	// .globl	_Z8Beckmannff

.visible .func  (.param .b32 func_retval0) _Z8Beckmannff(

	.param .b32 _Z8Beckmannff_param_0,

	.param .b32 _Z8Beckmannff_param_1

)

{

	.reg .pred 	%p<5>;

	.reg .f32 	%f<16>;





	ld.param.f32 	%f7, [_Z8Beckmannff_param_0];

	ld.param.f32 	%f5, [_Z8Beckmannff_param_1];

	mul.ftz.f32 	%f1, %f7, %f7;

	rcp.approx.ftz.f32 	%f8, %f1;

	mov.f32 	%f15, 0f3F800000;

	sub.ftz.f32 	%f9, %f15, %f8;

	div.approx.ftz.f32 	%f2, %f9, %f5;

	setp.gt.ftz.f32	%p1, %f9, 0fB727C5AC;

	@%p1 bra 	BB12_3;



	setp.gt.ftz.f32	%p2, %f5, 0f00000000;

	setp.gt.ftz.f32	%p3, %f2, 0fC3960000;

	and.pred  	%p4, %p2, %p3;

	mov.f32 	%f15, 0f00000000;

	@!%p4 bra 	BB12_3;

	bra.uni 	BB12_2;



BB12_2:

	mul.ftz.f32 	%f11, %f2, 0f3FB8AA3B;

	ex2.approx.ftz.f32 	%f15, %f11;



BB12_3:

	mul.ftz.f32 	%f12, %f1, %f1;

	mul.ftz.f32 	%f13, %f12, %f5;

	div.approx.ftz.f32 	%f14, %f15, %f13;

	st.param.f32	[func_retval0+0], %f14;

	ret;

}



	// .globl	_Z9BeckmannGff

.visible .func  (.param .b32 func_retval0) _Z9BeckmannGff(

	.param .b32 _Z9BeckmannGff_param_0,

	.param .b32 _Z9BeckmannGff_param_1

)

{

	.reg .pred 	%p<4>;

	.reg .f32 	%f<41>;





	ld.param.f32 	%f5, [_Z9BeckmannGff_param_0];

	ld.param.f32 	%f6, [_Z9BeckmannGff_param_1];

	abs.ftz.f32 	%f7, %f5;

	mov.f32 	%f40, 0f3F800000;

	sub.ftz.f32 	%f8, %f40, %f7;

	mul.ftz.f32 	%f9, %f8, 0f3F000000;

	sqrt.approx.ftz.f32 	%f10, %f9;

	setp.gt.ftz.f32	%p1, %f7, 0f3F11EB85;

	selp.f32	%f11, %f10, %f7, %p1;

	mul.ftz.f32 	%f12, %f11, %f11;

	mov.f32 	%f13, 0f3C94D2E9;

	mov.f32 	%f14, 0f3D53F941;

	fma.rn.ftz.f32 	%f15, %f14, %f12, %f13;

	mov.f32 	%f16, 0f3D3F841F;

	fma.rn.ftz.f32 	%f17, %f15, %f12, %f16;

	mov.f32 	%f18, 0f3D994929;

	fma.rn.ftz.f32 	%f19, %f17, %f12, %f18;

	mov.f32 	%f20, 0f3E2AAB94;

	fma.rn.ftz.f32 	%f21, %f19, %f12, %f20;

	mul.ftz.f32 	%f22, %f12, %f21;

	fma.rn.ftz.f32 	%f23, %f22, %f11, %f11;

	add.ftz.f32 	%f24, %f23, %f23;

	mov.f32 	%f25, 0f3FC90FDB;

	sub.ftz.f32 	%f26, %f25, %f23;

	selp.f32	%f27, %f24, %f26, %p1;

	mov.f32 	%f28, 0f40490FDB;

	sub.ftz.f32 	%f29, %f28, %f27;

	setp.lt.ftz.f32	%p2, %f5, 0f00000000;

	selp.f32	%f30, %f29, %f27, %p2;

	sin.approx.ftz.f32 	%f31, %f30;

	cos.approx.ftz.f32 	%f32, %f30;

	div.approx.ftz.f32 	%f33, %f31, %f32;

	mul.ftz.f32 	%f34, %f33, %f6;

	rcp.approx.ftz.f32 	%f1, %f34;

	setp.geu.ftz.f32	%p3, %f1, 0f3FCCCCCD;

	@%p3 bra 	BB13_2;



	mul.ftz.f32 	%f35, %f1, %f1;

	mul.ftz.f32 	%f36, %f35, 0f400B9581;

	fma.rn.ftz.f32 	%f37, %f1, 0f40623D71, %f36;

	fma.rn.ftz.f32 	%f38, %f1, 0f4011A9FC, 0f3F800000;

	fma.rn.ftz.f32 	%f39, %f35, 0f4024ED91, %f38;

	div.approx.ftz.f32 	%f40, %f37, %f39;



BB13_2:

	st.param.f32	[func_retval0+0], %f40;

	ret;

}



	// .globl	_Z14fresnelSchlickff

.visible .func  (.param .b32 func_retval0) _Z14fresnelSchlickff(

	.param .b32 _Z14fresnelSchlickff_param_0,

	.param .b32 _Z14fresnelSchlickff_param_1

)

{

	.reg .f32 	%f<11>;





	ld.param.f32 	%f1, [_Z14fresnelSchlickff_param_0];

	ld.param.f32 	%f2, [_Z14fresnelSchlickff_param_1];

	mov.f32 	%f3, 0f3F800000;

	sub.ftz.f32 	%f4, %f3, %f2;

	cvt.ftz.sat.f32.f32	%f5, %f4;

	lg2.approx.ftz.f32 	%f6, %f5;

	mul.ftz.f32 	%f7, %f6, 0f40A00000;

	ex2.approx.ftz.f32 	%f8, %f7;

	sub.ftz.f32 	%f9, %f3, %f1;

	fma.rn.ftz.f32 	%f10, %f9, %f8, %f1;

	st.param.f32	[func_retval0+0], %f10;

	ret;

}



	// .globl	_Z15getCookTorranceRK6float3S1_S1_fbfb

.visible .func  (.param .b32 func_retval0) _Z15getCookTorranceRK6float3S1_S1_fbfb(

	.param .b64 _Z15getCookTorranceRK6float3S1_S1_fbfb_param_0,

	.param .b64 _Z15getCookTorranceRK6float3S1_S1_fbfb_param_1,

	.param .b64 _Z15getCookTorranceRK6float3S1_S1_fbfb_param_2,

	.param .b32 _Z15getCookTorranceRK6float3S1_S1_fbfb_param_3,

	.param .b32 _Z15getCookTorranceRK6float3S1_S1_fbfb_param_4,

	.param .b32 _Z15getCookTorranceRK6float3S1_S1_fbfb_param_5,

	.param .b32 _Z15getCookTorranceRK6float3S1_S1_fbfb_param_6

)

{

	.reg .pred 	%p<16>;

	.reg .s16 	%rs<6>;

	.reg .f32 	%f<110>;

	.reg .s64 	%rd<4>;





	ld.param.u64 	%rd1, [_Z15getCookTorranceRK6float3S1_S1_fbfb_param_0];

	ld.param.u64 	%rd2, [_Z15getCookTorranceRK6float3S1_S1_fbfb_param_1];

	ld.param.u64 	%rd3, [_Z15getCookTorranceRK6float3S1_S1_fbfb_param_2];

	ld.param.f32 	%f21, [_Z15getCookTorranceRK6float3S1_S1_fbfb_param_3];

	ld.param.f32 	%f22, [_Z15getCookTorranceRK6float3S1_S1_fbfb_param_5];

	ld.param.s8 	%rs2, [_Z15getCookTorranceRK6float3S1_S1_fbfb_param_6];

	ld.param.s8 	%rs1, [_Z15getCookTorranceRK6float3S1_S1_fbfb_param_4];

	ld.f32 	%f24, [%rd2];

	ld.f32 	%f25, [%rd3];

	add.ftz.f32 	%f26, %f25, %f24;

	ld.f32 	%f27, [%rd2+4];

	ld.f32 	%f28, [%rd3+4];

	add.ftz.f32 	%f29, %f28, %f27;

	ld.f32 	%f30, [%rd2+8];

	ld.f32 	%f31, [%rd3+8];

	add.ftz.f32 	%f32, %f31, %f30;

	mul.ftz.f32 	%f33, %f29, %f29;

	fma.rn.ftz.f32 	%f34, %f26, %f26, %f33;

	fma.rn.ftz.f32 	%f35, %f32, %f32, %f34;

	sqrt.approx.ftz.f32 	%f36, %f35;

	rcp.approx.ftz.f32 	%f37, %f36;

	mul.ftz.f32 	%f38, %f26, %f37;

	mul.ftz.f32 	%f39, %f29, %f37;

	mul.ftz.f32 	%f40, %f32, %f37;

	ld.f32 	%f41, [%rd1];

	ld.f32 	%f42, [%rd1+4];

	mul.ftz.f32 	%f43, %f42, %f27;

	fma.rn.ftz.f32 	%f44, %f41, %f24, %f43;

	ld.f32 	%f45, [%rd1+8];

	fma.rn.ftz.f32 	%f1, %f45, %f30, %f44;

	mul.ftz.f32 	%f46, %f39, %f42;

	fma.rn.ftz.f32 	%f47, %f38, %f41, %f46;

	fma.rn.ftz.f32 	%f2, %f40, %f45, %f47;

	mul.ftz.f32 	%f48, %f39, %f27;

	fma.rn.ftz.f32 	%f49, %f38, %f24, %f48;

	fma.rn.ftz.f32 	%f50, %f40, %f30, %f49;

	setp.gt.ftz.f32	%p1, %f1, 0f00000000;

	setp.gt.ftz.f32	%p2, %f50, 0f00000000;

	and.pred  	%p3, %p1, %p2;

	setp.gt.ftz.f32	%p4, %f2, 0f00000000;

	and.pred  	%p5, %p3, %p4;

	mov.f32 	%f109, 0f00000000;

	@!%p5 bra 	BB15_11;

	bra.uni 	BB15_1;



BB15_1:

	and.b16  	%rs3, %rs1, 255;

	setp.eq.s16	%p6, %rs3, 0;

	mov.f32 	%f51, 0f3F800000;

	mov.f32 	%f107, %f51;

	@%p6 bra 	BB15_3;



	mov.f32 	%f52, 0f3F800000;

	sub.ftz.f32 	%f53, %f52, %f1;

	cvt.ftz.sat.f32.f32	%f54, %f53;

	lg2.approx.ftz.f32 	%f55, %f54;

	mul.ftz.f32 	%f56, %f55, 0f40A00000;

	ex2.approx.ftz.f32 	%f57, %f56;

	sub.ftz.f32 	%f58, %f52, %f22;

	fma.rn.ftz.f32 	%f59, %f58, %f57, %f22;

	cvt.ftz.sat.f32.f32	%f3, %f59;

	mov.f32 	%f107, %f3;



BB15_3:

	mov.f32 	%f4, %f107;

	mul.ftz.f32 	%f5, %f2, %f2;

	rcp.approx.ftz.f32 	%f61, %f5;

	sub.ftz.f32 	%f62, %f51, %f61;

	mul.ftz.f32 	%f6, %f21, %f21;

	div.approx.ftz.f32 	%f7, %f62, %f6;

	setp.gt.ftz.f32	%p7, %f62, 0fB727C5AC;

	mov.f32 	%f106, %f51;

	@%p7 bra 	BB15_6;



	setp.gt.ftz.f32	%p8, %f6, 0f00000000;

	setp.gt.ftz.f32	%p9, %f7, 0fC3960000;

	and.pred  	%p10, %p8, %p9;

	mov.f32 	%f106, 0f00000000;

	@!%p10 bra 	BB15_6;

	bra.uni 	BB15_5;



BB15_5:

	mul.ftz.f32 	%f64, %f7, 0f3FB8AA3B;

	ex2.approx.ftz.f32 	%f106, %f64;



BB15_6:

	mul.ftz.f32 	%f66, %f5, %f5;

	mul.ftz.f32 	%f67, %f6, %f66;

	div.approx.ftz.f32 	%f10, %f106, %f67;

	abs.ftz.f32 	%f68, %f1;

	sub.ftz.f32 	%f69, %f51, %f68;

	mul.ftz.f32 	%f70, %f69, 0f3F000000;

	sqrt.approx.ftz.f32 	%f71, %f70;

	setp.gt.ftz.f32	%p11, %f68, 0f3F11EB85;

	selp.f32	%f72, %f71, %f68, %p11;

	mul.ftz.f32 	%f73, %f72, %f72;

	mov.f32 	%f74, 0f3C94D2E9;

	mov.f32 	%f75, 0f3D53F941;

	fma.rn.ftz.f32 	%f76, %f75, %f73, %f74;

	mov.f32 	%f77, 0f3D3F841F;

	fma.rn.ftz.f32 	%f78, %f76, %f73, %f77;

	mov.f32 	%f79, 0f3D994929;

	fma.rn.ftz.f32 	%f80, %f78, %f73, %f79;

	mov.f32 	%f81, 0f3E2AAB94;

	fma.rn.ftz.f32 	%f82, %f80, %f73, %f81;

	mul.ftz.f32 	%f83, %f73, %f82;

	fma.rn.ftz.f32 	%f84, %f83, %f72, %f72;

	add.ftz.f32 	%f85, %f84, %f84;

	mov.f32 	%f86, 0f3FC90FDB;

	sub.ftz.f32 	%f87, %f86, %f84;

	selp.f32	%f88, %f85, %f87, %p11;

	mov.f32 	%f89, 0f40490FDB;

	sub.ftz.f32 	%f90, %f89, %f88;

	setp.lt.ftz.f32	%p12, %f1, 0f00000000;

	selp.f32	%f91, %f90, %f88, %p12;

	sin.approx.ftz.f32 	%f92, %f91;

	cos.approx.ftz.f32 	%f93, %f91;

	div.approx.ftz.f32 	%f94, %f92, %f93;

	mul.ftz.f32 	%f95, %f94, %f21;

	rcp.approx.ftz.f32 	%f11, %f95;

	setp.geu.ftz.f32	%p13, %f11, 0f3FCCCCCD;

	mov.f32 	%f105, %f51;

	@%p13 bra 	BB15_8;



	mul.ftz.f32 	%f96, %f11, %f11;

	mul.ftz.f32 	%f97, %f96, 0f400B9581;

	fma.rn.ftz.f32 	%f98, %f11, 0f40623D71, %f97;

	fma.rn.ftz.f32 	%f99, %f11, 0f4011A9FC, 0f3F800000;

	fma.rn.ftz.f32 	%f100, %f96, 0f4024ED91, %f99;

	div.approx.ftz.f32 	%f105, %f98, %f100;



BB15_8:

	mul.ftz.f32 	%f101, %f1, 0f41490FDB;

	mul.ftz.f32 	%f102, %f10, %f105;

	div.approx.ftz.f32 	%f108, %f102, %f101;

	and.b16  	%rs4, %rs2, 255;

	setp.eq.s16	%p14, %rs4, 0;

	@%p14 bra 	BB15_10;



	cvt.ftz.sat.f32.f32	%f108, %f108;



BB15_10:

	mul.ftz.f32 	%f109, %f4, %f108;



BB15_11:

	and.b16  	%rs5, %rs2, 255;

	setp.eq.s16	%p15, %rs5, 0;

	@%p15 bra 	BB15_13;



	cvt.ftz.sat.f32.f32	%f109, %f109;



BB15_13:

	st.param.f32	[func_retval0+0], %f109;

	ret;

}



	// .globl	_Z18getCookTorrancePdfRK6float3S1_S1_f

.visible .func  (.param .b32 func_retval0) _Z18getCookTorrancePdfRK6float3S1_S1_f(

	.param .b64 _Z18getCookTorrancePdfRK6float3S1_S1_f_param_0,

	.param .b64 _Z18getCookTorrancePdfRK6float3S1_S1_f_param_1,

	.param .b64 _Z18getCookTorrancePdfRK6float3S1_S1_f_param_2,

	.param .b32 _Z18getCookTorrancePdfRK6float3S1_S1_f_param_3

)

{

	.reg .pred 	%p<8>;

	.reg .f32 	%f<36>;

	.reg .s64 	%rd<4>;





	ld.param.u64 	%rd1, [_Z18getCookTorrancePdfRK6float3S1_S1_f_param_0];

	ld.param.u64 	%rd2, [_Z18getCookTorrancePdfRK6float3S1_S1_f_param_1];

	ld.param.u64 	%rd3, [_Z18getCookTorrancePdfRK6float3S1_S1_f_param_2];

	ld.param.f32 	%f11, [_Z18getCookTorrancePdfRK6float3S1_S1_f_param_3];

	ld.f32 	%f12, [%rd3];

	ld.f32 	%f13, [%rd1];

	ld.f32 	%f14, [%rd3+4];

	ld.f32 	%f15, [%rd1+4];

	mul.ftz.f32 	%f16, %f15, %f14;

	fma.rn.ftz.f32 	%f17, %f13, %f12, %f16;

	ld.f32 	%f18, [%rd3+8];

	ld.f32 	%f19, [%rd1+8];

	fma.rn.ftz.f32 	%f1, %f19, %f18, %f17;

	mul.ftz.f32 	%f2, %f1, %f1;

	ld.f32 	%f20, [%rd2];

	ld.f32 	%f21, [%rd2+4];

	mul.ftz.f32 	%f22, %f21, %f14;

	fma.rn.ftz.f32 	%f23, %f20, %f12, %f22;

	ld.f32 	%f24, [%rd2+8];

	fma.rn.ftz.f32 	%f3, %f24, %f18, %f23;

	mul.ftz.f32 	%f4, %f11, %f11;

	setp.gt.ftz.f32	%p1, %f3, 0f00000000;

	setp.gt.ftz.f32	%p2, %f1, 0f00000000;

	and.pred  	%p3, %p1, %p2;

	mov.f32 	%f35, 0f00000000;

	@!%p3 bra 	BB16_5;

	bra.uni 	BB16_1;



BB16_1:

	rcp.approx.ftz.f32 	%f26, %f2;

	mov.f32 	%f34, 0f3F800000;

	sub.ftz.f32 	%f27, %f34, %f26;

	div.approx.ftz.f32 	%f5, %f27, %f4;

	setp.gt.ftz.f32	%p4, %f27, 0fB727C5AC;

	@%p4 bra 	BB16_4;



	setp.gt.ftz.f32	%p5, %f4, 0f00000000;

	setp.gt.ftz.f32	%p6, %f5, 0fC3960000;

	and.pred  	%p7, %p5, %p6;

	mov.f32 	%f34, 0f00000000;

	@!%p7 bra 	BB16_4;

	bra.uni 	BB16_3;



BB16_3:

	mul.ftz.f32 	%f29, %f5, 0f3FB8AA3B;

	ex2.approx.ftz.f32 	%f34, %f29;



BB16_4:

	mul.ftz.f32 	%f30, %f3, 0f41490FDB;

	mul.ftz.f32 	%f31, %f4, %f30;

	mul.ftz.f32 	%f32, %f2, %f31;

	mul.ftz.f32 	%f33, %f1, %f32;

	div.approx.ftz.f32 	%f35, %f34, %f33;



BB16_5:

	st.param.f32	[func_retval0+0], %f35;

	ret;

}



	// .globl	_Z7getWardRK6float3S1_S1_S1_fbfffb

.visible .func  (.param .b32 func_retval0) _Z7getWardRK6float3S1_S1_S1_fbfffb(

	.param .b64 _Z7getWardRK6float3S1_S1_S1_fbfffb_param_0,

	.param .b64 _Z7getWardRK6float3S1_S1_S1_fbfffb_param_1,

	.param .b64 _Z7getWardRK6float3S1_S1_S1_fbfffb_param_2,

	.param .b64 _Z7getWardRK6float3S1_S1_S1_fbfffb_param_3,

	.param .b32 _Z7getWardRK6float3S1_S1_S1_fbfffb_param_4,

	.param .b32 _Z7getWardRK6float3S1_S1_S1_fbfffb_param_5,

	.param .b32 _Z7getWardRK6float3S1_S1_S1_fbfffb_param_6,

	.param .b32 _Z7getWardRK6float3S1_S1_S1_fbfffb_param_7,

	.param .b32 _Z7getWardRK6float3S1_S1_S1_fbfffb_param_8,

	.param .b32 _Z7getWardRK6float3S1_S1_S1_fbfffb_param_9

)

{

	.reg .pred 	%p<15>;

	.reg .s16 	%rs<5>;

	.reg .f32 	%f<142>;

	.reg .s64 	%rd<5>;





	ld.param.u64 	%rd1, [_Z7getWardRK6float3S1_S1_S1_fbfffb_param_0];

	ld.param.u64 	%rd2, [_Z7getWardRK6float3S1_S1_S1_fbfffb_param_1];

	ld.param.u64 	%rd3, [_Z7getWardRK6float3S1_S1_S1_fbfffb_param_2];

	ld.param.u64 	%rd4, [_Z7getWardRK6float3S1_S1_S1_fbfffb_param_3];

	ld.param.f32 	%f14, [_Z7getWardRK6float3S1_S1_S1_fbfffb_param_4];

	ld.param.f32 	%f15, [_Z7getWardRK6float3S1_S1_S1_fbfffb_param_6];

	ld.param.f32 	%f16, [_Z7getWardRK6float3S1_S1_S1_fbfffb_param_7];

	ld.param.f32 	%f17, [_Z7getWardRK6float3S1_S1_S1_fbfffb_param_8];

	ld.param.s8 	%rs2, [_Z7getWardRK6float3S1_S1_S1_fbfffb_param_9];

	ld.param.s8 	%rs1, [_Z7getWardRK6float3S1_S1_S1_fbfffb_param_5];

	setp.gt.ftz.f32	%p1, %f16, 0f00000000;

	setp.lt.ftz.f32	%p2, %f16, 0f3F800000;

	and.pred  	%p3, %p1, %p2;

	mov.f32 	%f141, 0f00000000;

	@!%p3 bra 	BB17_8;

	bra.uni 	BB17_1;



BB17_1:

	mov.f32 	%f20, 0f3F800000;

	sub.ftz.f32 	%f21, %f20, %f16;

	div.approx.ftz.f32 	%f22, %f16, %f21;

	min.ftz.f32 	%f23, %f22, %f20;

	mul.ftz.f32 	%f24, %f23, %f14;

	rcp.approx.ftz.f32 	%f25, %f22;

	min.ftz.f32 	%f26, %f25, %f20;

	mul.ftz.f32 	%f27, %f26, %f14;

	ld.f32 	%f28, [%rd4];

	ld.f32 	%f29, [%rd1];

	ld.f32 	%f30, [%rd4+4];

	mul.ftz.f32 	%f31, %f29, %f30;

	ld.f32 	%f32, [%rd4+8];

	mul.ftz.f32 	%f33, %f29, %f32;

	ld.f32 	%f34, [%rd1+4];

	mul.ftz.f32 	%f35, %f34, %f28;

	mul.ftz.f32 	%f36, %f34, %f30;

	mul.ftz.f32 	%f37, %f34, %f32;

	ld.f32 	%f38, [%rd1+8];

	mul.ftz.f32 	%f39, %f38, %f28;

	mul.ftz.f32 	%f40, %f38, %f30;

	mul.ftz.f32 	%f41, %f38, %f32;

	fma.rn.ftz.f32 	%f42, %f29, %f28, %f36;

	fma.rn.ftz.f32 	%f43, %f38, %f32, %f42;

	mul.ftz.f32 	%f44, %f34, %f34;

	mul.ftz.f32 	%f45, %f38, %f38;

	add.ftz.f32 	%f46, %f44, %f45;

	mul.ftz.f32 	%f47, %f28, %f46;

	add.ftz.f32 	%f48, %f36, %f41;

	mul.ftz.f32 	%f49, %f48, %f29;

	sub.ftz.f32 	%f50, %f47, %f49;

	cos.approx.ftz.f32 	%f51, %f17;

	mul.ftz.f32 	%f52, %f51, %f50;

	sub.ftz.f32 	%f53, %f37, %f40;

	sin.approx.ftz.f32 	%f54, %f17;

	fma.rn.ftz.f32 	%f55, %f53, %f54, %f52;

	fma.rn.ftz.f32 	%f56, %f43, %f29, %f55;

	fma.rn.ftz.f32 	%f57, %f29, %f29, %f45;

	mul.ftz.f32 	%f58, %f30, %f57;

	fma.rn.ftz.f32 	%f59, %f29, %f28, %f41;

	mul.ftz.f32 	%f60, %f59, %f34;

	sub.ftz.f32 	%f61, %f58, %f60;

	mul.ftz.f32 	%f62, %f51, %f61;

	sub.ftz.f32 	%f63, %f39, %f33;

	fma.rn.ftz.f32 	%f64, %f63, %f54, %f62;

	fma.rn.ftz.f32 	%f65, %f43, %f34, %f64;

	fma.rn.ftz.f32 	%f66, %f29, %f29, %f44;

	mul.ftz.f32 	%f67, %f32, %f66;

	mul.ftz.f32 	%f68, %f42, %f38;

	sub.ftz.f32 	%f69, %f67, %f68;

	mul.ftz.f32 	%f70, %f51, %f69;

	sub.ftz.f32 	%f71, %f31, %f35;

	fma.rn.ftz.f32 	%f72, %f71, %f54, %f70;

	fma.rn.ftz.f32 	%f73, %f43, %f38, %f72;

	mul.ftz.f32 	%f74, %f38, %f65;

	mul.ftz.f32 	%f75, %f34, %f73;

	sub.ftz.f32 	%f76, %f74, %f75;

	mul.ftz.f32 	%f77, %f29, %f73;

	mul.ftz.f32 	%f78, %f56, %f38;

	sub.ftz.f32 	%f79, %f77, %f78;

	mul.ftz.f32 	%f80, %f56, %f34;

	mul.ftz.f32 	%f81, %f65, %f29;

	sub.ftz.f32 	%f82, %f80, %f81;

	mul.ftz.f32 	%f83, %f79, %f79;

	fma.rn.ftz.f32 	%f84, %f76, %f76, %f83;

	fma.rn.ftz.f32 	%f85, %f82, %f82, %f84;

	sqrt.approx.ftz.f32 	%f86, %f85;

	rcp.approx.ftz.f32 	%f87, %f86;

	mul.ftz.f32 	%f88, %f76, %f87;

	mul.ftz.f32 	%f89, %f79, %f87;

	mul.ftz.f32 	%f90, %f82, %f87;

	ld.f32 	%f91, [%rd2];

	ld.f32 	%f92, [%rd3];

	add.ftz.f32 	%f93, %f92, %f91;

	ld.f32 	%f94, [%rd2+4];

	ld.f32 	%f95, [%rd3+4];

	add.ftz.f32 	%f96, %f95, %f94;

	ld.f32 	%f97, [%rd2+8];

	ld.f32 	%f98, [%rd3+8];

	add.ftz.f32 	%f99, %f98, %f97;

	mul.ftz.f32 	%f100, %f96, %f96;

	fma.rn.ftz.f32 	%f101, %f93, %f93, %f100;

	fma.rn.ftz.f32 	%f102, %f99, %f99, %f101;

	sqrt.approx.ftz.f32 	%f103, %f102;

	rcp.approx.ftz.f32 	%f104, %f103;

	mul.ftz.f32 	%f105, %f93, %f104;

	mul.ftz.f32 	%f106, %f96, %f104;

	mul.ftz.f32 	%f107, %f99, %f104;

	mul.ftz.f32 	%f108, %f65, %f106;

	fma.rn.ftz.f32 	%f109, %f56, %f105, %f108;

	fma.rn.ftz.f32 	%f110, %f73, %f107, %f109;

	div.approx.ftz.f32 	%f1, %f110, %f24;

	mul.ftz.f32 	%f111, %f89, %f106;

	fma.rn.ftz.f32 	%f112, %f88, %f105, %f111;

	fma.rn.ftz.f32 	%f113, %f90, %f107, %f112;

	div.approx.ftz.f32 	%f2, %f113, %f27;

	mul.ftz.f32 	%f114, %f106, %f34;

	fma.rn.ftz.f32 	%f115, %f105, %f29, %f114;

	fma.rn.ftz.f32 	%f3, %f107, %f38, %f115;

	mul.ftz.f32 	%f116, %f34, %f94;

	fma.rn.ftz.f32 	%f117, %f29, %f91, %f116;

	fma.rn.ftz.f32 	%f4, %f38, %f97, %f117;

	mul.ftz.f32 	%f118, %f95, %f34;

	fma.rn.ftz.f32 	%f119, %f92, %f29, %f118;

	fma.rn.ftz.f32 	%f120, %f98, %f38, %f119;

	mul.ftz.f32 	%f121, %f4, %f120;

	mul.ftz.f32 	%f122, %f24, 0f40490FDB;

	mul.ftz.f32 	%f123, %f122, %f27;

	sqrt.approx.ftz.f32 	%f124, %f121;

	mul.ftz.f32 	%f5, %f123, %f124;

	setp.gt.ftz.f32	%p4, %f121, 0f00000000;

	setp.gt.ftz.f32	%p5, %f5, 0f00000000;

	and.pred  	%p6, %p4, %p5;

	setp.gt.ftz.f32	%p7, %f3, 0f00000000;

	and.pred  	%p8, %p6, %p7;

	setp.gt.ftz.f32	%p9, %f120, 0f00000000;

	and.pred  	%p10, %p8, %p9;

	mov.f32 	%f141, 0f00000000;

	@!%p10 bra 	BB17_6;

	bra.uni 	BB17_2;



BB17_2:

	mul.ftz.f32 	%f125, %f3, %f3;

	mul.ftz.f32 	%f126, %f2, %f2;

	fma.rn.ftz.f32 	%f127, %f1, %f1, %f126;

	neg.ftz.f32 	%f128, %f127;

	div.approx.ftz.f32 	%f6, %f128, %f125;

	setp.gt.ftz.f32	%p11, %f3, 0f3F7FFF58;

	@%p11 bra 	BB17_5;

	bra.uni 	BB17_3;



BB17_5:

	rcp.approx.ftz.f32 	%f141, %f5;

	bra.uni 	BB17_6;



BB17_3:

	setp.leu.ftz.f32	%p12, %f6, 0fC3960000;

	@%p12 bra 	BB17_6;



	mul.ftz.f32 	%f130, %f6, 0f3FB8AA3B;

	ex2.approx.ftz.f32 	%f131, %f130;

	div.approx.ftz.f32 	%f141, %f131, %f5;



BB17_6:

	and.b16  	%rs3, %rs1, 255;

	setp.eq.s16	%p13, %rs3, 0;

	@%p13 bra 	BB17_8;



	sub.ftz.f32 	%f133, %f20, %f4;

	cvt.ftz.sat.f32.f32	%f134, %f133;

	lg2.approx.ftz.f32 	%f135, %f134;

	mul.ftz.f32 	%f136, %f135, 0f40A00000;

	ex2.approx.ftz.f32 	%f137, %f136;

	sub.ftz.f32 	%f138, %f20, %f15;

	fma.rn.ftz.f32 	%f139, %f138, %f137, %f15;

	cvt.ftz.sat.f32.f32	%f140, %f139;

	mul.ftz.f32 	%f141, %f141, %f140;



BB17_8:

	and.b16  	%rs4, %rs2, 255;

	setp.eq.s16	%p14, %rs4, 0;

	@%p14 bra 	BB17_10;



	cvt.ftz.sat.f32.f32	%f141, %f141;



BB17_10:

	st.param.f32	[func_retval0+0], %f141;

	ret;

}



	// .globl	_Z10getWardPdfRK6float3S1_S1_S1_ff

.visible .func  (.param .b32 func_retval0) _Z10getWardPdfRK6float3S1_S1_S1_ff(

	.param .b64 _Z10getWardPdfRK6float3S1_S1_S1_ff_param_0,

	.param .b64 _Z10getWardPdfRK6float3S1_S1_S1_ff_param_1,

	.param .b64 _Z10getWardPdfRK6float3S1_S1_S1_ff_param_2,

	.param .b64 _Z10getWardPdfRK6float3S1_S1_S1_ff_param_3,

	.param .b32 _Z10getWardPdfRK6float3S1_S1_S1_ff_param_4,

	.param .b32 _Z10getWardPdfRK6float3S1_S1_S1_ff_param_5

)

{

	.reg .pred 	%p<13>;

	.reg .f32 	%f<91>;

	.reg .s64 	%rd<5>;





	ld.param.u64 	%rd1, [_Z10getWardPdfRK6float3S1_S1_S1_ff_param_0];

	ld.param.u64 	%rd2, [_Z10getWardPdfRK6float3S1_S1_S1_ff_param_1];

	ld.param.u64 	%rd3, [_Z10getWardPdfRK6float3S1_S1_S1_ff_param_2];

	ld.param.u64 	%rd4, [_Z10getWardPdfRK6float3S1_S1_S1_ff_param_3];

	ld.param.f32 	%f10, [_Z10getWardPdfRK6float3S1_S1_S1_ff_param_4];

	ld.param.f32 	%f11, [_Z10getWardPdfRK6float3S1_S1_S1_ff_param_5];

	setp.gt.ftz.f32	%p1, %f11, 0f00000000;

	setp.lt.ftz.f32	%p2, %f11, 0f3F800000;

	and.pred  	%p3, %p1, %p2;

	mov.f32 	%f90, 0f00000000;

	@!%p3 bra 	BB18_6;

	bra.uni 	BB18_1;



BB18_1:

	mov.f32 	%f14, 0f3F800000;

	sub.ftz.f32 	%f15, %f14, %f11;

	div.approx.ftz.f32 	%f16, %f11, %f15;

	min.ftz.f32 	%f17, %f16, %f14;

	mul.ftz.f32 	%f18, %f17, %f10;

	rcp.approx.ftz.f32 	%f19, %f16;

	min.ftz.f32 	%f20, %f19, %f14;

	mul.ftz.f32 	%f21, %f20, %f10;

	ld.f32 	%f22, [%rd1+8];

	ld.f32 	%f23, [%rd4+4];

	mul.ftz.f32 	%f24, %f23, %f22;

	ld.f32 	%f25, [%rd1+4];

	ld.f32 	%f26, [%rd4+8];

	mul.ftz.f32 	%f27, %f26, %f25;

	sub.ftz.f32 	%f28, %f24, %f27;

	ld.f32 	%f29, [%rd1];

	mul.ftz.f32 	%f30, %f26, %f29;

	ld.f32 	%f31, [%rd4];

	mul.ftz.f32 	%f32, %f31, %f22;

	sub.ftz.f32 	%f33, %f30, %f32;

	mul.ftz.f32 	%f34, %f31, %f25;

	mul.ftz.f32 	%f35, %f23, %f29;

	sub.ftz.f32 	%f36, %f34, %f35;

	mul.ftz.f32 	%f37, %f33, %f33;

	fma.rn.ftz.f32 	%f38, %f28, %f28, %f37;

	fma.rn.ftz.f32 	%f39, %f36, %f36, %f38;

	sqrt.approx.ftz.f32 	%f40, %f39;

	rcp.approx.ftz.f32 	%f41, %f40;

	mul.ftz.f32 	%f42, %f28, %f41;

	mul.ftz.f32 	%f43, %f33, %f41;

	mul.ftz.f32 	%f44, %f36, %f41;

	ld.f32 	%f45, [%rd2];

	ld.f32 	%f46, [%rd3];

	add.ftz.f32 	%f47, %f46, %f45;

	ld.f32 	%f48, [%rd2+4];

	ld.f32 	%f49, [%rd3+4];

	add.ftz.f32 	%f50, %f49, %f48;

	ld.f32 	%f51, [%rd2+8];

	ld.f32 	%f52, [%rd3+8];

	add.ftz.f32 	%f53, %f52, %f51;

	mul.ftz.f32 	%f54, %f50, %f50;

	fma.rn.ftz.f32 	%f55, %f47, %f47, %f54;

	fma.rn.ftz.f32 	%f56, %f53, %f53, %f55;

	sqrt.approx.ftz.f32 	%f57, %f56;

	rcp.approx.ftz.f32 	%f58, %f57;

	mul.ftz.f32 	%f59, %f47, %f58;

	mul.ftz.f32 	%f60, %f50, %f58;

	mul.ftz.f32 	%f61, %f53, %f58;

	mul.ftz.f32 	%f62, %f60, %f23;

	fma.rn.ftz.f32 	%f63, %f59, %f31, %f62;

	fma.rn.ftz.f32 	%f64, %f61, %f26, %f63;

	div.approx.ftz.f32 	%f1, %f64, %f18;

	mul.ftz.f32 	%f65, %f43, %f60;

	fma.rn.ftz.f32 	%f66, %f42, %f59, %f65;

	fma.rn.ftz.f32 	%f67, %f44, %f61, %f66;

	div.approx.ftz.f32 	%f2, %f67, %f21;

	mul.ftz.f32 	%f68, %f60, %f25;

	fma.rn.ftz.f32 	%f69, %f59, %f29, %f68;

	fma.rn.ftz.f32 	%f3, %f61, %f22, %f69;

	mul.ftz.f32 	%f70, %f25, %f48;

	fma.rn.ftz.f32 	%f71, %f29, %f45, %f70;

	fma.rn.ftz.f32 	%f72, %f22, %f51, %f71;

	mul.ftz.f32 	%f73, %f49, %f25;

	fma.rn.ftz.f32 	%f74, %f46, %f29, %f73;

	fma.rn.ftz.f32 	%f75, %f52, %f22, %f74;

	mul.ftz.f32 	%f4, %f3, %f3;

	mul.ftz.f32 	%f76, %f72, %f75;

	mul.ftz.f32 	%f77, %f18, 0f41490FDB;

	mul.ftz.f32 	%f78, %f77, %f21;

	mul.ftz.f32 	%f79, %f60, %f48;

	fma.rn.ftz.f32 	%f80, %f59, %f45, %f79;

	fma.rn.ftz.f32 	%f81, %f61, %f51, %f80;

	mul.ftz.f32 	%f82, %f78, %f81;

	mul.ftz.f32 	%f83, %f4, %f82;

	mul.ftz.f32 	%f5, %f3, %f83;

	setp.gt.ftz.f32	%p4, %f76, 0f00000000;

	setp.gt.ftz.f32	%p5, %f5, 0f00000000;

	and.pred  	%p6, %p4, %p5;

	setp.gt.ftz.f32	%p7, %f3, 0f00000000;

	and.pred  	%p8, %p6, %p7;

	setp.gt.ftz.f32	%p9, %f75, 0f00000000;

	and.pred  	%p10, %p8, %p9;

	@!%p10 bra 	BB18_6;

	bra.uni 	BB18_2;



BB18_2:

	mul.ftz.f32 	%f84, %f2, %f2;

	fma.rn.ftz.f32 	%f85, %f1, %f1, %f84;

	neg.ftz.f32 	%f86, %f85;

	div.approx.ftz.f32 	%f6, %f86, %f4;

	setp.gt.ftz.f32	%p11, %f3, 0f3F7FFF58;

	@%p11 bra 	BB18_5;

	bra.uni 	BB18_3;



BB18_5:

	rcp.approx.ftz.f32 	%f90, %f5;

	bra.uni 	BB18_6;



BB18_3:

	setp.leu.ftz.f32	%p12, %f6, 0fC3960000;

	@%p12 bra 	BB18_6;



	mul.ftz.f32 	%f88, %f6, 0f3FB8AA3B;

	ex2.approx.ftz.f32 	%f89, %f88;

	div.approx.ftz.f32 	%f90, %f89, %f5;



BB18_6:

	st.param.f32	[func_retval0+0], %f90;

	ret;

}



	// .globl	_Z12getOrenNayarRK6float2RK6float3S4_S4_

.visible .func  (.param .b32 func_retval0) _Z12getOrenNayarRK6float2RK6float3S4_S4_(

	.param .b64 _Z12getOrenNayarRK6float2RK6float3S4_S4__param_0,

	.param .b64 _Z12getOrenNayarRK6float2RK6float3S4_S4__param_1,

	.param .b64 _Z12getOrenNayarRK6float2RK6float3S4_S4__param_2,

	.param .b64 _Z12getOrenNayarRK6float2RK6float3S4_S4__param_3

)

{

	.reg .pred 	%p<3>;

	.reg .f32 	%f<70>;

	.reg .s64 	%rd<5>;





	ld.param.u64 	%rd4, [_Z12getOrenNayarRK6float2RK6float3S4_S4__param_0];

	ld.param.u64 	%rd1, [_Z12getOrenNayarRK6float2RK6float3S4_S4__param_1];

	ld.param.u64 	%rd2, [_Z12getOrenNayarRK6float2RK6float3S4_S4__param_2];

	ld.param.u64 	%rd3, [_Z12getOrenNayarRK6float2RK6float3S4_S4__param_3];

	ld.v2.f32 	{%f10, %f11}, [%rd4];

	mov.f32 	%f69, %f10;

	setp.eq.ftz.f32	%p1, %f11, 0f00000000;

	@%p1 bra 	BB19_4;



	ld.f32 	%f13, [%rd3];

	ld.f32 	%f14, [%rd1];

	ld.f32 	%f15, [%rd3+4];

	ld.f32 	%f16, [%rd1+4];

	mul.ftz.f32 	%f17, %f16, %f15;

	fma.rn.ftz.f32 	%f18, %f14, %f13, %f17;

	ld.f32 	%f19, [%rd3+8];

	ld.f32 	%f20, [%rd1+8];

	fma.rn.ftz.f32 	%f21, %f20, %f19, %f18;

	ld.f32 	%f22, [%rd2];

	ld.f32 	%f23, [%rd2+4];

	mul.ftz.f32 	%f24, %f16, %f23;

	fma.rn.ftz.f32 	%f25, %f14, %f22, %f24;

	ld.f32 	%f26, [%rd2+8];

	fma.rn.ftz.f32 	%f27, %f20, %f26, %f25;

	cvt.ftz.sat.f32.f32	%f28, %f21;

	cvt.ftz.sat.f32.f32	%f29, %f27;

	mul.ftz.f32 	%f30, %f28, %f28;

	mul.ftz.f32 	%f31, %f29, %f29;

	mov.f32 	%f68, 0f3F800000;

	sub.ftz.f32 	%f32, %f68, %f30;

	sub.ftz.f32 	%f33, %f68, %f31;

	mul.ftz.f32 	%f3, %f32, %f33;

	mul.ftz.f32 	%f34, %f28, %f14;

	mul.ftz.f32 	%f35, %f28, %f16;

	mul.ftz.f32 	%f36, %f28, %f20;

	sub.ftz.f32 	%f37, %f13, %f34;

	sub.ftz.f32 	%f38, %f15, %f35;

	sub.ftz.f32 	%f39, %f19, %f36;

	mul.ftz.f32 	%f40, %f38, %f38;

	fma.rn.ftz.f32 	%f41, %f37, %f37, %f40;

	fma.rn.ftz.f32 	%f42, %f39, %f39, %f41;

	sqrt.approx.ftz.f32 	%f43, %f42;

	rcp.approx.ftz.f32 	%f44, %f43;

	mul.ftz.f32 	%f45, %f37, %f44;

	mul.ftz.f32 	%f46, %f38, %f44;

	mul.ftz.f32 	%f47, %f39, %f44;

	mul.ftz.f32 	%f48, %f29, %f14;

	mul.ftz.f32 	%f49, %f29, %f16;

	mul.ftz.f32 	%f50, %f29, %f20;

	sub.ftz.f32 	%f51, %f22, %f48;

	sub.ftz.f32 	%f52, %f23, %f49;

	sub.ftz.f32 	%f53, %f26, %f50;

	mul.ftz.f32 	%f54, %f52, %f52;

	fma.rn.ftz.f32 	%f55, %f51, %f51, %f54;

	fma.rn.ftz.f32 	%f56, %f53, %f53, %f55;

	sqrt.approx.ftz.f32 	%f57, %f56;

	rcp.approx.ftz.f32 	%f58, %f57;

	mul.ftz.f32 	%f59, %f51, %f58;

	mul.ftz.f32 	%f60, %f52, %f58;

	mul.ftz.f32 	%f61, %f53, %f58;

	mul.ftz.f32 	%f62, %f46, %f60;

	fma.rn.ftz.f32 	%f63, %f45, %f59, %f62;

	fma.rn.ftz.f32 	%f4, %f47, %f61, %f63;

	max.ftz.f32 	%f5, %f28, %f29;

	setp.leu.ftz.f32	%p2, %f5, 0f00000000;

	@%p2 bra 	BB19_3;



	cvt.ftz.sat.f32.f32	%f64, %f4;

	sqrt.approx.ftz.f32 	%f65, %f3;

	mul.ftz.f32 	%f66, %f64, %f65;

	div.approx.ftz.f32 	%f68, %f66, %f5;



BB19_3:

	fma.rn.ftz.f32 	%f69, %f68, %f11, %f10;



BB19_4:

	cvt.ftz.sat.f32.f32	%f67, %f69;

	st.param.f32	[func_retval0+0], %f67;

	ret;

}



	// .globl	_Z20getKajiyaKaySpelwlarRK6float3S1_S1_ff

.visible .func  (.param .b32 func_retval0) _Z20getKajiyaKaySpelwlarRK6float3S1_S1_ff(

	.param .b64 _Z20getKajiyaKaySpelwlarRK6float3S1_S1_ff_param_0,

	.param .b64 _Z20getKajiyaKaySpelwlarRK6float3S1_S1_ff_param_1,

	.param .b64 _Z20getKajiyaKaySpelwlarRK6float3S1_S1_ff_param_2,

	.param .b32 _Z20getKajiyaKaySpelwlarRK6float3S1_S1_ff_param_3,

	.param .b32 _Z20getKajiyaKaySpelwlarRK6float3S1_S1_ff_param_4

)

{

	.reg .f32 	%f<46>;

	.reg .s64 	%rd<4>;





	ld.param.u64 	%rd1, [_Z20getKajiyaKaySpelwlarRK6float3S1_S1_ff_param_0];

	ld.param.u64 	%rd2, [_Z20getKajiyaKaySpelwlarRK6float3S1_S1_ff_param_1];

	ld.param.u64 	%rd3, [_Z20getKajiyaKaySpelwlarRK6float3S1_S1_ff_param_2];

	ld.param.f32 	%f1, [_Z20getKajiyaKaySpelwlarRK6float3S1_S1_ff_param_3];

	ld.param.f32 	%f2, [_Z20getKajiyaKaySpelwlarRK6float3S1_S1_ff_param_4];

	ld.f32 	%f3, [%rd2];

	ld.f32 	%f4, [%rd2+4];

	ld.f32 	%f5, [%rd2+8];

	ld.f32 	%f6, [%rd1];

	fma.rn.ftz.f32 	%f7, %f3, %f2, %f6;

	ld.f32 	%f8, [%rd1+4];

	fma.rn.ftz.f32 	%f9, %f4, %f2, %f8;

	ld.f32 	%f10, [%rd1+8];

	fma.rn.ftz.f32 	%f11, %f5, %f2, %f10;

	mul.ftz.f32 	%f12, %f9, %f9;

	fma.rn.ftz.f32 	%f13, %f7, %f7, %f12;

	fma.rn.ftz.f32 	%f14, %f11, %f11, %f13;

	sqrt.approx.ftz.f32 	%f15, %f14;

	rcp.approx.ftz.f32 	%f16, %f15;

	mul.ftz.f32 	%f17, %f7, %f16;

	mul.ftz.f32 	%f18, %f9, %f16;

	mul.ftz.f32 	%f19, %f11, %f16;

	ld.f32 	%f20, [%rd3];

	ld.f32 	%f21, [%rd3+4];

	mul.ftz.f32 	%f22, %f18, %f21;

	fma.rn.ftz.f32 	%f23, %f17, %f20, %f22;

	ld.f32 	%f24, [%rd3+8];

	fma.rn.ftz.f32 	%f25, %f19, %f24, %f23;

	mul.ftz.f32 	%f26, %f25, %f25;

	mov.f32 	%f27, 0f3F800000;

	sub.ftz.f32 	%f28, %f27, %f26;

	sqrt.approx.ftz.f32 	%f29, %f28;

	add.ftz.f32 	%f30, %f25, 0f3F800000;

	div.approx.ftz.f32 	%f31, %f30, %f27;

	min.ftz.f32 	%f32, %f31, %f27;

	mov.f32 	%f33, 0f00000000;

	max.ftz.f32 	%f34, %f33, %f32;

	mul.ftz.f32 	%f35, %f34, %f34;

	fma.rn.ftz.f32 	%f36, %f34, 0fC0000000, 0f40400000;

	mul.ftz.f32 	%f37, %f35, %f36;

	sqrt.approx.ftz.f32 	%f38, %f1;

	mul.ftz.f32 	%f39, %f38, %f37;

	mov.f32 	%f40, 0f40C90FDB;

	div.approx.ftz.f32 	%f41, %f39, %f40;

	lg2.approx.ftz.f32 	%f42, %f29;

	mul.ftz.f32 	%f43, %f42, %f1;

	ex2.approx.ftz.f32 	%f44, %f43;

	mul.ftz.f32 	%f45, %f41, %f44;

	st.param.f32	[func_retval0+0], %f45;

	ret;

}



	// .globl	_Z23getKajiyaKaySpelwlarPdfRK6float3S1_S1_ff

.visible .func  (.param .b32 func_retval0) _Z23getKajiyaKaySpelwlarPdfRK6float3S1_S1_ff(

	.param .b64 _Z23getKajiyaKaySpelwlarPdfRK6float3S1_S1_ff_param_0,

	.param .b64 _Z23getKajiyaKaySpelwlarPdfRK6float3S1_S1_ff_param_1,

	.param .b64 _Z23getKajiyaKaySpelwlarPdfRK6float3S1_S1_ff_param_2,

	.param .b32 _Z23getKajiyaKaySpelwlarPdfRK6float3S1_S1_ff_param_3,

	.param .b32 _Z23getKajiyaKaySpelwlarPdfRK6float3S1_S1_ff_param_4

)

{

	.reg .f32 	%f<42>;

	.reg .s64 	%rd<4>;





	ld.param.u64 	%rd1, [_Z23getKajiyaKaySpelwlarPdfRK6float3S1_S1_ff_param_0];

	ld.param.u64 	%rd2, [_Z23getKajiyaKaySpelwlarPdfRK6float3S1_S1_ff_param_1];

	ld.param.u64 	%rd3, [_Z23getKajiyaKaySpelwlarPdfRK6float3S1_S1_ff_param_2];

	ld.param.f32 	%f1, [_Z23getKajiyaKaySpelwlarPdfRK6float3S1_S1_ff_param_3];

	ld.param.f32 	%f2, [_Z23getKajiyaKaySpelwlarPdfRK6float3S1_S1_ff_param_4];

	ld.f32 	%f3, [%rd2];

	ld.f32 	%f4, [%rd2+4];

	ld.f32 	%f5, [%rd2+8];

	ld.f32 	%f6, [%rd1];

	fma.rn.ftz.f32 	%f7, %f3, %f2, %f6;

	ld.f32 	%f8, [%rd1+4];

	fma.rn.ftz.f32 	%f9, %f4, %f2, %f8;

	ld.f32 	%f10, [%rd1+8];

	fma.rn.ftz.f32 	%f11, %f5, %f2, %f10;

	mul.ftz.f32 	%f12, %f9, %f9;

	fma.rn.ftz.f32 	%f13, %f7, %f7, %f12;

	fma.rn.ftz.f32 	%f14, %f11, %f11, %f13;

	sqrt.approx.ftz.f32 	%f15, %f14;

	rcp.approx.ftz.f32 	%f16, %f15;

	mul.ftz.f32 	%f17, %f7, %f16;

	mul.ftz.f32 	%f18, %f9, %f16;

	mul.ftz.f32 	%f19, %f11, %f16;

	ld.f32 	%f20, [%rd3];

	ld.f32 	%f21, [%rd3+4];

	mul.ftz.f32 	%f22, %f18, %f21;

	fma.rn.ftz.f32 	%f23, %f17, %f20, %f22;

	ld.f32 	%f24, [%rd3+8];

	fma.rn.ftz.f32 	%f25, %f19, %f24, %f23;

	mul.ftz.f32 	%f26, %f25, %f25;

	mov.f32 	%f27, 0f3F800000;

	sub.ftz.f32 	%f28, %f27, %f26;

	sqrt.approx.ftz.f32 	%f29, %f28;

	add.ftz.f32 	%f30, %f25, 0f3F800000;

	div.approx.ftz.f32 	%f31, %f30, %f27;

	min.ftz.f32 	%f32, %f31, %f27;

	mov.f32 	%f33, 0f00000000;

	max.ftz.f32 	%f34, %f33, %f32;

	mul.ftz.f32 	%f35, %f34, %f34;

	fma.rn.ftz.f32 	%f36, %f34, 0fC0000000, 0f40400000;

	mul.ftz.f32 	%f37, %f35, %f36;

	lg2.approx.ftz.f32 	%f38, %f29;

	mul.ftz.f32 	%f39, %f38, %f1;

	ex2.approx.ftz.f32 	%f40, %f39;

	mul.ftz.f32 	%f41, %f40, %f37;

	st.param.f32	[func_retval0+0], %f41;

	ret;

}



	// .globl	_Z18SuspendedParticles6float3ffffRfRS_S0_S1_

.visible .func  (.param .b32 func_retval0) _Z18SuspendedParticles6float3ffffRfRS_S0_S1_(

	.param .align 4 .b8 _Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_0[12],

	.param .b32 _Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_1,

	.param .b32 _Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_2,

	.param .b32 _Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_3,

	.param .b32 _Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_4,

	.param .b64 _Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_5,

	.param .b64 _Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_6,

	.param .b64 _Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_7,

	.param .b64 _Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_8

)

{

	.reg .pred 	%p<10>;

	.reg .f32 	%f<137>;

	.reg .s32 	%r<81>;

	.reg .s64 	%rd<22>;





	ld.param.f32 	%f25, [_Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_0+8];

	ld.param.f32 	%f24, [_Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_0+4];

	ld.param.f32 	%f23, [_Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_0];

	ld.param.f32 	%f28, [_Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_1];

	ld.param.f32 	%f26, [_Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_2];

	ld.param.f32 	%f27, [_Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_3];

	ld.param.f32 	%f29, [_Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_4];

	ld.param.u64 	%rd2, [_Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_5];

	ld.param.u64 	%rd3, [_Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_6];

	ld.param.u64 	%rd4, [_Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_7];

	ld.param.u64 	%rd5, [_Z18SuspendedParticles6float3ffffRfRS_S0_S1__param_8];

	cvt.rmi.ftz.f32.f32	%f30, %f23;

	cvt.rmi.ftz.f32.f32	%f31, %f24;

	cvt.rmi.ftz.f32.f32	%f32, %f25;

	add.ftz.f32 	%f1, %f30, 0f3F000000;

	add.ftz.f32 	%f2, %f31, 0f3F000000;

	add.ftz.f32 	%f3, %f32, 0f3F000000;

	mov.u32 	%r15, 2067830734;

	st.u32 	[%rd4], %r15;

	st.u32 	[%rd2], %r15;

	fma.rn.ftz.f32 	%f4, %f29, 0f447A0000, %f28;

	mul.ftz.f32 	%f5, %f4, 0f3F35C28F;

	mul.ftz.f32 	%f6, %f4, 0f3F28F5C3;

	mov.u32 	%r78, 0;

	mov.u32 	%r77, %r78;



BB22_1:

	mul.wide.u32 	%rd6, %r77, -1431655765;

	shr.u64 	%rd7, %rd6, 33;

	cvt.u32.u64	%r16, %rd7;

	mul.wide.u32 	%rd8, %r16, -1431655765;

	shr.u64 	%rd9, %rd8, 33;

	cvt.u32.u64	%r17, %rd9;

	mul.lo.s32 	%r18, %r17, 3;

	sub.s32 	%r19, %r16, %r18;

	mul.wide.u32 	%rd10, %r77, 954437177;

	shr.u64 	%rd11, %rd10, 33;

	cvt.u32.u64	%r20, %rd11;

	cvt.rn.f32.u32	%f33, %r20;

	cvt.rn.f32.u32	%f34, %r19;

	mul.lo.s32 	%r21, %r16, 3;

	sub.s32 	%r22, %r77, %r21;

	cvt.rn.f32.u32	%f35, %r22;

	add.ftz.f32 	%f36, %f1, %f33;

	add.ftz.f32 	%f37, %f2, %f34;

	add.ftz.f32 	%f38, %f3, %f35;

	add.ftz.f32 	%f134, %f36, 0fBF800000;

	add.ftz.f32 	%f135, %f37, 0fBF800000;

	add.ftz.f32 	%f136, %f38, 0fBF800000;

	setp.leu.ftz.f32	%p1, %f27, 0f00000000;

	@%p1 bra 	BB22_5;



	add.ftz.f32 	%f40, %f4, %f134;

	cvt.rmi.ftz.f32.f32	%f41, %f40;

	add.ftz.f32 	%f42, %f5, %f135;

	cvt.rmi.ftz.f32.f32	%f43, %f42;

	add.ftz.f32 	%f44, %f6, %f136;

	cvt.rmi.ftz.f32.f32	%f45, %f44;

	cvt.rzi.ftz.s32.f32	%r3, %f41;

	cvt.rzi.ftz.s32.f32	%r4, %f43;

	cvt.rzi.ftz.s32.f32	%r5, %f45;

	sub.ftz.f32 	%f10, %f40, %f41;

	sub.ftz.f32 	%f11, %f42, %f43;

	sub.ftz.f32 	%f12, %f44, %f45;

	mov.f32 	%f133, 0f4B18967F;

	mov.u32 	%r80, 0;

	mov.u32 	%r79, %r80;



BB22_3:

	mul.wide.u32 	%rd12, %r80, 954437177;

	shr.u64 	%rd13, %rd12, 33;

	cvt.u32.u64	%r25, %rd13;

	add.s32 	%r26, %r25, -1;

	mul.wide.u32 	%rd14, %r79, -1431655765;

	shr.u64 	%rd15, %rd14, 33;

	cvt.u32.u64	%r27, %rd15;

	mul.lo.s32 	%r28, %r27, 3;

	sub.s32 	%r29, %r79, %r28;

	add.s32 	%r30, %r29, -1;

	mul.wide.u32 	%rd16, %r80, -1431655765;

	shr.u64 	%rd17, %rd16, 33;

	cvt.u32.u64	%r31, %rd17;

	mul.lo.s32 	%r32, %r31, 3;

	sub.s32 	%r33, %r80, %r32;

	add.s32 	%r34, %r33, -1;

	add.s32 	%r35, %r34, %r3;

	add.s32 	%r36, %r30, %r4;

	add.s32 	%r37, %r26, %r5;

	mul.lo.s32 	%r38, %r36, 31;

	add.s32 	%r39, %r35, %r38;

	abs.s32 	%r40, %r39;

	cvt.rn.f32.s32	%f46, %r40;

	mad.lo.s32 	%r41, %r35, -3, %r37;

	abs.s32 	%r42, %r41;

	cvt.rn.f32.s32	%f47, %r42;

	cvt.rzi.ftz.u32.f32	%r43, %f46;

	cvt.rzi.ftz.u32.f32	%r44, %f47;

	and.b32  	%r45, %r43, 1023;

	cvt.rn.f32.u32	%f48, %r45;

	add.ftz.f32 	%f49, %f48, 0f3F000000;

	and.b32  	%r46, %r44, 127;

	cvt.rn.f32.u32	%f50, %r46;

	add.ftz.f32 	%f51, %f50, 0f3F000000;

	tex.2d.v4.f32.f32	{%f52, %f53, %f54, %f55}, [noise_texture, {%f49, %f51}];

	cvt.rn.f32.s32	%f56, %r34;

	cvt.rn.f32.s32	%f57, %r30;

	cvt.rn.f32.s32	%f58, %r26;

	add.ftz.f32 	%f59, %f56, %f52;

	add.ftz.f32 	%f60, %f57, %f53;

	add.ftz.f32 	%f61, %f58, %f54;

	sub.ftz.f32 	%f62, %f59, %f10;

	sub.ftz.f32 	%f63, %f60, %f11;

	sub.ftz.f32 	%f64, %f61, %f12;

	mul.ftz.f32 	%f65, %f63, %f63;

	fma.rn.ftz.f32 	%f66, %f62, %f62, %f65;

	fma.rn.ftz.f32 	%f67, %f64, %f64, %f66;

	setp.lt.ftz.f32	%p2, %f67, %f133;

	selp.f32	%f68, %f67, %f133, %p2;

	add.s32 	%r47, %r80, 1;

	mul.wide.u32 	%rd18, %r47, -1431655765;

	shr.u64 	%rd19, %rd18, 33;

	cvt.u32.u64	%r48, %rd19;

	mul.lo.s32 	%r49, %r48, 3;

	sub.s32 	%r50, %r47, %r49;

	add.s32 	%r51, %r50, -1;

	add.s32 	%r52, %r51, %r3;

	add.s32 	%r53, %r52, %r38;

	abs.s32 	%r54, %r53;

	cvt.rn.f32.s32	%f69, %r54;

	mad.lo.s32 	%r55, %r52, -3, %r37;

	abs.s32 	%r56, %r55;

	cvt.rn.f32.s32	%f70, %r56;

	cvt.rzi.ftz.u32.f32	%r57, %f69;

	cvt.rzi.ftz.u32.f32	%r58, %f70;

	and.b32  	%r59, %r57, 1023;

	cvt.rn.f32.u32	%f71, %r59;

	add.ftz.f32 	%f72, %f71, 0f3F000000;

	and.b32  	%r60, %r58, 127;

	cvt.rn.f32.u32	%f73, %r60;

	add.ftz.f32 	%f74, %f73, 0f3F000000;

	tex.2d.v4.f32.f32	{%f75, %f76, %f77, %f78}, [noise_texture, {%f72, %f74}];

	cvt.rn.f32.s32	%f79, %r51;

	add.ftz.f32 	%f80, %f79, %f75;

	add.ftz.f32 	%f81, %f57, %f76;

	add.ftz.f32 	%f82, %f58, %f77;

	sub.ftz.f32 	%f83, %f80, %f10;

	sub.ftz.f32 	%f84, %f81, %f11;

	sub.ftz.f32 	%f85, %f82, %f12;

	mul.ftz.f32 	%f86, %f84, %f84;

	fma.rn.ftz.f32 	%f87, %f83, %f83, %f86;

	fma.rn.ftz.f32 	%f88, %f85, %f85, %f87;

	setp.lt.ftz.f32	%p3, %f88, %f68;

	selp.f32	%f89, %f88, %f68, %p3;

	add.s32 	%r61, %r80, 2;

	mul.wide.u32 	%rd20, %r61, -1431655765;

	shr.u64 	%rd21, %rd20, 33;

	cvt.u32.u64	%r62, %rd21;

	mul.lo.s32 	%r63, %r62, 3;

	sub.s32 	%r64, %r61, %r63;

	add.s32 	%r65, %r64, -1;

	add.s32 	%r66, %r65, %r3;

	add.s32 	%r67, %r66, %r38;

	abs.s32 	%r68, %r67;

	cvt.rn.f32.s32	%f90, %r68;

	mad.lo.s32 	%r69, %r66, -3, %r37;

	abs.s32 	%r70, %r69;

	cvt.rn.f32.s32	%f91, %r70;

	cvt.rzi.ftz.u32.f32	%r71, %f90;

	cvt.rzi.ftz.u32.f32	%r72, %f91;

	and.b32  	%r73, %r71, 1023;

	cvt.rn.f32.u32	%f92, %r73;

	add.ftz.f32 	%f93, %f92, 0f3F000000;

	and.b32  	%r74, %r72, 127;

	cvt.rn.f32.u32	%f94, %r74;

	add.ftz.f32 	%f95, %f94, 0f3F000000;

	tex.2d.v4.f32.f32	{%f96, %f97, %f98, %f99}, [noise_texture, {%f93, %f95}];

	cvt.rn.f32.s32	%f100, %r65;

	add.ftz.f32 	%f101, %f100, %f96;

	add.ftz.f32 	%f102, %f57, %f97;

	add.ftz.f32 	%f103, %f58, %f98;

	sub.ftz.f32 	%f104, %f101, %f10;

	sub.ftz.f32 	%f105, %f102, %f11;

	sub.ftz.f32 	%f106, %f103, %f12;

	mul.ftz.f32 	%f107, %f105, %f105;

	fma.rn.ftz.f32 	%f108, %f104, %f104, %f107;

	fma.rn.ftz.f32 	%f109, %f106, %f106, %f108;

	setp.lt.ftz.f32	%p4, %f109, %f89;

	selp.f32	%f133, %f109, %f89, %p4;

	add.s32 	%r79, %r79, 1;

	add.s32 	%r80, %r80, 3;

	setp.ne.s32	%p5, %r80, 27;

	@%p5 bra 	BB22_3;



	sqrt.approx.ftz.f32 	%f110, %f133;

	mul.ftz.f32 	%f111, %f110, 0f44800000;

	cvt.rzi.ftz.u32.f32	%r75, %f111;

	and.b32  	%r76, %r75, 1023;

	cvt.rn.f32.u32	%f112, %r76;

	add.ftz.f32 	%f113, %f112, 0f3F000000;

	mov.f32 	%f114, 0f3F000000;

	tex.2d.v4.f32.f32	{%f115, %f116, %f117, %f118}, [noise_texture, {%f113, %f114}];

	add.ftz.f32 	%f119, %f115, 0fBF000000;

	add.ftz.f32 	%f120, %f116, 0fBF000000;

	add.ftz.f32 	%f121, %f117, 0fBF000000;

	fma.rn.ftz.f32 	%f134, %f119, %f27, %f134;

	fma.rn.ftz.f32 	%f135, %f120, %f27, %f135;

	fma.rn.ftz.f32 	%f136, %f121, %f27, %f136;



BB22_5:

	sub.ftz.f32 	%f122, %f134, %f23;

	sub.ftz.f32 	%f123, %f135, %f24;

	sub.ftz.f32 	%f124, %f136, %f25;

	mul.ftz.f32 	%f125, %f123, %f123;

	fma.rn.ftz.f32 	%f126, %f122, %f122, %f125;

	fma.rn.ftz.f32 	%f127, %f124, %f124, %f126;

	sqrt.approx.ftz.f32 	%f21, %f127;

	setp.geu.ftz.f32	%p6, %f21, %f26;

	@%p6 bra 	BB22_10;



	add.s32 	%r78, %r78, 1;

	ld.f32 	%f22, [%rd2];

	setp.lt.ftz.f32	%p7, %f21, %f22;

	@%p7 bra 	BB22_9;

	bra.uni 	BB22_7;



BB22_9:

	st.f32 	[%rd4], %f22;

	ld.f32 	%f129, [%rd3];

	ld.f32 	%f130, [%rd3+4];

	ld.f32 	%f131, [%rd3+8];

	st.f32 	[%rd5+8], %f131;

	st.f32 	[%rd5+4], %f130;

	st.f32 	[%rd5], %f129;

	st.f32 	[%rd2], %f21;

	st.f32 	[%rd3+8], %f136;

	st.f32 	[%rd3+4], %f135;

	st.f32 	[%rd3], %f134;

	bra.uni 	BB22_10;



BB22_7:

	ld.f32 	%f128, [%rd4];

	setp.geu.ftz.f32	%p8, %f21, %f128;

	@%p8 bra 	BB22_10;



	st.f32 	[%rd4], %f21;

	st.f32 	[%rd5], %f134;

	st.f32 	[%rd5+4], %f135;

	st.f32 	[%rd5+8], %f136;



BB22_10:

	add.s32 	%r77, %r77, 1;

	setp.lt.u32	%p9, %r77, 27;

	@%p9 bra 	BB22_1;



	cvt.rn.f32.u32	%f132, %r78;

	st.param.f32	[func_retval0+0], %f132;

	ret;

}



	// .globl	_ZN9RandUtils14gpuCellNoise3DERK6float3

.visible .func  (.param .align 4 .b8 func_retval0[12]) _ZN9RandUtils14gpuCellNoise3DERK6float3(

	.param .b64 _ZN9RandUtils14gpuCellNoise3DERK6float3_param_0

)

{

	.reg .pred 	%p<5>;

	.reg .f32 	%f<87>;

	.reg .s32 	%r<64>;

	.reg .s64 	%rd<13>;





	ld.param.u64 	%rd2, [_ZN9RandUtils14gpuCellNoise3DERK6float3_param_0];

	ld.f32 	%f7, [%rd2];

	cvt.rmi.ftz.f32.f32	%f8, %f7;

	ld.f32 	%f9, [%rd2+4];

	cvt.rmi.ftz.f32.f32	%f10, %f9;

	ld.f32 	%f11, [%rd2+8];

	cvt.rmi.ftz.f32.f32	%f12, %f11;

	cvt.rzi.ftz.s32.f32	%r1, %f8;

	cvt.rzi.ftz.s32.f32	%r2, %f10;

	cvt.rzi.ftz.s32.f32	%r3, %f12;

	sub.ftz.f32 	%f1, %f7, %f8;

	sub.ftz.f32 	%f2, %f9, %f10;

	sub.ftz.f32 	%f3, %f11, %f12;

	mov.f32 	%f86, 0f4B18967F;

	mov.u32 	%r63, 0;

	mov.u32 	%r62, %r63;



BB23_1:

	mul.wide.u32 	%rd3, %r63, 954437177;

	shr.u64 	%rd4, %rd3, 33;

	cvt.u32.u64	%r10, %rd4;

	add.s32 	%r11, %r10, -1;

	mul.wide.u32 	%rd5, %r62, -1431655765;

	shr.u64 	%rd6, %rd5, 33;

	cvt.u32.u64	%r12, %rd6;

	mul.lo.s32 	%r13, %r12, 3;

	sub.s32 	%r14, %r62, %r13;

	add.s32 	%r15, %r14, -1;

	mul.wide.u32 	%rd7, %r63, -1431655765;

	shr.u64 	%rd8, %rd7, 33;

	cvt.u32.u64	%r16, %rd8;

	mul.lo.s32 	%r17, %r16, 3;

	sub.s32 	%r18, %r63, %r17;

	add.s32 	%r19, %r18, -1;

	add.s32 	%r20, %r19, %r1;

	add.s32 	%r21, %r15, %r2;

	add.s32 	%r22, %r11, %r3;

	mul.lo.s32 	%r23, %r21, 31;

	add.s32 	%r24, %r20, %r23;

	abs.s32 	%r25, %r24;

	cvt.rn.f32.s32	%f13, %r25;

	mad.lo.s32 	%r26, %r20, -3, %r22;

	abs.s32 	%r27, %r26;

	cvt.rn.f32.s32	%f14, %r27;

	cvt.rzi.ftz.u32.f32	%r28, %f13;

	cvt.rzi.ftz.u32.f32	%r29, %f14;

	and.b32  	%r30, %r28, 1023;

	cvt.rn.f32.u32	%f15, %r30;

	add.ftz.f32 	%f16, %f15, 0f3F000000;

	and.b32  	%r31, %r29, 127;

	cvt.rn.f32.u32	%f17, %r31;

	add.ftz.f32 	%f18, %f17, 0f3F000000;

	tex.2d.v4.f32.f32	{%f19, %f20, %f21, %f22}, [noise_texture, {%f16, %f18}];

	cvt.rn.f32.s32	%f23, %r19;

	cvt.rn.f32.s32	%f24, %r15;

	cvt.rn.f32.s32	%f25, %r11;

	add.ftz.f32 	%f26, %f23, %f19;

	add.ftz.f32 	%f27, %f24, %f20;

	add.ftz.f32 	%f28, %f25, %f21;

	sub.ftz.f32 	%f29, %f26, %f1;

	sub.ftz.f32 	%f30, %f27, %f2;

	sub.ftz.f32 	%f31, %f28, %f3;

	mul.ftz.f32 	%f32, %f30, %f30;

	fma.rn.ftz.f32 	%f33, %f29, %f29, %f32;

	fma.rn.ftz.f32 	%f34, %f31, %f31, %f33;

	setp.lt.ftz.f32	%p1, %f34, %f86;

	selp.f32	%f35, %f34, %f86, %p1;

	add.s32 	%r32, %r63, 1;

	mul.wide.u32 	%rd9, %r32, -1431655765;

	shr.u64 	%rd10, %rd9, 33;

	cvt.u32.u64	%r33, %rd10;

	mul.lo.s32 	%r34, %r33, 3;

	sub.s32 	%r35, %r32, %r34;

	add.s32 	%r36, %r35, -1;

	add.s32 	%r37, %r36, %r1;

	add.s32 	%r38, %r37, %r23;

	abs.s32 	%r39, %r38;

	cvt.rn.f32.s32	%f36, %r39;

	mad.lo.s32 	%r40, %r37, -3, %r22;

	abs.s32 	%r41, %r40;

	cvt.rn.f32.s32	%f37, %r41;

	cvt.rzi.ftz.u32.f32	%r42, %f36;

	cvt.rzi.ftz.u32.f32	%r43, %f37;

	and.b32  	%r44, %r42, 1023;

	cvt.rn.f32.u32	%f38, %r44;

	add.ftz.f32 	%f39, %f38, 0f3F000000;

	and.b32  	%r45, %r43, 127;

	cvt.rn.f32.u32	%f40, %r45;

	add.ftz.f32 	%f41, %f40, 0f3F000000;

	tex.2d.v4.f32.f32	{%f42, %f43, %f44, %f45}, [noise_texture, {%f39, %f41}];

	cvt.rn.f32.s32	%f46, %r36;

	add.ftz.f32 	%f47, %f46, %f42;

	add.ftz.f32 	%f48, %f24, %f43;

	add.ftz.f32 	%f49, %f25, %f44;

	sub.ftz.f32 	%f50, %f47, %f1;

	sub.ftz.f32 	%f51, %f48, %f2;

	sub.ftz.f32 	%f52, %f49, %f3;

	mul.ftz.f32 	%f53, %f51, %f51;

	fma.rn.ftz.f32 	%f54, %f50, %f50, %f53;

	fma.rn.ftz.f32 	%f55, %f52, %f52, %f54;

	setp.lt.ftz.f32	%p2, %f55, %f35;

	selp.f32	%f56, %f55, %f35, %p2;

	add.s32 	%r46, %r63, 2;

	mul.wide.u32 	%rd11, %r46, -1431655765;

	shr.u64 	%rd12, %rd11, 33;

	cvt.u32.u64	%r47, %rd12;

	mul.lo.s32 	%r48, %r47, 3;

	sub.s32 	%r49, %r46, %r48;

	add.s32 	%r50, %r49, -1;

	add.s32 	%r51, %r50, %r1;

	add.s32 	%r52, %r51, %r23;

	abs.s32 	%r53, %r52;

	cvt.rn.f32.s32	%f57, %r53;

	mad.lo.s32 	%r54, %r51, -3, %r22;

	abs.s32 	%r55, %r54;

	cvt.rn.f32.s32	%f58, %r55;

	cvt.rzi.ftz.u32.f32	%r56, %f57;

	cvt.rzi.ftz.u32.f32	%r57, %f58;

	and.b32  	%r58, %r56, 1023;

	cvt.rn.f32.u32	%f59, %r58;

	add.ftz.f32 	%f60, %f59, 0f3F000000;

	and.b32  	%r59, %r57, 127;

	cvt.rn.f32.u32	%f61, %r59;

	add.ftz.f32 	%f62, %f61, 0f3F000000;

	tex.2d.v4.f32.f32	{%f63, %f64, %f65, %f66}, [noise_texture, {%f60, %f62}];

	cvt.rn.f32.s32	%f67, %r50;

	add.ftz.f32 	%f68, %f67, %f63;

	add.ftz.f32 	%f69, %f24, %f64;

	add.ftz.f32 	%f70, %f25, %f65;

	sub.ftz.f32 	%f71, %f68, %f1;

	sub.ftz.f32 	%f72, %f69, %f2;

	sub.ftz.f32 	%f73, %f70, %f3;

	mul.ftz.f32 	%f74, %f72, %f72;

	fma.rn.ftz.f32 	%f75, %f71, %f71, %f74;

	fma.rn.ftz.f32 	%f76, %f73, %f73, %f75;

	setp.lt.ftz.f32	%p3, %f76, %f56;

	selp.f32	%f86, %f76, %f56, %p3;

	add.s32 	%r62, %r62, 1;

	add.s32 	%r63, %r63, 3;

	setp.ne.s32	%p4, %r63, 27;

	@%p4 bra 	BB23_1;



	sqrt.approx.ftz.f32 	%f77, %f86;

	mul.ftz.f32 	%f78, %f77, 0f44800000;

	cvt.rzi.ftz.u32.f32	%r60, %f78;

	and.b32  	%r61, %r60, 1023;

	cvt.rn.f32.u32	%f79, %r61;

	add.ftz.f32 	%f80, %f79, 0f3F000000;

	mov.f32 	%f81, 0f3F000000;

	tex.2d.v4.f32.f32	{%f82, %f83, %f84, %f85}, [noise_texture, {%f80, %f81}];

	st.param.f32	[func_retval0+0], %f82;

	st.param.f32	[func_retval0+4], %f83;

	st.param.f32	[func_retval0+8], %f84;

	ret;

}



	// .globl	_Z6flakesRK6float3ffRfRS_

.visible .func _Z6flakesRK6float3ffRfRS_(

	.param .b64 _Z6flakesRK6float3ffRfRS__param_0,

	.param .b32 _Z6flakesRK6float3ffRfRS__param_1,

	.param .b32 _Z6flakesRK6float3ffRfRS__param_2,

	.param .b64 _Z6flakesRK6float3ffRfRS__param_3,

	.param .b64 _Z6flakesRK6float3ffRfRS__param_4

)

{

	.reg .pred 	%p<13>;

	.reg .f32 	%f<280>;

	.reg .s32 	%r<149>;

	.reg .f64 	%fd<3>;

	.reg .s64 	%rd<31>;





	ld.param.u64 	%rd4, [_Z6flakesRK6float3ffRfRS__param_0];

	ld.param.f32 	%f35, [_Z6flakesRK6float3ffRfRS__param_1];

	ld.param.f32 	%f36, [_Z6flakesRK6float3ffRfRS__param_2];

	ld.param.u64 	%rd2, [_Z6flakesRK6float3ffRfRS__param_3];

	ld.param.u64 	%rd3, [_Z6flakesRK6float3ffRfRS__param_4];

	mov.u32 	%r21, 0;

	st.u32 	[%rd3+8], %r21;

	st.u32 	[%rd3+4], %r21;

	st.u32 	[%rd3], %r21;

	st.u32 	[%rd2], %r21;

	mov.f32 	%f37, 0f400CCCCD;

	div.approx.ftz.f32 	%f38, %f37, %f36;

	ld.f32 	%f39, [%rd4+8];

	ld.f32 	%f40, [%rd4+4];

	ld.f32 	%f41, [%rd4];

	mul.ftz.f32 	%f42, %f41, %f38;

	mul.ftz.f32 	%f43, %f40, %f38;

	mov.f32 	%f44, 0f44800000;

	div.approx.ftz.f32 	%f45, %f42, %f44;

	mov.f32 	%f46, 0f43000000;

	div.approx.ftz.f32 	%f47, %f43, %f46;

	cvt.rmi.ftz.f32.f32	%f48, %f45;

	sub.ftz.f32 	%f49, %f45, %f48;

	mul.ftz.f32 	%f50, %f49, 0f44800000;

	cvt.rmi.ftz.f32.f32	%f51, %f47;

	sub.ftz.f32 	%f52, %f47, %f51;

	mul.ftz.f32 	%f53, %f52, 0f43000000;

	tex.2d.v4.f32.f32	{%f54, %f55, %f56, %f57}, [noise_texture, {%f50, %f53}];

	add.ftz.f32 	%f58, %f56, %f56;

	fma.rn.ftz.f32 	%f1, %f54, 0f40000000, %f42;

	fma.rn.ftz.f32 	%f2, %f55, 0f40000000, %f43;

	fma.rn.ftz.f32 	%f3, %f39, %f38, %f58;

	sqrt.approx.ftz.f32 	%f4, %f35;

	cvt.rmi.ftz.f32.f32	%f59, %f1;

	cvt.rmi.ftz.f32.f32	%f60, %f2;

	cvt.rmi.ftz.f32.f32	%f61, %f3;

	add.ftz.f32 	%f5, %f59, 0f3F000000;

	add.ftz.f32 	%f6, %f60, 0f3F000000;

	add.ftz.f32 	%f7, %f61, 0f3F000000;

	mov.f32 	%f261, 0f7B4097CE;

	mov.u32 	%r138, %r21;

	mov.u32 	%r145, %r21;



BB24_1:

	mov.u32 	%r142, %r145;

	mov.u32 	%r146, %r142;

	mov.f32 	%f273, %f276;

	mov.f32 	%f11, %f273;

	mov.f32 	%f268, %f271;

	mov.f32 	%f10, %f268;

	mov.f32 	%f263, %f266;

	mov.f32 	%f9, %f263;

	mov.f32 	%f258, %f261;

	mov.f32 	%f8, %f258;

	mul.wide.u32 	%rd5, %r138, -1431655765;

	shr.u64 	%rd6, %rd5, 33;

	cvt.u32.u64	%r24, %rd6;

	mul.wide.u32 	%rd7, %r24, -1431655765;

	shr.u64 	%rd8, %rd7, 33;

	cvt.u32.u64	%r25, %rd8;

	mul.lo.s32 	%r26, %r25, 3;

	sub.s32 	%r27, %r24, %r26;

	mul.wide.u32 	%rd9, %r138, 954437177;

	shr.u64 	%rd10, %rd9, 33;

	cvt.u32.u64	%r28, %rd10;

	cvt.rn.f32.u32	%f63, %r28;

	cvt.rn.f32.u32	%f64, %r27;

	mul.lo.s32 	%r29, %r24, 3;

	sub.s32 	%r30, %r138, %r29;

	cvt.rn.f32.u32	%f65, %r30;

	add.ftz.f32 	%f66, %f5, %f63;

	add.ftz.f32 	%f67, %f6, %f64;

	add.ftz.f32 	%f68, %f7, %f65;

	add.ftz.f32 	%f12, %f66, 0fBF800000;

	add.ftz.f32 	%f13, %f67, 0fBF800000;

	add.ftz.f32 	%f14, %f68, 0fBF800000;

	add.ftz.f32 	%f69, %f12, 0f00000000;

	add.ftz.f32 	%f70, %f13, 0f00000000;

	add.ftz.f32 	%f71, %f14, 0f00000000;

	cvt.rmi.ftz.f32.f32	%f72, %f69;

	cvt.rmi.ftz.f32.f32	%f73, %f70;

	cvt.rmi.ftz.f32.f32	%f74, %f71;

	cvt.rzi.ftz.s32.f32	%r3, %f72;

	cvt.rzi.ftz.s32.f32	%r4, %f73;

	cvt.rzi.ftz.s32.f32	%r5, %f74;

	sub.ftz.f32 	%f15, %f69, %f72;

	sub.ftz.f32 	%f16, %f70, %f73;

	sub.ftz.f32 	%f17, %f71, %f74;

	mov.f32 	%f278, 0f4B18967F;

	mov.u32 	%r139, %r21;

	mov.u32 	%r144, %r21;



BB24_2:

	mov.u32 	%r7, %r144;

	mul.wide.u32 	%rd11, %r7, 954437177;

	shr.u64 	%rd12, %rd11, 33;

	cvt.u32.u64	%r31, %rd12;

	add.s32 	%r32, %r31, -1;

	mul.wide.u32 	%rd13, %r139, -1431655765;

	shr.u64 	%rd14, %rd13, 33;

	cvt.u32.u64	%r33, %rd14;

	mul.lo.s32 	%r34, %r33, 3;

	sub.s32 	%r35, %r139, %r34;

	add.s32 	%r36, %r35, -1;

	mul.wide.u32 	%rd15, %r7, -1431655765;

	shr.u64 	%rd16, %rd15, 33;

	cvt.u32.u64	%r37, %rd16;

	mul.lo.s32 	%r38, %r37, 3;

	sub.s32 	%r39, %r7, %r38;

	add.s32 	%r40, %r39, -1;

	add.s32 	%r41, %r40, %r3;

	add.s32 	%r42, %r36, %r4;

	add.s32 	%r43, %r32, %r5;

	mul.lo.s32 	%r44, %r42, 31;

	add.s32 	%r45, %r41, %r44;

	abs.s32 	%r46, %r45;

	cvt.rn.f32.s32	%f75, %r46;

	mad.lo.s32 	%r47, %r41, -3, %r43;

	abs.s32 	%r48, %r47;

	cvt.rn.f32.s32	%f76, %r48;

	cvt.rzi.ftz.u32.f32	%r49, %f75;

	cvt.rzi.ftz.u32.f32	%r50, %f76;

	and.b32  	%r51, %r49, 1023;

	cvt.rn.f32.u32	%f77, %r51;

	add.ftz.f32 	%f78, %f77, 0f3F000000;

	and.b32  	%r52, %r50, 127;

	cvt.rn.f32.u32	%f79, %r52;

	add.ftz.f32 	%f80, %f79, 0f3F000000;

	tex.2d.v4.f32.f32	{%f81, %f82, %f83, %f84}, [noise_texture, {%f78, %f80}];

	cvt.rn.f32.s32	%f85, %r40;

	cvt.rn.f32.s32	%f86, %r36;

	cvt.rn.f32.s32	%f87, %r32;

	add.ftz.f32 	%f88, %f85, %f81;

	add.ftz.f32 	%f89, %f86, %f82;

	add.ftz.f32 	%f90, %f87, %f83;

	sub.ftz.f32 	%f91, %f88, %f15;

	sub.ftz.f32 	%f92, %f89, %f16;

	sub.ftz.f32 	%f93, %f90, %f17;

	mul.ftz.f32 	%f94, %f92, %f92;

	fma.rn.ftz.f32 	%f95, %f91, %f91, %f94;

	fma.rn.ftz.f32 	%f96, %f93, %f93, %f95;

	setp.lt.ftz.f32	%p1, %f96, %f278;

	selp.f32	%f97, %f96, %f278, %p1;

	add.s32 	%r53, %r7, 1;

	mul.wide.u32 	%rd17, %r53, -1431655765;

	shr.u64 	%rd18, %rd17, 33;

	cvt.u32.u64	%r54, %rd18;

	mul.lo.s32 	%r55, %r54, 3;

	sub.s32 	%r56, %r53, %r55;

	add.s32 	%r57, %r56, -1;

	add.s32 	%r58, %r57, %r3;

	add.s32 	%r59, %r58, %r44;

	abs.s32 	%r60, %r59;

	cvt.rn.f32.s32	%f98, %r60;

	mad.lo.s32 	%r61, %r58, -3, %r43;

	abs.s32 	%r62, %r61;

	cvt.rn.f32.s32	%f99, %r62;

	cvt.rzi.ftz.u32.f32	%r63, %f98;

	cvt.rzi.ftz.u32.f32	%r64, %f99;

	and.b32  	%r65, %r63, 1023;

	cvt.rn.f32.u32	%f100, %r65;

	add.ftz.f32 	%f101, %f100, 0f3F000000;

	and.b32  	%r66, %r64, 127;

	cvt.rn.f32.u32	%f102, %r66;

	add.ftz.f32 	%f103, %f102, 0f3F000000;

	tex.2d.v4.f32.f32	{%f104, %f105, %f106, %f107}, [noise_texture, {%f101, %f103}];

	cvt.rn.f32.s32	%f108, %r57;

	add.ftz.f32 	%f109, %f108, %f104;

	add.ftz.f32 	%f110, %f86, %f105;

	add.ftz.f32 	%f111, %f87, %f106;

	sub.ftz.f32 	%f112, %f109, %f15;

	sub.ftz.f32 	%f113, %f110, %f16;

	sub.ftz.f32 	%f114, %f111, %f17;

	mul.ftz.f32 	%f115, %f113, %f113;

	fma.rn.ftz.f32 	%f116, %f112, %f112, %f115;

	fma.rn.ftz.f32 	%f117, %f114, %f114, %f116;

	setp.lt.ftz.f32	%p2, %f117, %f97;

	selp.f32	%f118, %f117, %f97, %p2;

	add.s32 	%r67, %r7, 2;

	mul.wide.u32 	%rd19, %r67, -1431655765;

	shr.u64 	%rd20, %rd19, 33;

	cvt.u32.u64	%r68, %rd20;

	mul.lo.s32 	%r69, %r68, 3;

	sub.s32 	%r70, %r67, %r69;

	add.s32 	%r71, %r70, -1;

	add.s32 	%r72, %r71, %r3;

	add.s32 	%r73, %r72, %r44;

	abs.s32 	%r74, %r73;

	cvt.rn.f32.s32	%f119, %r74;

	mad.lo.s32 	%r75, %r72, -3, %r43;

	abs.s32 	%r76, %r75;

	cvt.rn.f32.s32	%f120, %r76;

	cvt.rzi.ftz.u32.f32	%r77, %f119;

	cvt.rzi.ftz.u32.f32	%r78, %f120;

	and.b32  	%r79, %r77, 1023;

	cvt.rn.f32.u32	%f121, %r79;

	add.ftz.f32 	%f122, %f121, 0f3F000000;

	and.b32  	%r80, %r78, 127;

	cvt.rn.f32.u32	%f123, %r80;

	add.ftz.f32 	%f124, %f123, 0f3F000000;

	tex.2d.v4.f32.f32	{%f125, %f126, %f127, %f128}, [noise_texture, {%f122, %f124}];

	cvt.rn.f32.s32	%f129, %r71;

	add.ftz.f32 	%f130, %f129, %f125;

	add.ftz.f32 	%f131, %f86, %f126;

	add.ftz.f32 	%f132, %f87, %f127;

	sub.ftz.f32 	%f133, %f130, %f15;

	sub.ftz.f32 	%f134, %f131, %f16;

	sub.ftz.f32 	%f135, %f132, %f17;

	mul.ftz.f32 	%f136, %f134, %f134;

	fma.rn.ftz.f32 	%f137, %f133, %f133, %f136;

	fma.rn.ftz.f32 	%f138, %f135, %f135, %f137;

	setp.lt.ftz.f32	%p3, %f138, %f118;

	selp.f32	%f278, %f138, %f118, %p3;

	add.s32 	%r139, %r139, 1;

	add.s32 	%r9, %r7, 3;

	setp.ne.s32	%p4, %r9, 27;

	mov.u32 	%r144, %r9;

	@%p4 bra 	BB24_2;



	sqrt.approx.ftz.f32 	%f139, %f278;

	mul.ftz.f32 	%f140, %f139, 0f44800000;

	cvt.rzi.ftz.u32.f32	%r81, %f140;

	and.b32  	%r82, %r81, 1023;

	cvt.rn.f32.u32	%f141, %r82;

	add.ftz.f32 	%f142, %f141, 0f3F000000;

	mov.f32 	%f143, 0f3F000000;

	tex.2d.v4.f32.f32	{%f144, %f145, %f146, %f147}, [noise_texture, {%f142, %f143}];

	add.ftz.f32 	%f148, %f144, 0fBF000000;

	add.ftz.f32 	%f149, %f145, 0fBF000000;

	add.ftz.f32 	%f150, %f146, 0fBF000000;

	add.ftz.f32 	%f20, %f12, %f148;

	add.ftz.f32 	%f21, %f13, %f149;

	add.ftz.f32 	%f22, %f14, %f150;

	sub.ftz.f32 	%f151, %f20, %f1;

	sub.ftz.f32 	%f152, %f21, %f2;

	sub.ftz.f32 	%f153, %f22, %f3;

	mul.ftz.f32 	%f154, %f152, %f152;

	fma.rn.ftz.f32 	%f155, %f151, %f151, %f154;

	fma.rn.ftz.f32 	%f156, %f153, %f153, %f155;

	sqrt.approx.ftz.f32 	%f23, %f156;

	setp.geu.ftz.f32	%p5, %f23, %f4;

	mov.f32 	%f262, %f8;

	mov.f32 	%f267, %f9;

	mov.f32 	%f272, %f10;

	mov.f32 	%f277, %f11;

	@%p5 bra 	BB24_6;



	add.s32 	%r146, %r146, 1;

	setp.lt.ftz.f32	%p6, %f23, %f8;

	mov.f32 	%f262, %f23;

	mov.f32 	%f267, %f22;

	mov.f32 	%f272, %f21;

	mov.f32 	%f277, %f20;

	@%p6 bra 	BB24_6;



	mov.f32 	%f262, %f8;

	mov.f32 	%f267, %f9;

	mov.f32 	%f272, %f10;

	mov.f32 	%f277, %f11;



BB24_6:

	mov.u32 	%r145, %r146;

	mov.f32 	%f276, %f277;

	mov.f32 	%f271, %f272;

	mov.f32 	%f266, %f267;

	mov.f32 	%f261, %f262;

	add.s32 	%r138, %r138, 1;

	setp.lt.u32	%p7, %r138, 27;

	@%p7 bra 	BB24_1;



	cvt.rn.f32.u32	%f157, %r145;

	cvt.rzi.ftz.s32.f32	%r83, %f157;

	setp.eq.s32	%p8, %r83, 0;

	@%p8 bra 	BB24_11;



	add.ftz.f32 	%f159, %f276, 0f3F800000;

	cvt.rmi.ftz.f32.f32	%f160, %f159;

	add.ftz.f32 	%f161, %f271, 0f40E00000;

	cvt.rmi.ftz.f32.f32	%f162, %f161;

	add.ftz.f32 	%f163, %f266, 0f447FC000;

	cvt.rmi.ftz.f32.f32	%f164, %f163;

	cvt.rzi.ftz.s32.f32	%r13, %f160;

	cvt.rzi.ftz.s32.f32	%r14, %f162;

	cvt.rzi.ftz.s32.f32	%r15, %f164;

	sub.ftz.f32 	%f28, %f159, %f160;

	sub.ftz.f32 	%f29, %f161, %f162;

	sub.ftz.f32 	%f30, %f163, %f164;

	mov.f32 	%f279, 0f4B18967F;

	mov.u32 	%r148, 0;

	mov.u32 	%r147, %r148;



BB24_9:

	mul.wide.u32 	%rd21, %r148, 954437177;

	shr.u64 	%rd22, %rd21, 33;

	cvt.u32.u64	%r86, %rd22;

	add.s32 	%r87, %r86, -1;

	mul.wide.u32 	%rd23, %r147, -1431655765;

	shr.u64 	%rd24, %rd23, 33;

	cvt.u32.u64	%r88, %rd24;

	mul.lo.s32 	%r89, %r88, 3;

	sub.s32 	%r90, %r147, %r89;

	add.s32 	%r91, %r90, -1;

	mul.wide.u32 	%rd25, %r148, -1431655765;

	shr.u64 	%rd26, %rd25, 33;

	cvt.u32.u64	%r92, %rd26;

	mul.lo.s32 	%r93, %r92, 3;

	sub.s32 	%r94, %r148, %r93;

	add.s32 	%r95, %r94, -1;

	add.s32 	%r96, %r95, %r13;

	add.s32 	%r97, %r91, %r14;

	add.s32 	%r98, %r87, %r15;

	mul.lo.s32 	%r99, %r97, 31;

	add.s32 	%r100, %r96, %r99;

	abs.s32 	%r101, %r100;

	cvt.rn.f32.s32	%f165, %r101;

	mad.lo.s32 	%r102, %r96, -3, %r98;

	abs.s32 	%r103, %r102;

	cvt.rn.f32.s32	%f166, %r103;

	cvt.rzi.ftz.u32.f32	%r104, %f165;

	cvt.rzi.ftz.u32.f32	%r105, %f166;

	and.b32  	%r106, %r104, 1023;

	cvt.rn.f32.u32	%f167, %r106;

	add.ftz.f32 	%f168, %f167, 0f3F000000;

	and.b32  	%r107, %r105, 127;

	cvt.rn.f32.u32	%f169, %r107;

	add.ftz.f32 	%f170, %f169, 0f3F000000;

	tex.2d.v4.f32.f32	{%f171, %f172, %f173, %f174}, [noise_texture, {%f168, %f170}];

	cvt.rn.f32.s32	%f175, %r95;

	cvt.rn.f32.s32	%f176, %r91;

	cvt.rn.f32.s32	%f177, %r87;

	add.ftz.f32 	%f178, %f175, %f171;

	add.ftz.f32 	%f179, %f176, %f172;

	add.ftz.f32 	%f180, %f177, %f173;

	sub.ftz.f32 	%f181, %f178, %f28;

	sub.ftz.f32 	%f182, %f179, %f29;

	sub.ftz.f32 	%f183, %f180, %f30;

	mul.ftz.f32 	%f184, %f182, %f182;

	fma.rn.ftz.f32 	%f185, %f181, %f181, %f184;

	fma.rn.ftz.f32 	%f186, %f183, %f183, %f185;

	setp.lt.ftz.f32	%p9, %f186, %f279;

	selp.f32	%f187, %f186, %f279, %p9;

	add.s32 	%r108, %r148, 1;

	mul.wide.u32 	%rd27, %r108, -1431655765;

	shr.u64 	%rd28, %rd27, 33;

	cvt.u32.u64	%r109, %rd28;

	mul.lo.s32 	%r110, %r109, 3;

	sub.s32 	%r111, %r108, %r110;

	add.s32 	%r112, %r111, -1;

	add.s32 	%r113, %r112, %r13;

	add.s32 	%r114, %r113, %r99;

	abs.s32 	%r115, %r114;

	cvt.rn.f32.s32	%f188, %r115;

	mad.lo.s32 	%r116, %r113, -3, %r98;

	abs.s32 	%r117, %r116;

	cvt.rn.f32.s32	%f189, %r117;

	cvt.rzi.ftz.u32.f32	%r118, %f188;

	cvt.rzi.ftz.u32.f32	%r119, %f189;

	and.b32  	%r120, %r118, 1023;

	cvt.rn.f32.u32	%f190, %r120;

	add.ftz.f32 	%f191, %f190, 0f3F000000;

	and.b32  	%r121, %r119, 127;

	cvt.rn.f32.u32	%f192, %r121;

	add.ftz.f32 	%f193, %f192, 0f3F000000;

	tex.2d.v4.f32.f32	{%f194, %f195, %f196, %f197}, [noise_texture, {%f191, %f193}];

	cvt.rn.f32.s32	%f198, %r112;

	add.ftz.f32 	%f199, %f198, %f194;

	add.ftz.f32 	%f200, %f176, %f195;

	add.ftz.f32 	%f201, %f177, %f196;

	sub.ftz.f32 	%f202, %f199, %f28;

	sub.ftz.f32 	%f203, %f200, %f29;

	sub.ftz.f32 	%f204, %f201, %f30;

	mul.ftz.f32 	%f205, %f203, %f203;

	fma.rn.ftz.f32 	%f206, %f202, %f202, %f205;

	fma.rn.ftz.f32 	%f207, %f204, %f204, %f206;

	setp.lt.ftz.f32	%p10, %f207, %f187;

	selp.f32	%f208, %f207, %f187, %p10;

	add.s32 	%r122, %r148, 2;

	mul.wide.u32 	%rd29, %r122, -1431655765;

	shr.u64 	%rd30, %rd29, 33;

	cvt.u32.u64	%r123, %rd30;

	mul.lo.s32 	%r124, %r123, 3;

	sub.s32 	%r125, %r122, %r124;

	add.s32 	%r126, %r125, -1;

	add.s32 	%r127, %r126, %r13;

	add.s32 	%r128, %r127, %r99;

	abs.s32 	%r129, %r128;

	cvt.rn.f32.s32	%f209, %r129;

	mad.lo.s32 	%r130, %r127, -3, %r98;

	abs.s32 	%r131, %r130;

	cvt.rn.f32.s32	%f210, %r131;

	cvt.rzi.ftz.u32.f32	%r132, %f209;

	cvt.rzi.ftz.u32.f32	%r133, %f210;

	and.b32  	%r134, %r132, 1023;

	cvt.rn.f32.u32	%f211, %r134;

	add.ftz.f32 	%f212, %f211, 0f3F000000;

	and.b32  	%r135, %r133, 127;

	cvt.rn.f32.u32	%f213, %r135;

	add.ftz.f32 	%f214, %f213, 0f3F000000;

	tex.2d.v4.f32.f32	{%f215, %f216, %f217, %f218}, [noise_texture, {%f212, %f214}];

	cvt.rn.f32.s32	%f219, %r126;

	add.ftz.f32 	%f220, %f219, %f215;

	add.ftz.f32 	%f221, %f176, %f216;

	add.ftz.f32 	%f222, %f177, %f217;

	sub.ftz.f32 	%f223, %f220, %f28;

	sub.ftz.f32 	%f224, %f221, %f29;

	sub.ftz.f32 	%f225, %f222, %f30;

	mul.ftz.f32 	%f226, %f224, %f224;

	fma.rn.ftz.f32 	%f227, %f223, %f223, %f226;

	fma.rn.ftz.f32 	%f228, %f225, %f225, %f227;

	setp.lt.ftz.f32	%p11, %f228, %f208;

	selp.f32	%f279, %f228, %f208, %p11;

	add.s32 	%r147, %r147, 1;

	add.s32 	%r148, %r148, 3;

	setp.ne.s32	%p12, %r148, 27;

	@%p12 bra 	BB24_9;



	sqrt.approx.ftz.f32 	%f229, %f279;

	mul.ftz.f32 	%f230, %f229, 0f44800000;

	cvt.rzi.ftz.u32.f32	%r136, %f230;

	and.b32  	%r137, %r136, 1023;

	cvt.rn.f32.u32	%f231, %r137;

	add.ftz.f32 	%f232, %f231, 0f3F000000;

	tex.2d.v4.f32.f32	{%f234, %f235, %f236, %f237}, [noise_texture, {%f232, %f143}];

	add.ftz.f32 	%f238, %f234, 0fBF000000;

	add.ftz.f32 	%f239, %f235, 0fBF000000;

	add.ftz.f32 	%f240, %f236, 0fBF000000;

	st.f32 	[%rd3], %f238;

	st.f32 	[%rd3+4], %f239;

	st.f32 	[%rd3+8], %f240;

	add.ftz.f32 	%f241, %f238, %f239;

	add.ftz.f32 	%f242, %f240, %f241;

	mov.f32 	%f243, 0f40400000;

	div.approx.ftz.f32 	%f244, %f242, %f243;

	mul.ftz.f32 	%f245, %f244, 0f3E99999A;

	cvt.ftz.f64.f32	%fd1, %f245;

	add.f64 	%fd2, %fd1, 0d3FD3333333333333;

	cvt.rn.ftz.f32.f64	%f246, %fd2;

	st.f32 	[%rd2], %f246;

	ld.f32 	%f247, [%rd3];

	ld.f32 	%f248, [%rd3+4];

	mul.ftz.f32 	%f249, %f248, %f248;

	fma.rn.ftz.f32 	%f250, %f247, %f247, %f249;

	ld.f32 	%f251, [%rd3+8];

	fma.rn.ftz.f32 	%f252, %f251, %f251, %f250;

	sqrt.approx.ftz.f32 	%f253, %f252;

	rcp.approx.ftz.f32 	%f254, %f253;

	mul.ftz.f32 	%f255, %f254, %f247;

	mul.ftz.f32 	%f256, %f254, %f248;

	mul.ftz.f32 	%f257, %f254, %f251;

	st.f32 	[%rd3], %f255;

	st.f32 	[%rd3+4], %f256;

	st.f32 	[%rd3+8], %f257;



BB24_11:

	ret;

}



	// .globl	_ZN9RandUtils13getRandSmoothERK6float2

.visible .func  (.param .align 16 .b8 func_retval0[16]) _ZN9RandUtils13getRandSmoothERK6float2(

	.param .b64 _ZN9RandUtils13getRandSmoothERK6float2_param_0

)

{

	.reg .f32 	%f<15>;

	.reg .s64 	%rd<3>;





	ld.param.u64 	%rd1, [_ZN9RandUtils13getRandSmoothERK6float2_param_0];

	ld.v2.f32 	{%f1, %f2}, [%rd1];

	cvt.rmi.ftz.f32.f32	%f4, %f1;

	sub.ftz.f32 	%f5, %f1, %f4;

	mul.ftz.f32 	%f6, %f5, 0f44800000;

	cvt.rmi.ftz.f32.f32	%f8, %f2;

	sub.ftz.f32 	%f9, %f2, %f8;

	mul.ftz.f32 	%f10, %f9, 0f43000000;

	tex.2d.v4.f32.f32	{%f11, %f12, %f13, %f14}, [noise_texture, {%f6, %f10}];

	st.param.f32	[func_retval0+0], %f11;

	st.param.f32	[func_retval0+4], %f12;

	st.param.f32	[func_retval0+8], %f13;

	st.param.f32	[func_retval0+12], %f14;

	ret;

}



	// .globl	_Z12getRaysCountRjS_jjj

.visible .func _Z12getRaysCountRjS_jjj(

	.param .b64 _Z12getRaysCountRjS_jjj_param_0,

	.param .b64 _Z12getRaysCountRjS_jjj_param_1,

	.param .b32 _Z12getRaysCountRjS_jjj_param_2,

	.param .b32 _Z12getRaysCountRjS_jjj_param_3,

	.param .b32 _Z12getRaysCountRjS_jjj_param_4

)

{

	.reg .pred 	%p<2>;

	.reg .s32 	%r<16>;

	.reg .s64 	%rd<3>;





	ld.param.u64 	%rd1, [_Z12getRaysCountRjS_jjj_param_0];

	ld.param.u64 	%rd2, [_Z12getRaysCountRjS_jjj_param_1];

	ld.param.u32 	%r6, [_Z12getRaysCountRjS_jjj_param_2];

	ld.param.u32 	%r8, [_Z12getRaysCountRjS_jjj_param_3];

	ld.param.u32 	%r7, [_Z12getRaysCountRjS_jjj_param_4];

	div.u32 	%r1, %r6, %r8;

	st.u32 	[%rd1], %r1;

	rem.u32 	%r2, %r6, %r8;

	setp.gt.u32	%p1, %r2, %r7;

	@%p1 bra 	BB26_2;

	bra.uni 	BB26_1;



BB26_2:

	add.s32 	%r9, %r1, 1;

	st.u32 	[%rd1], %r9;

	mul.lo.s32 	%r15, %r9, %r7;

	bra.uni 	BB26_3;



BB26_1:

	mad.lo.s32 	%r15, %r1, %r7, %r2;



BB26_3:

	st.u32 	[%rd2], %r15;

	sub.s32 	%r10, %r6, %r15;

	mov.u32 	%r11, 0;

	max.s32 	%r12, %r11, %r10;

	ld.u32 	%r13, [%rd1];

	min.u32 	%r14, %r12, %r13;

	st.u32 	[%rd1], %r14;

	ret;

}



	// .globl	_Z12getRaysCountRjS_bbjjjjbj

.visible .func _Z12getRaysCountRjS_bbjjjjbj(

	.param .b64 _Z12getRaysCountRjS_bbjjjjbj_param_0,

	.param .b64 _Z12getRaysCountRjS_bbjjjjbj_param_1,

	.param .b32 _Z12getRaysCountRjS_bbjjjjbj_param_2,

	.param .b32 _Z12getRaysCountRjS_bbjjjjbj_param_3,

	.param .b32 _Z12getRaysCountRjS_bbjjjjbj_param_4,

	.param .b32 _Z12getRaysCountRjS_bbjjjjbj_param_5,

	.param .b32 _Z12getRaysCountRjS_bbjjjjbj_param_6,

	.param .b32 _Z12getRaysCountRjS_bbjjjjbj_param_7,

	.param .b32 _Z12getRaysCountRjS_bbjjjjbj_param_8,

	.param .b32 _Z12getRaysCountRjS_bbjjjjbj_param_9

)

{

	.reg .pred 	%p<8>;

	.reg .s16 	%rs<7>;

	.reg .s32 	%r<39>;

	.reg .s64 	%rd<3>;





	ld.param.u64 	%rd1, [_Z12getRaysCountRjS_bbjjjjbj_param_0];

	ld.param.u64 	%rd2, [_Z12getRaysCountRjS_bbjjjjbj_param_1];

	ld.param.u32 	%r15, [_Z12getRaysCountRjS_bbjjjjbj_param_4];

	ld.param.u32 	%r16, [_Z12getRaysCountRjS_bbjjjjbj_param_5];

	ld.param.u32 	%r19, [_Z12getRaysCountRjS_bbjjjjbj_param_6];

	ld.param.u32 	%r17, [_Z12getRaysCountRjS_bbjjjjbj_param_7];

	ld.param.u32 	%r18, [_Z12getRaysCountRjS_bbjjjjbj_param_9];

	ld.param.s8 	%rs1, [_Z12getRaysCountRjS_bbjjjjbj_param_3];

	sub.s32 	%r20, %r15, %r16;

	ld.param.s8 	%rs2, [_Z12getRaysCountRjS_bbjjjjbj_param_2];

	and.b16  	%rs3, %rs2, 255;

	setp.eq.s16	%p1, %rs3, 0;

	selp.b32	%r21, %r20, 0, %p1;

	add.s32 	%r1, %r21, %r19;

	mov.u32 	%r22, 0;

	st.u32 	[%rd2], %r22;

	st.u32 	[%rd1], %r22;

	setp.ne.s16	%p2, %rs3, 0;

	ld.param.s8 	%rs4, [_Z12getRaysCountRjS_bbjjjjbj_param_8];

	and.b16  	%rs5, %rs4, 255;

	setp.ne.s16	%p3, %rs5, 0;

	and.pred  	%p4, %p2, %p3;

	div.u32 	%r2, %r18, %r17;

	@%p4 bra 	BB27_2;

	bra.uni 	BB27_1;



BB27_2:

	st.u32 	[%rd1], %r2;

	rem.u32 	%r3, %r18, %r17;

	setp.lt.u32	%p5, %r1, %r3;

	@%p5 bra 	BB27_4;

	bra.uni 	BB27_3;



BB27_4:

	add.s32 	%r25, %r2, 1;

	st.u32 	[%rd1], %r25;

	mul.lo.s32 	%r36, %r25, %r1;

	bra.uni 	BB27_5;



BB27_1:

	add.s32 	%r23, %r2, 1;

	st.u32 	[%rd1], %r23;

	mul.lo.s32 	%r24, %r23, %r1;

	st.u32 	[%rd2], %r24;

	bra.uni 	BB27_10;



BB27_3:

	mad.lo.s32 	%r36, %r2, %r1, %r3;



BB27_5:

	st.u32 	[%rd2], %r36;

	sub.s32 	%r26, %r18, %r36;

	max.s32 	%r28, %r22, %r26;

	ld.u32 	%r29, [%rd1];

	min.u32 	%r7, %r28, %r29;

	st.u32 	[%rd1], %r7;

	and.b16  	%rs6, %rs1, 255;

	setp.eq.s16	%p6, %rs6, 0;

	@%p6 bra 	BB27_10;



	div.u32 	%r37, %r7, %r16;

	st.u32 	[%rd1], %r37;

	rem.u32 	%r9, %r7, %r16;

	setp.gt.u32	%p7, %r9, %r15;

	@%p7 bra 	BB27_8;

	bra.uni 	BB27_7;



BB27_8:

	add.s32 	%r37, %r37, 1;

	st.u32 	[%rd1], %r37;

	mul.lo.s32 	%r38, %r37, %r15;

	bra.uni 	BB27_9;



BB27_7:

	mad.lo.s32 	%r38, %r37, %r15, %r9;



BB27_9:

	sub.s32 	%r30, %r7, %r38;

	max.s32 	%r32, %r22, %r30;

	min.u32 	%r33, %r32, %r37;

	st.u32 	[%rd1], %r33;

	ld.u32 	%r34, [%rd2];

	add.s32 	%r35, %r34, %r38;

	st.u32 	[%rd2], %r35;



BB27_10:

	ret;

}



	// .globl	_Z12getRoughnessffb

.visible .func  (.param .b32 func_retval0) _Z12getRoughnessffb(

	.param .b32 _Z12getRoughnessffb_param_0,

	.param .b32 _Z12getRoughnessffb_param_1,

	.param .b32 _Z12getRoughnessffb_param_2

)

{

	.reg .pred 	%p<2>;

	.reg .s16 	%rs<3>;

	.reg .f32 	%f<11>;





	ld.param.f32 	%f10, [_Z12getRoughnessffb_param_0];

	ld.param.f32 	%f4, [_Z12getRoughnessffb_param_1];

	ld.param.s8 	%rs1, [_Z12getRoughnessffb_param_2];

	and.b16  	%rs2, %rs1, 255;

	setp.eq.s16	%p1, %rs2, 0;

	@%p1 bra 	BB28_2;



	cvt.ftz.sat.f32.f32	%f5, %f4;

	sqrt.approx.ftz.f32 	%f6, %f5;

	fma.rn.ftz.f32 	%f7, %f6, 0fBE4CCCCD, 0f3F99999A;

	mul.ftz.f32 	%f10, %f7, %f10;



BB28_2:

	mov.f32 	%f8, 0f3727C5AC;

	max.ftz.f32 	%f9, %f10, %f8;

	st.param.f32	[func_retval0+0], %f9;

	ret;

}



	// .globl	_Z27ComputeShadowAnyHitMaterialI17BasicMaterialDataEvRT_

.visible .func _Z27ComputeShadowAnyHitMaterialI17BasicMaterialDataEvRT_(

	.param .b64 _Z27ComputeShadowAnyHitMaterialI17BasicMaterialDataEvRT__param_0

)

{

	.reg .pred 	%p<15>;

	.reg .s16 	%rs<4>;

	.reg .f32 	%f<80>;

	.reg .s32 	%r<34>;

	.reg .s64 	%rd<29>;





	ld.param.u64 	%rd2, [_Z27ComputeShadowAnyHitMaterialI17BasicMaterialDataEvRT__param_0];

	add.s64 	%rd1, %rd2, 704;

	ld.f32 	%f69, [%rd2+704];

	ld.u32 	%r5, [%rd2+724];

	setp.eq.s32	%p1, %r5, -1;

	@%p1 bra 	BB29_3;



	ld.u32 	%r1, [%rd1+16];

	setp.gt.u32	%p2, %r1, 6;

	@%p2 bra 	BB29_3;



	cvt.u64.u32	%rd5, %r1;

	mov.u64 	%rd10, textureSampleBuff;

	cvta.global.u64 	%rd4, %rd10;

	mov.u32 	%r6, 1;

	mov.u32 	%r7, 4;

	mov.u64 	%rd8, 0;

	// inline asm

	call (%rd3), _rt_buffer_get_64, (%rd4, %r6, %r7, %rd5, %rd8, %rd8, %rd8);

	// inline asm

	ld.u32 	%r9, [%rd1+20];

	ld.global.f32 	%f33, [in_attributes+92];

	ld.global.u32 	%r10, [in_attributes+88];

	ld.global.u32 	%r11, [in_attributes+84];

	ld.global.f32 	%f34, [in_attributes+80];

	ld.global.f32 	%f35, [in_attributes+76];

	ld.global.f32 	%f36, [in_attributes+72];

	ld.u32 	%r8, [%rd3];

	// inline asm

	call (%rd9), _rt_callable_program_from_id_64, (%r8);

	// inline asm

	mov.u16 	%rs1, 1;

	cvt.s32.s16	%r12, %rs1;

	// Callseq Start 0

	{

	.reg .b32 temp_param_reg;

	// <end>}

	.param .b32 param0;

	st.param.b32	[param0+0], %r9;

	.param .align 4 .b8 param1[24];

	st.param.f32	[param1+0], %f36;

	st.param.f32	[param1+4], %f35;

	st.param.f32	[param1+8], %f34;

	st.param.b32	[param1+12], %r11;

	st.param.b32	[param1+16], %r10;

	st.param.f32	[param1+20], %f33;

	.param .b32 param2;

	st.param.b32	[param2+0], %r12;

	.param .align 16 .b8 retval0[16];

	prototype_0 : .callprototype (.param .align 16 .b8 _[16]) _ (.param .b32 _, .param .align 4 .b8 _[24], .param .b32 _);

	call (retval0), 

	%rd9, 

	(

	param0, 

	param1, 

	param2

	)

	, prototype_0;

	ld.param.f32	%f69, [retval0+0];

	ld.param.f32	%f37, [retval0+4];

	ld.param.f32	%f38, [retval0+8];

	ld.param.f32	%f39, [retval0+12];

	

	//{

	}// Callseq End 0



BB29_3:

	ld.f32 	%f40, [%rd1+216];

	setp.lt.ftz.f32	%p3, %f69, %f40;

	@%p3 bra 	BB29_17;

	bra.uni 	BB29_4;



BB29_17:

	// inline asm

	call _rt_ignore_intersection, ();

	// inline asm

	bra.uni 	BB29_18;



BB29_4:

	ld.global.u32 	%r13, [in_attributes+188];

	ld.global.u32 	%r14, [in_attributes+184];

	st.global.v2.u32 	[opt_prdShadow], {%r14, %r13};

	mov.u32 	%r15, -1;

	st.global.u32 	[opt_prdShadow+8], %r15;

	ld.global.f32 	%f4, [in_attributes+120];

	ld.f32 	%f70, [%rd1+-96];

	ld.u32 	%r16, [%rd1+-76];

	setp.eq.s32	%p4, %r16, -1;

	@%p4 bra 	BB29_7;



	ld.u32 	%r2, [%rd1+-80];

	setp.gt.u32	%p5, %r2, 6;

	@%p5 bra 	BB29_7;



	cvt.u64.u32	%rd13, %r2;

	mov.u64 	%rd18, textureSampleBuff;

	cvta.global.u64 	%rd12, %rd18;

	mov.u32 	%r17, 1;

	mov.u32 	%r18, 4;

	mov.u64 	%rd16, 0;

	// inline asm

	call (%rd11), _rt_buffer_get_64, (%rd12, %r17, %r18, %rd13, %rd16, %rd16, %rd16);

	// inline asm

	ld.u32 	%r20, [%rd1+-76];

	ld.global.f32 	%f41, [in_attributes+92];

	ld.global.u32 	%r21, [in_attributes+88];

	ld.global.u32 	%r22, [in_attributes+84];

	ld.global.f32 	%f42, [in_attributes+80];

	ld.global.f32 	%f43, [in_attributes+76];

	ld.global.f32 	%f44, [in_attributes+72];

	ld.u32 	%r19, [%rd11];

	// inline asm

	call (%rd17), _rt_callable_program_from_id_64, (%r19);

	// inline asm

	mov.u16 	%rs2, 1;

	cvt.s32.s16	%r23, %rs2;

	// Callseq Start 1

	{

	.reg .b32 temp_param_reg;

	// <end>}

	.param .b32 param0;

	st.param.b32	[param0+0], %r20;

	.param .align 4 .b8 param1[24];

	st.param.f32	[param1+0], %f44;

	st.param.f32	[param1+4], %f43;

	st.param.f32	[param1+8], %f42;

	st.param.b32	[param1+12], %r22;

	st.param.b32	[param1+16], %r21;

	st.param.f32	[param1+20], %f41;

	.param .b32 param2;

	st.param.b32	[param2+0], %r23;

	.param .align 16 .b8 retval0[16];

	prototype_1 : .callprototype (.param .align 16 .b8 _[16]) _ (.param .b32 _, .param .align 4 .b8 _[24], .param .b32 _);

	call (retval0), 

	%rd17, 

	(

	param0, 

	param1, 

	param2

	)

	, prototype_1;

	ld.param.f32	%f70, [retval0+0];

	ld.param.f32	%f45, [retval0+4];

	ld.param.f32	%f46, [retval0+8];

	ld.param.f32	%f47, [retval0+12];

	

	//{

	}// Callseq End 1



BB29_7:

	ld.v4.f32 	{%f48, %f49, %f50, %f51}, [%rd1+-128];

	mov.f32 	%f71, %f48;

	mov.f32 	%f72, %f49;

	mov.f32 	%f73, %f50;

	mov.f32 	%f74, %f51;

	ld.u32 	%r24, [%rd1+-108];

	setp.eq.s32	%p6, %r24, -1;

	@%p6 bra 	BB29_10;



	ld.u32 	%r3, [%rd1+-112];

	setp.gt.u32	%p7, %r3, 6;

	@%p7 bra 	BB29_10;



	cvt.u64.u32	%rd21, %r3;

	mov.u64 	%rd26, textureSampleBuff;

	cvta.global.u64 	%rd20, %rd26;

	mov.u32 	%r25, 1;

	mov.u32 	%r26, 4;

	mov.u64 	%rd24, 0;

	// inline asm

	call (%rd19), _rt_buffer_get_64, (%rd20, %r25, %r26, %rd21, %rd24, %rd24, %rd24);

	// inline asm

	ld.u32 	%r28, [%rd1+-108];

	ld.global.f32 	%f52, [in_attributes+92];

	ld.global.u32 	%r29, [in_attributes+88];

	ld.global.u32 	%r30, [in_attributes+84];

	ld.global.f32 	%f53, [in_attributes+80];

	ld.global.f32 	%f54, [in_attributes+76];

	ld.global.f32 	%f55, [in_attributes+72];

	ld.u32 	%r27, [%rd19];

	// inline asm

	call (%rd25), _rt_callable_program_from_id_64, (%r27);

	// inline asm

	mov.u16 	%rs3, 1;

	cvt.s32.s16	%r31, %rs3;

	// Callseq Start 2

	{

	.reg .b32 temp_param_reg;

	// <end>}

	.param .b32 param0;

	st.param.b32	[param0+0], %r28;

	.param .align 4 .b8 param1[24];

	st.param.f32	[param1+0], %f55;

	st.param.f32	[param1+4], %f54;

	st.param.f32	[param1+8], %f53;

	st.param.b32	[param1+12], %r30;

	st.param.b32	[param1+16], %r29;

	st.param.f32	[param1+20], %f52;

	.param .b32 param2;

	st.param.b32	[param2+0], %r31;

	.param .align 16 .b8 retval0[16];

	prototype_2 : .callprototype (.param .align 16 .b8 _[16]) _ (.param .b32 _, .param .align 4 .b8 _[24], .param .b32 _);

	call (retval0), 

	%rd25, 

	(

	param0, 

	param1, 

	param2

	)

	, prototype_2;

	ld.param.f32	%f71, [retval0+0];

	ld.param.f32	%f72, [retval0+4];

	ld.param.f32	%f73, [retval0+8];

	ld.param.f32	%f74, [retval0+12];

	

	//{

	}// Callseq End 2



BB29_10:

	mul.ftz.f32 	%f20, %f70, %f71;

	mov.f32 	%f56, 0f3F800000;

	sub.ftz.f32 	%f21, %f56, %f20;

	mul.ftz.f32 	%f22, %f70, %f72;

	sub.ftz.f32 	%f23, %f56, %f22;

	mul.ftz.f32 	%f24, %f70, %f73;

	sub.ftz.f32 	%f25, %f56, %f24;

	ld.u64 	%rd27, [%rd1+160];

	cvt.u32.u64	%r32, %rd27;

	setp.eq.s32	%p8, %r32, 2;

	shr.u64 	%rd28, %rd27, 32;

	cvt.u32.u64	%r4, %rd28;

	setp.eq.s32	%p9, %r4, 1;

	and.pred  	%p10, %p8, %p9;

	setp.ne.s32	%p11, %r32, 2;

	or.pred  	%p12, %p10, %p11;

	mul.ftz.f32 	%f57, %f70, %f74;

	selp.f32	%f26, %f57, %f21, %p10;

	selp.f32	%f27, %f57, %f23, %p10;

	selp.f32	%f28, %f57, %f25, %p10;

	mov.f32 	%f77, %f28;

	mov.f32 	%f78, %f27;

	mov.f32 	%f79, %f26;

	@%p12 bra 	BB29_13;



	setp.ne.s32	%p13, %r4, 0;

	mov.f32 	%f77, %f25;

	mov.f32 	%f78, %f23;

	mov.f32 	%f79, %f21;

	@%p13 bra 	BB29_13;



	add.ftz.f32 	%f58, %f20, %f22;

	add.ftz.f32 	%f59, %f58, %f24;

	mov.f32 	%f60, 0f40400000;

	div.approx.ftz.f32 	%f79, %f59, %f60;

	mov.f32 	%f78, %f79;

	mov.f32 	%f77, %f79;



BB29_13:

	add.ftz.f32 	%f61, %f79, %f78;

	add.ftz.f32 	%f62, %f61, %f77;

	mov.f32 	%f63, 0f40400000;

	div.approx.ftz.f32 	%f64, %f62, %f63;

	mul.ftz.f32 	%f65, %f4, %f64;

	ld.global.f32 	%f66, [in_attributes+128];

	mul.ftz.f32 	%f67, %f65, %f66;

	setp.lt.ftz.f32	%p14, %f67, 0f3F800000;

	@%p14 bra 	BB29_15;

	bra.uni 	BB29_14;



BB29_15:

	mov.u32 	%r33, 1065353216;

	st.global.u32 	[opt_prdShadow+72], %r33;

	bra.uni 	BB29_16;



BB29_14:

	st.global.v4.f32 	[opt_prdShadow+32], {%f56, %f56, %f56, %f56};



BB29_16:

	// inline asm

	call _rt_terminate_ray, ();

	// inline asm



BB29_18:

	ret;

}



	// .globl	_ZN10ColorUtils17DoGammaCorrectionERK6float4j

.visible .func  (.param .align 16 .b8 func_retval0[16]) _ZN10ColorUtils17DoGammaCorrectionERK6float4j(

	.param .b64 _ZN10ColorUtils17DoGammaCorrectionERK6float4j_param_0,

	.param .b32 _ZN10ColorUtils17DoGammaCorrectionERK6float4j_param_1

)

{

	.reg .pred 	%p<4>;

	.reg .f32 	%f<39>;

	.reg .s32 	%r<2>;

	.reg .s64 	%rd<3>;





	ld.param.u64 	%rd2, [_ZN10ColorUtils17DoGammaCorrectionERK6float4j_param_0];

	ld.param.u32 	%r1, [_ZN10ColorUtils17DoGammaCorrectionERK6float4j_param_1];

	mov.f32 	%f35, 0f3F800000;

	setp.eq.s32	%p1, %r1, 1;

	@%p1 bra 	BB30_3;

	bra.uni 	BB30_1;



BB30_3:

	ld.global.f32 	%f35, [materialGamma];

	bra.uni 	BB30_4;



BB30_1:

	setp.ne.s32	%p2, %r1, 2;

	@%p2 bra 	BB30_4;



	ld.global.f32 	%f35, [lightsGamma];



BB30_4:

	ld.v4.f32 	{%f18, %f19, %f20, %f21}, [%rd2];

	mov.f32 	%f36, %f18;

	mov.f32 	%f37, %f19;

	mov.f32 	%f38, %f20;

	setp.eq.ftz.f32	%p3, %f35, 0f3F800000;

	@%p3 bra 	BB30_6;



	mov.f32 	%f22, 0f00000000;

	max.ftz.f32 	%f23, %f18, %f22;

	max.ftz.f32 	%f24, %f22, %f23;

	max.ftz.f32 	%f25, %f19, %f22;

	max.ftz.f32 	%f26, %f22, %f25;

	max.ftz.f32 	%f27, %f20, %f22;

	max.ftz.f32 	%f28, %f22, %f27;

	lg2.approx.ftz.f32 	%f29, %f24;

	mul.ftz.f32 	%f30, %f35, %f29;

	ex2.approx.ftz.f32 	%f36, %f30;

	lg2.approx.ftz.f32 	%f31, %f26;

	mul.ftz.f32 	%f32, %f35, %f31;

	ex2.approx.ftz.f32 	%f37, %f32;

	lg2.approx.ftz.f32 	%f33, %f28;

	mul.ftz.f32 	%f34, %f35, %f33;

	ex2.approx.ftz.f32 	%f38, %f34;



BB30_6:

	st.param.f32	[func_retval0+0], %f36;

	st.param.f32	[func_retval0+4], %f37;

	st.param.f32	[func_retval0+8], %f38;

	st.param.f32	[func_retval0+12], %f21;

	ret;

}



	// .globl	_ZN10AlphaUtils8GetAlphaERK11TextureDataRK11SamplerInfoRK5uint2S2_

.visible .func  (.param .align 16 .b8 func_retval0[16]) _ZN10AlphaUtils8GetAlphaERK11TextureDataRK11SamplerInfoRK5uint2S2_(

	.param .b64 _ZN10AlphaUtils8GetAlphaERK11TextureDataRK11SamplerInfoRK5uint2S2__param_0,

	.param .b64 _ZN10AlphaUtils8GetAlphaERK11TextureDataRK11SamplerInfoRK5uint2S2__param_1,

	.param .b64 _ZN10AlphaUtils8GetAlphaERK11TextureDataRK11SamplerInfoRK5uint2S2__param_2,

	.param .b64 _ZN10AlphaUtils8GetAlphaERK11TextureDataRK11SamplerInfoRK5uint2S2__param_3

)

{

	.reg .pred 	%p<11>;

	.reg .s16 	%rs<3>;

	.reg .f32 	%f<63>;

	.reg .s32 	%r<23>;

	.reg .s64 	%rd<24>;





	ld.param.u64 	%rd3, [_ZN10AlphaUtils8GetAlphaERK11TextureDataRK11SamplerInfoRK5uint2S2__param_0];

	ld.param.u64 	%rd4, [_ZN10AlphaUtils8GetAlphaERK11TextureDataRK11SamplerInfoRK5uint2S2__param_1];

	ld.param.u64 	%rd5, [_ZN10AlphaUtils8GetAlphaERK11TextureDataRK11SamplerInfoRK5uint2S2__param_2];

	ld.param.u64 	%rd1, [_ZN10AlphaUtils8GetAlphaERK11TextureDataRK11SamplerInfoRK5uint2S2__param_3];

	ld.f32 	%f53, [%rd1];

	ld.u32 	%r4, [%rd1+20];

	setp.eq.s32	%p1, %r4, -1;

	@%p1 bra 	BB31_3;



	ld.u32 	%r1, [%rd1+16];

	setp.gt.u32	%p2, %r1, 6;

	@%p2 bra 	BB31_3;



	cvt.u64.u32	%rd8, %r1;

	mov.u64 	%rd13, textureSampleBuff;

	cvta.global.u64 	%rd7, %rd13;

	mov.u32 	%r5, 1;

	mov.u32 	%r6, 4;

	mov.u64 	%rd11, 0;

	// inline asm

	call (%rd6), _rt_buffer_get_64, (%rd7, %r5, %r6, %rd8, %rd11, %rd11, %rd11);

	// inline asm

	ld.u32 	%r8, [%rd1+20];

	ld.f32 	%f29, [%rd4+20];

	ld.u32 	%r9, [%rd4+16];

	ld.u32 	%r10, [%rd4+12];

	ld.f32 	%f30, [%rd4+8];

	ld.f32 	%f31, [%rd4+4];

	ld.f32 	%f32, [%rd4];

	ld.u32 	%r7, [%rd6];

	// inline asm

	call (%rd12), _rt_callable_program_from_id_64, (%r7);

	// inline asm

	mov.u16 	%rs1, 1;

	cvt.s32.s16	%r11, %rs1;

	// Callseq Start 3

	{

	.reg .b32 temp_param_reg;

	// <end>}

	.param .b32 param0;

	st.param.b32	[param0+0], %r8;

	.param .align 4 .b8 param1[24];

	st.param.f32	[param1+0], %f32;

	st.param.f32	[param1+4], %f31;

	st.param.f32	[param1+8], %f30;

	st.param.b32	[param1+12], %r10;

	st.param.b32	[param1+16], %r9;

	st.param.f32	[param1+20], %f29;

	.param .b32 param2;

	st.param.b32	[param2+0], %r11;

	.param .align 16 .b8 retval0[16];

	prototype_3 : .callprototype (.param .align 16 .b8 _[16]) _ (.param .b32 _, .param .align 4 .b8 _[24], .param .b32 _);

	call (retval0), 

	%rd12, 

	(

	param0, 

	param1, 

	param2

	)

	, prototype_3;

	ld.param.f32	%f53, [retval0+0];

	ld.param.f32	%f33, [retval0+4];

	ld.param.f32	%f34, [retval0+8];

	ld.param.f32	%f35, [retval0+12];

	

	//{

	}// Callseq End 3



BB31_3:

	ld.v4.f32 	{%f36, %f37, %f38, %f39}, [%rd3];

	mov.f32 	%f54, %f36;

	mov.f32 	%f55, %f37;

	mov.f32 	%f56, %f38;

	mov.f32 	%f57, %f39;

	ld.v2.u32 	{%r12, %r13}, [%rd3+16];

	setp.eq.s32	%p3, %r13, -1;

	@%p3 bra 	BB31_6;



	setp.gt.u32	%p4, %r12, 6;

	@%p4 bra 	BB31_6;



	cvt.u64.u32	%rd16, %r12;

	mov.u64 	%rd21, textureSampleBuff;

	cvta.global.u64 	%rd15, %rd21;

	mov.u32 	%r15, 1;

	mov.u32 	%r16, 4;

	mov.u64 	%rd19, 0;

	// inline asm

	call (%rd14), _rt_buffer_get_64, (%rd15, %r15, %r16, %rd16, %rd19, %rd19, %rd19);

	// inline asm

	ld.u32 	%r18, [%rd3+20];

	ld.f32 	%f40, [%rd4+20];

	ld.u32 	%r19, [%rd4+16];

	ld.u32 	%r20, [%rd4+12];

	ld.f32 	%f41, [%rd4+8];

	ld.f32 	%f42, [%rd4+4];

	ld.f32 	%f43, [%rd4];

	ld.u32 	%r17, [%rd14];

	// inline asm

	call (%rd20), _rt_callable_program_from_id_64, (%r17);

	// inline asm

	mov.u16 	%rs2, 1;

	cvt.s32.s16	%r21, %rs2;

	// Callseq Start 4

	{

	.reg .b32 temp_param_reg;

	// <end>}

	.param .b32 param0;

	st.param.b32	[param0+0], %r18;

	.param .align 4 .b8 param1[24];

	st.param.f32	[param1+0], %f43;

	st.param.f32	[param1+4], %f42;

	st.param.f32	[param1+8], %f41;

	st.param.b32	[param1+12], %r20;

	st.param.b32	[param1+16], %r19;

	st.param.f32	[param1+20], %f40;

	.param .b32 param2;

	st.param.b32	[param2+0], %r21;

	.param .align 16 .b8 retval0[16];

	prototype_4 : .callprototype (.param .align 16 .b8 _[16]) _ (.param .b32 _, .param .align 4 .b8 _[24], .param .b32 _);

	call (retval0), 

	%rd20, 

	(

	param0, 

	param1, 

	param2

	)

	, prototype_4;

	ld.param.f32	%f54, [retval0+0];

	ld.param.f32	%f55, [retval0+4];

	ld.param.f32	%f56, [retval0+8];

	ld.param.f32	%f57, [retval0+12];

	

	//{

	}// Callseq End 4



BB31_6:

	mul.ftz.f32 	%f16, %f53, %f54;

	mov.f32 	%f44, 0f3F800000;

	sub.ftz.f32 	%f17, %f44, %f16;

	mul.ftz.f32 	%f18, %f53, %f55;

	sub.ftz.f32 	%f19, %f44, %f18;

	mul.ftz.f32 	%f20, %f53, %f56;

	sub.ftz.f32 	%f21, %f44, %f20;

	ld.u64 	%rd22, [%rd5];

	cvt.u32.u64	%r22, %rd22;

	setp.eq.s32	%p5, %r22, 2;

	shr.u64 	%rd23, %rd22, 32;

	cvt.u32.u64	%r3, %rd23;

	setp.eq.s32	%p6, %r3, 1;

	and.pred  	%p7, %p5, %p6;

	setp.ne.s32	%p8, %r22, 2;

	or.pred  	%p9, %p7, %p8;

	mul.ftz.f32 	%f45, %f53, %f57;

	selp.f32	%f22, %f45, %f17, %p7;

	selp.f32	%f23, %f45, %f19, %p7;

	selp.f32	%f24, %f45, %f21, %p7;

	mov.f32 	%f60, %f24;

	mov.f32 	%f61, %f23;

	mov.f32 	%f62, %f22;

	@%p9 bra 	BB31_9;



	setp.ne.s32	%p10, %r3, 0;

	mov.f32 	%f60, %f21;

	mov.f32 	%f61, %f19;

	mov.f32 	%f62, %f17;

	@%p10 bra 	BB31_9;



	add.ftz.f32 	%f46, %f16, %f18;

	add.ftz.f32 	%f47, %f46, %f20;

	mov.f32 	%f48, 0f40400000;

	div.approx.ftz.f32 	%f62, %f47, %f48;

	mov.f32 	%f61, %f62;

	mov.f32 	%f60, %f62;



BB31_9:

	add.ftz.f32 	%f49, %f62, %f61;

	add.ftz.f32 	%f50, %f49, %f60;

	mov.f32 	%f51, 0f40400000;

	div.approx.ftz.f32 	%f52, %f50, %f51;

	st.param.f32	[func_retval0+0], %f62;

	st.param.f32	[func_retval0+4], %f61;

	st.param.f32	[func_retval0+8], %f60;

	st.param.f32	[func_retval0+12], %f52;

	ret;

}



	// .globl	_Z31ComputeShadowClosestHitMaterialI17BasicMaterialDataEvRT_

.visible .func _Z31ComputeShadowClosestHitMaterialI17BasicMaterialDataEvRT_(

	.param .b64 _Z31ComputeShadowClosestHitMaterialI17BasicMaterialDataEvRT__param_0

)

{

	.reg .pred 	%p<16>;

	.reg .s16 	%rs<4>;

	.reg .f32 	%f<142>;

	.reg .s32 	%r<41>;

	.reg .s64 	%rd<29>;





	ld.param.u64 	%rd2, [_Z31ComputeShadowClosestHitMaterialI17BasicMaterialDataEvRT__param_0];

	ld.global.u32 	%r40, [in_attributes+184];

	ld.global.u32 	%r9, [in_attributes+188];

	st.global.v2.u32 	[opt_prdShadow], {%r40, %r9};

	mov.u32 	%r10, -1;

	st.global.u32 	[opt_prdShadow+8], %r10;

	add.s64 	%rd1, %rd2, 704;

	ld.f32 	%f131, [%rd2+704];

	ld.u32 	%r11, [%rd2+724];

	setp.eq.s32	%p1, %r11, -1;

	@%p1 bra 	BB32_3;



	ld.u32 	%r2, [%rd1+16];

	setp.gt.u32	%p2, %r2, 6;

	@%p2 bra 	BB32_3;



	cvt.u64.u32	%rd5, %r2;

	mov.u64 	%rd10, textureSampleBuff;

	cvta.global.u64 	%rd4, %rd10;

	mov.u32 	%r12, 1;

	mov.u32 	%r13, 4;

	mov.u64 	%rd8, 0;

	// inline asm

	call (%rd3), _rt_buffer_get_64, (%rd4, %r12, %r13, %rd5, %rd8, %rd8, %rd8);

	// inline asm

	ld.u32 	%r15, [%rd1+20];

	ld.global.f32 	%f32, [in_attributes+92];

	ld.global.u32 	%r16, [in_attributes+88];

	ld.global.u32 	%r17, [in_attributes+84];

	ld.global.f32 	%f33, [in_attributes+80];

	ld.global.f32 	%f34, [in_attributes+76];

	ld.global.f32 	%f35, [in_attributes+72];

	ld.u32 	%r14, [%rd3];

	// inline asm

	call (%rd9), _rt_callable_program_from_id_64, (%r14);

	// inline asm

	mov.u16 	%rs1, 1;

	cvt.s32.s16	%r18, %rs1;

	// Callseq Start 5

	{

	.reg .b32 temp_param_reg;

	// <end>}

	.param .b32 param0;

	st.param.b32	[param0+0], %r15;

	.param .align 4 .b8 param1[24];

	st.param.f32	[param1+0], %f35;

	st.param.f32	[param1+4], %f34;

	st.param.f32	[param1+8], %f33;

	st.param.b32	[param1+12], %r17;

	st.param.b32	[param1+16], %r16;

	st.param.f32	[param1+20], %f32;

	.param .b32 param2;

	st.param.b32	[param2+0], %r18;

	.param .align 16 .b8 retval0[16];

	prototype_5 : .callprototype (.param .align 16 .b8 _[16]) _ (.param .b32 _, .param .align 4 .b8 _[24], .param .b32 _);

	call (retval0), 

	%rd9, 

	(

	param0, 

	param1, 

	param2

	)

	, prototype_5;

	ld.param.f32	%f131, [retval0+0];

	ld.param.f32	%f36, [retval0+4];

	ld.param.f32	%f37, [retval0+8];

	ld.param.f32	%f38, [retval0+12];

	

	//{

	}// Callseq End 5

	ld.global.u32 	%r40, [in_attributes+184];



BB32_3:

	ld.f32 	%f39, [%rd1+216];

	setp.lt.ftz.f32	%p3, %f131, %f39;

	ld.global.u32 	%r19, [opt_prdShadow+80];

	setp.eq.s32	%p4, %r19, %r40;

	or.pred  	%p5, %p3, %p4;

	ld.v2.u32 	{%r20, %r21}, [%rd2+624];

	@%p5 bra 	BB32_14;



	ld.f32 	%f132, [%rd1+-96];

	setp.eq.s32	%p6, %r21, -1;

	@%p6 bra 	BB32_7;



	setp.gt.u32	%p7, %r20, 6;

	@%p7 bra 	BB32_7;



	cvt.u64.u32	%rd13, %r20;

	mov.u64 	%rd18, textureSampleBuff;

	cvta.global.u64 	%rd12, %rd18;

	mov.u32 	%r22, 1;

	mov.u32 	%r23, 4;

	mov.u64 	%rd16, 0;

	// inline asm

	call (%rd11), _rt_buffer_get_64, (%rd12, %r22, %r23, %rd13, %rd16, %rd16, %rd16);

	// inline asm

	ld.u32 	%r25, [%rd1+-76];

	ld.global.f32 	%f40, [in_attributes+92];

	ld.global.u32 	%r26, [in_attributes+88];

	ld.global.u32 	%r27, [in_attributes+84];

	ld.global.f32 	%f41, [in_attributes+80];

	ld.global.f32 	%f42, [in_attributes+76];

	ld.global.f32 	%f43, [in_attributes+72];

	ld.u32 	%r24, [%rd11];

	// inline asm

	call (%rd17), _rt_callable_program_from_id_64, (%r24);

	// inline asm

	mov.u16 	%rs2, 1;

	cvt.s32.s16	%r28, %rs2;

	// Callseq Start 6

	{

	.reg .b32 temp_param_reg;

	// <end>}

	.param .b32 param0;

	st.param.b32	[param0+0], %r25;

	.param .align 4 .b8 param1[24];

	st.param.f32	[param1+0], %f43;

	st.param.f32	[param1+4], %f42;

	st.param.f32	[param1+8], %f41;

	st.param.b32	[param1+12], %r27;

	st.param.b32	[param1+16], %r26;

	st.param.f32	[param1+20], %f40;

	.param .b32 param2;

	st.param.b32	[param2+0], %r28;

	.param .align 16 .b8 retval0[16];

	prototype_6 : .callprototype (.param .align 16 .b8 _[16]) _ (.param .b32 _, .param .align 4 .b8 _[24], .param .b32 _);

	call (retval0), 

	%rd17, 

	(

	param0, 

	param1, 

	param2

	)

	, prototype_6;

	ld.param.f32	%f132, [retval0+0];

	ld.param.f32	%f44, [retval0+4];

	ld.param.f32	%f45, [retval0+8];

	ld.param.f32	%f46, [retval0+12];

	

	//{

	}// Callseq End 6



BB32_7:

	ld.v4.f32 	{%f47, %f48, %f49, %f50}, [%rd1+-128];

	mov.f32 	%f133, %f47;

	mov.f32 	%f134, %f48;

	mov.f32 	%f135, %f49;

	mov.f32 	%f136, %f50;

	ld.u32 	%r29, [%rd1+-108];

	setp.eq.s32	%p8, %r29, -1;

	@%p8 bra 	BB32_10;



	ld.u32 	%r7, [%rd1+-112];

	setp.gt.u32	%p9, %r7, 6;

	@%p9 bra 	BB32_10;



	cvt.u64.u32	%rd21, %r7;

	mov.u64 	%rd26, textureSampleBuff;

	cvta.global.u64 	%rd20, %rd26;

	mov.u32 	%r30, 1;

	mov.u32 	%r31, 4;

	mov.u64 	%rd24, 0;

	// inline asm

	call (%rd19), _rt_buffer_get_64, (%rd20, %r30, %r31, %rd21, %rd24, %rd24, %rd24);

	// inline asm

	ld.u32 	%r33, [%rd1+-108];

	ld.global.f32 	%f51, [in_attributes+92];

	ld.global.u32 	%r34, [in_attributes+88];

	ld.global.u32 	%r35, [in_attributes+84];

	ld.global.f32 	%f52, [in_attributes+80];

	ld.global.f32 	%f53, [in_attributes+76];

	ld.global.f32 	%f54, [in_attributes+72];

	ld.u32 	%r32, [%rd19];

	// inline asm

	call (%rd25), _rt_callable_program_from_id_64, (%r32);

	// inline asm

	mov.u16 	%rs3, 1;

	cvt.s32.s16	%r36, %rs3;

	// Callseq Start 7

	{

	.reg .b32 temp_param_reg;

	// <end>}

	.param .b32 param0;

	st.param.b32	[param0+0], %r33;

	.param .align 4 .b8 param1[24];

	st.param.f32	[param1+0], %f54;

	st.param.f32	[param1+4], %f53;

	st.param.f32	[param1+8], %f52;

	st.param.b32	[param1+12], %r35;

	st.param.b32	[param1+16], %r34;

	st.param.f32	[param1+20], %f51;

	.param .b32 param2;

	st.param.b32	[param2+0], %r36;

	.param .align 16 .b8 retval0[16];

	prototype_7 : .callprototype (.param .align 16 .b8 _[16]) _ (.param .b32 _, .param .align 4 .b8 _[24], .param .b32 _);

	call (retval0), 

	%rd25, 

	(

	param0, 

	param1, 

	param2

	)

	, prototype_7;

	ld.param.f32	%f133, [retval0+0];

	ld.param.f32	%f134, [retval0+4];

	ld.param.f32	%f135, [retval0+8];

	ld.param.f32	%f136, [retval0+12];

	

	//{

	}// Callseq End 7



BB32_10:

	mul.ftz.f32 	%f19, %f132, %f133;

	mov.f32 	%f55, 0f3F800000;

	sub.ftz.f32 	%f20, %f55, %f19;

	mul.ftz.f32 	%f21, %f132, %f134;

	sub.ftz.f32 	%f22, %f55, %f21;

	mul.ftz.f32 	%f23, %f132, %f135;

	sub.ftz.f32 	%f24, %f55, %f23;

	ld.u64 	%rd27, [%rd1+160];

	cvt.u32.u64	%r37, %rd27;

	setp.eq.s32	%p10, %r37, 2;

	shr.u64 	%rd28, %rd27, 32;

	cvt.u32.u64	%r8, %rd28;

	setp.eq.s32	%p11, %r8, 1;

	and.pred  	%p12, %p10, %p11;

	setp.ne.s32	%p13, %r37, 2;

	or.pred  	%p14, %p12, %p13;

	mul.ftz.f32 	%f56, %f132, %f136;

	selp.f32	%f25, %f56, %f20, %p12;

	selp.f32	%f26, %f56, %f22, %p12;

	selp.f32	%f27, %f56, %f24, %p12;

	mov.f32 	%f139, %f27;

	mov.f32 	%f140, %f26;

	mov.f32 	%f141, %f25;

	@%p14 bra 	BB32_13;



	setp.ne.s32	%p15, %r8, 0;

	mov.f32 	%f139, %f24;

	mov.f32 	%f140, %f22;

	mov.f32 	%f141, %f20;

	@%p15 bra 	BB32_13;



	add.ftz.f32 	%f57, %f19, %f21;

	add.ftz.f32 	%f58, %f57, %f23;

	mov.f32 	%f59, 0f40400000;

	div.approx.ftz.f32 	%f141, %f58, %f59;

	mov.f32 	%f140, %f141;

	mov.f32 	%f139, %f141;



BB32_13:

	add.ftz.f32 	%f68, %f141, %f140;

	add.ftz.f32 	%f69, %f68, %f139;

	mov.f32 	%f70, 0f40400000;

	div.approx.ftz.f32 	%f71, %f69, %f70;

	ld.global.f32 	%f72, [in_attributes+128];

	ld.global.f32 	%f64, [in_attributes+144];

	ld.global.f32 	%f65, [in_attributes+148];

	ld.global.f32 	%f66, [in_attributes+152];

	mov.u32 	%r38, 7937;

	mov.f32 	%f67, 0f00000000;

	// inline asm

	call (%f60, %f61, %f62, %f63), _rt_transform_tuple, (%r38, %f64, %f65, %f66, %f67);

	// inline asm

	mul.ftz.f32 	%f73, %f61, %f61;

	fma.rn.ftz.f32 	%f74, %f60, %f60, %f73;

	fma.rn.ftz.f32 	%f75, %f62, %f62, %f74;

	sqrt.approx.ftz.f32 	%f76, %f75;

	rcp.approx.ftz.f32 	%f77, %f76;

	mul.ftz.f32 	%f78, %f60, %f77;

	mul.ftz.f32 	%f79, %f61, %f77;

	mul.ftz.f32 	%f80, %f62, %f77;

	ld.global.v4.f32 	{%f81, %f82, %f83, %f84}, [opt_prdShadow+32];

	sub.ftz.f32 	%f87, %f55, %f81;

	sub.ftz.f32 	%f89, %f55, %f82;

	sub.ftz.f32 	%f91, %f55, %f83;

	sub.ftz.f32 	%f93, %f55, %f84;

	ld.global.f32 	%f94, [in_attributes+120];

	mul.ftz.f32 	%f95, %f94, %f87;

	mul.ftz.f32 	%f96, %f94, %f89;

	mul.ftz.f32 	%f97, %f94, %f91;

	mul.ftz.f32 	%f98, %f94, %f93;

	ld.global.f32 	%f99, [opt_ray+12];

	ld.global.f32 	%f100, [opt_ray+16];

	mul.ftz.f32 	%f101, %f100, %f100;

	fma.rn.ftz.f32 	%f102, %f99, %f99, %f101;

	ld.global.f32 	%f103, [opt_ray+20];

	fma.rn.ftz.f32 	%f104, %f103, %f103, %f102;

	sqrt.approx.ftz.f32 	%f105, %f104;

	rcp.approx.ftz.f32 	%f106, %f105;

	mul.ftz.f32 	%f107, %f106, %f99;

	mul.ftz.f32 	%f108, %f106, %f100;

	mul.ftz.f32 	%f109, %f106, %f103;

	mul.ftz.f32 	%f110, %f79, %f108;

	fma.rn.ftz.f32 	%f111, %f78, %f107, %f110;

	fma.rn.ftz.f32 	%f112, %f80, %f109, %f111;

	abs.ftz.f32 	%f113, %f112;

	sub.ftz.f32 	%f114, %f55, %f113;

	ld.f32 	%f115, [%rd1+212];

	mul.ftz.f32 	%f116, %f115, %f114;

	sub.ftz.f32 	%f117, %f55, %f116;

	fma.rn.ftz.f32 	%f118, %f141, %f72, 0fBF800000;

	fma.rn.ftz.f32 	%f119, %f140, %f72, 0fBF800000;

	fma.rn.ftz.f32 	%f120, %f139, %f72, 0fBF800000;

	fma.rn.ftz.f32 	%f121, %f71, %f72, 0fBF800000;

	fma.rn.ftz.f32 	%f122, %f118, %f117, 0f3F800000;

	fma.rn.ftz.f32 	%f123, %f119, %f117, 0f3F800000;

	fma.rn.ftz.f32 	%f124, %f120, %f117, 0f3F800000;

	fma.rn.ftz.f32 	%f125, %f121, %f117, 0f3F800000;

	fma.rn.ftz.f32 	%f126, %f98, %f125, %f84;

	fma.rn.ftz.f32 	%f127, %f97, %f124, %f83;

	fma.rn.ftz.f32 	%f128, %f96, %f123, %f82;

	fma.rn.ftz.f32 	%f129, %f95, %f122, %f81;

	st.global.v4.f32 	[opt_prdShadow+32], {%f129, %f128, %f127, %f126};



BB32_14:

	ld.global.f32 	%f130, [opt_intersectionDistance];

	st.global.f32 	[opt_prdShadow+72], %f130;

	st.global.u32 	[opt_prdShadow+80], %r10;

	ret;

}



	// .globl	_Z13shadowsAnyHitv

.visible .entry _Z13shadowsAnyHitv(



)

{

	.reg .pred 	%p<18>;

	.reg .s16 	%rs<4>;

	.reg .f32 	%f<79>;

	.reg .s32 	%r<42>;

	.reg .s64 	%rd<28>;





	mov.u64 	%rd1, matData;

	add.s64 	%rd2, %rd1, 704;

	ldu.global.f32 	%f66, [%rd2];

	add.s64 	%rd3, %rd1, 720;

	ldu.global.v2.u32 	{%r7, %r8}, [%rd3];

	setp.lt.u32	%p1, %r7, 7;

	setp.ne.s32	%p2, %r8, -1;

	and.pred  	%p3, %p1, %p2;

	@!%p3 bra 	BB33_2;

	bra.uni 	BB33_1;



BB33_1:

	cvt.u64.u32	%rd6, %r7;

	mov.u64 	%rd11, textureSampleBuff;

	cvta.global.u64 	%rd5, %rd11;

	mov.u32 	%r10, 1;

	mov.u32 	%r11, 4;

	mov.u64 	%rd9, 0;

	// inline asm

	call (%rd4), _rt_buffer_get_64, (%rd5, %r10, %r11, %rd6, %rd9, %rd9, %rd9);

	// inline asm

	ld.global.u32 	%r13, [matData+724];

	ld.global.f32 	%f31, [in_attributes+92];

	ld.global.u32 	%r14, [in_attributes+88];

	ld.global.u32 	%r15, [in_attributes+84];

	ld.global.f32 	%f32, [in_attributes+80];

	ld.global.f32 	%f33, [in_attributes+76];

	ld.global.f32 	%f34, [in_attributes+72];

	ld.u32 	%r12, [%rd4];

	// inline asm

	call (%rd10), _rt_callable_program_from_id_64, (%r12);

	// inline asm

	mov.u16 	%rs1, 1;

	cvt.s32.s16	%r16, %rs1;

	// Callseq Start 8

	{

	.reg .b32 temp_param_reg;

	// <end>}

	.param .b32 param0;

	st.param.b32	[param0+0], %r13;

	.param .align 4 .b8 param1[24];

	st.param.f32	[param1+0], %f34;

	st.param.f32	[param1+4], %f33;

	st.param.f32	[param1+8], %f32;

	st.param.b32	[param1+12], %r15;

	st.param.b32	[param1+16], %r14;

	st.param.f32	[param1+20], %f31;

	.param .b32 param2;

	st.param.b32	[param2+0], %r16;

	.param .align 16 .b8 retval0[16];

	prototype_8 : .callprototype (.param .align 16 .b8 _[16]) _ (.param .b32 _, .param .align 4 .b8 _[24], .param .b32 _);

	call (retval0), 

	%rd10, 

	(

	param0, 

	param1, 

	param2

	)

	, prototype_8;

	ld.param.f32	%f66, [retval0+0];

	ld.param.f32	%f35, [retval0+4];

	ld.param.f32	%f36, [retval0+8];

	ld.param.f32	%f37, [retval0+12];

	

	//{

	}// Callseq End 8



BB33_2:

	ld.global.f32 	%f38, [matData+920];

	setp.lt.ftz.f32	%p4, %f66, %f38;

	ld.global.v2.u32 	{%r17, %r18}, [matData+624];

	@%p4 bra 	BB33_14;

	bra.uni 	BB33_3;



BB33_14:

	// inline asm

	call _rt_ignore_intersection, ();

	// inline asm

	bra.uni 	BB33_15;



BB33_3:

	ld.global.u32 	%r19, [in_attributes+188];

	ld.global.u32 	%r20, [in_attributes+184];

	st.global.v2.u32 	[opt_prdShadow], {%r20, %r19};

	mov.u32 	%r21, -1;

	st.global.u32 	[opt_prdShadow+8], %r21;

	ld.global.f32 	%f4, [in_attributes+120];

	ld.global.f32 	%f67, [matData+608];

	setp.lt.u32	%p5, %r17, 7;

	setp.ne.s32	%p6, %r18, -1;

	and.pred  	%p7, %p5, %p6;

	@!%p7 bra 	BB33_5;

	bra.uni 	BB33_4;



BB33_4:

	cvt.u64.u32	%rd14, %r17;

	mov.u64 	%rd19, textureSampleBuff;

	cvta.global.u64 	%rd13, %rd19;

	mov.u32 	%r22, 1;

	mov.u32 	%r23, 4;

	mov.u64 	%rd17, 0;

	// inline asm

	call (%rd12), _rt_buffer_get_64, (%rd13, %r22, %r23, %rd14, %rd17, %rd17, %rd17);

	// inline asm

	ld.global.u32 	%r25, [matData+628];

	ld.global.f32 	%f39, [in_attributes+92];

	ld.global.u32 	%r26, [in_attributes+88];

	ld.global.u32 	%r27, [in_attributes+84];

	ld.global.f32 	%f40, [in_attributes+80];

	ld.global.f32 	%f41, [in_attributes+76];

	ld.global.f32 	%f42, [in_attributes+72];

	ld.u32 	%r24, [%rd12];

	// inline asm

	call (%rd18), _rt_callable_program_from_id_64, (%r24);

	// inline asm

	mov.u16 	%rs2, 1;

	cvt.s32.s16	%r28, %rs2;

	// Callseq Start 9

	{

	.reg .b32 temp_param_reg;

	// <end>}

	.param .b32 param0;

	st.param.b32	[param0+0], %r25;

	.param .align 4 .b8 param1[24];

	st.param.f32	[param1+0], %f42;

	st.param.f32	[param1+4], %f41;

	st.param.f32	[param1+8], %f40;

	st.param.b32	[param1+12], %r27;

	st.param.b32	[param1+16], %r26;

	st.param.f32	[param1+20], %f39;

	.param .b32 param2;

	st.param.b32	[param2+0], %r28;

	.param .align 16 .b8 retval0[16];

	prototype_9 : .callprototype (.param .align 16 .b8 _[16]) _ (.param .b32 _, .param .align 4 .b8 _[24], .param .b32 _);

	call (retval0), 

	%rd18, 

	(

	param0, 

	param1, 

	param2

	)

	, prototype_9;

	ld.param.f32	%f67, [retval0+0];

	ld.param.f32	%f43, [retval0+4];

	ld.param.f32	%f44, [retval0+8];

	ld.param.f32	%f45, [retval0+12];

	

	//{

	}// Callseq End 9



BB33_5:

	ld.global.v4.f32 	{%f46, %f47, %f48, %f49}, [matData+576];

	mov.f32 	%f68, %f46;

	mov.f32 	%f69, %f47;

	mov.f32 	%f70, %f48;

	mov.f32 	%f71, %f49;

	ld.global.v2.u32 	{%r29, %r30}, [matData+592];

	setp.lt.u32	%p8, %r29, 7;

	setp.ne.s32	%p9, %r30, -1;

	and.pred  	%p10, %p8, %p9;

	@!%p10 bra 	BB33_7;

	bra.uni 	BB33_6;



BB33_6:

	cvt.u64.u32	%rd22, %r29;

	mov.u64 	%rd27, textureSampleBuff;

	cvta.global.u64 	%rd21, %rd27;

	mov.u32 	%r32, 1;

	mov.u32 	%r33, 4;

	mov.u64 	%rd25, 0;

	// inline asm

	call (%rd20), _rt_buffer_get_64, (%rd21, %r32, %r33, %rd22, %rd25, %rd25, %rd25);

	// inline asm

	ld.global.u32 	%r35, [matData+596];

	ld.global.f32 	%f50, [in_attributes+92];

	ld.global.u32 	%r36, [in_attributes+88];

	ld.global.u32 	%r37, [in_attributes+84];

	ld.global.f32 	%f51, [in_attributes+80];

	ld.global.f32 	%f52, [in_attributes+76];

	ld.global.f32 	%f53, [in_attributes+72];

	ld.u32 	%r34, [%rd20];

	// inline asm

	call (%rd26), _rt_callable_program_from_id_64, (%r34);

	// inline asm

	mov.u16 	%rs3, 1;

	cvt.s32.s16	%r38, %rs3;

	// Callseq Start 10

	{

	.reg .b32 temp_param_reg;

	// <end>}

	.param .b32 param0;

	st.param.b32	[param0+0], %r35;

	.param .align 4 .b8 param1[24];

	st.param.f32	[param1+0], %f53;

	st.param.f32	[param1+4], %f52;

	st.param.f32	[param1+8], %f51;

	st.param.b32	[param1+12], %r37;

	st.param.b32	[param1+16], %r36;

	st.param.f32	[param1+20], %f50;

	.param .b32 param2;

	st.param.b32	[param2+0], %r38;

	.param .align 16 .b8 retval0[16];

	prototype_10 : .callprototype (.param .align 16 .b8 _[16]) _ (.param .b32 _, .param .align 4 .b8 _[24], .param .b32 _);

	call (retval0), 

	%rd26, 

	(

	param0, 

	param1, 

	param2

	)

	, prototype_10;

	ld.param.f32	%f68, [retval0+0];

	ld.param.f32	%f69, [retval0+4];

	ld.param.f32	%f70, [retval0+8];

	ld.param.f32	%f71, [retval0+12];

	

	//{

	}// Callseq End 10



BB33_7:

	mul.ftz.f32 	%f78, %f67, %f71;

	mul.ftz.f32 	%f21, %f67, %f68;

	mul.ftz.f32 	%f22, %f67, %f69;

	mul.ftz.f32 	%f23, %f67, %f70;

	ld.global.v2.u32 	{%r39, %r40}, [matData+864];

	setp.eq.s32	%p11, %r39, 2;

	setp.eq.s32	%p12, %r40, 1;

	and.pred  	%p13, %p11, %p12;

	mov.f32 	%f77, %f78;

	mov.f32 	%f76, %f78;

	@%p13 bra 	BB33_10;



	mov.f32 	%f54, 0f3F800000;

	sub.ftz.f32 	%f78, %f54, %f21;

	sub.ftz.f32 	%f77, %f54, %f22;

	sub.ftz.f32 	%f76, %f54, %f23;

	setp.eq.s32	%p15, %r40, 0;

	and.pred  	%p16, %p11, %p15;

	@!%p16 bra 	BB33_10;

	bra.uni 	BB33_9;



BB33_9:

	add.ftz.f32 	%f55, %f21, %f22;

	add.ftz.f32 	%f56, %f55, %f23;

	mov.f32 	%f57, 0f40400000;

	div.approx.ftz.f32 	%f78, %f56, %f57;

	mov.f32 	%f77, %f78;

	mov.f32 	%f76, %f78;



BB33_10:

	add.ftz.f32 	%f58, %f78, %f77;

	add.ftz.f32 	%f59, %f58, %f76;

	mov.f32 	%f60, 0f40400000;

	div.approx.ftz.f32 	%f61, %f59, %f60;

	mul.ftz.f32 	%f62, %f4, %f61;

	ld.global.f32 	%f63, [in_attributes+128];

	mul.ftz.f32 	%f64, %f62, %f63;

	setp.lt.ftz.f32	%p17, %f64, 0f3F800000;

	@%p17 bra 	BB33_12;

	bra.uni 	BB33_11;



BB33_12:

	mov.u32 	%r41, 1065353216;

	st.global.u32 	[opt_prdShadow+72], %r41;

	bra.uni 	BB33_13;



BB33_11:

	mov.f32 	%f65, 0f3F800000;

	st.global.v4.f32 	[opt_prdShadow+32], {%f65, %f65, %f65, %f65};



BB33_13:

	// inline asm

	call _rt_terminate_ray, ();

	// inline asm



BB33_15:

	ret;

}



	// .globl	_Z17shadowsClosestHitv

.visible .entry _Z17shadowsClosestHitv(



)

{

	.reg .pred 	%p<19>;

	.reg .s16 	%rs<4>;

	.reg .f32 	%f<141>;

	.reg .s32 	%r<45>;

	.reg .s64 	%rd<32>;





	mov.u64 	%rd1, in_attributes;

	add.s64 	%rd2, %rd1, 184;

	ldu.global.u32 	%r44, [%rd2];

	add.s64 	%rd3, %rd1, 188;

	ldu.global.u32 	%r10, [%rd3];

	st.global.v2.u32 	[opt_prdShadow], {%r44, %r10};

	mov.u32 	%r11, -1;

	st.global.u32 	[opt_prdShadow+8], %r11;

	mov.u64 	%rd4, matData;

	add.s64 	%rd5, %rd4, 704;

	ldu.global.f32 	%f128, [%rd5];

	add.s64 	%rd6, %rd4, 720;

	ldu.global.u32 	%r2, [%rd6];

	setp.lt.u32	%p1, %r2, 7;

	add.s64 	%rd7, %rd4, 724;

	ldu.global.u32 	%r12, [%rd7];

	setp.ne.s32	%p2, %r12, -1;

	and.pred  	%p3, %p1, %p2;

	@!%p3 bra 	BB34_2;

	bra.uni 	BB34_1;



BB34_1:

	cvt.u64.u32	%rd10, %r2;

	mov.u64 	%rd15, textureSampleBuff;

	cvta.global.u64 	%rd9, %rd15;

	mov.u32 	%r13, 1;

	mov.u32 	%r14, 4;

	mov.u64 	%rd13, 0;

	// inline asm

	call (%rd8), _rt_buffer_get_64, (%rd9, %r13, %r14, %rd10, %rd13, %rd13, %rd13);

	// inline asm

	ld.global.u32 	%r16, [matData+724];

	ld.global.f32 	%f30, [in_attributes+92];

	ld.global.u32 	%r17, [in_attributes+88];

	ld.global.u32 	%r18, [in_attributes+84];

	ld.global.f32 	%f31, [in_attributes+80];

	ld.global.f32 	%f32, [in_attributes+76];

	ld.global.f32 	%f33, [in_attributes+72];

	ld.u32 	%r15, [%rd8];

	// inline asm

	call (%rd14), _rt_callable_program_from_id_64, (%r15);

	// inline asm

	mov.u16 	%rs1, 1;

	cvt.s32.s16	%r19, %rs1;

	// Callseq Start 11

	{

	.reg .b32 temp_param_reg;

	// <end>}

	.param .b32 param0;

	st.param.b32	[param0+0], %r16;

	.param .align 4 .b8 param1[24];

	st.param.f32	[param1+0], %f33;

	st.param.f32	[param1+4], %f32;

	st.param.f32	[param1+8], %f31;

	st.param.b32	[param1+12], %r18;

	st.param.b32	[param1+16], %r17;

	st.param.f32	[param1+20], %f30;

	.param .b32 param2;

	st.param.b32	[param2+0], %r19;

	.param .align 16 .b8 retval0[16];

	prototype_11 : .callprototype (.param .align 16 .b8 _[16]) _ (.param .b32 _, .param .align 4 .b8 _[24], .param .b32 _);

	call (retval0), 

	%rd14, 

	(

	param0, 

	param1, 

	param2

	)

	, prototype_11;

	ld.param.f32	%f128, [retval0+0];

	ld.param.f32	%f34, [retval0+4];

	ld.param.f32	%f35, [retval0+8];

	ld.param.f32	%f36, [retval0+12];

	

	//{

	}// Callseq End 11

	ld.global.u32 	%r44, [in_attributes+184];



BB34_2:

	ld.global.f32 	%f37, [matData+920];

	setp.lt.ftz.f32	%p4, %f128, %f37;

	ld.global.u32 	%r20, [opt_prdShadow+80];

	setp.eq.s32	%p5, %r20, %r44;

	or.pred  	%p6, %p4, %p5;

	ld.global.v2.u32 	{%r21, %r22}, [matData+624];

	@%p6 bra 	BB34_11;



	ld.global.f32 	%f129, [matData+608];

	setp.lt.u32	%p7, %r21, 7;

	setp.ne.s32	%p8, %r22, -1;

	and.pred  	%p9, %p7, %p8;

	@!%p9 bra 	BB34_5;

	bra.uni 	BB34_4;



BB34_4:

	cvt.u64.u32	%rd18, %r21;

	mov.u64 	%rd23, textureSampleBuff;

	cvta.global.u64 	%rd17, %rd23;

	mov.u32 	%r23, 1;

	mov.u32 	%r24, 4;

	mov.u64 	%rd21, 0;

	// inline asm

	call (%rd16), _rt_buffer_get_64, (%rd17, %r23, %r24, %rd18, %rd21, %rd21, %rd21);

	// inline asm

	ld.global.u32 	%r26, [matData+628];

	ld.global.f32 	%f38, [in_attributes+92];

	ld.global.u32 	%r27, [in_attributes+88];

	ld.global.u32 	%r28, [in_attributes+84];

	ld.global.f32 	%f39, [in_attributes+80];

	ld.global.f32 	%f40, [in_attributes+76];

	ld.global.f32 	%f41, [in_attributes+72];

	ld.u32 	%r25, [%rd16];

	// inline asm

	call (%rd22), _rt_callable_program_from_id_64, (%r25);

	// inline asm

	mov.u16 	%rs2, 1;

	cvt.s32.s16	%r29, %rs2;

	// Callseq Start 12

	{

	.reg .b32 temp_param_reg;

	// <end>}

	.param .b32 param0;

	st.param.b32	[param0+0], %r26;

	.param .align 4 .b8 param1[24];

	st.param.f32	[param1+0], %f41;

	st.param.f32	[param1+4], %f40;

	st.param.f32	[param1+8], %f39;

	st.param.b32	[param1+12], %r28;

	st.param.b32	[param1+16], %r27;

	st.param.f32	[param1+20], %f38;

	.param .b32 param2;

	st.param.b32	[param2+0], %r29;

	.param .align 16 .b8 retval0[16];

	prototype_12 : .callprototype (.param .align 16 .b8 _[16]) _ (.param .b32 _, .param .align 4 .b8 _[24], .param .b32 _);

	call (retval0), 

	%rd22, 

	(

	param0, 

	param1, 

	param2

	)

	, prototype_12;

	ld.param.f32	%f129, [retval0+0];

	ld.param.f32	%f42, [retval0+4];

	ld.param.f32	%f43, [retval0+8];

	ld.param.f32	%f44, [retval0+12];

	

	//{

	}// Callseq End 12



BB34_5:

	ld.global.v4.f32 	{%f45, %f46, %f47, %f48}, [matData+576];

	mov.f32 	%f130, %f45;

	mov.f32 	%f131, %f46;

	mov.f32 	%f132, %f47;

	mov.f32 	%f133, %f48;

	ld.global.v2.u32 	{%r30, %r31}, [matData+592];

	setp.lt.u32	%p10, %r30, 7;

	setp.ne.s32	%p11, %r31, -1;

	and.pred  	%p12, %p10, %p11;

	@!%p12 bra 	BB34_7;

	bra.uni 	BB34_6;



BB34_6:

	cvt.u64.u32	%rd26, %r30;

	mov.u64 	%rd31, textureSampleBuff;

	cvta.global.u64 	%rd25, %rd31;

	mov.u32 	%r33, 1;

	mov.u32 	%r34, 4;

	mov.u64 	%rd29, 0;

	// inline asm

	call (%rd24), _rt_buffer_get_64, (%rd25, %r33, %r34, %rd26, %rd29, %rd29, %rd29);

	// inline asm

	ld.global.u32 	%r36, [matData+596];

	ld.global.f32 	%f49, [in_attributes+92];

	ld.global.u32 	%r37, [in_attributes+88];

	ld.global.u32 	%r38, [in_attributes+84];

	ld.global.f32 	%f50, [in_attributes+80];

	ld.global.f32 	%f51, [in_attributes+76];

	ld.global.f32 	%f52, [in_attributes+72];

	ld.u32 	%r35, [%rd24];

	// inline asm

	call (%rd30), _rt_callable_program_from_id_64, (%r35);

	// inline asm

	mov.u16 	%rs3, 1;

	cvt.s32.s16	%r39, %rs3;

	// Callseq Start 13

	{

	.reg .b32 temp_param_reg;

	// <end>}

	.param .b32 param0;

	st.param.b32	[param0+0], %r36;

	.param .align 4 .b8 param1[24];

	st.param.f32	[param1+0], %f52;

	st.param.f32	[param1+4], %f51;

	st.param.f32	[param1+8], %f50;

	st.param.b32	[param1+12], %r38;

	st.param.b32	[param1+16], %r37;

	st.param.f32	[param1+20], %f49;

	.param .b32 param2;

	st.param.b32	[param2+0], %r39;

	.param .align 16 .b8 retval0[16];

	prototype_13 : .callprototype (.param .align 16 .b8 _[16]) _ (.param .b32 _, .param .align 4 .b8 _[24], .param .b32 _);

	call (retval0), 

	%rd30, 

	(

	param0, 

	param1, 

	param2

	)

	, prototype_13;

	ld.param.f32	%f130, [retval0+0];

	ld.param.f32	%f131, [retval0+4];

	ld.param.f32	%f132, [retval0+8];

	ld.param.f32	%f133, [retval0+12];

	

	//{

	}// Callseq End 13



BB34_7:

	mul.ftz.f32 	%f140, %f129, %f133;

	mul.ftz.f32 	%f20, %f129, %f130;

	mul.ftz.f32 	%f21, %f129, %f131;

	mul.ftz.f32 	%f22, %f129, %f132;

	ld.global.v2.u32 	{%r40, %r41}, [matData+864];

	setp.eq.s32	%p13, %r40, 2;

	setp.eq.s32	%p14, %r41, 1;

	and.pred  	%p15, %p13, %p14;

	mov.f32 	%f139, %f140;

	mov.f32 	%f138, %f140;

	@%p15 bra 	BB34_10;



	mov.f32 	%f53, 0f3F800000;

	sub.ftz.f32 	%f140, %f53, %f20;

	sub.ftz.f32 	%f139, %f53, %f21;

	sub.ftz.f32 	%f138, %f53, %f22;

	setp.eq.s32	%p17, %r41, 0;

	and.pred  	%p18, %p13, %p17;

	@!%p18 bra 	BB34_10;

	bra.uni 	BB34_9;



BB34_9:

	add.ftz.f32 	%f54, %f20, %f21;

	add.ftz.f32 	%f55, %f54, %f22;

	mov.f32 	%f56, 0f40400000;

	div.approx.ftz.f32 	%f140, %f55, %f56;

	mov.f32 	%f139, %f140;

	mov.f32 	%f138, %f140;



BB34_10:

	add.ftz.f32 	%f65, %f140, %f139;

	add.ftz.f32 	%f66, %f65, %f138;

	mov.f32 	%f67, 0f40400000;

	div.approx.ftz.f32 	%f68, %f66, %f67;

	ld.global.f32 	%f69, [in_attributes+128];

	ld.global.f32 	%f61, [in_attributes+144];

	ld.global.f32 	%f62, [in_attributes+148];

	ld.global.f32 	%f63, [in_attributes+152];

	mov.u32 	%r42, 7937;

	mov.f32 	%f64, 0f00000000;

	// inline asm

	call (%f57, %f58, %f59, %f60), _rt_transform_tuple, (%r42, %f61, %f62, %f63, %f64);

	// inline asm

	mul.ftz.f32 	%f70, %f58, %f58;

	fma.rn.ftz.f32 	%f71, %f57, %f57, %f70;

	fma.rn.ftz.f32 	%f72, %f59, %f59, %f71;

	sqrt.approx.ftz.f32 	%f73, %f72;

	rcp.approx.ftz.f32 	%f74, %f73;

	mul.ftz.f32 	%f75, %f57, %f74;

	mul.ftz.f32 	%f76, %f58, %f74;

	mul.ftz.f32 	%f77, %f59, %f74;

	ld.global.v4.f32 	{%f78, %f79, %f80, %f81}, [opt_prdShadow+32];

	mov.f32 	%f83, 0f3F800000;

	sub.ftz.f32 	%f84, %f83, %f78;

	sub.ftz.f32 	%f86, %f83, %f79;

	sub.ftz.f32 	%f88, %f83, %f80;

	sub.ftz.f32 	%f90, %f83, %f81;

	ld.global.f32 	%f91, [in_attributes+120];

	mul.ftz.f32 	%f92, %f91, %f84;

	mul.ftz.f32 	%f93, %f91, %f86;

	mul.ftz.f32 	%f94, %f91, %f88;

	mul.ftz.f32 	%f95, %f91, %f90;

	ld.global.f32 	%f96, [opt_ray+12];

	ld.global.f32 	%f97, [opt_ray+16];

	mul.ftz.f32 	%f98, %f97, %f97;

	fma.rn.ftz.f32 	%f99, %f96, %f96, %f98;

	ld.global.f32 	%f100, [opt_ray+20];

	fma.rn.ftz.f32 	%f101, %f100, %f100, %f99;

	sqrt.approx.ftz.f32 	%f102, %f101;

	rcp.approx.ftz.f32 	%f103, %f102;

	mul.ftz.f32 	%f104, %f103, %f96;

	mul.ftz.f32 	%f105, %f103, %f97;

	mul.ftz.f32 	%f106, %f103, %f100;

	mul.ftz.f32 	%f107, %f76, %f105;

	fma.rn.ftz.f32 	%f108, %f75, %f104, %f107;

	fma.rn.ftz.f32 	%f109, %f77, %f106, %f108;

	abs.ftz.f32 	%f110, %f109;

	sub.ftz.f32 	%f111, %f83, %f110;

	ld.global.f32 	%f112, [matData+916];

	mul.ftz.f32 	%f113, %f112, %f111;

	sub.ftz.f32 	%f114, %f83, %f113;

	fma.rn.ftz.f32 	%f115, %f140, %f69, 0fBF800000;

	fma.rn.ftz.f32 	%f116, %f139, %f69, 0fBF800000;

	fma.rn.ftz.f32 	%f117, %f138, %f69, 0fBF800000;

	fma.rn.ftz.f32 	%f118, %f68, %f69, 0fBF800000;

	fma.rn.ftz.f32 	%f119, %f115, %f114, 0f3F800000;

	fma.rn.ftz.f32 	%f120, %f116, %f114, 0f3F800000;

	fma.rn.ftz.f32 	%f121, %f117, %f114, 0f3F800000;

	fma.rn.ftz.f32 	%f122, %f118, %f114, 0f3F800000;

	fma.rn.ftz.f32 	%f123, %f95, %f122, %f81;

	fma.rn.ftz.f32 	%f124, %f94, %f121, %f80;

	fma.rn.ftz.f32 	%f125, %f93, %f120, %f79;

	fma.rn.ftz.f32 	%f126, %f92, %f119, %f78;

	st.global.v4.f32 	[opt_prdShadow+32], {%f126, %f125, %f124, %f123};



BB34_11:

	ld.global.f32 	%f127, [opt_intersectionDistance];

	st.global.f32 	[opt_prdShadow+72], %f127;

	st.global.u32 	[opt_prdShadow+80], %r11;

	ret;

}



	// .globl	_ZNK11BumpMapData6SampleE6float3S0_RK11SamplerInfo

.visible .func  (.param .align 4 .b8 func_retval0[12]) _ZNK11BumpMapData6SampleE6float3S0_RK11SamplerInfo(

	.param .b64 _ZNK11BumpMapData6SampleE6float3S0_RK11SamplerInfo_param_0,

	.param .align 4 .b8 _ZNK11BumpMapData6SampleE6float3S0_RK11SamplerInfo_param_1[12],

	.param .align 4 .b8 _ZNK11BumpMapData6SampleE6float3S0_RK11SamplerInfo_param_2[12],

	.param .b64 _ZNK11BumpMapData6SampleE6float3S0_RK11SamplerInfo_param_3

)

{

	.reg .pred 	%p<5>;

	.reg .s16 	%rs<2>;

	.reg .f32 	%f<106>;

	.reg .s32 	%r<16>;

	.reg .s64 	%rd<14>;





	ld.param.u64 	%rd3, [_ZNK11BumpMapData6SampleE6float3S0_RK11SamplerInfo_param_0];

	ld.param.f32 	%f3, [_ZNK11BumpMapData6SampleE6float3S0_RK11SamplerInfo_param_1+8];

	ld.param.f32 	%f2, [_ZNK11BumpMapData6SampleE6float3S0_RK11SamplerInfo_param_1+4];

	ld.param.f32 	%f1, [_ZNK11BumpMapData6SampleE6float3S0_RK11SamplerInfo_param_1];

	ld.param.f32 	%f4, [_ZNK11BumpMapData6SampleE6float3S0_RK11SamplerInfo_param_2+8];

	ld.param.f32 	%f39, [_ZNK11BumpMapData6SampleE6float3S0_RK11SamplerInfo_param_2+4];

	ld.param.f32 	%f38, [_ZNK11BumpMapData6SampleE6float3S0_RK11SamplerInfo_param_2];

	ld.param.u64 	%rd4, [_ZNK11BumpMapData6SampleE6float3S0_RK11SamplerInfo_param_3];

	mov.f32 	%f105, %f3;

	mov.f32 	%f104, %f2;

	mov.f32 	%f103, %f1;

	add.s64 	%rd1, %rd3, 32;

	ld.u64 	%rd2, [%rd3+32];

	cvt.u32.u64	%r15, %rd2;

	setp.eq.s32	%p1, %r15, 0;

	@%p1 bra 	BB35_8;



	shr.u64 	%rd5, %rd2, 32;

	cvt.u32.u64	%r5, %rd5;

	mov.b32 	 %f96, %r5;

	ld.v4.f32 	{%f41, %f42, %f43, %f44}, [%rd1+-32];

	mov.f32 	%f97, %f41;

	mov.f32 	%f98, %f42;

	mov.f32 	%f99, %f43;

	ld.u32 	%r6, [%rd1+-12];

	setp.eq.s32	%p2, %r6, -1;

	ld.u32 	%r2, [%rd3+16];

	@%p2 bra 	BB35_4;



	setp.gt.u32	%p3, %r2, 6;

	@%p3 bra 	BB35_4;



	cvt.u64.u32	%rd8, %r2;

	mov.u64 	%rd13, textureSampleBuff;

	cvta.global.u64 	%rd7, %rd13;

	mov.u32 	%r7, 1;

	mov.u32 	%r8, 4;

	mov.u64 	%rd11, 0;

	// inline asm

	call (%rd6), _rt_buffer_get_64, (%rd7, %r7, %r8, %rd8, %rd11, %rd11, %rd11);

	// inline asm

	ld.u32 	%r10, [%rd1+-12];

	ld.f32 	%f45, [%rd4+20];

	ld.u32 	%r11, [%rd4+16];

	ld.u32 	%r12, [%rd4+12];

	ld.f32 	%f46, [%rd4+8];

	ld.f32 	%f47, [%rd4+4];

	ld.f32 	%f48, [%rd4];

	ld.u32 	%r9, [%rd6];

	// inline asm

	call (%rd12), _rt_callable_program_from_id_64, (%r9);

	// inline asm

	mov.u16 	%rs1, 0;

	cvt.s32.s16	%r13, %rs1;

	// Callseq Start 14

	{

	.reg .b32 temp_param_reg;

	// <end>}

	.param .b32 param0;

	st.param.b32	[param0+0], %r10;

	.param .align 4 .b8 param1[24];

	st.param.f32	[param1+0], %f48;

	st.param.f32	[param1+4], %f47;

	st.param.f32	[param1+8], %f46;

	st.param.b32	[param1+12], %r12;

	st.param.b32	[param1+16], %r11;

	st.param.f32	[param1+20], %f45;

	.param .b32 param2;

	st.param.b32	[param2+0], %r13;

	.param .align 16 .b8 retval0[16];

	prototype_14 : .callprototype (.param .align 16 .b8 _[16]) _ (.param .b32 _, .param .align 4 .b8 _[24], .param .b32 _);

	call (retval0), 

	%rd12, 

	(

	param0, 

	param1, 

	param2

	)

	, prototype_14;

	ld.param.f32	%f97, [retval0+0];

	ld.param.f32	%f98, [retval0+4];

	ld.param.f32	%f99, [retval0+8];

	ld.param.f32	%f49, [retval0+12];

	

	//{

	}// Callseq End 14

	ld.f32 	%f96, [%rd1+4];

	ld.u32 	%r15, [%rd1];



BB35_4:

	fma.rn.ftz.f32 	%f50, %f97, 0f40000000, 0fBF800000;

	fma.rn.ftz.f32 	%f51, %f98, 0f40000000, 0fBF800000;

	fma.rn.ftz.f32 	%f17, %f99, 0f40000000, 0fBF800000;

	mul.ftz.f32 	%f18, %f96, %f50;

	mul.ftz.f32 	%f19, %f96, %f51;

	setp.eq.s32	%p4, %r15, 3;

	@%p4 bra 	BB35_6;

	bra.uni 	BB35_5;



BB35_6:

	mov.u32 	%r14, 7937;

	mov.f32 	%f90, 0f00000000;

	// inline asm

	call (%f83, %f84, %f85, %f86), _rt_transform_tuple, (%r14, %f18, %f19, %f17, %f90);

	// inline asm

	mov.f32 	%f100, %f83;

	mov.f32 	%f101, %f84;

	mov.f32 	%f102, %f85;

	bra.uni 	BB35_7;



BB35_5:

	mul.ftz.f32 	%f52, %f39, %f39;

	fma.rn.ftz.f32 	%f53, %f38, %f38, %f52;

	fma.rn.ftz.f32 	%f54, %f4, %f4, %f53;

	sqrt.approx.ftz.f32 	%f55, %f54;

	rcp.approx.ftz.f32 	%f56, %f55;

	mul.ftz.f32 	%f57, %f38, %f56;

	mul.ftz.f32 	%f58, %f39, %f56;

	mul.ftz.f32 	%f59, %f4, %f56;

	mul.ftz.f32 	%f60, %f2, %f59;

	mul.ftz.f32 	%f61, %f3, %f58;

	sub.ftz.f32 	%f62, %f60, %f61;

	mul.ftz.f32 	%f63, %f3, %f57;

	mul.ftz.f32 	%f64, %f1, %f59;

	sub.ftz.f32 	%f65, %f63, %f64;

	mul.ftz.f32 	%f66, %f1, %f58;

	mul.ftz.f32 	%f67, %f2, %f57;

	sub.ftz.f32 	%f68, %f66, %f67;

	mul.ftz.f32 	%f69, %f65, %f65;

	fma.rn.ftz.f32 	%f70, %f62, %f62, %f69;

	fma.rn.ftz.f32 	%f71, %f68, %f68, %f70;

	sqrt.approx.ftz.f32 	%f72, %f71;

	rcp.approx.ftz.f32 	%f73, %f72;

	mul.ftz.f32 	%f74, %f73, %f62;

	mul.ftz.f32 	%f75, %f73, %f65;

	mul.ftz.f32 	%f76, %f73, %f68;

	fma.rn.ftz.f32 	%f77, %f18, %f57, 0f00000000;

	fma.rn.ftz.f32 	%f78, %f19, %f74, %f77;

	fma.rn.ftz.f32 	%f100, %f17, %f1, %f78;

	fma.rn.ftz.f32 	%f79, %f18, %f58, 0f00000000;

	fma.rn.ftz.f32 	%f80, %f19, %f75, %f79;

	fma.rn.ftz.f32 	%f101, %f17, %f2, %f80;

	fma.rn.ftz.f32 	%f81, %f18, %f59, 0f00000000;

	fma.rn.ftz.f32 	%f82, %f19, %f76, %f81;

	fma.rn.ftz.f32 	%f102, %f17, %f3, %f82;



BB35_7:

	mul.ftz.f32 	%f91, %f101, %f101;

	fma.rn.ftz.f32 	%f92, %f100, %f100, %f91;

	fma.rn.ftz.f32 	%f93, %f102, %f102, %f92;

	sqrt.approx.ftz.f32 	%f94, %f93;

	rcp.approx.ftz.f32 	%f95, %f94;

	mul.ftz.f32 	%f103, %f95, %f100;

	mul.ftz.f32 	%f104, %f95, %f101;

	mul.ftz.f32 	%f105, %f95, %f102;



BB35_8:

	st.param.f32	[func_retval0+0], %f103;

	st.param.f32	[func_retval0+4], %f104;

	st.param.f32	[func_retval0+8], %f105;

	ret;

}



	// .globl	_ZN5optix6MatrixILj3ELj3EEC1Ev

.visible .func _ZN5optix6MatrixILj3ELj3EEC1Ev(

	.param .b64 _ZN5optix6MatrixILj3ELj3EEC1Ev_param_0

)

{







	ret;

}



	// .globl	_ZN5optix6MatrixILj3ELj3EEixEj

.visible .func  (.param .b64 func_retval0) _ZN5optix6MatrixILj3ELj3EEixEj(

	.param .b64 _ZN5optix6MatrixILj3ELj3EEixEj_param_0,

	.param .b32 _ZN5optix6MatrixILj3ELj3EEixEj_param_1

)

{

	.reg .s32 	%r<2>;

	.reg .s64 	%rd<4>;





	ld.param.u64 	%rd1, [_ZN5optix6MatrixILj3ELj3EEixEj_param_0];

	ld.param.u32 	%r1, [_ZN5optix6MatrixILj3ELj3EEixEj_param_1];

	mul.wide.u32 	%rd2, %r1, 4;

	add.s64 	%rd3, %rd1, %rd2;

	st.param.b64	[func_retval0+0], %rd3;

	ret;

}



	// .globl	_ZN5optix6MatrixILj3ELj3EEC1EPKf

.visible .func _ZN5optix6MatrixILj3ELj3EEC1EPKf(

	.param .b64 _ZN5optix6MatrixILj3ELj3EEC1EPKf_param_0,

	.param .b64 _ZN5optix6MatrixILj3ELj3EEC1EPKf_param_1

)

{

	.reg .f32 	%f<10>;

	.reg .s64 	%rd<3>;





	ld.param.u64 	%rd1, [_ZN5optix6MatrixILj3ELj3EEC1EPKf_param_0];

	ld.param.u64 	%rd2, [_ZN5optix6MatrixILj3ELj3EEC1EPKf_param_1];

	ld.f32 	%f1, [%rd2];

	st.f32 	[%rd1], %f1;

	ld.f32 	%f2, [%rd2+4];

	st.f32 	[%rd1+4], %f2;

	ld.f32 	%f3, [%rd2+8];

	st.f32 	[%rd1+8], %f3;

	ld.f32 	%f4, [%rd2+12];

	st.f32 	[%rd1+12], %f4;

	ld.f32 	%f5, [%rd2+16];

	st.f32 	[%rd1+16], %f5;

	ld.f32 	%f6, [%rd2+20];

	st.f32 	[%rd1+20], %f6;

	ld.f32 	%f7, [%rd2+24];

	st.f32 	[%rd1+24], %f7;

	ld.f32 	%f8, [%rd2+28];

	st.f32 	[%rd1+28], %f8;

	ld.f32 	%f9, [%rd2+32];

	st.f32 	[%rd1+32], %f9;

	ret;

}



	// .globl	_ZN10ColorUtils17DoGammaCorrectionERK6float3j

.visible .func  (.param .align 4 .b8 func_retval0[12]) _ZN10ColorUtils17DoGammaCorrectionERK6float3j(

	.param .b64 _ZN10ColorUtils17DoGammaCorrectionERK6float3j_param_0,

	.param .b32 _ZN10ColorUtils17DoGammaCorrectionERK6float3j_param_1

)

{

	.reg .pred 	%p<4>;

	.reg .f32 	%f<34>;

	.reg .s32 	%r<2>;

	.reg .s64 	%rd<2>;





	ld.param.u64 	%rd1, [_ZN10ColorUtils17DoGammaCorrectionERK6float3j_param_0];

	ld.param.u32 	%r1, [_ZN10ColorUtils17DoGammaCorrectionERK6float3j_param_1];

	mov.f32 	%f30, 0f3F800000;

	setp.eq.s32	%p1, %r1, 1;

	@%p1 bra 	BB39_3;

	bra.uni 	BB39_1;



BB39_3:

	ld.global.f32 	%f30, [materialGamma];

	bra.uni 	BB39_4;



BB39_1:

	setp.ne.s32	%p2, %r1, 2;

	@%p2 bra 	BB39_4;



	ld.global.f32 	%f30, [lightsGamma];



BB39_4:

	ld.f32 	%f33, [%rd1+8];

	ld.f32 	%f32, [%rd1+4];

	ld.f32 	%f31, [%rd1];

	setp.eq.ftz.f32	%p3, %f30, 0f3F800000;

	@%p3 bra 	BB39_6;



	ld.f32 	%f14, [%rd1];

	mov.f32 	%f15, 0f00000000;

	max.ftz.f32 	%f16, %f14, %f15;

	ld.f32 	%f17, [%rd1+4];

	max.ftz.f32 	%f18, %f17, %f15;

	ld.f32 	%f19, [%rd1+8];

	max.ftz.f32 	%f20, %f19, %f15;

	max.ftz.f32 	%f21, %f15, %f16;

	max.ftz.f32 	%f22, %f15, %f18;

	max.ftz.f32 	%f23, %f15, %f20;

	lg2.approx.ftz.f32 	%f24, %f21;

	mul.ftz.f32 	%f25, %f30, %f24;

	ex2.approx.ftz.f32 	%f31, %f25;

	lg2.approx.ftz.f32 	%f26, %f22;

	mul.ftz.f32 	%f27, %f30, %f26;

	ex2.approx.ftz.f32 	%f32, %f27;

	lg2.approx.ftz.f32 	%f28, %f23;

	mul.ftz.f32 	%f29, %f30, %f28;

	ex2.approx.ftz.f32 	%f33, %f29;



BB39_6:

	st.param.f32	[func_retval0+0], %f31;

	st.param.f32	[func_retval0+4], %f32;

	st.param.f32	[func_retval0+8], %f33;

	ret;

}



	// .globl	_ZN10ColorUtils7rgb2hsvERK6float3

.visible .func  (.param .align 4 .b8 func_retval0[12]) _ZN10ColorUtils7rgb2hsvERK6float3(

	.param .b64 _ZN10ColorUtils7rgb2hsvERK6float3_param_0

)

{

	.reg .pred 	%p<8>;

	.reg .f32 	%f<41>;

	.reg .s64 	%rd<2>;





	ld.param.u64 	%rd1, [_ZN10ColorUtils7rgb2hsvERK6float3_param_0];

	ld.f32 	%f1, [%rd1+4];

	ld.f32 	%f2, [%rd1];

	min.ftz.f32 	%f18, %f2, %f1;

	ld.f32 	%f3, [%rd1+8];

	min.ftz.f32 	%f19, %f18, %f3;

	max.ftz.f32 	%f20, %f2, %f1;

	max.ftz.f32 	%f4, %f20, %f3;

	sub.ftz.f32 	%f5, %f4, %f19;

	mov.f32 	%f17, 0f00000000;

	setp.eq.ftz.f32	%p1, %f4, 0f00000000;

	mov.f32 	%f40, %f17;

	@%p1 bra 	BB40_2;



	div.approx.ftz.f32 	%f6, %f5, %f4;

	mov.f32 	%f40, %f6;



BB40_2:

	mov.f32 	%f7, %f40;

	setp.eq.ftz.f32	%p2, %f5, 0f00000000;

	mov.f32 	%f39, %f17;

	@%p2 bra 	BB40_9;



	sub.ftz.f32 	%f22, %f4, %f2;

	sub.ftz.f32 	%f23, %f4, %f1;

	sub.ftz.f32 	%f24, %f4, %f3;

	mov.f32 	%f25, 0f40000000;

	div.approx.ftz.f32 	%f26, %f5, %f25;

	fma.rn.ftz.f32 	%f27, %f22, 0f3E2AAAAB, %f26;

	fma.rn.ftz.f32 	%f28, %f23, 0f3E2AAAAB, %f26;

	fma.rn.ftz.f32 	%f29, %f24, 0f3E2AAAAB, %f26;

	rcp.approx.ftz.f32 	%f30, %f5;

	mul.ftz.f32 	%f8, %f27, %f30;

	mul.ftz.f32 	%f9, %f28, %f30;

	mul.ftz.f32 	%f10, %f30, %f29;

	setp.eq.ftz.f32	%p3, %f2, %f4;

	@%p3 bra 	BB40_7;

	bra.uni 	BB40_4;



BB40_7:

	sub.ftz.f32 	%f37, %f10, %f9;

	bra.uni 	BB40_8;



BB40_4:

	setp.eq.ftz.f32	%p4, %f1, %f4;

	@%p4 bra 	BB40_6;

	bra.uni 	BB40_5;



BB40_6:

	add.ftz.f32 	%f33, %f8, 0f3EAAAAAB;

	sub.ftz.f32 	%f37, %f33, %f10;

	bra.uni 	BB40_8;



BB40_5:

	setp.eq.ftz.f32	%p5, %f3, %f4;

	add.ftz.f32 	%f31, %f9, 0f3F2AAAAB;

	sub.ftz.f32 	%f32, %f31, %f8;

	selp.f32	%f37, %f32, 0f00000000, %p5;



BB40_8:

	add.ftz.f32 	%f34, %f37, 0f3F800000;

	setp.lt.ftz.f32	%p6, %f37, 0f00000000;

	selp.f32	%f35, %f34, %f37, %p6;

	setp.gt.ftz.f32	%p7, %f35, 0f3F800000;

	add.ftz.f32 	%f36, %f35, 0fBF800000;

	selp.f32	%f39, %f36, %f35, %p7;



BB40_9:

	st.param.f32	[func_retval0+0], %f39;

	st.param.f32	[func_retval0+4], %f7;

	st.param.f32	[func_retval0+8], %f4;

	ret;

}



	// .globl	_ZN10ColorUtils7hsv2rgbERK6float3

.visible .func  (.param .align 4 .b8 func_retval0[12]) _ZN10ColorUtils7hsv2rgbERK6float3(

	.param .b64 _ZN10ColorUtils7hsv2rgbERK6float3_param_0

)

{

	.reg .pred 	%p<9>;

	.reg .f32 	%f<53>;

	.reg .s64 	%rd<2>;





	ld.param.u64 	%rd1, [_ZN10ColorUtils7hsv2rgbERK6float3_param_0];

	ld.f32 	%f1, [%rd1];

	ld.f32 	%f2, [%rd1+8];

	ld.f32 	%f9, [%rd1+4];

	mov.f32 	%f52, %f2;

	mov.f32 	%f51, %f2;

	mov.f32 	%f50, %f2;

	setp.eq.ftz.f32	%p1, %f9, 0f00000000;

	@%p1 bra 	BB41_13;



	setp.lt.ftz.f32	%p2, %f1, 0f00000000;

	add.ftz.f32 	%f37, %f1, 0f3F800000;

	selp.f32	%f38, %f37, %f1, %p2;

	setp.gt.ftz.f32	%p3, %f38, 0f3F800000;

	add.ftz.f32 	%f39, %f38, 0fBF800000;

	selp.f32	%f40, %f39, %f38, %p3;

	mul.ftz.f32 	%f41, %f40, 0f40C00000;

	cvt.rmi.ftz.f32.f32	%f10, %f41;

	mov.f32 	%f42, 0f3F800000;

	sub.ftz.f32 	%f43, %f42, %f9;

	mul.ftz.f32 	%f11, %f2, %f43;

	sub.ftz.f32 	%f44, %f41, %f10;

	mul.ftz.f32 	%f45, %f9, %f44;

	sub.ftz.f32 	%f46, %f42, %f45;

	mul.ftz.f32 	%f12, %f2, %f46;

	sub.ftz.f32 	%f47, %f42, %f44;

	mul.ftz.f32 	%f48, %f9, %f47;

	sub.ftz.f32 	%f49, %f42, %f48;

	mul.ftz.f32 	%f13, %f2, %f49;

	setp.eq.ftz.f32	%p4, %f10, 0f00000000;

	@%p4 bra 	BB41_11;

	bra.uni 	BB41_2;



BB41_11:

	mov.f32 	%f52, %f11;

	mov.f32 	%f51, %f13;



BB41_12:

	mov.f32 	%f50, %f2;

	bra.uni 	BB41_13;



BB41_2:

	setp.eq.ftz.f32	%p5, %f10, 0f3F800000;

	@%p5 bra 	BB41_10;

	bra.uni 	BB41_3;



BB41_10:

	mov.f32 	%f52, %f11;

	mov.f32 	%f51, %f2;

	mov.f32 	%f50, %f12;

	bra.uni 	BB41_13;



BB41_3:

	setp.eq.ftz.f32	%p6, %f10, 0f40000000;

	@%p6 bra 	BB41_9;

	bra.uni 	BB41_4;



BB41_9:

	mov.f32 	%f52, %f13;

	mov.f32 	%f51, %f2;

	mov.f32 	%f50, %f11;

	bra.uni 	BB41_13;



BB41_4:

	setp.eq.ftz.f32	%p7, %f10, 0f40400000;

	@%p7 bra 	BB41_8;

	bra.uni 	BB41_5;



BB41_8:

	mov.f32 	%f52, %f2;

	mov.f32 	%f51, %f12;

	mov.f32 	%f50, %f11;

	bra.uni 	BB41_13;



BB41_5:

	setp.eq.ftz.f32	%p8, %f10, 0f40800000;

	@%p8 bra 	BB41_7;

	bra.uni 	BB41_6;



BB41_7:

	mov.f32 	%f52, %f2;

	mov.f32 	%f51, %f11;

	mov.f32 	%f50, %f13;



BB41_13:

	st.param.f32	[func_retval0+0], %f50;

	st.param.f32	[func_retval0+4], %f51;

	st.param.f32	[func_retval0+8], %f52;

	ret;



BB41_6:

	mov.f32 	%f52, %f12;

	mov.f32 	%f51, %f11;

	bra.uni 	BB41_12;

}



	// .globl	_ZN10ColorUtils13ColorVarianceE6float3RKS0_S2_

.visible .func  (.param .align 4 .b8 func_retval0[12]) _ZN10ColorUtils13ColorVarianceE6float3RKS0_S2_(

	.param .align 4 .b8 _ZN10ColorUtils13ColorVarianceE6float3RKS0_S2__param_0[12],

	.param .b64 _ZN10ColorUtils13ColorVarianceE6float3RKS0_S2__param_1,

	.param .b64 _ZN10ColorUtils13ColorVarianceE6float3RKS0_S2__param_2

)

{

	.reg .pred 	%p<19>;

	.reg .f32 	%f<119>;

	.reg .s64 	%rd<4>;





	ld.param.f32 	%f118, [_ZN10ColorUtils13ColorVarianceE6float3RKS0_S2__param_0+8];

	ld.param.f32 	%f117, [_ZN10ColorUtils13ColorVarianceE6float3RKS0_S2__param_0+4];

	ld.param.f32 	%f116, [_ZN10ColorUtils13ColorVarianceE6float3RKS0_S2__param_0];

	ld.param.u64 	%rd2, [_ZN10ColorUtils13ColorVarianceE6float3RKS0_S2__param_1];

	ld.param.u64 	%rd3, [_ZN10ColorUtils13ColorVarianceE6float3RKS0_S2__param_2];

	ld.f32 	%f4, [%rd2];

	abs.ftz.f32 	%f64, %f4;

	setp.gt.ftz.f32	%p1, %f64, 0f3727C5AC;

	@%p1 bra 	BB42_3;



	ld.f32 	%f65, [%rd2+4];

	abs.ftz.f32 	%f66, %f65;

	setp.gt.ftz.f32	%p2, %f66, 0f3727C5AC;

	@%p2 bra 	BB42_3;



	ld.f32 	%f67, [%rd2+8];

	abs.ftz.f32 	%f68, %f67;

	setp.leu.ftz.f32	%p3, %f68, 0f3727C5AC;

	@%p3 bra 	BB42_26;



BB42_3:

	ld.f32 	%f5, [%rd3];

	ld.f32 	%f6, [%rd3+4];

	ld.f32 	%f7, [%rd3+8];

	min.ftz.f32 	%f70, %f116, %f117;

	min.ftz.f32 	%f71, %f70, %f118;

	max.ftz.f32 	%f72, %f116, %f117;

	max.ftz.f32 	%f8, %f72, %f118;

	sub.ftz.f32 	%f9, %f8, %f71;

	mov.f32 	%f69, 0f00000000;

	setp.eq.ftz.f32	%p4, %f8, 0f00000000;

	mov.f32 	%f112, %f69;

	@%p4 bra 	BB42_5;



	div.approx.ftz.f32 	%f10, %f9, %f8;

	mov.f32 	%f112, %f10;



BB42_5:

	mov.f32 	%f11, %f112;

	setp.eq.ftz.f32	%p5, %f9, 0f00000000;

	mov.f32 	%f111, %f69;

	@%p5 bra 	BB42_12;



	sub.ftz.f32 	%f74, %f8, %f116;

	sub.ftz.f32 	%f75, %f8, %f117;

	sub.ftz.f32 	%f76, %f8, %f118;

	mov.f32 	%f77, 0f40000000;

	div.approx.ftz.f32 	%f78, %f9, %f77;

	fma.rn.ftz.f32 	%f79, %f74, 0f3E2AAAAB, %f78;

	fma.rn.ftz.f32 	%f80, %f75, 0f3E2AAAAB, %f78;

	fma.rn.ftz.f32 	%f81, %f76, 0f3E2AAAAB, %f78;

	rcp.approx.ftz.f32 	%f82, %f9;

	mul.ftz.f32 	%f12, %f79, %f82;

	mul.ftz.f32 	%f13, %f80, %f82;

	mul.ftz.f32 	%f14, %f81, %f82;

	setp.eq.ftz.f32	%p6, %f116, %f8;

	@%p6 bra 	BB42_10;

	bra.uni 	BB42_7;



BB42_10:

	sub.ftz.f32 	%f109, %f14, %f13;

	bra.uni 	BB42_11;



BB42_7:

	setp.eq.ftz.f32	%p7, %f117, %f8;

	@%p7 bra 	BB42_9;

	bra.uni 	BB42_8;



BB42_9:

	add.ftz.f32 	%f85, %f12, 0f3EAAAAAB;

	sub.ftz.f32 	%f109, %f85, %f14;

	bra.uni 	BB42_11;



BB42_8:

	setp.eq.ftz.f32	%p8, %f118, %f8;

	add.ftz.f32 	%f83, %f13, 0f3F2AAAAB;

	sub.ftz.f32 	%f84, %f83, %f12;

	selp.f32	%f109, %f84, 0f00000000, %p8;



BB42_11:

	add.ftz.f32 	%f86, %f109, 0f3F800000;

	setp.lt.ftz.f32	%p9, %f109, 0f00000000;

	selp.f32	%f87, %f86, %f109, %p9;

	setp.gt.ftz.f32	%p10, %f87, 0f3F800000;

	add.ftz.f32 	%f88, %f87, 0fBF800000;

	selp.f32	%f111, %f88, %f87, %p10;



BB42_12:

	fma.rn.ftz.f32 	%f89, %f5, 0f40000000, 0fBF800000;

	fma.rn.ftz.f32 	%f90, %f6, 0f40000000, 0fBF800000;

	fma.rn.ftz.f32 	%f91, %f7, 0f40000000, 0fBF800000;

	fma.rn.ftz.f32 	%f21, %f89, %f4, %f111;

	ld.f32 	%f92, [%rd2+4];

	fma.rn.ftz.f32 	%f22, %f90, %f92, %f11;

	ld.f32 	%f93, [%rd2+8];

	fma.rn.ftz.f32 	%f23, %f91, %f93, %f8;

	mov.f32 	%f115, %f23;

	mov.f32 	%f114, %f23;

	mov.f32 	%f113, %f23;

	setp.eq.ftz.f32	%p11, %f22, 0f00000000;

	@%p11 bra 	BB42_25;



	setp.lt.ftz.f32	%p12, %f21, 0f00000000;

	add.ftz.f32 	%f96, %f21, 0f3F800000;

	selp.f32	%f97, %f96, %f21, %p12;

	setp.gt.ftz.f32	%p13, %f97, 0f3F800000;

	add.ftz.f32 	%f98, %f97, 0fBF800000;

	selp.f32	%f99, %f98, %f97, %p13;

	mul.ftz.f32 	%f100, %f99, 0f40C00000;

	cvt.rmi.ftz.f32.f32	%f30, %f100;

	mov.f32 	%f101, 0f3F800000;

	sub.ftz.f32 	%f102, %f101, %f22;

	mul.ftz.f32 	%f31, %f23, %f102;

	sub.ftz.f32 	%f103, %f100, %f30;

	mul.ftz.f32 	%f104, %f22, %f103;

	sub.ftz.f32 	%f105, %f101, %f104;

	mul.ftz.f32 	%f32, %f23, %f105;

	sub.ftz.f32 	%f106, %f101, %f103;

	mul.ftz.f32 	%f107, %f22, %f106;

	sub.ftz.f32 	%f108, %f101, %f107;

	mul.ftz.f32 	%f33, %f23, %f108;

	setp.eq.ftz.f32	%p14, %f30, 0f00000000;

	@%p14 bra 	BB42_23;

	bra.uni 	BB42_14;



BB42_23:

	mov.f32 	%f115, %f31;

	mov.f32 	%f114, %f33;



BB42_24:

	mov.f32 	%f113, %f23;

	bra.uni 	BB42_25;



BB42_14:

	setp.eq.ftz.f32	%p15, %f30, 0f3F800000;

	@%p15 bra 	BB42_22;

	bra.uni 	BB42_15;



BB42_22:

	mov.f32 	%f115, %f31;

	mov.f32 	%f114, %f23;

	mov.f32 	%f113, %f32;

	bra.uni 	BB42_25;



BB42_15:

	setp.eq.ftz.f32	%p16, %f30, 0f40000000;

	@%p16 bra 	BB42_21;

	bra.uni 	BB42_16;



BB42_21:

	mov.f32 	%f115, %f33;

	mov.f32 	%f114, %f23;

	mov.f32 	%f113, %f31;

	bra.uni 	BB42_25;



BB42_16:

	setp.eq.ftz.f32	%p17, %f30, 0f40400000;

	@%p17 bra 	BB42_20;

	bra.uni 	BB42_17;



BB42_20:

	mov.f32 	%f115, %f23;

	mov.f32 	%f114, %f32;

	mov.f32 	%f113, %f31;

	bra.uni 	BB42_25;



BB42_17:

	setp.eq.ftz.f32	%p18, %f30, 0f40800000;

	@%p18 bra 	BB42_19;

	bra.uni 	BB42_18;



BB42_19:

	mov.f32 	%f115, %f23;

	mov.f32 	%f114, %f31;

	mov.f32 	%f113, %f33;



BB42_25:

	cvt.ftz.sat.f32.f32	%f116, %f113;

	cvt.ftz.sat.f32.f32	%f117, %f114;

	cvt.ftz.sat.f32.f32	%f118, %f115;



BB42_26:

	st.param.f32	[func_retval0+0], %f116;

	st.param.f32	[func_retval0+4], %f117;

	st.param.f32	[func_retval0+8], %f118;

	ret;



BB42_18:

	mov.f32 	%f115, %f32;

	mov.f32 	%f114, %f31;

	bra.uni 	BB42_24;

}



	// .globl	_ZN21SphericalMappingUtils16SphericalMappingERK6float3

.visible .func  (.param .align 8 .b8 func_retval0[8]) _ZN21SphericalMappingUtils16SphericalMappingERK6float3(

	.param .b64 _ZN21SphericalMappingUtils16SphericalMappingERK6float3_param_0

)

{

	.reg .pred 	%p<6>;

	.reg .f32 	%f<59>;

	.reg .s32 	%r<5>;

	.reg .s64 	%rd<2>;





	ld.param.u64 	%rd1, [_ZN21SphericalMappingUtils16SphericalMappingERK6float3_param_0];

	ld.f32 	%f1, [%rd1];

	ld.f32 	%f2, [%rd1+8];

	mul.ftz.f32 	%f3, %f2, %f2;

	fma.rn.ftz.f32 	%f4, %f1, %f1, %f3;

	sqrt.approx.ftz.f32 	%f5, %f4;

	div.approx.ftz.f32 	%f6, %f1, %f5;

	mov.f32 	%f7, 0f3F800000;

	min.ftz.f32 	%f8, %f6, %f7;

	mov.f32 	%f9, 0fBF800000;

	max.ftz.f32 	%f10, %f9, %f8;

	abs.ftz.f32 	%f11, %f10;

	sub.ftz.f32 	%f12, %f7, %f11;

	mul.ftz.f32 	%f13, %f12, 0f3F000000;

	sqrt.approx.ftz.f32 	%f14, %f13;

	setp.gt.ftz.f32	%p1, %f11, 0f3F11EB85;

	selp.f32	%f15, %f14, %f11, %p1;

	mul.ftz.f32 	%f16, %f15, %f15;

	mov.f32 	%f17, 0f3C94D2E9;

	mov.f32 	%f18, 0f3D53F941;

	fma.rn.ftz.f32 	%f19, %f18, %f16, %f17;

	mov.f32 	%f20, 0f3D3F841F;

	fma.rn.ftz.f32 	%f21, %f19, %f16, %f20;

	mov.f32 	%f22, 0f3D994929;

	fma.rn.ftz.f32 	%f23, %f21, %f16, %f22;

	mov.f32 	%f24, 0f3E2AAB94;

	fma.rn.ftz.f32 	%f25, %f23, %f16, %f24;

	mul.ftz.f32 	%f26, %f16, %f25;

	fma.rn.ftz.f32 	%f27, %f26, %f15, %f15;

	add.ftz.f32 	%f28, %f27, %f27;

	mov.f32 	%f29, 0f3FC90FDB;

	sub.ftz.f32 	%f30, %f29, %f27;

	selp.f32	%f31, %f28, %f30, %p1;

	setp.lt.ftz.f32	%p2, %f10, 0f00000000;

	mov.f32 	%f32, 0f40490FDB;

	sub.ftz.f32 	%f33, %f32, %f31;

	selp.f32	%f34, %f33, %f31, %p2;

	mul.ftz.f32 	%f35, %f34, 0f3E22F981;

	ld.f32 	%f36, [%rd1+4];

	min.ftz.f32 	%f37, %f36, %f7;

	max.ftz.f32 	%f38, %f9, %f37;

	abs.ftz.f32 	%f39, %f38;

	sub.ftz.f32 	%f40, %f7, %f39;

	mul.ftz.f32 	%f41, %f40, 0f3F000000;

	sqrt.approx.ftz.f32 	%f42, %f41;

	setp.gt.ftz.f32	%p3, %f39, 0f3F11EB85;

	selp.f32	%f43, %f42, %f39, %p3;

	mul.ftz.f32 	%f44, %f43, %f43;

	fma.rn.ftz.f32 	%f45, %f18, %f44, %f17;

	fma.rn.ftz.f32 	%f46, %f45, %f44, %f20;

	fma.rn.ftz.f32 	%f47, %f46, %f44, %f22;

	fma.rn.ftz.f32 	%f48, %f47, %f44, %f24;

	mul.ftz.f32 	%f49, %f44, %f48;

	fma.rn.ftz.f32 	%f50, %f49, %f43, %f43;

	mov.f32 	%f51, 0fC0000000;

	fma.rn.ftz.f32 	%f52, %f51, %f50, %f29;

	selp.f32	%f53, %f52, %f50, %p3;

	setp.gtu.ftz.f32	%p4, %f53, 0f7F800000;

	mov.b32 	 %r1, %f53;

	mov.b32 	 %r2, %f38;

	and.b32  	%r3, %r2, -2147483648;

	or.b32  	%r4, %r1, %r3;

	mov.b32 	 %f54, %r4;

	selp.f32	%f55, %f53, %f54, %p4;

	fma.rn.ftz.f32 	%f56, %f55, 0f3EA2F984, 0f3F000000;

	setp.lt.ftz.f32	%p5, %f2, 0f00000000;

	sub.ftz.f32 	%f57, %f7, %f35;

	selp.f32	%f58, %f57, %f35, %p5;

	st.param.f32	[func_retval0+0], %f58;

	st.param.f32	[func_retval0+4], %f56;

	ret;

}



	// .globl	_ZN21SphericalMappingUtils16SphericalMappingERK6float3S2_S2_

.visible .func  (.param .align 8 .b8 func_retval0[8]) _ZN21SphericalMappingUtils16SphericalMappingERK6float3S2_S2_(

	.param .b64 _ZN21SphericalMappingUtils16SphericalMappingERK6float3S2_S2__param_0,

	.param .b64 _ZN21SphericalMappingUtils16SphericalMappingERK6float3S2_S2__param_1,

	.param .b64 _ZN21SphericalMappingUtils16SphericalMappingERK6float3S2_S2__param_2

)

{

	.reg .pred 	%p<6>;

	.reg .f32 	%f<83>;

	.reg .s32 	%r<5>;

	.reg .s64 	%rd<4>;





	ld.param.u64 	%rd1, [_ZN21SphericalMappingUtils16SphericalMappingERK6float3S2_S2__param_0];

	ld.param.u64 	%rd2, [_ZN21SphericalMappingUtils16SphericalMappingERK6float3S2_S2__param_2];

	ld.f32 	%f1, [%rd2+4];

	ld.param.u64 	%rd3, [_ZN21SphericalMappingUtils16SphericalMappingERK6float3S2_S2__param_1];

	ld.f32 	%f2, [%rd3+8];

	mul.ftz.f32 	%f3, %f1, %f2;

	ld.f32 	%f4, [%rd2+8];

	ld.f32 	%f5, [%rd3+4];

	mul.ftz.f32 	%f6, %f4, %f5;

	sub.ftz.f32 	%f7, %f3, %f6;

	ld.f32 	%f8, [%rd3];

	mul.ftz.f32 	%f9, %f4, %f8;

	ld.f32 	%f10, [%rd2];

	mul.ftz.f32 	%f11, %f10, %f2;

	sub.ftz.f32 	%f12, %f9, %f11;

	mul.ftz.f32 	%f13, %f10, %f5;

	mul.ftz.f32 	%f14, %f1, %f8;

	sub.ftz.f32 	%f15, %f13, %f14;

	ld.f32 	%f16, [%rd1];

	fma.rn.ftz.f32 	%f17, %f7, %f16, 0f00000000;

	ld.f32 	%f18, [%rd1+4];

	fma.rn.ftz.f32 	%f19, %f12, %f18, %f17;

	ld.f32 	%f20, [%rd1+8];

	fma.rn.ftz.f32 	%f21, %f15, %f20, %f19;

	fma.rn.ftz.f32 	%f22, %f10, %f16, 0f00000000;

	fma.rn.ftz.f32 	%f23, %f1, %f18, %f22;

	fma.rn.ftz.f32 	%f24, %f4, %f20, %f23;

	fma.rn.ftz.f32 	%f25, %f8, %f16, 0f00000000;

	fma.rn.ftz.f32 	%f26, %f5, %f18, %f25;

	fma.rn.ftz.f32 	%f27, %f2, %f20, %f26;

	mul.ftz.f32 	%f28, %f27, %f27;

	fma.rn.ftz.f32 	%f29, %f21, %f21, %f28;

	sqrt.approx.ftz.f32 	%f30, %f29;

	div.approx.ftz.f32 	%f31, %f21, %f30;

	mov.f32 	%f32, 0f3F800000;

	min.ftz.f32 	%f33, %f31, %f32;

	mov.f32 	%f34, 0fBF800000;

	max.ftz.f32 	%f35, %f34, %f33;

	abs.ftz.f32 	%f36, %f35;

	sub.ftz.f32 	%f37, %f32, %f36;

	mul.ftz.f32 	%f38, %f37, 0f3F000000;

	sqrt.approx.ftz.f32 	%f39, %f38;

	setp.gt.ftz.f32	%p1, %f36, 0f3F11EB85;

	selp.f32	%f40, %f39, %f36, %p1;

	mul.ftz.f32 	%f41, %f40, %f40;

	mov.f32 	%f42, 0f3C94D2E9;

	mov.f32 	%f43, 0f3D53F941;

	fma.rn.ftz.f32 	%f44, %f43, %f41, %f42;

	mov.f32 	%f45, 0f3D3F841F;

	fma.rn.ftz.f32 	%f46, %f44, %f41, %f45;

	mov.f32 	%f47, 0f3D994929;

	fma.rn.ftz.f32 	%f48, %f46, %f41, %f47;

	mov.f32 	%f49, 0f3E2AAB94;

	fma.rn.ftz.f32 	%f50, %f48, %f41, %f49;

	mul.ftz.f32 	%f51, %f41, %f50;

	fma.rn.ftz.f32 	%f52, %f51, %f40, %f40;

	add.ftz.f32 	%f53, %f52, %f52;

	mov.f32 	%f54, 0f3FC90FDB;

	sub.ftz.f32 	%f55, %f54, %f52;

	selp.f32	%f56, %f53, %f55, %p1;

	setp.lt.ftz.f32	%p2, %f35, 0f00000000;

	mov.f32 	%f57, 0f40490FDB;

	sub.ftz.f32 	%f58, %f57, %f56;

	selp.f32	%f59, %f58, %f56, %p2;

	mul.ftz.f32 	%f60, %f59, 0f3E22F981;

	min.ftz.f32 	%f61, %f24, %f32;

	max.ftz.f32 	%f62, %f34, %f61;

	abs.ftz.f32 	%f63, %f62;

	sub.ftz.f32 	%f64, %f32, %f63;

	mul.ftz.f32 	%f65, %f64, 0f3F000000;

	sqrt.approx.ftz.f32 	%f66, %f65;

	setp.gt.ftz.f32	%p3, %f63, 0f3F11EB85;

	selp.f32	%f67, %f66, %f63, %p3;

	mul.ftz.f32 	%f68, %f67, %f67;

	fma.rn.ftz.f32 	%f69, %f43, %f68, %f42;

	fma.rn.ftz.f32 	%f70, %f69, %f68, %f45;

	fma.rn.ftz.f32 	%f71, %f70, %f68, %f47;

	fma.rn.ftz.f32 	%f72, %f71, %f68, %f49;

	mul.ftz.f32 	%f73, %f68, %f72;

	fma.rn.ftz.f32 	%f74, %f73, %f67, %f67;

	mov.f32 	%f75, 0fC0000000;

	fma.rn.ftz.f32 	%f76, %f75, %f74, %f54;

	selp.f32	%f77, %f76, %f74, %p3;

	setp.gtu.ftz.f32	%p4, %f77, 0f7F800000;

	mov.b32 	 %r1, %f77;

	mov.b32 	 %r2, %f62;

	and.b32  	%r3, %r2, -2147483648;

	or.b32  	%r4, %r1, %r3;

	mov.b32 	 %f78, %r4;

	selp.f32	%f79, %f77, %f78, %p4;

	fma.rn.ftz.f32 	%f80, %f79, 0f3EA2F984, 0f3F000000;

	setp.lt.ftz.f32	%p5, %f27, 0f00000000;

	sub.ftz.f32 	%f81, %f32, %f60;

	selp.f32	%f82, %f81, %f60, %p5;

	st.param.f32	[func_retval0+0], %f82;

	st.param.f32	[func_retval0+4], %f80;

	ret;

}



	// .globl	_ZN21SphericalMappingUtils19SphericalMappingIlwERK6float2

.visible .func  (.param .align 4 .b8 func_retval0[12]) _ZN21SphericalMappingUtils19SphericalMappingIlwERK6float2(

	.param .b64 _ZN21SphericalMappingUtils19SphericalMappingIlwERK6float2_param_0

)

{

	.reg .pred 	%p<5>;

	.reg .f32 	%f<27>;

	.reg .s64 	%rd<2>;





	ld.param.u64 	%rd1, [_ZN21SphericalMappingUtils19SphericalMappingIlwERK6float2_param_0];

	ld.v2.f32 	{%f1, %f2}, [%rd1];

	add.ftz.f32 	%f4, %f1, %f1;

	mul.ftz.f32 	%f5, %f4, 0f40490FDB;

	sin.approx.ftz.f32 	%f6, %f5;

	cos.approx.ftz.f32 	%f7, %f5;

	div.approx.ftz.f32 	%f8, %f6, %f7;

	add.ftz.f32 	%f10, %f2, 0fBF000000;

	mul.ftz.f32 	%f11, %f10, 0f40490FDB;

	sin.approx.ftz.f32 	%f12, %f11;

	mul.ftz.f32 	%f13, %f12, %f12;

	mov.f32 	%f14, 0f3F800000;

	sub.ftz.f32 	%f15, %f14, %f13;

	fma.rn.ftz.f32 	%f16, %f8, %f8, 0f3F800000;

	div.approx.ftz.f32 	%f17, %f15, %f16;

	sqrt.approx.ftz.f32 	%f18, %f17;

	mul.ftz.f32 	%f19, %f18, %f18;

	mul.ftz.f32 	%f20, %f8, %f19;

	mul.ftz.f32 	%f21, %f8, %f20;

	sqrt.approx.ftz.f32 	%f22, %f21;

	setp.gt.ftz.f32	%p1, %f1, 0f3F000000;

	neg.ftz.f32 	%f23, %f22;

	selp.f32	%f24, %f23, %f22, %p1;

	setp.gt.ftz.f32	%p2, %f1, 0f3E800000;

	setp.lt.ftz.f32	%p3, %f1, 0f3F400000;

	and.pred  	%p4, %p2, %p3;

	neg.ftz.f32 	%f25, %f18;

	selp.f32	%f26, %f25, %f18, %p4;

	st.param.f32	[func_retval0+0], %f26;

	st.param.f32	[func_retval0+4], %f12;

	st.param.f32	[func_retval0+8], %f24;

	ret;

}



	// .globl	_ZN21SphericalMappingUtils19SphericalMappingIlwERK6float2RK6float3S5_

.visible .func  (.param .align 4 .b8 func_retval0[12]) _ZN21SphericalMappingUtils19SphericalMappingIlwERK6float2RK6float3S5_(

	.param .b64 _ZN21SphericalMappingUtils19SphericalMappingIlwERK6float2RK6float3S5__param_0,

	.param .b64 _ZN21SphericalMappingUtils19SphericalMappingIlwERK6float2RK6float3S5__param_1,

	.param .b64 _ZN21SphericalMappingUtils19SphericalMappingIlwERK6float2RK6float3S5__param_2

)

{

	.reg .pred 	%p<5>;

	.reg .f32 	%f<59>;

	.reg .s64 	%rd<4>;





	ld.param.u64 	%rd1, [_ZN21SphericalMappingUtils19SphericalMappingIlwERK6float2RK6float3S5__param_0];

	ld.param.u64 	%rd2, [_ZN21SphericalMappingUtils19SphericalMappingIlwERK6float2RK6float3S5__param_2];

	ld.f32 	%f1, [%rd2+4];

	ld.param.u64 	%rd3, [_ZN21SphericalMappingUtils19SphericalMappingIlwERK6float2RK6float3S5__param_1];

	ld.f32 	%f2, [%rd3+8];

	mul.ftz.f32 	%f3, %f1, %f2;

	ld.f32 	%f4, [%rd2+8];

	ld.f32 	%f5, [%rd3+4];

	mul.ftz.f32 	%f6, %f4, %f5;

	sub.ftz.f32 	%f7, %f3, %f6;

	ld.f32 	%f8, [%rd3];

	mul.ftz.f32 	%f9, %f4, %f8;

	ld.f32 	%f10, [%rd2];

	mul.ftz.f32 	%f11, %f10, %f2;

	sub.ftz.f32 	%f12, %f9, %f11;

	mul.ftz.f32 	%f13, %f10, %f5;

	mul.ftz.f32 	%f14, %f1, %f8;

	sub.ftz.f32 	%f15, %f13, %f14;

	ld.v2.f32 	{%f16, %f17}, [%rd1];

	add.ftz.f32 	%f19, %f16, %f16;

	mul.ftz.f32 	%f20, %f19, 0f40490FDB;

	sin.approx.ftz.f32 	%f21, %f20;

	cos.approx.ftz.f32 	%f22, %f20;

	div.approx.ftz.f32 	%f23, %f21, %f22;

	add.ftz.f32 	%f25, %f17, 0fBF000000;

	mul.ftz.f32 	%f26, %f25, 0f40490FDB;

	sin.approx.ftz.f32 	%f27, %f26;

	mul.ftz.f32 	%f28, %f27, %f27;

	mov.f32 	%f29, 0f3F800000;

	sub.ftz.f32 	%f30, %f29, %f28;

	fma.rn.ftz.f32 	%f31, %f23, %f23, 0f3F800000;

	div.approx.ftz.f32 	%f32, %f30, %f31;

	sqrt.approx.ftz.f32 	%f33, %f32;

	mul.ftz.f32 	%f34, %f33, %f33;

	mul.ftz.f32 	%f35, %f23, %f34;

	mul.ftz.f32 	%f36, %f23, %f35;

	sqrt.approx.ftz.f32 	%f37, %f36;

	setp.gt.ftz.f32	%p1, %f16, 0f3F000000;

	neg.ftz.f32 	%f38, %f37;

	selp.f32	%f39, %f38, %f37, %p1;

	setp.gt.ftz.f32	%p2, %f16, 0f3E800000;

	setp.lt.ftz.f32	%p3, %f16, 0f3F400000;

	and.pred  	%p4, %p2, %p3;

	neg.ftz.f32 	%f40, %f33;

	selp.f32	%f41, %f40, %f33, %p4;

	fma.rn.ftz.f32 	%f42, %f41, %f7, 0f00000000;

	fma.rn.ftz.f32 	%f43, %f27, %f10, %f42;

	fma.rn.ftz.f32 	%f44, %f39, %f8, %f43;

	fma.rn.ftz.f32 	%f45, %f41, %f12, 0f00000000;

	fma.rn.ftz.f32 	%f46, %f27, %f1, %f45;

	fma.rn.ftz.f32 	%f47, %f39, %f5, %f46;

	fma.rn.ftz.f32 	%f48, %f41, %f15, 0f00000000;

	fma.rn.ftz.f32 	%f49, %f27, %f4, %f48;

	fma.rn.ftz.f32 	%f50, %f39, %f2, %f49;

	mul.ftz.f32 	%f51, %f47, %f47;

	fma.rn.ftz.f32 	%f52, %f44, %f44, %f51;

	fma.rn.ftz.f32 	%f53, %f50, %f50, %f52;

	sqrt.approx.ftz.f32 	%f54, %f53;

	rcp.approx.ftz.f32 	%f55, %f54;

	mul.ftz.f32 	%f56, %f44, %f55;

	mul.ftz.f32 	%f57, %f47, %f55;

	mul.ftz.f32 	%f58, %f50, %f55;

	st.param.f32	[func_retval0+0], %f56;

	st.param.f32	[func_retval0+4], %f57;

	st.param.f32	[func_retval0+8], %f58;

	ret;

}



	// .globl	_ZN9RandUtils7getRandERK5uint2

.visible .func  (.param .align 16 .b8 func_retval0[16]) _ZN9RandUtils7getRandERK5uint2(

	.param .b64 _ZN9RandUtils7getRandERK5uint2_param_0

)

{

	.reg .f32 	%f<9>;

	.reg .s32 	%r<7>;

	.reg .s64 	%rd<3>;





	ld.param.u64 	%rd1, [_ZN9RandUtils7getRandERK5uint2_param_0];

	ld.v2.u32 	{%r1, %r2}, [%rd1];

	and.b32  	%r4, %r1, 1023;

	cvt.rn.f32.u32	%f1, %r4;

	add.ftz.f32 	%f2, %f1, 0f3F000000;

	and.b32  	%r6, %r2, 127;

	cvt.rn.f32.u32	%f3, %r6;

	add.ftz.f32 	%f4, %f3, 0f3F000000;

	tex.2d.v4.f32.f32	{%f5, %f6, %f7, %f8}, [noise_texture, {%f2, %f4}];

	st.param.f32	[func_retval0+0], %f5;

	st.param.f32	[func_retval0+4], %f6;

	st.param.f32	[func_retval0+8], %f7;

	st.param.f32	[func_retval0+12], %f8;

	ret;

}



	// .globl	_ZN9RandUtils7getRandEjj

.visible .func  (.param .align 16 .b8 func_retval0[16]) _ZN9RandUtils7getRandEjj(

	.param .b32 _ZN9RandUtils7getRandEjj_param_0,

	.param .b32 _ZN9RandUtils7getRandEjj_param_1

)

{

	.reg .f32 	%f<9>;

	.reg .s32 	%r<5>;

	.reg .s64 	%rd<2>;





	ld.param.u32 	%r1, [_ZN9RandUtils7getRandEjj_param_0];

	ld.param.u32 	%r2, [_ZN9RandUtils7getRandEjj_param_1];

	and.b32  	%r3, %r1, 1023;

	cvt.rn.f32.u32	%f1, %r3;

	add.ftz.f32 	%f2, %f1, 0f3F000000;

	and.b32  	%r4, %r2, 127;

	cvt.rn.f32.u32	%f3, %r4;

	add.ftz.f32 	%f4, %f3, 0f3F000000;

	tex.2d.v4.f32.f32	{%f5, %f6, %f7, %f8}, [noise_texture, {%f2, %f4}];

	st.param.f32	[func_retval0+0], %f5;

	st.param.f32	[func_retval0+4], %f6;

	st.param.f32	[func_retval0+8], %f7;

	st.param.f32	[func_retval0+12], %f8;

	ret;

}



	// .globl	_ZN9RandUtils7getRandEj

.visible .func  (.param .align 16 .b8 func_retval0[16]) _ZN9RandUtils7getRandEj(

	.param .b32 _ZN9RandUtils7getRandEj_param_0

)

{

	.reg .f32 	%f<9>;

	.reg .s32 	%r<4>;

	.reg .s64 	%rd<2>;





	ld.param.u32 	%r1, [_ZN9RandUtils7getRandEj_param_0];

	and.b32  	%r2, %r1, 1023;

	cvt.rn.f32.u32	%f1, %r2;

	add.ftz.f32 	%f2, %f1, 0f3F000000;

	bfe.u32 	%r3, %r1, 10, 7;

	cvt.rn.f32.u32	%f3, %r3;

	add.ftz.f32 	%f4, %f3, 0f3F000000;

	tex.2d.v4.f32.f32	{%f5, %f6, %f7, %f8}, [noise_texture, {%f2, %f4}];

	st.param.f32	[func_retval0+0], %f5;

	st.param.f32	[func_retval0+4], %f6;

	st.param.f32	[func_retval0+8], %f7;

	st.param.f32	[func_retval0+12], %f8;

	ret;

}



	// .globl	_ZN9RandUtils9getRand11ERK5uint2

.visible .func  (.param .align 16 .b8 func_retval0[16]) _ZN9RandUtils9getRand11ERK5uint2(

	.param .b64 _ZN9RandUtils9getRand11ERK5uint2_param_0

)

{

	.reg .f32 	%f<13>;

	.reg .s32 	%r<7>;

	.reg .s64 	%rd<3>;





	ld.param.u64 	%rd1, [_ZN9RandUtils9getRand11ERK5uint2_param_0];

	ld.v2.u32 	{%r1, %r2}, [%rd1];

	and.b32  	%r4, %r1, 1023;

	cvt.rn.f32.u32	%f1, %r4;

	add.ftz.f32 	%f2, %f1, 0f3F000000;

	and.b32  	%r6, %r2, 127;

	cvt.rn.f32.u32	%f3, %r6;

	add.ftz.f32 	%f4, %f3, 0f3F000000;

	tex.2d.v4.f32.f32	{%f5, %f6, %f7, %f8}, [noise_texture, {%f2, %f4}];

	fma.rn.ftz.f32 	%f9, %f5, 0f40000000, 0fBF800000;

	fma.rn.ftz.f32 	%f10, %f6, 0f40000000, 0fBF800000;

	fma.rn.ftz.f32 	%f11, %f7, 0f40000000, 0fBF800000;

	fma.rn.ftz.f32 	%f12, %f8, 0f40000000, 0fBF800000;

	st.param.f32	[func_retval0+0], %f9;

	st.param.f32	[func_retval0+4], %f10;

	st.param.f32	[func_retval0+8], %f11;

	st.param.f32	[func_retval0+12], %f12;

	ret;

}



	// .globl	_ZN9RandUtils9getRand11Ejj

.visible .func  (.param .align 16 .b8 func_retval0[16]) _ZN9RandUtils9getRand11Ejj(

	.param .b32 _ZN9RandUtils9getRand11Ejj_param_0,

	.param .b32 _ZN9RandUtils9getRand11Ejj_param_1

)

{

	.reg .f32 	%f<13>;

	.reg .s32 	%r<5>;

	.reg .s64 	%rd<2>;





	ld.param.u32 	%r1, [_ZN9RandUtils9getRand11Ejj_param_0];

	ld.param.u32 	%r2, [_ZN9RandUtils9getRand11Ejj_param_1];

	and.b32  	%r3, %r1, 1023;

	cvt.rn.f32.u32	%f1, %r3;

	add.ftz.f32 	%f2, %f1, 0f3F000000;

	and.b32  	%r4, %r2, 127;

	cvt.rn.f32.u32	%f3, %r4;

	add.ftz.f32 	%f4, %f3, 0f3F000000;

	tex.2d.v4.f32.f32	{%f5, %f6, %f7, %f8}, [noise_texture, {%f2, %f4}];

	fma.rn.ftz.f32 	%f9, %f5, 0f40000000, 0fBF800000;

	fma.rn.ftz.f32 	%f10, %f6, 0f40000000, 0fBF800000;

	fma.rn.ftz.f32 	%f11, %f7, 0f40000000, 0fBF800000;

	fma.rn.ftz.f32 	%f12, %f8, 0f40000000, 0fBF800000;

	st.param.f32	[func_retval0+0], %f9;

	st.param.f32	[func_retval0+4], %f10;

	st.param.f32	[func_retval0+8], %f11;

	st.param.f32	[func_retval0+12], %f12;

	ret;

}



	// .globl	_ZN9RandUtils9getRand11Ej

.visible .func  (.param .align 16 .b8 func_retval0[16]) _ZN9RandUtils9getRand11Ej(

	.param .b32 _ZN9RandUtils9getRand11Ej_param_0

)

{

	.reg .f32 	%f<13>;

	.reg .s32 	%r<4>;

	.reg .s64 	%rd<2>;





	ld.param.u32 	%r1, [_ZN9RandUtils9getRand11Ej_param_0];

	and.b32  	%r2, %r1, 1023;

	cvt.rn.f32.u32	%f1, %r2;

	add.ftz.f32 	%f2, %f1, 0f3F000000;

	bfe.u32 	%r3, %r1, 10, 7;

	cvt.rn.f32.u32	%f3, %r3;

	add.ftz.f32 	%f4, %f3, 0f3F000000;

	tex.2d.v4.f32.f32	{%f5, %f6, %f7, %f8}, [noise_texture, {%f2, %f4}];

	fma.rn.ftz.f32 	%f9, %f5, 0f40000000, 0fBF800000;

	fma.rn.ftz.f32 	%f10, %f6, 0f40000000, 0fBF800000;

	fma.rn.ftz.f32 	%f11, %f7, 0f40000000, 0fBF800000;

	fma.rn.ftz.f32 	%f12, %f8, 0f40000000, 0fBF800000;

	st.param.f32	[func_retval0+0], %f9;

	st.param.f32	[func_retval0+4], %f10;

	st.param.f32	[func_retval0+8], %f11;

	st.param.f32	[func_retval0+12], %f12;

	ret;

}



	// .globl	_ZN9RandUtils12gpuGetCell3DERK4int3

.visible .func  (.param .align 16 .b8 func_retval0[16]) _ZN9RandUtils12gpuGetCell3DERK4int3(

	.param .b64 _ZN9RandUtils12gpuGetCell3DERK4int3_param_0

)

{

	.reg .f32 	%f<11>;

	.reg .s32 	%r<12>;

	.reg .s64 	%rd<3>;





	ld.param.u64 	%rd1, [_ZN9RandUtils12gpuGetCell3DERK4int3_param_0];

	ld.u32 	%r1, [%rd1];

	ld.u32 	%r2, [%rd1+4];

	mad.lo.s32 	%r3, %r2, 31, %r1;

	abs.s32 	%r4, %r3;

	cvt.rn.f32.s32	%f1, %r4;

	ld.u32 	%r5, [%rd1+8];

	mad.lo.s32 	%r6, %r1, -3, %r5;

	abs.s32 	%r7, %r6;

	cvt.rn.f32.s32	%f2, %r7;

	cvt.rzi.ftz.u32.f32	%r8, %f1;

	cvt.rzi.ftz.u32.f32	%r9, %f2;

	and.b32  	%r10, %r8, 1023;

	cvt.rn.f32.u32	%f3, %r10;

	add.ftz.f32 	%f4, %f3, 0f3F000000;

	and.b32  	%r11, %r9, 127;

	cvt.rn.f32.u32	%f5, %r11;

	add.ftz.f32 	%f6, %f5, 0f3F000000;

	tex.2d.v4.f32.f32	{%f7, %f8, %f9, %f10}, [noise_texture, {%f4, %f6}];

	st.param.f32	[func_retval0+0], %f7;

	st.param.f32	[func_retval0+4], %f8;

	st.param.f32	[func_retval0+8], %f9;

	st.param.f32	[func_retval0+12], %f10;

	ret;

}



	// .globl	_ZN9RandUtils8cellFuncERK6float3R6float2

.visible .func _ZN9RandUtils8cellFuncERK6float3R6float2(

	.param .b64 _ZN9RandUtils8cellFuncERK6float3R6float2_param_0,

	.param .b64 _ZN9RandUtils8cellFuncERK6float3R6float2_param_1

)

{

	.reg .pred 	%p<3>;

	.reg .f32 	%f<11>;

	.reg .s64 	%rd<3>;





	ld.param.u64 	%rd2, [_ZN9RandUtils8cellFuncERK6float3R6float2_param_0];

	ld.param.u64 	%rd1, [_ZN9RandUtils8cellFuncERK6float3R6float2_param_1];

	ld.f32 	%f4, [%rd2];

	ld.f32 	%f5, [%rd2+4];

	mul.ftz.f32 	%f6, %f5, %f5;

	fma.rn.ftz.f32 	%f7, %f4, %f4, %f6;

	ld.f32 	%f8, [%rd2+8];

	fma.rn.ftz.f32 	%f1, %f8, %f8, %f7;

	ld.v2.f32 	{%f9, %f10}, [%rd1];

	setp.lt.ftz.f32	%p1, %f1, %f9;

	@%p1 bra 	BB54_3;

	bra.uni 	BB54_1;



BB54_3:

	st.v2.f32 	[%rd1], {%f1, %f9};

	bra.uni 	BB54_4;



BB54_1:

	setp.geu.ftz.f32	%p2, %f1, %f10;

	@%p2 bra 	BB54_4;



	st.f32 	[%rd1+4], %f1;



BB54_4:

	ret;

}



	// .globl	_ZN11NormalUtils9getNormalERK6float3b

.visible .func  (.param .align 4 .b8 func_retval0[12]) _ZN11NormalUtils9getNormalERK6float3b(

	.param .b64 _ZN11NormalUtils9getNormalERK6float3b_param_0,

	.param .b32 _ZN11NormalUtils9getNormalERK6float3b_param_1

)

{

	.reg .pred 	%p<2>;

	.reg .s16 	%rs<3>;

	.reg .f32 	%f<30>;

	.reg .s64 	%rd<2>;





	ld.param.u64 	%rd1, [_ZN11NormalUtils9getNormalERK6float3b_param_0];

	ld.param.s8 	%rs1, [_ZN11NormalUtils9getNormalERK6float3b_param_1];

	and.b16  	%rs2, %rs1, 255;

	setp.eq.s16	%p1, %rs2, 0;

	@%p1 bra 	BB55_2;



	ld.f32 	%f27, [%rd1+8];

	ld.f32 	%f28, [%rd1+4];

	ld.f32 	%f29, [%rd1];

	bra.uni 	BB55_3;



BB55_2:

	ld.f32 	%f16, [%rd1];

	neg.ftz.f32 	%f8, %f16;

	mov.f32 	%f29, %f8;

	ld.f32 	%f17, [%rd1+4];

	neg.ftz.f32 	%f9, %f17;

	mov.f32 	%f28, %f9;

	ld.f32 	%f18, [%rd1+8];

	neg.ftz.f32 	%f27, %f18;



BB55_3:

	mul.ftz.f32 	%f19, %f29, %f29;

	fma.rn.ftz.f32 	%f20, %f28, %f28, %f19;

	fma.rn.ftz.f32 	%f21, %f27, %f27, %f20;

	sqrt.approx.ftz.f32 	%f22, %f21;

	rcp.approx.ftz.f32 	%f23, %f22;

	mul.ftz.f32 	%f24, %f29, %f23;

	mul.ftz.f32 	%f25, %f28, %f23;

	mul.ftz.f32 	%f26, %f27, %f23;

	st.param.f32	[func_retval0+0], %f24;

	st.param.f32	[func_retval0+4], %f25;

	st.param.f32	[func_retval0+8], %f26;

	ret;

}



	// .globl	_ZN11NormalUtils9getNormalERK6float3bRK11BumpMapDataRK11SamplerInfoS2_

.visible .func  (.param .align 4 .b8 func_retval0[12]) _ZN11NormalUtils9getNormalERK6float3bRK11BumpMapDataRK11SamplerInfoS2_(

	.param .b64 _ZN11NormalUtils9getNormalERK6float3bRK11BumpMapDataRK11SamplerInfoS2__param_0,

	.param .b32 _ZN11NormalUtils9getNormalERK6float3bRK11BumpMapDataRK11SamplerInfoS2__param_1,

	.param .b64 _ZN11NormalUtils9getNormalERK6float3bRK11BumpMapDataRK11SamplerInfoS2__param_2,

	.param .b64 _ZN11NormalUtils9getNormalERK6float3bRK11BumpMapDataRK11SamplerInfoS2__param_3,

	.param .b64 _ZN11NormalUtils9getNormalERK6float3bRK11BumpMapDataRK11SamplerInfoS2__param_4

)

{

	.reg .pred 	%p<6>;

	.reg .s16 	%rs<4>;

	.reg .f32 	%f<138>;

	.reg .s32 	%r<17>;

	.reg .s64 	%rd<16>;





	ld.param.u64 	%rd1, [_ZN11NormalUtils9getNormalERK6float3bRK11BumpMapDataRK11SamplerInfoS2__param_0];

	ld.param.u64 	%rd4, [_ZN11NormalUtils9getNormalERK6float3bRK11BumpMapDataRK11SamplerInfoS2__param_2];

	ld.param.u64 	%rd5, [_ZN11NormalUtils9getNormalERK6float3bRK11BumpMapDataRK11SamplerInfoS2__param_3];

	ld.param.u64 	%rd6, [_ZN11NormalUtils9getNormalERK6float3bRK11BumpMapDataRK11SamplerInfoS2__param_4];

	ld.param.s8 	%rs1, [_ZN11NormalUtils9getNormalERK6float3bRK11BumpMapDataRK11SamplerInfoS2__param_1];

	and.b16  	%rs2, %rs1, 255;

	setp.eq.s16	%p1, %rs2, 0;

	@%p1 bra 	BB56_2;



	ld.f32 	%f125, [%rd1+8];

	ld.f32 	%f127, [%rd1+4];

	ld.f32 	%f126, [%rd1];

	bra.uni 	BB56_3;



BB56_2:

	ld.f32 	%f62, [%rd1];

	neg.ftz.f32 	%f8, %f62;

	mov.f32 	%f126, %f8;

	ld.f32 	%f63, [%rd1+4];

	neg.ftz.f32 	%f9, %f63;

	mov.f32 	%f127, %f9;

	ld.f32 	%f64, [%rd1+8];

	neg.ftz.f32 	%f125, %f64;



BB56_3:

	mul.ftz.f32 	%f65, %f127, %f127;

	fma.rn.ftz.f32 	%f66, %f126, %f126, %f65;

	fma.rn.ftz.f32 	%f67, %f125, %f125, %f66;

	sqrt.approx.ftz.f32 	%f68, %f67;

	rcp.approx.ftz.f32 	%f69, %f68;

	mul.ftz.f32 	%f16, %f126, %f69;

	mul.ftz.f32 	%f17, %f127, %f69;

	mul.ftz.f32 	%f18, %f125, %f69;

	ld.f32 	%f19, [%rd6];

	ld.f32 	%f20, [%rd6+4];

	ld.f32 	%f21, [%rd6+8];

	add.s64 	%rd2, %rd4, 32;

	ld.u64 	%rd3, [%rd4+32];

	cvt.u32.u64	%r16, %rd3;

	setp.eq.s32	%p2, %r16, 0;

	@%p2 bra 	BB56_11;



	shr.u64 	%rd7, %rd3, 32;

	cvt.u32.u64	%r6, %rd7;

	mov.b32 	 %f128, %r6;

	ld.v4.f32 	{%f70, %f71, %f72, %f73}, [%rd2+-32];

	mov.f32 	%f129, %f70;

	mov.f32 	%f130, %f71;

	mov.f32 	%f131, %f72;

	ld.u32 	%r7, [%rd2+-12];

	setp.eq.s32	%p3, %r7, -1;

	ld.u32 	%r2, [%rd4+16];

	@%p3 bra 	BB56_7;



	mov.f32 	%f129, %f70;

	mov.f32 	%f130, %f71;

	mov.f32 	%f131, %f72;

	setp.gt.u32	%p4, %r2, 6;

	@%p4 bra 	BB56_7;



	cvt.u64.u32	%rd10, %r2;

	mov.u64 	%rd15, textureSampleBuff;

	cvta.global.u64 	%rd9, %rd15;

	mov.u32 	%r8, 1;

	mov.u32 	%r9, 4;

	mov.u64 	%rd13, 0;

	// inline asm

	call (%rd8), _rt_buffer_get_64, (%rd9, %r8, %r9, %rd10, %rd13, %rd13, %rd13);

	// inline asm

	ld.u32 	%r11, [%rd2+-12];

	ld.f32 	%f74, [%rd5+20];

	ld.u32 	%r12, [%rd5+16];

	ld.u32 	%r13, [%rd5+12];

	ld.f32 	%f75, [%rd5+8];

	ld.f32 	%f76, [%rd5+4];

	ld.f32 	%f77, [%rd5];

	ld.u32 	%r10, [%rd8];

	// inline asm

	call (%rd14), _rt_callable_program_from_id_64, (%r10);

	// inline asm

	mov.u16 	%rs3, 0;

	cvt.s32.s16	%r14, %rs3;

	// Callseq Start 15

	{

	.reg .b32 temp_param_reg;

	// <end>}

	.param .b32 param0;

	st.param.b32	[param0+0], %r11;

	.param .align 4 .b8 param1[24];

	st.param.f32	[param1+0], %f77;

	st.param.f32	[param1+4], %f76;

	st.param.f32	[param1+8], %f75;

	st.param.b32	[param1+12], %r13;

	st.param.b32	[param1+16], %r12;

	st.param.f32	[param1+20], %f74;

	.param .b32 param2;

	st.param.b32	[param2+0], %r14;

	.param .align 16 .b8 retval0[16];

	prototype_15 : .callprototype (.param .align 16 .b8 _[16]) _ (.param .b32 _, .param .align 4 .b8 _[24], .param .b32 _);

	call (retval0), 

	%rd14, 

	(

	param0, 

	param1, 

	param2

	)

	, prototype_15;

	ld.param.f32	%f129, [retval0+0];

	ld.param.f32	%f130, [retval0+4];

	ld.param.f32	%f131, [retval0+8];

	ld.param.f32	%f78, [retval0+12];

	

	//{

	}// Callseq End 15

	ld.f32 	%f128, [%rd2+4];

	ld.u32 	%r16, [%rd2];



BB56_7:

	fma.rn.ftz.f32 	%f79, %f129, 0f40000000, 0fBF800000;

	fma.rn.ftz.f32 	%f80, %f130, 0f40000000, 0fBF800000;

	fma.rn.ftz.f32 	%f41, %f131, 0f40000000, 0fBF800000;

	mul.ftz.f32 	%f42, %f128, %f79;

	mul.ftz.f32 	%f43, %f128, %f80;

	setp.eq.s32	%p5, %r16, 3;

	@%p5 bra 	BB56_9;

	bra.uni 	BB56_8;



BB56_9:

	mov.u32 	%r15, 7937;

	mov.f32 	%f119, 0f00000000;

	// inline asm

	call (%f112, %f113, %f114, %f115), _rt_transform_tuple, (%r15, %f42, %f43, %f41, %f119);

	// inline asm

	mov.f32 	%f132, %f112;

	mov.f32 	%f133, %f113;

	mov.f32 	%f134, %f114;

	bra.uni 	BB56_10;



BB56_11:

	mov.f32 	%f137, %f18;

	mov.f32 	%f136, %f17;

	mov.f32 	%f135, %f16;

	bra.uni 	BB56_12;



BB56_8:

	mul.ftz.f32 	%f81, %f20, %f20;

	fma.rn.ftz.f32 	%f82, %f19, %f19, %f81;

	fma.rn.ftz.f32 	%f83, %f21, %f21, %f82;

	sqrt.approx.ftz.f32 	%f84, %f83;

	rcp.approx.ftz.f32 	%f85, %f84;

	mul.ftz.f32 	%f86, %f19, %f85;

	mul.ftz.f32 	%f87, %f20, %f85;

	mul.ftz.f32 	%f88, %f21, %f85;

	mul.ftz.f32 	%f89, %f17, %f88;

	mul.ftz.f32 	%f90, %f18, %f87;

	sub.ftz.f32 	%f91, %f89, %f90;

	mul.ftz.f32 	%f92, %f18, %f86;

	mul.ftz.f32 	%f93, %f16, %f88;

	sub.ftz.f32 	%f94, %f92, %f93;

	mul.ftz.f32 	%f95, %f16, %f87;

	mul.ftz.f32 	%f96, %f17, %f86;

	sub.ftz.f32 	%f97, %f95, %f96;

	mul.ftz.f32 	%f98, %f94, %f94;

	fma.rn.ftz.f32 	%f99, %f91, %f91, %f98;

	fma.rn.ftz.f32 	%f100, %f97, %f97, %f99;

	sqrt.approx.ftz.f32 	%f101, %f100;

	rcp.approx.ftz.f32 	%f102, %f101;

	mul.ftz.f32 	%f103, %f102, %f91;

	mul.ftz.f32 	%f104, %f102, %f94;

	mul.ftz.f32 	%f105, %f102, %f97;

	fma.rn.ftz.f32 	%f106, %f42, %f86, 0f00000000;

	fma.rn.ftz.f32 	%f107, %f43, %f103, %f106;

	fma.rn.ftz.f32 	%f132, %f41, %f16, %f107;

	fma.rn.ftz.f32 	%f108, %f42, %f87, 0f00000000;

	fma.rn.ftz.f32 	%f109, %f43, %f104, %f108;

	fma.rn.ftz.f32 	%f133, %f41, %f17, %f109;

	fma.rn.ftz.f32 	%f110, %f42, %f88, 0f00000000;

	fma.rn.ftz.f32 	%f111, %f43, %f105, %f110;

	fma.rn.ftz.f32 	%f134, %f41, %f18, %f111;



BB56_10:

	mul.ftz.f32 	%f120, %f133, %f133;

	fma.rn.ftz.f32 	%f121, %f132, %f132, %f120;

	fma.rn.ftz.f32 	%f122, %f134, %f134, %f121;

	sqrt.approx.ftz.f32 	%f123, %f122;

	rcp.approx.ftz.f32 	%f124, %f123;

	mul.ftz.f32 	%f135, %f124, %f132;

	mul.ftz.f32 	%f136, %f124, %f133;

	mul.ftz.f32 	%f137, %f124, %f134;



BB56_12:

	st.param.f32	[func_retval0+0], %f135;

	st.param.f32	[func_retval0+4], %f136;

	st.param.f32	[func_retval0+8], %f137;

	ret;

}





