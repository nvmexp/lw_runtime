//
// Generated by LWPU LWVM Compiler
// Compiler built on Thu May 15 11:00:55 2014 (1400169655)
// Driver 
//

.version 3.0
.target sm_30, texmode_independent
.address_size 32


.entry clearBuffer(
	.param .u32 .ptr .global .align 4 clearBuffer_param_0,
	.param .u32 clearBuffer_param_1
)
{
	.reg .pred 	%p<6>;
	.reg .s32 	%r<45>;


	ld.param.u32 	%r2, [clearBuffer_param_1];
	// inline asm
	mov.u32 	%r13, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r14, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r15, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r16, %tid.x;
	// inline asm
	add.s32 	%r17, %r16, %r13;
	mad.lo.s32 	%r42, %r15, %r14, %r17;
	shr.s32 	%r18, %r2, 31;
	shr.u32 	%r19, %r18, 30;
	add.s32 	%r20, %r2, %r19;
	shr.s32 	%r4, %r20, 2;
	setp.ge.s32 	%p1, %r42, %r4;
	@%p1 bra 	BB0_2;

BB0_1:
	shl.b32 	%r23, %r42, 4;
	ld.param.u32 	%r39, [clearBuffer_param_0];
	add.s32 	%r24, %r39, %r23;
	mov.u32 	%r25, 0;
	st.global.v4.u32 	[%r24], {%r25, %r25, %r25, %r25};
	// inline asm
	mov.u32 	%r21, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r22, %ntid.x;
	// inline asm
	mad.lo.s32 	%r42, %r22, %r21, %r42;
	setp.lt.s32 	%p2, %r42, %r4;
	@%p2 bra 	BB0_1;

BB0_2:
	// inline asm
	mov.u32 	%r26, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r27, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r28, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r30, %r28, %r27, %r26;
	// inline asm
	mov.u32 	%r29, %tid.x;
	// inline asm
	neg.s32 	%r31, %r29;
	setp.ne.s32 	%p3, %r30, %r31;
	@%p3 bra 	BB0_6;

	shl.b32 	%r44, %r4, 2;
	ld.param.u32 	%r41, [clearBuffer_param_1];
	setp.ge.s32 	%p4, %r44, %r41;
	@%p4 bra 	BB0_6;

	shl.b32 	%r32, %r4, 4;
	ld.param.u32 	%r38, [clearBuffer_param_0];
	add.s32 	%r43, %r38, %r32;

BB0_5:
	mov.u32 	%r33, 0;
	st.global.u32 	[%r43], %r33;
	add.s32 	%r43, %r43, 4;
	add.s32 	%r44, %r44, 1;
	ld.param.u32 	%r40, [clearBuffer_param_1];
	setp.lt.s32 	%p5, %r44, %r40;
	@%p5 bra 	BB0_5;

BB0_6:
	ret;
}

.entry clearTwoBuffers(
	.param .u32 .ptr .global .align 4 clearTwoBuffers_param_0,
	.param .u32 clearTwoBuffers_param_1,
	.param .u32 .ptr .global .align 4 clearTwoBuffers_param_2,
	.param .u32 clearTwoBuffers_param_3
)
{
	.reg .pred 	%p<11>;
	.reg .s32 	%r<90>;


	ld.param.u32 	%r2, [clearTwoBuffers_param_1];
	// inline asm
	mov.u32 	%r25, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r26, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r27, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r28, %tid.x;
	// inline asm
	add.s32 	%r29, %r28, %r25;
	mad.lo.s32 	%r84, %r27, %r26, %r29;
	shr.s32 	%r30, %r2, 31;
	shr.u32 	%r31, %r30, 30;
	add.s32 	%r32, %r2, %r31;
	shr.s32 	%r6, %r32, 2;
	setp.ge.s32 	%p1, %r84, %r6;
	@%p1 bra 	BB1_2;

BB1_1:
	shl.b32 	%r35, %r84, 4;
	ld.param.u32 	%r76, [clearTwoBuffers_param_0];
	add.s32 	%r36, %r76, %r35;
	mov.u32 	%r37, 0;
	st.global.v4.u32 	[%r36], {%r37, %r37, %r37, %r37};
	// inline asm
	mov.u32 	%r33, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r34, %ntid.x;
	// inline asm
	mad.lo.s32 	%r84, %r34, %r33, %r84;
	setp.lt.s32 	%p2, %r84, %r6;
	@%p2 bra 	BB1_1;

BB1_2:
	// inline asm
	mov.u32 	%r38, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r39, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r40, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r42, %r40, %r39, %r38;
	// inline asm
	mov.u32 	%r41, %tid.x;
	// inline asm
	neg.s32 	%r43, %r41;
	setp.ne.s32 	%p3, %r42, %r43;
	@%p3 bra 	BB1_6;

	shl.b32 	%r86, %r6, 2;
	ld.param.u32 	%r78, [clearTwoBuffers_param_1];
	setp.ge.s32 	%p4, %r86, %r78;
	@%p4 bra 	BB1_6;

	shl.b32 	%r44, %r6, 4;
	ld.param.u32 	%r75, [clearTwoBuffers_param_0];
	add.s32 	%r85, %r75, %r44;

BB1_5:
	mov.u32 	%r45, 0;
	st.global.u32 	[%r85], %r45;
	add.s32 	%r85, %r85, 4;
	add.s32 	%r86, %r86, 1;
	ld.param.u32 	%r77, [clearTwoBuffers_param_1];
	setp.lt.s32 	%p5, %r86, %r77;
	@%p5 bra 	BB1_5;

BB1_6:
	// inline asm
	mov.u32 	%r46, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r47, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r48, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r49, %tid.x;
	// inline asm
	add.s32 	%r50, %r49, %r46;
	mad.lo.s32 	%r87, %r48, %r47, %r50;
	ld.param.u32 	%r83, [clearTwoBuffers_param_3];
	shr.s32 	%r51, %r83, 31;
	shr.u32 	%r52, %r51, 30;
	add.s32 	%r53, %r83, %r52;
	shr.s32 	%r16, %r53, 2;
	setp.ge.s32 	%p6, %r87, %r16;
	@%p6 bra 	BB1_8;

BB1_7:
	shl.b32 	%r56, %r87, 4;
	ld.param.u32 	%r80, [clearTwoBuffers_param_2];
	add.s32 	%r57, %r80, %r56;
	mov.u32 	%r58, 0;
	st.global.v4.u32 	[%r57], {%r58, %r58, %r58, %r58};
	// inline asm
	mov.u32 	%r54, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r55, %ntid.x;
	// inline asm
	mad.lo.s32 	%r87, %r55, %r54, %r87;
	setp.lt.s32 	%p7, %r87, %r16;
	@%p7 bra 	BB1_7;

BB1_8:
	// inline asm
	mov.u32 	%r59, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r60, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r61, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r63, %r61, %r60, %r59;
	// inline asm
	mov.u32 	%r62, %tid.x;
	// inline asm
	neg.s32 	%r64, %r62;
	setp.ne.s32 	%p8, %r63, %r64;
	@%p8 bra 	BB1_12;

	shl.b32 	%r89, %r16, 2;
	ld.param.u32 	%r82, [clearTwoBuffers_param_3];
	setp.ge.s32 	%p9, %r89, %r82;
	@%p9 bra 	BB1_12;

	shl.b32 	%r65, %r16, 4;
	ld.param.u32 	%r79, [clearTwoBuffers_param_2];
	add.s32 	%r88, %r79, %r65;

BB1_11:
	mov.u32 	%r66, 0;
	st.global.u32 	[%r88], %r66;
	add.s32 	%r88, %r88, 4;
	add.s32 	%r89, %r89, 1;
	ld.param.u32 	%r81, [clearTwoBuffers_param_3];
	setp.lt.s32 	%p10, %r89, %r81;
	@%p10 bra 	BB1_11;

BB1_12:
	ret;
}

.entry clearThreeBuffers(
	.param .u32 .ptr .global .align 4 clearThreeBuffers_param_0,
	.param .u32 clearThreeBuffers_param_1,
	.param .u32 .ptr .global .align 4 clearThreeBuffers_param_2,
	.param .u32 clearThreeBuffers_param_3,
	.param .u32 .ptr .global .align 4 clearThreeBuffers_param_4,
	.param .u32 clearThreeBuffers_param_5
)
{
	.reg .pred 	%p<16>;
	.reg .s32 	%r<135>;


	ld.param.u32 	%r2, [clearThreeBuffers_param_1];
	// inline asm
	mov.u32 	%r37, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r38, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r39, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r40, %tid.x;
	// inline asm
	add.s32 	%r41, %r40, %r37;
	mad.lo.s32 	%r126, %r39, %r38, %r41;
	shr.s32 	%r42, %r2, 31;
	shr.u32 	%r43, %r42, 30;
	add.s32 	%r44, %r2, %r43;
	shr.s32 	%r8, %r44, 2;
	setp.ge.s32 	%p1, %r126, %r8;
	@%p1 bra 	BB2_2;

BB2_1:
	shl.b32 	%r47, %r126, 4;
	ld.param.u32 	%r113, [clearThreeBuffers_param_0];
	add.s32 	%r48, %r113, %r47;
	mov.u32 	%r49, 0;
	st.global.v4.u32 	[%r48], {%r49, %r49, %r49, %r49};
	// inline asm
	mov.u32 	%r45, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r46, %ntid.x;
	// inline asm
	mad.lo.s32 	%r126, %r46, %r45, %r126;
	setp.lt.s32 	%p2, %r126, %r8;
	@%p2 bra 	BB2_1;

BB2_2:
	// inline asm
	mov.u32 	%r50, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r51, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r52, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r54, %r52, %r51, %r50;
	// inline asm
	mov.u32 	%r53, %tid.x;
	// inline asm
	neg.s32 	%r55, %r53;
	setp.ne.s32 	%p3, %r54, %r55;
	@%p3 bra 	BB2_6;

	shl.b32 	%r128, %r8, 2;
	ld.param.u32 	%r115, [clearThreeBuffers_param_1];
	setp.ge.s32 	%p4, %r128, %r115;
	@%p4 bra 	BB2_6;

	shl.b32 	%r56, %r8, 4;
	ld.param.u32 	%r112, [clearThreeBuffers_param_0];
	add.s32 	%r127, %r112, %r56;

BB2_5:
	mov.u32 	%r57, 0;
	st.global.u32 	[%r127], %r57;
	add.s32 	%r127, %r127, 4;
	add.s32 	%r128, %r128, 1;
	ld.param.u32 	%r114, [clearThreeBuffers_param_1];
	setp.lt.s32 	%p5, %r128, %r114;
	@%p5 bra 	BB2_5;

BB2_6:
	// inline asm
	mov.u32 	%r58, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r59, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r60, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r61, %tid.x;
	// inline asm
	add.s32 	%r62, %r61, %r58;
	mad.lo.s32 	%r129, %r60, %r59, %r62;
	ld.param.u32 	%r120, [clearThreeBuffers_param_3];
	shr.s32 	%r63, %r120, 31;
	shr.u32 	%r64, %r63, 30;
	add.s32 	%r65, %r120, %r64;
	shr.s32 	%r18, %r65, 2;
	setp.ge.s32 	%p6, %r129, %r18;
	@%p6 bra 	BB2_8;

BB2_7:
	shl.b32 	%r68, %r129, 4;
	ld.param.u32 	%r117, [clearThreeBuffers_param_2];
	add.s32 	%r69, %r117, %r68;
	mov.u32 	%r70, 0;
	st.global.v4.u32 	[%r69], {%r70, %r70, %r70, %r70};
	// inline asm
	mov.u32 	%r66, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r67, %ntid.x;
	// inline asm
	mad.lo.s32 	%r129, %r67, %r66, %r129;
	setp.lt.s32 	%p7, %r129, %r18;
	@%p7 bra 	BB2_7;

BB2_8:
	// inline asm
	mov.u32 	%r71, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r72, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r73, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r75, %r73, %r72, %r71;
	// inline asm
	mov.u32 	%r74, %tid.x;
	// inline asm
	neg.s32 	%r76, %r74;
	setp.ne.s32 	%p8, %r75, %r76;
	@%p8 bra 	BB2_12;

	shl.b32 	%r131, %r18, 2;
	ld.param.u32 	%r119, [clearThreeBuffers_param_3];
	setp.ge.s32 	%p9, %r131, %r119;
	@%p9 bra 	BB2_12;

	shl.b32 	%r77, %r18, 4;
	ld.param.u32 	%r116, [clearThreeBuffers_param_2];
	add.s32 	%r130, %r116, %r77;

BB2_11:
	mov.u32 	%r78, 0;
	st.global.u32 	[%r130], %r78;
	add.s32 	%r130, %r130, 4;
	add.s32 	%r131, %r131, 1;
	ld.param.u32 	%r118, [clearThreeBuffers_param_3];
	setp.lt.s32 	%p10, %r131, %r118;
	@%p10 bra 	BB2_11;

BB2_12:
	// inline asm
	mov.u32 	%r79, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r80, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r81, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r82, %tid.x;
	// inline asm
	add.s32 	%r83, %r82, %r79;
	mad.lo.s32 	%r132, %r81, %r80, %r83;
	ld.param.u32 	%r125, [clearThreeBuffers_param_5];
	shr.s32 	%r84, %r125, 31;
	shr.u32 	%r85, %r84, 30;
	add.s32 	%r86, %r125, %r85;
	shr.s32 	%r28, %r86, 2;
	setp.ge.s32 	%p11, %r132, %r28;
	@%p11 bra 	BB2_14;

BB2_13:
	shl.b32 	%r89, %r132, 4;
	ld.param.u32 	%r122, [clearThreeBuffers_param_4];
	add.s32 	%r90, %r122, %r89;
	mov.u32 	%r91, 0;
	st.global.v4.u32 	[%r90], {%r91, %r91, %r91, %r91};
	// inline asm
	mov.u32 	%r87, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r88, %ntid.x;
	// inline asm
	mad.lo.s32 	%r132, %r88, %r87, %r132;
	setp.lt.s32 	%p12, %r132, %r28;
	@%p12 bra 	BB2_13;

BB2_14:
	// inline asm
	mov.u32 	%r92, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r93, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r94, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r96, %r94, %r93, %r92;
	// inline asm
	mov.u32 	%r95, %tid.x;
	// inline asm
	neg.s32 	%r97, %r95;
	setp.ne.s32 	%p13, %r96, %r97;
	@%p13 bra 	BB2_18;

	shl.b32 	%r134, %r28, 2;
	ld.param.u32 	%r124, [clearThreeBuffers_param_5];
	setp.ge.s32 	%p14, %r134, %r124;
	@%p14 bra 	BB2_18;

	shl.b32 	%r98, %r28, 4;
	ld.param.u32 	%r121, [clearThreeBuffers_param_4];
	add.s32 	%r133, %r121, %r98;

BB2_17:
	mov.u32 	%r99, 0;
	st.global.u32 	[%r133], %r99;
	add.s32 	%r133, %r133, 4;
	add.s32 	%r134, %r134, 1;
	ld.param.u32 	%r123, [clearThreeBuffers_param_5];
	setp.lt.s32 	%p15, %r134, %r123;
	@%p15 bra 	BB2_17;

BB2_18:
	ret;
}

.entry clearFourBuffers(
	.param .u32 .ptr .global .align 4 clearFourBuffers_param_0,
	.param .u32 clearFourBuffers_param_1,
	.param .u32 .ptr .global .align 4 clearFourBuffers_param_2,
	.param .u32 clearFourBuffers_param_3,
	.param .u32 .ptr .global .align 4 clearFourBuffers_param_4,
	.param .u32 clearFourBuffers_param_5,
	.param .u32 .ptr .global .align 4 clearFourBuffers_param_6,
	.param .u32 clearFourBuffers_param_7
)
{
	.reg .pred 	%p<21>;
	.reg .s32 	%r<180>;


	ld.param.u32 	%r2, [clearFourBuffers_param_1];
	// inline asm
	mov.u32 	%r49, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r50, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r51, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r52, %tid.x;
	// inline asm
	add.s32 	%r53, %r52, %r49;
	mad.lo.s32 	%r168, %r51, %r50, %r53;
	shr.s32 	%r54, %r2, 31;
	shr.u32 	%r55, %r54, 30;
	add.s32 	%r56, %r2, %r55;
	shr.s32 	%r10, %r56, 2;
	setp.ge.s32 	%p1, %r168, %r10;
	@%p1 bra 	BB3_2;

BB3_1:
	shl.b32 	%r59, %r168, 4;
	ld.param.u32 	%r150, [clearFourBuffers_param_0];
	add.s32 	%r60, %r150, %r59;
	mov.u32 	%r61, 0;
	st.global.v4.u32 	[%r60], {%r61, %r61, %r61, %r61};
	// inline asm
	mov.u32 	%r57, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r58, %ntid.x;
	// inline asm
	mad.lo.s32 	%r168, %r58, %r57, %r168;
	setp.lt.s32 	%p2, %r168, %r10;
	@%p2 bra 	BB3_1;

BB3_2:
	// inline asm
	mov.u32 	%r62, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r63, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r64, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r66, %r64, %r63, %r62;
	// inline asm
	mov.u32 	%r65, %tid.x;
	// inline asm
	neg.s32 	%r67, %r65;
	setp.ne.s32 	%p3, %r66, %r67;
	@%p3 bra 	BB3_6;

	shl.b32 	%r170, %r10, 2;
	ld.param.u32 	%r152, [clearFourBuffers_param_1];
	setp.ge.s32 	%p4, %r170, %r152;
	@%p4 bra 	BB3_6;

	shl.b32 	%r68, %r10, 4;
	ld.param.u32 	%r149, [clearFourBuffers_param_0];
	add.s32 	%r169, %r149, %r68;

BB3_5:
	mov.u32 	%r69, 0;
	st.global.u32 	[%r169], %r69;
	add.s32 	%r169, %r169, 4;
	add.s32 	%r170, %r170, 1;
	ld.param.u32 	%r151, [clearFourBuffers_param_1];
	setp.lt.s32 	%p5, %r170, %r151;
	@%p5 bra 	BB3_5;

BB3_6:
	// inline asm
	mov.u32 	%r70, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r71, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r72, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r73, %tid.x;
	// inline asm
	add.s32 	%r74, %r73, %r70;
	mad.lo.s32 	%r171, %r72, %r71, %r74;
	ld.param.u32 	%r157, [clearFourBuffers_param_3];
	shr.s32 	%r75, %r157, 31;
	shr.u32 	%r76, %r75, 30;
	add.s32 	%r77, %r157, %r76;
	shr.s32 	%r20, %r77, 2;
	setp.ge.s32 	%p6, %r171, %r20;
	@%p6 bra 	BB3_8;

BB3_7:
	shl.b32 	%r80, %r171, 4;
	ld.param.u32 	%r154, [clearFourBuffers_param_2];
	add.s32 	%r81, %r154, %r80;
	mov.u32 	%r82, 0;
	st.global.v4.u32 	[%r81], {%r82, %r82, %r82, %r82};
	// inline asm
	mov.u32 	%r78, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r79, %ntid.x;
	// inline asm
	mad.lo.s32 	%r171, %r79, %r78, %r171;
	setp.lt.s32 	%p7, %r171, %r20;
	@%p7 bra 	BB3_7;

BB3_8:
	// inline asm
	mov.u32 	%r83, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r84, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r85, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r87, %r85, %r84, %r83;
	// inline asm
	mov.u32 	%r86, %tid.x;
	// inline asm
	neg.s32 	%r88, %r86;
	setp.ne.s32 	%p8, %r87, %r88;
	@%p8 bra 	BB3_12;

	shl.b32 	%r173, %r20, 2;
	ld.param.u32 	%r156, [clearFourBuffers_param_3];
	setp.ge.s32 	%p9, %r173, %r156;
	@%p9 bra 	BB3_12;

	shl.b32 	%r89, %r20, 4;
	ld.param.u32 	%r153, [clearFourBuffers_param_2];
	add.s32 	%r172, %r153, %r89;

BB3_11:
	mov.u32 	%r90, 0;
	st.global.u32 	[%r172], %r90;
	add.s32 	%r172, %r172, 4;
	add.s32 	%r173, %r173, 1;
	ld.param.u32 	%r155, [clearFourBuffers_param_3];
	setp.lt.s32 	%p10, %r173, %r155;
	@%p10 bra 	BB3_11;

BB3_12:
	// inline asm
	mov.u32 	%r91, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r92, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r93, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r94, %tid.x;
	// inline asm
	add.s32 	%r95, %r94, %r91;
	mad.lo.s32 	%r174, %r93, %r92, %r95;
	ld.param.u32 	%r162, [clearFourBuffers_param_5];
	shr.s32 	%r96, %r162, 31;
	shr.u32 	%r97, %r96, 30;
	add.s32 	%r98, %r162, %r97;
	shr.s32 	%r30, %r98, 2;
	setp.ge.s32 	%p11, %r174, %r30;
	@%p11 bra 	BB3_14;

BB3_13:
	shl.b32 	%r101, %r174, 4;
	ld.param.u32 	%r159, [clearFourBuffers_param_4];
	add.s32 	%r102, %r159, %r101;
	mov.u32 	%r103, 0;
	st.global.v4.u32 	[%r102], {%r103, %r103, %r103, %r103};
	// inline asm
	mov.u32 	%r99, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r100, %ntid.x;
	// inline asm
	mad.lo.s32 	%r174, %r100, %r99, %r174;
	setp.lt.s32 	%p12, %r174, %r30;
	@%p12 bra 	BB3_13;

BB3_14:
	// inline asm
	mov.u32 	%r104, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r105, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r106, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r108, %r106, %r105, %r104;
	// inline asm
	mov.u32 	%r107, %tid.x;
	// inline asm
	neg.s32 	%r109, %r107;
	setp.ne.s32 	%p13, %r108, %r109;
	@%p13 bra 	BB3_18;

	shl.b32 	%r176, %r30, 2;
	ld.param.u32 	%r161, [clearFourBuffers_param_5];
	setp.ge.s32 	%p14, %r176, %r161;
	@%p14 bra 	BB3_18;

	shl.b32 	%r110, %r30, 4;
	ld.param.u32 	%r158, [clearFourBuffers_param_4];
	add.s32 	%r175, %r158, %r110;

BB3_17:
	mov.u32 	%r111, 0;
	st.global.u32 	[%r175], %r111;
	add.s32 	%r175, %r175, 4;
	add.s32 	%r176, %r176, 1;
	ld.param.u32 	%r160, [clearFourBuffers_param_5];
	setp.lt.s32 	%p15, %r176, %r160;
	@%p15 bra 	BB3_17;

BB3_18:
	// inline asm
	mov.u32 	%r112, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r113, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r114, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r115, %tid.x;
	// inline asm
	add.s32 	%r116, %r115, %r112;
	mad.lo.s32 	%r177, %r114, %r113, %r116;
	ld.param.u32 	%r167, [clearFourBuffers_param_7];
	shr.s32 	%r117, %r167, 31;
	shr.u32 	%r118, %r117, 30;
	add.s32 	%r119, %r167, %r118;
	shr.s32 	%r40, %r119, 2;
	setp.ge.s32 	%p16, %r177, %r40;
	@%p16 bra 	BB3_20;

BB3_19:
	shl.b32 	%r122, %r177, 4;
	ld.param.u32 	%r164, [clearFourBuffers_param_6];
	add.s32 	%r123, %r164, %r122;
	mov.u32 	%r124, 0;
	st.global.v4.u32 	[%r123], {%r124, %r124, %r124, %r124};
	// inline asm
	mov.u32 	%r120, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r121, %ntid.x;
	// inline asm
	mad.lo.s32 	%r177, %r121, %r120, %r177;
	setp.lt.s32 	%p17, %r177, %r40;
	@%p17 bra 	BB3_19;

BB3_20:
	// inline asm
	mov.u32 	%r125, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r126, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r127, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r129, %r127, %r126, %r125;
	// inline asm
	mov.u32 	%r128, %tid.x;
	// inline asm
	neg.s32 	%r130, %r128;
	setp.ne.s32 	%p18, %r129, %r130;
	@%p18 bra 	BB3_24;

	shl.b32 	%r179, %r40, 2;
	ld.param.u32 	%r166, [clearFourBuffers_param_7];
	setp.ge.s32 	%p19, %r179, %r166;
	@%p19 bra 	BB3_24;

	shl.b32 	%r131, %r40, 4;
	ld.param.u32 	%r163, [clearFourBuffers_param_6];
	add.s32 	%r178, %r163, %r131;

BB3_23:
	mov.u32 	%r132, 0;
	st.global.u32 	[%r178], %r132;
	add.s32 	%r178, %r178, 4;
	add.s32 	%r179, %r179, 1;
	ld.param.u32 	%r165, [clearFourBuffers_param_7];
	setp.lt.s32 	%p20, %r179, %r165;
	@%p20 bra 	BB3_23;

BB3_24:
	ret;
}

.entry clearFiveBuffers(
	.param .u32 .ptr .global .align 4 clearFiveBuffers_param_0,
	.param .u32 clearFiveBuffers_param_1,
	.param .u32 .ptr .global .align 4 clearFiveBuffers_param_2,
	.param .u32 clearFiveBuffers_param_3,
	.param .u32 .ptr .global .align 4 clearFiveBuffers_param_4,
	.param .u32 clearFiveBuffers_param_5,
	.param .u32 .ptr .global .align 4 clearFiveBuffers_param_6,
	.param .u32 clearFiveBuffers_param_7,
	.param .u32 .ptr .global .align 4 clearFiveBuffers_param_8,
	.param .u32 clearFiveBuffers_param_9
)
{
	.reg .pred 	%p<26>;
	.reg .s32 	%r<225>;


	ld.param.u32 	%r2, [clearFiveBuffers_param_1];
	// inline asm
	mov.u32 	%r61, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r62, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r63, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r64, %tid.x;
	// inline asm
	add.s32 	%r65, %r64, %r61;
	mad.lo.s32 	%r210, %r63, %r62, %r65;
	shr.s32 	%r66, %r2, 31;
	shr.u32 	%r67, %r66, 30;
	add.s32 	%r68, %r2, %r67;
	shr.s32 	%r12, %r68, 2;
	setp.ge.s32 	%p1, %r210, %r12;
	@%p1 bra 	BB4_2;

BB4_1:
	shl.b32 	%r71, %r210, 4;
	ld.param.u32 	%r187, [clearFiveBuffers_param_0];
	add.s32 	%r72, %r187, %r71;
	mov.u32 	%r73, 0;
	st.global.v4.u32 	[%r72], {%r73, %r73, %r73, %r73};
	// inline asm
	mov.u32 	%r69, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r70, %ntid.x;
	// inline asm
	mad.lo.s32 	%r210, %r70, %r69, %r210;
	setp.lt.s32 	%p2, %r210, %r12;
	@%p2 bra 	BB4_1;

BB4_2:
	// inline asm
	mov.u32 	%r74, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r75, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r76, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r78, %r76, %r75, %r74;
	// inline asm
	mov.u32 	%r77, %tid.x;
	// inline asm
	neg.s32 	%r79, %r77;
	setp.ne.s32 	%p3, %r78, %r79;
	@%p3 bra 	BB4_6;

	shl.b32 	%r212, %r12, 2;
	ld.param.u32 	%r189, [clearFiveBuffers_param_1];
	setp.ge.s32 	%p4, %r212, %r189;
	@%p4 bra 	BB4_6;

	shl.b32 	%r80, %r12, 4;
	ld.param.u32 	%r186, [clearFiveBuffers_param_0];
	add.s32 	%r211, %r186, %r80;

BB4_5:
	mov.u32 	%r81, 0;
	st.global.u32 	[%r211], %r81;
	add.s32 	%r211, %r211, 4;
	add.s32 	%r212, %r212, 1;
	ld.param.u32 	%r188, [clearFiveBuffers_param_1];
	setp.lt.s32 	%p5, %r212, %r188;
	@%p5 bra 	BB4_5;

BB4_6:
	// inline asm
	mov.u32 	%r82, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r83, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r84, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r85, %tid.x;
	// inline asm
	add.s32 	%r86, %r85, %r82;
	mad.lo.s32 	%r213, %r84, %r83, %r86;
	ld.param.u32 	%r194, [clearFiveBuffers_param_3];
	shr.s32 	%r87, %r194, 31;
	shr.u32 	%r88, %r87, 30;
	add.s32 	%r89, %r194, %r88;
	shr.s32 	%r22, %r89, 2;
	setp.ge.s32 	%p6, %r213, %r22;
	@%p6 bra 	BB4_8;

BB4_7:
	shl.b32 	%r92, %r213, 4;
	ld.param.u32 	%r191, [clearFiveBuffers_param_2];
	add.s32 	%r93, %r191, %r92;
	mov.u32 	%r94, 0;
	st.global.v4.u32 	[%r93], {%r94, %r94, %r94, %r94};
	// inline asm
	mov.u32 	%r90, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r91, %ntid.x;
	// inline asm
	mad.lo.s32 	%r213, %r91, %r90, %r213;
	setp.lt.s32 	%p7, %r213, %r22;
	@%p7 bra 	BB4_7;

BB4_8:
	// inline asm
	mov.u32 	%r95, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r96, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r97, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r99, %r97, %r96, %r95;
	// inline asm
	mov.u32 	%r98, %tid.x;
	// inline asm
	neg.s32 	%r100, %r98;
	setp.ne.s32 	%p8, %r99, %r100;
	@%p8 bra 	BB4_12;

	shl.b32 	%r215, %r22, 2;
	ld.param.u32 	%r193, [clearFiveBuffers_param_3];
	setp.ge.s32 	%p9, %r215, %r193;
	@%p9 bra 	BB4_12;

	shl.b32 	%r101, %r22, 4;
	ld.param.u32 	%r190, [clearFiveBuffers_param_2];
	add.s32 	%r214, %r190, %r101;

BB4_11:
	mov.u32 	%r102, 0;
	st.global.u32 	[%r214], %r102;
	add.s32 	%r214, %r214, 4;
	add.s32 	%r215, %r215, 1;
	ld.param.u32 	%r192, [clearFiveBuffers_param_3];
	setp.lt.s32 	%p10, %r215, %r192;
	@%p10 bra 	BB4_11;

BB4_12:
	// inline asm
	mov.u32 	%r103, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r104, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r105, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r106, %tid.x;
	// inline asm
	add.s32 	%r107, %r106, %r103;
	mad.lo.s32 	%r216, %r105, %r104, %r107;
	ld.param.u32 	%r199, [clearFiveBuffers_param_5];
	shr.s32 	%r108, %r199, 31;
	shr.u32 	%r109, %r108, 30;
	add.s32 	%r110, %r199, %r109;
	shr.s32 	%r32, %r110, 2;
	setp.ge.s32 	%p11, %r216, %r32;
	@%p11 bra 	BB4_14;

BB4_13:
	shl.b32 	%r113, %r216, 4;
	ld.param.u32 	%r196, [clearFiveBuffers_param_4];
	add.s32 	%r114, %r196, %r113;
	mov.u32 	%r115, 0;
	st.global.v4.u32 	[%r114], {%r115, %r115, %r115, %r115};
	// inline asm
	mov.u32 	%r111, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r112, %ntid.x;
	// inline asm
	mad.lo.s32 	%r216, %r112, %r111, %r216;
	setp.lt.s32 	%p12, %r216, %r32;
	@%p12 bra 	BB4_13;

BB4_14:
	// inline asm
	mov.u32 	%r116, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r117, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r118, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r120, %r118, %r117, %r116;
	// inline asm
	mov.u32 	%r119, %tid.x;
	// inline asm
	neg.s32 	%r121, %r119;
	setp.ne.s32 	%p13, %r120, %r121;
	@%p13 bra 	BB4_18;

	shl.b32 	%r218, %r32, 2;
	ld.param.u32 	%r198, [clearFiveBuffers_param_5];
	setp.ge.s32 	%p14, %r218, %r198;
	@%p14 bra 	BB4_18;

	shl.b32 	%r122, %r32, 4;
	ld.param.u32 	%r195, [clearFiveBuffers_param_4];
	add.s32 	%r217, %r195, %r122;

BB4_17:
	mov.u32 	%r123, 0;
	st.global.u32 	[%r217], %r123;
	add.s32 	%r217, %r217, 4;
	add.s32 	%r218, %r218, 1;
	ld.param.u32 	%r197, [clearFiveBuffers_param_5];
	setp.lt.s32 	%p15, %r218, %r197;
	@%p15 bra 	BB4_17;

BB4_18:
	// inline asm
	mov.u32 	%r124, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r125, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r126, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r127, %tid.x;
	// inline asm
	add.s32 	%r128, %r127, %r124;
	mad.lo.s32 	%r219, %r126, %r125, %r128;
	ld.param.u32 	%r204, [clearFiveBuffers_param_7];
	shr.s32 	%r129, %r204, 31;
	shr.u32 	%r130, %r129, 30;
	add.s32 	%r131, %r204, %r130;
	shr.s32 	%r42, %r131, 2;
	setp.ge.s32 	%p16, %r219, %r42;
	@%p16 bra 	BB4_20;

BB4_19:
	shl.b32 	%r134, %r219, 4;
	ld.param.u32 	%r201, [clearFiveBuffers_param_6];
	add.s32 	%r135, %r201, %r134;
	mov.u32 	%r136, 0;
	st.global.v4.u32 	[%r135], {%r136, %r136, %r136, %r136};
	// inline asm
	mov.u32 	%r132, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r133, %ntid.x;
	// inline asm
	mad.lo.s32 	%r219, %r133, %r132, %r219;
	setp.lt.s32 	%p17, %r219, %r42;
	@%p17 bra 	BB4_19;

BB4_20:
	// inline asm
	mov.u32 	%r137, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r138, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r139, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r141, %r139, %r138, %r137;
	// inline asm
	mov.u32 	%r140, %tid.x;
	// inline asm
	neg.s32 	%r142, %r140;
	setp.ne.s32 	%p18, %r141, %r142;
	@%p18 bra 	BB4_24;

	shl.b32 	%r221, %r42, 2;
	ld.param.u32 	%r203, [clearFiveBuffers_param_7];
	setp.ge.s32 	%p19, %r221, %r203;
	@%p19 bra 	BB4_24;

	shl.b32 	%r143, %r42, 4;
	ld.param.u32 	%r200, [clearFiveBuffers_param_6];
	add.s32 	%r220, %r200, %r143;

BB4_23:
	mov.u32 	%r144, 0;
	st.global.u32 	[%r220], %r144;
	add.s32 	%r220, %r220, 4;
	add.s32 	%r221, %r221, 1;
	ld.param.u32 	%r202, [clearFiveBuffers_param_7];
	setp.lt.s32 	%p20, %r221, %r202;
	@%p20 bra 	BB4_23;

BB4_24:
	// inline asm
	mov.u32 	%r145, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r146, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r147, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r148, %tid.x;
	// inline asm
	add.s32 	%r149, %r148, %r145;
	mad.lo.s32 	%r222, %r147, %r146, %r149;
	ld.param.u32 	%r209, [clearFiveBuffers_param_9];
	shr.s32 	%r150, %r209, 31;
	shr.u32 	%r151, %r150, 30;
	add.s32 	%r152, %r209, %r151;
	shr.s32 	%r52, %r152, 2;
	setp.ge.s32 	%p21, %r222, %r52;
	@%p21 bra 	BB4_26;

BB4_25:
	shl.b32 	%r155, %r222, 4;
	ld.param.u32 	%r206, [clearFiveBuffers_param_8];
	add.s32 	%r156, %r206, %r155;
	mov.u32 	%r157, 0;
	st.global.v4.u32 	[%r156], {%r157, %r157, %r157, %r157};
	// inline asm
	mov.u32 	%r153, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r154, %ntid.x;
	// inline asm
	mad.lo.s32 	%r222, %r154, %r153, %r222;
	setp.lt.s32 	%p22, %r222, %r52;
	@%p22 bra 	BB4_25;

BB4_26:
	// inline asm
	mov.u32 	%r158, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r159, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r160, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r162, %r160, %r159, %r158;
	// inline asm
	mov.u32 	%r161, %tid.x;
	// inline asm
	neg.s32 	%r163, %r161;
	setp.ne.s32 	%p23, %r162, %r163;
	@%p23 bra 	BB4_30;

	shl.b32 	%r224, %r52, 2;
	ld.param.u32 	%r208, [clearFiveBuffers_param_9];
	setp.ge.s32 	%p24, %r224, %r208;
	@%p24 bra 	BB4_30;

	shl.b32 	%r164, %r52, 4;
	ld.param.u32 	%r205, [clearFiveBuffers_param_8];
	add.s32 	%r223, %r205, %r164;

BB4_29:
	mov.u32 	%r165, 0;
	st.global.u32 	[%r223], %r165;
	add.s32 	%r223, %r223, 4;
	add.s32 	%r224, %r224, 1;
	ld.param.u32 	%r207, [clearFiveBuffers_param_9];
	setp.lt.s32 	%p25, %r224, %r207;
	@%p25 bra 	BB4_29;

BB4_30:
	ret;
}

.entry clearSixBuffers(
	.param .u32 .ptr .global .align 4 clearSixBuffers_param_0,
	.param .u32 clearSixBuffers_param_1,
	.param .u32 .ptr .global .align 4 clearSixBuffers_param_2,
	.param .u32 clearSixBuffers_param_3,
	.param .u32 .ptr .global .align 4 clearSixBuffers_param_4,
	.param .u32 clearSixBuffers_param_5,
	.param .u32 .ptr .global .align 4 clearSixBuffers_param_6,
	.param .u32 clearSixBuffers_param_7,
	.param .u32 .ptr .global .align 4 clearSixBuffers_param_8,
	.param .u32 clearSixBuffers_param_9,
	.param .u32 .ptr .global .align 4 clearSixBuffers_param_10,
	.param .u32 clearSixBuffers_param_11
)
{
	.reg .pred 	%p<31>;
	.reg .s32 	%r<270>;


	ld.param.u32 	%r2, [clearSixBuffers_param_1];
	// inline asm
	mov.u32 	%r73, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r74, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r75, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r76, %tid.x;
	// inline asm
	add.s32 	%r77, %r76, %r73;
	mad.lo.s32 	%r252, %r75, %r74, %r77;
	shr.s32 	%r78, %r2, 31;
	shr.u32 	%r79, %r78, 30;
	add.s32 	%r80, %r2, %r79;
	shr.s32 	%r14, %r80, 2;
	setp.ge.s32 	%p1, %r252, %r14;
	@%p1 bra 	BB5_2;

BB5_1:
	shl.b32 	%r83, %r252, 4;
	ld.param.u32 	%r224, [clearSixBuffers_param_0];
	add.s32 	%r84, %r224, %r83;
	mov.u32 	%r85, 0;
	st.global.v4.u32 	[%r84], {%r85, %r85, %r85, %r85};
	// inline asm
	mov.u32 	%r81, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r82, %ntid.x;
	// inline asm
	mad.lo.s32 	%r252, %r82, %r81, %r252;
	setp.lt.s32 	%p2, %r252, %r14;
	@%p2 bra 	BB5_1;

BB5_2:
	// inline asm
	mov.u32 	%r86, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r87, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r88, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r90, %r88, %r87, %r86;
	// inline asm
	mov.u32 	%r89, %tid.x;
	// inline asm
	neg.s32 	%r91, %r89;
	setp.ne.s32 	%p3, %r90, %r91;
	@%p3 bra 	BB5_6;

	shl.b32 	%r254, %r14, 2;
	ld.param.u32 	%r226, [clearSixBuffers_param_1];
	setp.ge.s32 	%p4, %r254, %r226;
	@%p4 bra 	BB5_6;

	shl.b32 	%r92, %r14, 4;
	ld.param.u32 	%r223, [clearSixBuffers_param_0];
	add.s32 	%r253, %r223, %r92;

BB5_5:
	mov.u32 	%r93, 0;
	st.global.u32 	[%r253], %r93;
	add.s32 	%r253, %r253, 4;
	add.s32 	%r254, %r254, 1;
	ld.param.u32 	%r225, [clearSixBuffers_param_1];
	setp.lt.s32 	%p5, %r254, %r225;
	@%p5 bra 	BB5_5;

BB5_6:
	// inline asm
	mov.u32 	%r94, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r95, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r96, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r97, %tid.x;
	// inline asm
	add.s32 	%r98, %r97, %r94;
	mad.lo.s32 	%r255, %r96, %r95, %r98;
	ld.param.u32 	%r231, [clearSixBuffers_param_3];
	shr.s32 	%r99, %r231, 31;
	shr.u32 	%r100, %r99, 30;
	add.s32 	%r101, %r231, %r100;
	shr.s32 	%r24, %r101, 2;
	setp.ge.s32 	%p6, %r255, %r24;
	@%p6 bra 	BB5_8;

BB5_7:
	shl.b32 	%r104, %r255, 4;
	ld.param.u32 	%r228, [clearSixBuffers_param_2];
	add.s32 	%r105, %r228, %r104;
	mov.u32 	%r106, 0;
	st.global.v4.u32 	[%r105], {%r106, %r106, %r106, %r106};
	// inline asm
	mov.u32 	%r102, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r103, %ntid.x;
	// inline asm
	mad.lo.s32 	%r255, %r103, %r102, %r255;
	setp.lt.s32 	%p7, %r255, %r24;
	@%p7 bra 	BB5_7;

BB5_8:
	// inline asm
	mov.u32 	%r107, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r108, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r109, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r111, %r109, %r108, %r107;
	// inline asm
	mov.u32 	%r110, %tid.x;
	// inline asm
	neg.s32 	%r112, %r110;
	setp.ne.s32 	%p8, %r111, %r112;
	@%p8 bra 	BB5_12;

	shl.b32 	%r257, %r24, 2;
	ld.param.u32 	%r230, [clearSixBuffers_param_3];
	setp.ge.s32 	%p9, %r257, %r230;
	@%p9 bra 	BB5_12;

	shl.b32 	%r113, %r24, 4;
	ld.param.u32 	%r227, [clearSixBuffers_param_2];
	add.s32 	%r256, %r227, %r113;

BB5_11:
	mov.u32 	%r114, 0;
	st.global.u32 	[%r256], %r114;
	add.s32 	%r256, %r256, 4;
	add.s32 	%r257, %r257, 1;
	ld.param.u32 	%r229, [clearSixBuffers_param_3];
	setp.lt.s32 	%p10, %r257, %r229;
	@%p10 bra 	BB5_11;

BB5_12:
	// inline asm
	mov.u32 	%r115, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r116, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r117, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r118, %tid.x;
	// inline asm
	add.s32 	%r119, %r118, %r115;
	mad.lo.s32 	%r258, %r117, %r116, %r119;
	ld.param.u32 	%r236, [clearSixBuffers_param_5];
	shr.s32 	%r120, %r236, 31;
	shr.u32 	%r121, %r120, 30;
	add.s32 	%r122, %r236, %r121;
	shr.s32 	%r34, %r122, 2;
	setp.ge.s32 	%p11, %r258, %r34;
	@%p11 bra 	BB5_14;

BB5_13:
	shl.b32 	%r125, %r258, 4;
	ld.param.u32 	%r233, [clearSixBuffers_param_4];
	add.s32 	%r126, %r233, %r125;
	mov.u32 	%r127, 0;
	st.global.v4.u32 	[%r126], {%r127, %r127, %r127, %r127};
	// inline asm
	mov.u32 	%r123, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r124, %ntid.x;
	// inline asm
	mad.lo.s32 	%r258, %r124, %r123, %r258;
	setp.lt.s32 	%p12, %r258, %r34;
	@%p12 bra 	BB5_13;

BB5_14:
	// inline asm
	mov.u32 	%r128, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r129, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r130, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r132, %r130, %r129, %r128;
	// inline asm
	mov.u32 	%r131, %tid.x;
	// inline asm
	neg.s32 	%r133, %r131;
	setp.ne.s32 	%p13, %r132, %r133;
	@%p13 bra 	BB5_18;

	shl.b32 	%r260, %r34, 2;
	ld.param.u32 	%r235, [clearSixBuffers_param_5];
	setp.ge.s32 	%p14, %r260, %r235;
	@%p14 bra 	BB5_18;

	shl.b32 	%r134, %r34, 4;
	ld.param.u32 	%r232, [clearSixBuffers_param_4];
	add.s32 	%r259, %r232, %r134;

BB5_17:
	mov.u32 	%r135, 0;
	st.global.u32 	[%r259], %r135;
	add.s32 	%r259, %r259, 4;
	add.s32 	%r260, %r260, 1;
	ld.param.u32 	%r234, [clearSixBuffers_param_5];
	setp.lt.s32 	%p15, %r260, %r234;
	@%p15 bra 	BB5_17;

BB5_18:
	// inline asm
	mov.u32 	%r136, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r137, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r138, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r139, %tid.x;
	// inline asm
	add.s32 	%r140, %r139, %r136;
	mad.lo.s32 	%r261, %r138, %r137, %r140;
	ld.param.u32 	%r241, [clearSixBuffers_param_7];
	shr.s32 	%r141, %r241, 31;
	shr.u32 	%r142, %r141, 30;
	add.s32 	%r143, %r241, %r142;
	shr.s32 	%r44, %r143, 2;
	setp.ge.s32 	%p16, %r261, %r44;
	@%p16 bra 	BB5_20;

BB5_19:
	shl.b32 	%r146, %r261, 4;
	ld.param.u32 	%r238, [clearSixBuffers_param_6];
	add.s32 	%r147, %r238, %r146;
	mov.u32 	%r148, 0;
	st.global.v4.u32 	[%r147], {%r148, %r148, %r148, %r148};
	// inline asm
	mov.u32 	%r144, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r145, %ntid.x;
	// inline asm
	mad.lo.s32 	%r261, %r145, %r144, %r261;
	setp.lt.s32 	%p17, %r261, %r44;
	@%p17 bra 	BB5_19;

BB5_20:
	// inline asm
	mov.u32 	%r149, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r150, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r151, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r153, %r151, %r150, %r149;
	// inline asm
	mov.u32 	%r152, %tid.x;
	// inline asm
	neg.s32 	%r154, %r152;
	setp.ne.s32 	%p18, %r153, %r154;
	@%p18 bra 	BB5_24;

	shl.b32 	%r263, %r44, 2;
	ld.param.u32 	%r240, [clearSixBuffers_param_7];
	setp.ge.s32 	%p19, %r263, %r240;
	@%p19 bra 	BB5_24;

	shl.b32 	%r155, %r44, 4;
	ld.param.u32 	%r237, [clearSixBuffers_param_6];
	add.s32 	%r262, %r237, %r155;

BB5_23:
	mov.u32 	%r156, 0;
	st.global.u32 	[%r262], %r156;
	add.s32 	%r262, %r262, 4;
	add.s32 	%r263, %r263, 1;
	ld.param.u32 	%r239, [clearSixBuffers_param_7];
	setp.lt.s32 	%p20, %r263, %r239;
	@%p20 bra 	BB5_23;

BB5_24:
	// inline asm
	mov.u32 	%r157, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r158, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r159, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r160, %tid.x;
	// inline asm
	add.s32 	%r161, %r160, %r157;
	mad.lo.s32 	%r264, %r159, %r158, %r161;
	ld.param.u32 	%r246, [clearSixBuffers_param_9];
	shr.s32 	%r162, %r246, 31;
	shr.u32 	%r163, %r162, 30;
	add.s32 	%r164, %r246, %r163;
	shr.s32 	%r54, %r164, 2;
	setp.ge.s32 	%p21, %r264, %r54;
	@%p21 bra 	BB5_26;

BB5_25:
	shl.b32 	%r167, %r264, 4;
	ld.param.u32 	%r243, [clearSixBuffers_param_8];
	add.s32 	%r168, %r243, %r167;
	mov.u32 	%r169, 0;
	st.global.v4.u32 	[%r168], {%r169, %r169, %r169, %r169};
	// inline asm
	mov.u32 	%r165, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r166, %ntid.x;
	// inline asm
	mad.lo.s32 	%r264, %r166, %r165, %r264;
	setp.lt.s32 	%p22, %r264, %r54;
	@%p22 bra 	BB5_25;

BB5_26:
	// inline asm
	mov.u32 	%r170, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r171, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r172, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r174, %r172, %r171, %r170;
	// inline asm
	mov.u32 	%r173, %tid.x;
	// inline asm
	neg.s32 	%r175, %r173;
	setp.ne.s32 	%p23, %r174, %r175;
	@%p23 bra 	BB5_30;

	shl.b32 	%r266, %r54, 2;
	ld.param.u32 	%r245, [clearSixBuffers_param_9];
	setp.ge.s32 	%p24, %r266, %r245;
	@%p24 bra 	BB5_30;

	shl.b32 	%r176, %r54, 4;
	ld.param.u32 	%r242, [clearSixBuffers_param_8];
	add.s32 	%r265, %r242, %r176;

BB5_29:
	mov.u32 	%r177, 0;
	st.global.u32 	[%r265], %r177;
	add.s32 	%r265, %r265, 4;
	add.s32 	%r266, %r266, 1;
	ld.param.u32 	%r244, [clearSixBuffers_param_9];
	setp.lt.s32 	%p25, %r266, %r244;
	@%p25 bra 	BB5_29;

BB5_30:
	// inline asm
	mov.u32 	%r178, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r179, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r180, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r181, %tid.x;
	// inline asm
	add.s32 	%r182, %r181, %r178;
	mad.lo.s32 	%r267, %r180, %r179, %r182;
	ld.param.u32 	%r251, [clearSixBuffers_param_11];
	shr.s32 	%r183, %r251, 31;
	shr.u32 	%r184, %r183, 30;
	add.s32 	%r185, %r251, %r184;
	shr.s32 	%r64, %r185, 2;
	setp.ge.s32 	%p26, %r267, %r64;
	@%p26 bra 	BB5_32;

BB5_31:
	shl.b32 	%r188, %r267, 4;
	ld.param.u32 	%r248, [clearSixBuffers_param_10];
	add.s32 	%r189, %r248, %r188;
	mov.u32 	%r190, 0;
	st.global.v4.u32 	[%r189], {%r190, %r190, %r190, %r190};
	// inline asm
	mov.u32 	%r186, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r187, %ntid.x;
	// inline asm
	mad.lo.s32 	%r267, %r187, %r186, %r267;
	setp.lt.s32 	%p27, %r267, %r64;
	@%p27 bra 	BB5_31;

BB5_32:
	// inline asm
	mov.u32 	%r191, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r192, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r193, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r195, %r193, %r192, %r191;
	// inline asm
	mov.u32 	%r194, %tid.x;
	// inline asm
	neg.s32 	%r196, %r194;
	setp.ne.s32 	%p28, %r195, %r196;
	@%p28 bra 	BB5_36;

	shl.b32 	%r269, %r64, 2;
	ld.param.u32 	%r250, [clearSixBuffers_param_11];
	setp.ge.s32 	%p29, %r269, %r250;
	@%p29 bra 	BB5_36;

	shl.b32 	%r197, %r64, 4;
	ld.param.u32 	%r247, [clearSixBuffers_param_10];
	add.s32 	%r268, %r247, %r197;

BB5_35:
	mov.u32 	%r198, 0;
	st.global.u32 	[%r268], %r198;
	add.s32 	%r268, %r268, 4;
	add.s32 	%r269, %r269, 1;
	ld.param.u32 	%r249, [clearSixBuffers_param_11];
	setp.lt.s32 	%p30, %r269, %r249;
	@%p30 bra 	BB5_35;

BB5_36:
	ret;
}

.entry reduceReal4Buffer(
	.param .u32 .ptr .global .align 16 reduceReal4Buffer_param_0,
	.param .u32 reduceReal4Buffer_param_1,
	.param .u32 reduceReal4Buffer_param_2
)
{
	.reg .f32 	%f<25>;
	.reg .pred 	%p<5>;
	.reg .s32 	%r<29>;


	ld.param.u32 	%r2, [reduceReal4Buffer_param_1];
	ld.param.u32 	%r15, [reduceReal4Buffer_param_2];
	// inline asm
	mov.u32 	%r11, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r12, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r13, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r14, %tid.x;
	// inline asm
	add.s32 	%r16, %r14, %r11;
	mad.lo.s32 	%r27, %r13, %r12, %r16;
	mul.lo.s32 	%r4, %r15, %r2;
	setp.ge.s32 	%p1, %r27, %r2;
	@%p1 bra 	BB6_4;

BB6_1:
	shl.b32 	%r17, %r27, 4;
	ld.param.u32 	%r23, [reduceReal4Buffer_param_0];
	add.s32 	%r6, %r23, %r17;
	ld.global.v4.f32 	{%f21, %f22, %f23, %f24}, [%r6];
	ld.param.u32 	%r26, [reduceReal4Buffer_param_1];
	add.s32 	%r28, %r27, %r26;
	setp.lt.s32 	%p2, %r28, %r4;
	@%p2 bra 	BB6_2;
	bra.uni 	BB6_3;

BB6_2:
	shl.b32 	%r18, %r28, 4;
	ld.param.u32 	%r22, [reduceReal4Buffer_param_0];
	add.s32 	%r19, %r22, %r18;
	ld.global.v4.f32 	{%f17, %f18, %f19, %f20}, [%r19];
	add.ftz.f32 	%f21, %f21, %f17;
	add.ftz.f32 	%f22, %f22, %f18;
	add.ftz.f32 	%f23, %f23, %f19;
	add.ftz.f32 	%f24, %f24, %f20;
	ld.param.u32 	%r25, [reduceReal4Buffer_param_1];
	add.s32 	%r28, %r28, %r25;
	setp.lt.s32 	%p3, %r28, %r4;
	@%p3 bra 	BB6_2;

BB6_3:
	st.global.v4.f32 	[%r6], {%f21, %f22, %f23, %f24};
	// inline asm
	mov.u32 	%r20, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r21, %ntid.x;
	// inline asm
	mad.lo.s32 	%r27, %r21, %r20, %r27;
	ld.param.u32 	%r24, [reduceReal4Buffer_param_1];
	setp.lt.s32 	%p4, %r27, %r24;
	@%p4 bra 	BB6_1;

BB6_4:
	ret;
}

.entry reduceForces(
	.param .u32 .ptr .global .align 8 reduceForces_param_0,
	.param .u32 .ptr .global .align 16 reduceForces_param_1,
	.param .u32 reduceForces_param_2,
	.param .u32 reduceForces_param_3
)
{
	.reg .f32 	%f<32>;
	.reg .pred 	%p<5>;
	.reg .s32 	%r<41>;
	.reg .s64 	%rl<4>;


	ld.param.u32 	%r3, [reduceForces_param_2];
	ld.param.u32 	%r15, [reduceForces_param_3];
	mul.lo.s32 	%r4, %r15, %r3;
	// inline asm
	mov.u32 	%r11, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r12, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r13, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r14, %tid.x;
	// inline asm
	add.s32 	%r16, %r14, %r11;
	mad.lo.s32 	%r40, %r13, %r12, %r16;
	setp.ge.s32 	%p1, %r40, %r3;
	@%p1 bra 	BB7_6;

	ld.param.u32 	%r37, [reduceForces_param_2];
	shl.b32 	%r6, %r37, 1;

BB7_2:
	mov.u32 	%r38, %r40;
	mov.u32 	%r7, %r38;
	shl.b32 	%r17, %r7, 3;
	ld.param.u32 	%r31, [reduceForces_param_0];
	add.s32 	%r18, %r31, %r17;
	ld.global.u64 	%rl1, [%r18];
	cvt.rn.f32.s64 	%f1, %rl1;
	mul.ftz.f32 	%f2, %f1, 0f2F800000;
	ld.param.u32 	%r36, [reduceForces_param_2];
	add.s32 	%r19, %r7, %r36;
	shl.b32 	%r20, %r19, 3;
	add.s32 	%r21, %r31, %r20;
	ld.global.u64 	%rl2, [%r21];
	cvt.rn.f32.s64 	%f3, %rl2;
	mul.ftz.f32 	%f4, %f3, 0f2F800000;
	add.s32 	%r22, %r7, %r6;
	shl.b32 	%r23, %r22, 3;
	add.s32 	%r24, %r31, %r23;
	ld.global.u64 	%rl3, [%r24];
	cvt.rn.f32.s64 	%f5, %rl3;
	mul.ftz.f32 	%f6, %f5, 0f2F800000;
	mov.f32 	%f7, 0f00000000;
	mov.f32 	%f28, %f2;
	mov.f32 	%f29, %f4;
	mov.f32 	%f30, %f6;
	mov.f32 	%f31, %f7;
	setp.lt.s32 	%p2, %r7, %r4;
	@%p2 bra 	BB7_3;
	bra.uni 	BB7_5;

BB7_3:
	mov.u32 	%r39, %r7;

BB7_4:
	mov.u32 	%r8, %r39;
	shl.b32 	%r25, %r8, 4;
	ld.param.u32 	%r33, [reduceForces_param_1];
	add.s32 	%r26, %r33, %r25;
	ld.global.v4.f32 	{%f24, %f25, %f26, %f27}, [%r26];
	add.ftz.f32 	%f28, %f28, %f24;
	add.ftz.f32 	%f29, %f29, %f25;
	add.ftz.f32 	%f30, %f30, %f26;
	add.ftz.f32 	%f31, %f31, %f27;
	ld.param.u32 	%r35, [reduceForces_param_2];
	add.s32 	%r9, %r8, %r35;
	setp.lt.s32 	%p3, %r9, %r4;
	mov.u32 	%r39, %r9;
	@%p3 bra 	BB7_4;

BB7_5:
	shl.b32 	%r29, %r7, 4;
	ld.param.u32 	%r32, [reduceForces_param_1];
	add.s32 	%r30, %r32, %r29;
	st.global.v4.f32 	[%r30], {%f28, %f29, %f30, %f31};
	// inline asm
	mov.u32 	%r27, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r28, %ntid.x;
	// inline asm
	mad.lo.s32 	%r10, %r28, %r27, %r7;
	ld.param.u32 	%r34, [reduceForces_param_2];
	setp.lt.s32 	%p4, %r10, %r34;
	mov.u32 	%r40, %r10;
	@%p4 bra 	BB7_2;

BB7_6:
	ret;
}

.entry determineNativeAclwracy(
	.param .u32 .ptr .global .align 32 determineNativeAclwracy_param_0,
	.param .u32 determineNativeAclwracy_param_1
)
{
	.reg .f32 	%f<24>;
	.reg .pred 	%p<3>;
	.reg .s32 	%r<18>;


	ld.param.u32 	%r2, [determineNativeAclwracy_param_1];
	// inline asm
	mov.u32 	%r6, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r7, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r8, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r9, %tid.x;
	// inline asm
	add.s32 	%r10, %r9, %r6;
	mad.lo.s32 	%r17, %r8, %r7, %r10;
	setp.ge.s32 	%p1, %r17, %r2;
	@%p1 bra 	BB8_2;

BB8_1:
	shl.b32 	%r13, %r17, 5;
	ld.param.u32 	%r15, [determineNativeAclwracy_param_0];
	add.s32 	%r14, %r15, %r13;
	ld.global.v4.f32 	{%f12, %f13, %f14, %f15}, [%r14];
	// inline asm
	sqrt.approx.f32 	%f1, %f12;
	// inline asm
	// inline asm
	rsqrt.approx.f32 	%f3, %f12;
	// inline asm
	// inline asm
	div.approx.f32 	%f5, 1.0, %f12;
	// inline asm
	// inline asm
	mul.f32 	%f7, %f12, 0f3FB8AA3B;ex2.approx.f32 	%f7, %f7;
	// inline asm
	// inline asm
	lg2.approx.f32 	%f9, %f12;mul.f32 	%f9, %f9, 0f3F317218;
	// inline asm
	mov.f32 	%f11, 0f00000000;
	st.global.v4.f32 	[%r14+16], {%f7, %f9, %f11, %f11};
	st.global.v4.f32 	[%r14], {%f12, %f1, %f3, %f5};
	// inline asm
	mov.u32 	%r11, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r12, %ntid.x;
	// inline asm
	mad.lo.s32 	%r17, %r12, %r11, %r17;
	ld.param.u32 	%r16, [determineNativeAclwracy_param_1];
	setp.lt.s32 	%p2, %r17, %r16;
	@%p2 bra 	BB8_1;

BB8_2:
	ret;
}



//
// Generated by LWPU LWVM Compiler
// Compiler built on Thu May 15 11:00:55 2014 (1400169655)
// Driver 
//

//.version 3.0
//.target sm_30, texmode_independent
//.address_size 32


.entry timeShiftVelocities(
	.param .u32 .ptr .global .align 16 timeShiftVelocities_param_0,
	.param .u32 .ptr .global .align 16 timeShiftVelocities_param_1,
	.param .f32 timeShiftVelocities_param_2
)
{
	.reg .f32 	%f<55>;
	.reg .f64 	%fd<2>;
	.reg .pred 	%p<4>;
	.reg .s32 	%r<20>;


	// inline asm
	mov.u32 	%r7, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r8, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r9, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r10, %tid.x;
	// inline asm
	add.s32 	%r11, %r10, %r7;
	mad.lo.s32 	%r19, %r9, %r8, %r11;
	setp.gt.s32 	%p1, %r19, 23557;
	@%p1 bra 	BB0_4;

BB0_1:
	shl.b32 	%r12, %r19, 4;
	ld.param.u32 	%r17, [timeShiftVelocities_param_0];
	add.s32 	%r5, %r17, %r12;
	ld.global.v4.f32 	{%f26, %f27, %f28, %f29}, [%r5];
	cvt.ftz.f64.f32 	%fd1, %f29;
	setp.eq.f64 	%p2, %fd1, 0d0000000000000000;
	@%p2 bra 	BB0_3;

	ld.param.u32 	%r18, [timeShiftVelocities_param_1];
	add.s32 	%r14, %r18, %r12;
	ld.global.v4.f32 	{%f6, %f7, %f8, %f9}, [%r14];
	ld.param.f32 	%f54, [timeShiftVelocities_param_2];
	mul.ftz.f32 	%f10, %f54, %f6;
	mul.ftz.f32 	%f11, %f54, %f7;
	mul.ftz.f32 	%f12, %f54, %f8;
	fma.rn.ftz.f32 	%f38, %f10, %f29, %f26;
	fma.rn.ftz.f32 	%f39, %f11, %f29, %f27;
	fma.rn.ftz.f32 	%f40, %f12, %f29, %f28;
	st.global.v4.f32 	[%r5], {%f38, %f39, %f40, %f29};

BB0_3:
	// inline asm
	mov.u32 	%r15, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r16, %ntid.x;
	// inline asm
	mad.lo.s32 	%r19, %r16, %r15, %r19;
	setp.lt.s32 	%p3, %r19, 23558;
	@%p3 bra 	BB0_1;

BB0_4:
	ret;
}



//
// Generated by LWPU LWVM Compiler
// Compiler built on Thu May 15 11:00:55 2014 (1400169655)
// Driver 
//

//.version 3.0
//.target sm_30, texmode_independent
//.address_size 32


.entry applySettle(
	.param .u32 applySettle_param_0,
	.param .f32 applySettle_param_1,
	.param .u32 .ptr .global .align 16 applySettle_param_2,
	.param .u32 .ptr .global .align 16 applySettle_param_3,
	.param .u32 .ptr .global .align 16 applySettle_param_4,
	.param .u32 .ptr .global .align 16 applySettle_param_5,
	.param .u32 .ptr .global .align 16 applySettle_param_6,
	.param .u32 .ptr .global .align 8 applySettle_param_7
)
{
	.reg .f32 	%f<345>;
	.reg .f64 	%fd<4>;
	.reg .pred 	%p<3>;
	.reg .s32 	%r<47>;


	ld.param.u32 	%r1, [applySettle_param_0];
	// inline asm
	mov.u32 	%r10, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r11, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r12, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r13, %tid.x;
	// inline asm
	add.s32 	%r14, %r13, %r10;
	mad.lo.s32 	%r46, %r12, %r11, %r14;
	setp.ge.s32 	%p1, %r46, %r1;
	@%p1 bra 	BB0_2;

BB0_1:
	shl.b32 	%r17, %r46, 3;
	ld.param.u32 	%r45, [applySettle_param_7];
	add.s32 	%r18, %r45, %r17;
	ld.global.v2.f32 	{%f271, %f272}, [%r18];
	shl.b32 	%r19, %r46, 4;
	ld.param.u32 	%r44, [applySettle_param_6];
	add.s32 	%r20, %r44, %r19;
	ld.global.v4.u32 	{%r36, %r37, %r38, %r39}, [%r20];
	shl.b32 	%r22, %r36, 4;
	ld.param.u32 	%r41, [applySettle_param_2];
	add.s32 	%r23, %r41, %r22;
	ld.param.u32 	%r42, [applySettle_param_4];
	add.s32 	%r24, %r42, %r22;
	shl.b32 	%r26, %r37, 4;
	add.s32 	%r27, %r41, %r26;
	add.s32 	%r28, %r42, %r26;
	shl.b32 	%r30, %r38, 4;
	add.s32 	%r31, %r41, %r30;
	add.s32 	%r32, %r42, %r30;
	ld.param.u32 	%r43, [applySettle_param_5];
	add.s32 	%r33, %r43, %r22;
	ld.global.v4.f32 	{%f273, %f274, %f275, %f276}, [%r33];
	rcp.approx.ftz.f32 	%f20, %f276;
	mov.f32 	%f21, 0f3F800000;
	add.s32 	%r34, %r43, %r26;
	ld.global.v4.f32 	{%f277, %f278, %f279, %f280}, [%r34];
	rcp.approx.ftz.f32 	%f23, %f280;
	add.s32 	%r35, %r43, %r30;
	ld.global.v4.f32 	{%f281, %f282, %f283, %f284}, [%r35];
	rcp.approx.ftz.f32 	%f25, %f284;
	ld.global.v4.f32 	{%f285, %f286, %f287, %f288}, [%r27];
	ld.global.v4.f32 	{%f289, %f290, %f291, %f292}, [%r23];
	sub.ftz.f32 	%f28, %f285, %f289;
	sub.ftz.f32 	%f31, %f286, %f290;
	sub.ftz.f32 	%f34, %f287, %f291;
	ld.global.v4.f32 	{%f293, %f294, %f295, %f296}, [%r31];
	sub.ftz.f32 	%f36, %f293, %f289;
	sub.ftz.f32 	%f38, %f294, %f290;
	sub.ftz.f32 	%f40, %f295, %f291;
	add.ftz.f32 	%f41, %f20, %f23;
	add.ftz.f32 	%f42, %f41, %f25;
	rcp.approx.ftz.f32 	%f43, %f42;
	ld.global.v4.f32 	{%f297, %f298, %f299, %f300}, [%r24];
	ld.global.v4.f32 	{%f301, %f302, %f303, %f304}, [%r28];
	add.ftz.f32 	%f46, %f28, %f301;
	mul.ftz.f32 	%f47, %f46, %f23;
	fma.rn.ftz.f32 	%f48, %f297, %f20, %f47;
	ld.global.v4.f32 	{%f305, %f306, %f307, %f308}, [%r32];
	add.ftz.f32 	%f50, %f36, %f305;
	fma.rn.ftz.f32 	%f51, %f50, %f25, %f48;
	add.ftz.f32 	%f54, %f31, %f302;
	mul.ftz.f32 	%f55, %f54, %f23;
	fma.rn.ftz.f32 	%f56, %f298, %f20, %f55;
	add.ftz.f32 	%f58, %f38, %f306;
	fma.rn.ftz.f32 	%f59, %f58, %f25, %f56;
	add.ftz.f32 	%f62, %f34, %f303;
	mul.ftz.f32 	%f63, %f62, %f23;
	fma.rn.ftz.f32 	%f64, %f299, %f20, %f63;
	add.ftz.f32 	%f66, %f40, %f307;
	fma.rn.ftz.f32 	%f67, %f66, %f25, %f64;
	neg.f32 	%f68, %f51;
	fma.rn.ftz.f32 	%f69, %f68, %f43, %f297;
	neg.f32 	%f70, %f59;
	fma.rn.ftz.f32 	%f71, %f70, %f43, %f298;
	neg.f32 	%f72, %f67;
	fma.rn.ftz.f32 	%f73, %f72, %f43, %f299;
	fma.rn.ftz.f32 	%f74, %f68, %f43, %f46;
	fma.rn.ftz.f32 	%f75, %f70, %f43, %f54;
	fma.rn.ftz.f32 	%f76, %f72, %f43, %f62;
	fma.rn.ftz.f32 	%f77, %f68, %f43, %f50;
	fma.rn.ftz.f32 	%f78, %f70, %f43, %f58;
	fma.rn.ftz.f32 	%f79, %f72, %f43, %f66;
	mul.ftz.f32 	%f80, %f31, %f40;
	neg.f32 	%f81, %f34;
	fma.rn.ftz.f32 	%f82, %f81, %f38, %f80;
	mul.ftz.f32 	%f83, %f34, %f36;
	neg.f32 	%f84, %f28;
	fma.rn.ftz.f32 	%f85, %f84, %f40, %f83;
	mul.ftz.f32 	%f86, %f28, %f38;
	neg.f32 	%f87, %f31;
	fma.rn.ftz.f32 	%f88, %f87, %f36, %f86;
	mul.ftz.f32 	%f89, %f71, %f88;
	neg.f32 	%f90, %f73;
	fma.rn.ftz.f32 	%f91, %f90, %f85, %f89;
	mul.ftz.f32 	%f92, %f73, %f82;
	neg.f32 	%f93, %f69;
	fma.rn.ftz.f32 	%f94, %f93, %f88, %f92;
	mul.ftz.f32 	%f95, %f69, %f85;
	neg.f32 	%f96, %f71;
	fma.rn.ftz.f32 	%f97, %f96, %f82, %f95;
	mul.ftz.f32 	%f98, %f85, %f97;
	neg.f32 	%f99, %f88;
	fma.rn.ftz.f32 	%f100, %f99, %f94, %f98;
	mul.ftz.f32 	%f101, %f88, %f91;
	neg.f32 	%f102, %f82;
	fma.rn.ftz.f32 	%f103, %f102, %f97, %f101;
	mul.ftz.f32 	%f104, %f82, %f94;
	neg.f32 	%f105, %f85;
	fma.rn.ftz.f32 	%f106, %f105, %f91, %f104;
	mul.ftz.f32 	%f107, %f94, %f94;
	fma.rn.ftz.f32 	%f108, %f91, %f91, %f107;
	fma.rn.ftz.f32 	%f2, %f97, %f97, %f108;
	// inline asm
	sqrt.approx.f32 	%f1, %f2;
	// inline asm
	mul.ftz.f32 	%f109, %f103, %f103;
	fma.rn.ftz.f32 	%f110, %f100, %f100, %f109;
	fma.rn.ftz.f32 	%f4, %f106, %f106, %f110;
	// inline asm
	sqrt.approx.f32 	%f3, %f4;
	// inline asm
	mul.ftz.f32 	%f111, %f85, %f85;
	fma.rn.ftz.f32 	%f112, %f82, %f82, %f111;
	fma.rn.ftz.f32 	%f6, %f88, %f88, %f112;
	// inline asm
	sqrt.approx.f32 	%f5, %f6;
	// inline asm
	div.approx.ftz.f32 	%f113, %f91, %f1;
	div.approx.ftz.f32 	%f114, %f94, %f1;
	div.approx.ftz.f32 	%f115, %f97, %f1;
	div.approx.ftz.f32 	%f116, %f100, %f3;
	div.approx.ftz.f32 	%f117, %f103, %f3;
	div.approx.ftz.f32 	%f118, %f106, %f3;
	div.approx.ftz.f32 	%f119, %f82, %f5;
	div.approx.ftz.f32 	%f120, %f85, %f5;
	div.approx.ftz.f32 	%f121, %f88, %f5;
	mul.ftz.f32 	%f122, %f114, %f31;
	fma.rn.ftz.f32 	%f123, %f113, %f28, %f122;
	fma.rn.ftz.f32 	%f124, %f115, %f34, %f123;
	mul.ftz.f32 	%f125, %f117, %f31;
	fma.rn.ftz.f32 	%f126, %f116, %f28, %f125;
	fma.rn.ftz.f32 	%f127, %f118, %f34, %f126;
	mul.ftz.f32 	%f128, %f114, %f38;
	fma.rn.ftz.f32 	%f129, %f113, %f36, %f128;
	fma.rn.ftz.f32 	%f130, %f115, %f40, %f129;
	mul.ftz.f32 	%f131, %f117, %f38;
	fma.rn.ftz.f32 	%f132, %f116, %f36, %f131;
	fma.rn.ftz.f32 	%f133, %f118, %f40, %f132;
	mul.ftz.f32 	%f134, %f120, %f71;
	fma.rn.ftz.f32 	%f135, %f119, %f69, %f134;
	fma.rn.ftz.f32 	%f136, %f121, %f73, %f135;
	mul.ftz.f32 	%f137, %f114, %f75;
	fma.rn.ftz.f32 	%f138, %f113, %f74, %f137;
	fma.rn.ftz.f32 	%f139, %f115, %f76, %f138;
	mul.ftz.f32 	%f140, %f117, %f75;
	fma.rn.ftz.f32 	%f141, %f116, %f74, %f140;
	fma.rn.ftz.f32 	%f142, %f118, %f76, %f141;
	mul.ftz.f32 	%f143, %f120, %f75;
	fma.rn.ftz.f32 	%f144, %f119, %f74, %f143;
	fma.rn.ftz.f32 	%f145, %f121, %f76, %f144;
	mul.ftz.f32 	%f146, %f114, %f78;
	fma.rn.ftz.f32 	%f147, %f113, %f77, %f146;
	fma.rn.ftz.f32 	%f148, %f115, %f79, %f147;
	mul.ftz.f32 	%f149, %f117, %f78;
	fma.rn.ftz.f32 	%f150, %f116, %f77, %f149;
	fma.rn.ftz.f32 	%f151, %f118, %f79, %f150;
	mul.ftz.f32 	%f152, %f120, %f78;
	fma.rn.ftz.f32 	%f153, %f119, %f77, %f152;
	fma.rn.ftz.f32 	%f154, %f121, %f79, %f153;
	mul.ftz.f32 	%f156, %f272, 0f3F000000;
	mul.ftz.f32 	%f158, %f271, %f271;
	neg.f32 	%f159, %f156;
	fma.rn.ftz.f32 	%f8, %f159, %f156, %f158;
	// inline asm
	sqrt.approx.f32 	%f7, %f8;
	// inline asm
	add.ftz.f32 	%f160, %f23, %f25;
	mul.ftz.f32 	%f161, %f7, %f160;
	mul.ftz.f32 	%f162, %f161, %f43;
	neg.f32 	%f163, %f161;
	fma.rn.ftz.f32 	%f164, %f163, %f43, %f7;
	div.approx.ftz.f32 	%f165, %f136, %f162;
	neg.f32 	%f166, %f165;
	fma.rn.ftz.f32 	%f10, %f166, %f165, %f21;
	// inline asm
	sqrt.approx.f32 	%f9, %f10;
	// inline asm
	sub.ftz.f32 	%f167, %f145, %f154;
	fma.rn.ftz.f32 	%f168, %f272, 0f3F000000, %f156;
	mul.ftz.f32 	%f169, %f168, %f9;
	div.approx.ftz.f32 	%f170, %f167, %f169;
	neg.f32 	%f171, %f170;
	fma.rn.ftz.f32 	%f12, %f171, %f170, %f21;
	// inline asm
	sqrt.approx.f32 	%f11, %f12;
	// inline asm
	mul.ftz.f32 	%f172, %f162, %f9;
	neg.ftz.f32 	%f173, %f156;
	mul.ftz.f32 	%f174, %f11, %f173;
	neg.ftz.f32 	%f175, %f164;
	mul.ftz.f32 	%f176, %f9, %f175;
	mul.ftz.f32 	%f177, %f156, %f170;
	mul.ftz.f32 	%f178, %f177, %f165;
	neg.f32 	%f179, %f177;
	fma.rn.ftz.f32 	%f180, %f179, %f165, %f176;
	fma.rn.ftz.f32 	%f181, %f9, %f175, %f178;
	mul.ftz.f32 	%f182, %f174, %f174;
	mov.f32 	%f183, 0f40800000;
	sub.ftz.f32 	%f184, %f180, %f181;
	mul.ftz.f32 	%f185, %f184, %f184;
	fma.rn.ftz.f32 	%f186, %f182, 0f40800000, %f185;
	fma.rn.ftz.f32 	%f187, %f167, %f167, %f186;
	fma.rn.ftz.f32 	%f188, %f11, %f173, %f174;
	neg.f32 	%f189, %f187;
	fma.rn.ftz.f32 	%f190, %f182, %f183, %f189;
	fma.rn.ftz.f32 	%f14, %f272, %f272, %f190;
	// inline asm
	sqrt.approx.f32 	%f13, %f14;
	// inline asm
	add.ftz.f32 	%f191, %f188, %f13;
	cvt.ftz.f64.f32 	%fd1, %f191;
	cvt.ftz.f64.f32 	%fd2, %f174;
	fma.rn.f64 	%fd3, %fd1, 0dBFE0000000000000, %fd2;
	cvt.rn.ftz.f32.f64 	%f192, %fd3;
	sub.ftz.f32 	%f193, %f124, %f130;
	mul.ftz.f32 	%f194, %f127, %f180;
	fma.rn.ftz.f32 	%f195, %f192, %f193, %f194;
	fma.rn.ftz.f32 	%f196, %f133, %f181, %f195;
	sub.ftz.f32 	%f197, %f133, %f127;
	mul.ftz.f32 	%f198, %f124, %f180;
	fma.rn.ftz.f32 	%f199, %f192, %f197, %f198;
	fma.rn.ftz.f32 	%f200, %f130, %f181, %f199;
	mul.ftz.f32 	%f201, %f124, %f142;
	neg.f32 	%f202, %f139;
	fma.rn.ftz.f32 	%f203, %f202, %f127, %f201;
	fma.rn.ftz.f32 	%f204, %f130, %f151, %f203;
	neg.f32 	%f205, %f148;
	fma.rn.ftz.f32 	%f206, %f205, %f133, %f204;
	mul.ftz.f32 	%f207, %f200, %f200;
	fma.rn.ftz.f32 	%f208, %f196, %f196, %f207;
	mul.ftz.f32 	%f209, %f196, %f206;
	neg.f32 	%f210, %f206;
	fma.rn.ftz.f32 	%f16, %f210, %f206, %f208;
	// inline asm
	sqrt.approx.f32 	%f15, %f16;
	// inline asm
	neg.f32 	%f211, %f200;
	fma.rn.ftz.f32 	%f212, %f211, %f15, %f209;
	div.approx.ftz.f32 	%f213, %f212, %f208;
	neg.f32 	%f214, %f213;
	fma.rn.ftz.f32 	%f18, %f214, %f213, %f21;
	// inline asm
	sqrt.approx.f32 	%f17, %f18;
	// inline asm
	neg.ftz.f32 	%f215, %f172;
	mul.ftz.f32 	%f216, %f213, %f215;
	mul.ftz.f32 	%f217, %f172, %f17;
	mul.ftz.f32 	%f218, %f192, %f17;
	neg.f32 	%f219, %f180;
	fma.rn.ftz.f32 	%f220, %f219, %f213, %f218;
	mul.ftz.f32 	%f221, %f180, %f17;
	fma.rn.ftz.f32 	%f222, %f213, %f192, %f221;
	neg.ftz.f32 	%f223, %f192;
	mul.ftz.f32 	%f224, %f17, %f223;
	neg.f32 	%f225, %f181;
	fma.rn.ftz.f32 	%f226, %f225, %f213, %f224;
	mul.ftz.f32 	%f227, %f181, %f17;
	fma.rn.ftz.f32 	%f228, %f214, %f192, %f227;
	mul.ftz.f32 	%f229, %f116, %f217;
	fma.rn.ftz.f32 	%f230, %f113, %f216, %f229;
	fma.rn.ftz.f32 	%f231, %f119, %f136, %f230;
	mul.ftz.f32 	%f232, %f117, %f217;
	fma.rn.ftz.f32 	%f233, %f114, %f216, %f232;
	fma.rn.ftz.f32 	%f234, %f120, %f136, %f233;
	mul.ftz.f32 	%f235, %f118, %f217;
	fma.rn.ftz.f32 	%f236, %f115, %f216, %f235;
	fma.rn.ftz.f32 	%f237, %f121, %f136, %f236;
	mul.ftz.f32 	%f238, %f116, %f222;
	fma.rn.ftz.f32 	%f239, %f113, %f220, %f238;
	fma.rn.ftz.f32 	%f240, %f119, %f145, %f239;
	mul.ftz.f32 	%f241, %f117, %f222;
	fma.rn.ftz.f32 	%f242, %f114, %f220, %f241;
	fma.rn.ftz.f32 	%f243, %f120, %f145, %f242;
	mul.ftz.f32 	%f244, %f118, %f222;
	fma.rn.ftz.f32 	%f245, %f115, %f220, %f244;
	fma.rn.ftz.f32 	%f246, %f121, %f145, %f245;
	mul.ftz.f32 	%f247, %f116, %f228;
	fma.rn.ftz.f32 	%f248, %f113, %f226, %f247;
	fma.rn.ftz.f32 	%f249, %f119, %f154, %f248;
	mul.ftz.f32 	%f250, %f117, %f228;
	fma.rn.ftz.f32 	%f251, %f114, %f226, %f250;
	fma.rn.ftz.f32 	%f252, %f120, %f154, %f251;
	mul.ftz.f32 	%f253, %f118, %f228;
	fma.rn.ftz.f32 	%f254, %f115, %f226, %f253;
	fma.rn.ftz.f32 	%f255, %f121, %f154, %f254;
	fma.rn.ftz.f32 	%f256, %f51, %f43, %f231;
	fma.rn.ftz.f32 	%f257, %f59, %f43, %f234;
	fma.rn.ftz.f32 	%f258, %f67, %f43, %f237;
	fma.rn.ftz.f32 	%f259, %f51, %f43, %f240;
	sub.ftz.f32 	%f260, %f259, %f28;
	fma.rn.ftz.f32 	%f261, %f59, %f43, %f243;
	sub.ftz.f32 	%f262, %f261, %f31;
	fma.rn.ftz.f32 	%f263, %f67, %f43, %f246;
	sub.ftz.f32 	%f264, %f263, %f34;
	fma.rn.ftz.f32 	%f265, %f51, %f43, %f249;
	sub.ftz.f32 	%f266, %f265, %f36;
	fma.rn.ftz.f32 	%f267, %f59, %f43, %f252;
	sub.ftz.f32 	%f268, %f267, %f38;
	fma.rn.ftz.f32 	%f269, %f67, %f43, %f255;
	sub.ftz.f32 	%f270, %f269, %f40;
	st.global.v4.f32 	[%r24], {%f256, %f257, %f258, %f300};
	st.global.v4.f32 	[%r28], {%f260, %f262, %f264, %f304};
	st.global.v4.f32 	[%r32], {%f266, %f268, %f270, %f308};
	// inline asm
	mov.u32 	%r15, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r16, %ntid.x;
	// inline asm
	mad.lo.s32 	%r46, %r16, %r15, %r46;
	ld.param.u32 	%r40, [applySettle_param_0];
	setp.lt.s32 	%p2, %r46, %r40;
	@%p2 bra 	BB0_1;

BB0_2:
	ret;
}

.entry constrailwelocities(
	.param .u32 constrailwelocities_param_0,
	.param .f32 constrailwelocities_param_1,
	.param .u32 .ptr .global .align 16 constrailwelocities_param_2,
	.param .u32 .ptr .global .align 16 constrailwelocities_param_3,
	.param .u32 .ptr .global .align 16 constrailwelocities_param_4,
	.param .u32 .ptr .global .align 16 constrailwelocities_param_5,
	.param .u32 .ptr .global .align 16 constrailwelocities_param_6,
	.param .u32 .ptr .global .align 8 constrailwelocities_param_7
)
{
	.reg .f32 	%f<400>;
	.reg .pred 	%p<3>;
	.reg .s32 	%r<38>;


	ld.param.u32 	%r1, [constrailwelocities_param_0];
	// inline asm
	mov.u32 	%r8, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r9, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r10, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r11, %tid.x;
	// inline asm
	add.s32 	%r12, %r11, %r8;
	mad.lo.s32 	%r37, %r10, %r9, %r12;
	setp.ge.s32 	%p1, %r37, %r1;
	@%p1 bra 	BB1_2;

BB1_1:
	shl.b32 	%r15, %r37, 4;
	ld.param.u32 	%r36, [constrailwelocities_param_6];
	add.s32 	%r16, %r36, %r15;
	ld.global.v4.u32 	{%r29, %r30, %r31, %r32}, [%r16];
	shl.b32 	%r18, %r29, 4;
	ld.param.u32 	%r34, [constrailwelocities_param_2];
	add.s32 	%r19, %r34, %r18;
	shl.b32 	%r21, %r30, 4;
	add.s32 	%r22, %r34, %r21;
	shl.b32 	%r24, %r31, 4;
	add.s32 	%r25, %r34, %r24;
	ld.param.u32 	%r35, [constrailwelocities_param_5];
	add.s32 	%r26, %r35, %r18;
	add.s32 	%r27, %r35, %r21;
	add.s32 	%r28, %r35, %r24;
	ld.global.v4.f32 	{%f160, %f161, %f162, %f163}, [%r26];
	rcp.approx.ftz.f32 	%f8, %f163;
	mov.f32 	%f9, 0f3F800000;
	ld.global.v4.f32 	{%f164, %f165, %f166, %f167}, [%r27];
	rcp.approx.ftz.f32 	%f11, %f167;
	ld.global.v4.f32 	{%f168, %f169, %f170, %f171}, [%r28];
	rcp.approx.ftz.f32 	%f13, %f171;
	ld.global.v4.f32 	{%f172, %f173, %f174, %f175}, [%r22];
	ld.global.v4.f32 	{%f176, %f177, %f178, %f179}, [%r19];
	sub.ftz.f32 	%f180, %f172, %f176;
	sub.ftz.f32 	%f181, %f173, %f177;
	sub.ftz.f32 	%f182, %f174, %f178;
	ld.global.v4.f32 	{%f184, %f185, %f186, %f187}, [%r25];
	sub.ftz.f32 	%f188, %f184, %f172;
	sub.ftz.f32 	%f189, %f185, %f173;
	sub.ftz.f32 	%f190, %f186, %f174;
	sub.ftz.f32 	%f192, %f176, %f184;
	sub.ftz.f32 	%f193, %f177, %f185;
	sub.ftz.f32 	%f194, %f178, %f186;
	mul.ftz.f32 	%f16, %f181, %f181;
	fma.rn.ftz.f32 	%f17, %f180, %f180, %f16;
	fma.rn.ftz.f32 	%f2, %f182, %f182, %f17;
	// inline asm
	sqrt.approx.f32 	%f1, %f2;
	// inline asm
	div.approx.ftz.f32 	%f208, %f180, %f1;
	div.approx.ftz.f32 	%f209, %f181, %f1;
	div.approx.ftz.f32 	%f210, %f182, %f1;
	mul.ftz.f32 	%f24, %f189, %f189;
	fma.rn.ftz.f32 	%f25, %f188, %f188, %f24;
	fma.rn.ftz.f32 	%f4, %f190, %f190, %f25;
	// inline asm
	sqrt.approx.f32 	%f3, %f4;
	// inline asm
	div.approx.ftz.f32 	%f228, %f188, %f3;
	div.approx.ftz.f32 	%f229, %f189, %f3;
	div.approx.ftz.f32 	%f230, %f190, %f3;
	mul.ftz.f32 	%f32, %f193, %f193;
	fma.rn.ftz.f32 	%f33, %f192, %f192, %f32;
	fma.rn.ftz.f32 	%f6, %f194, %f194, %f33;
	// inline asm
	sqrt.approx.f32 	%f5, %f6;
	// inline asm
	div.approx.ftz.f32 	%f248, %f192, %f5;
	div.approx.ftz.f32 	%f249, %f193, %f5;
	div.approx.ftz.f32 	%f250, %f194, %f5;
	sub.ftz.f32 	%f40, %f164, %f160;
	sub.ftz.f32 	%f44, %f165, %f161;
	mul.ftz.f32 	%f46, %f44, %f209;
	fma.rn.ftz.f32 	%f47, %f40, %f208, %f46;
	sub.ftz.f32 	%f50, %f166, %f162;
	fma.rn.ftz.f32 	%f52, %f50, %f210, %f47;
	sub.ftz.f32 	%f54, %f168, %f164;
	sub.ftz.f32 	%f57, %f169, %f165;
	mul.ftz.f32 	%f59, %f57, %f229;
	fma.rn.ftz.f32 	%f60, %f54, %f228, %f59;
	sub.ftz.f32 	%f62, %f170, %f166;
	fma.rn.ftz.f32 	%f64, %f62, %f230, %f60;
	sub.ftz.f32 	%f65, %f160, %f168;
	sub.ftz.f32 	%f67, %f161, %f169;
	mul.ftz.f32 	%f69, %f67, %f249;
	fma.rn.ftz.f32 	%f70, %f65, %f248, %f69;
	sub.ftz.f32 	%f71, %f162, %f170;
	fma.rn.ftz.f32 	%f73, %f71, %f250, %f70;
	mul.ftz.f32 	%f74, %f209, %f249;
	fma.rn.ftz.f32 	%f75, %f208, %f248, %f74;
	fma.rn.ftz.f32 	%f76, %f210, %f250, %f75;
	mul.ftz.f32 	%f77, %f209, %f229;
	fma.rn.ftz.f32 	%f78, %f208, %f228, %f77;
	fma.rn.ftz.f32 	%f79, %f210, %f230, %f78;
	neg.ftz.f32 	%f80, %f79;
	mul.ftz.f32 	%f81, %f229, %f249;
	fma.rn.ftz.f32 	%f82, %f228, %f248, %f81;
	fma.rn.ftz.f32 	%f83, %f230, %f250, %f82;
	neg.f32 	%f84, %f76;
	fma.rn.ftz.f32 	%f85, %f84, %f76, %f9;
	neg.f32 	%f86, %f79;
	fma.rn.ftz.f32 	%f87, %f86, %f79, %f9;
	neg.f32 	%f88, %f83;
	fma.rn.ftz.f32 	%f89, %f88, %f83, %f9;
	mul.ftz.f32 	%f90, %f8, %f11;
	mul.ftz.f32 	%f91, %f90, %f13;
	rcp.approx.ftz.f32 	%f92, %f91;
	mul.ftz.f32 	%f93, %f85, %f11;
	mul.ftz.f32 	%f94, %f87, %f8;
	fma.rn.ftz.f32 	%f95, %f85, %f11, %f94;
	mul.ftz.f32 	%f96, %f93, %f11;
	mul.ftz.f32 	%f97, %f76, %f79;
	neg.f32 	%f98, %f97;
	fma.rn.ftz.f32 	%f99, %f98, %f83, %f9;
	add.ftz.f32 	%f100, %f99, %f99;
	mul.ftz.f32 	%f101, %f100, %f8;
	mul.ftz.f32 	%f102, %f101, %f11;
	fma.rn.ftz.f32 	%f103, %f93, %f11, %f102;
	mul.ftz.f32 	%f104, %f94, %f8;
	fma.rn.ftz.f32 	%f105, %f94, %f8, %f103;
	fma.rn.ftz.f32 	%f106, %f95, %f13, %f105;
	mul.ftz.f32 	%f107, %f89, %f8;
	mul.ftz.f32 	%f108, %f107, %f11;
	add.ftz.f32 	%f109, %f8, %f11;
	mul.ftz.f32 	%f110, %f108, %f109;
	fma.rn.ftz.f32 	%f111, %f106, %f13, %f110;
	mul.ftz.f32 	%f112, %f111, %f92;
	mul.ftz.f32 	%f113, %f79, %f83;
	mul.ftz.f32 	%f114, %f11, %f76;
	fma.rn.ftz.f32 	%f115, %f113, %f8, %f114;
	fma.rn.ftz.f32 	%f116, %f13, %f76, %f115;
	mul.ftz.f32 	%f117, %f76, %f83;
	mul.ftz.f32 	%f118, %f117, %f11;
	neg.f32 	%f119, %f13;
	fma.rn.ftz.f32 	%f120, %f119, %f80, %f118;
	neg.f32 	%f121, %f8;
	fma.rn.ftz.f32 	%f122, %f121, %f80, %f120;
	mul.ftz.f32 	%f123, %f122, %f64;
	fma.rn.ftz.f32 	%f124, %f116, %f73, %f123;
	mul.ftz.f32 	%f125, %f107, %f8;
	mul.ftz.f32 	%f126, %f125, %f11;
	mul.ftz.f32 	%f127, %f126, %f11;
	add.ftz.f32 	%f128, %f109, %f13;
	fma.rn.ftz.f32 	%f129, %f127, %f92, %f128;
	fma.rn.ftz.f32 	%f130, %f129, %f52, %f124;
	div.approx.ftz.f32 	%f131, %f130, %f112;
	mul.ftz.f32 	%f132, %f11, %f83;
	fma.rn.ftz.f32 	%f133, %f97, %f13, %f132;
	fma.rn.ftz.f32 	%f134, %f8, %f83, %f133;
	mul.ftz.f32 	%f135, %f96, %f13;
	mul.ftz.f32 	%f136, %f135, %f13;
	fma.rn.ftz.f32 	%f137, %f136, %f92, %f128;
	mul.ftz.f32 	%f138, %f137, %f64;
	fma.rn.ftz.f32 	%f139, %f134, %f73, %f138;
	fma.rn.ftz.f32 	%f140, %f121, %f80, %f118;
	fma.rn.ftz.f32 	%f141, %f119, %f80, %f140;
	fma.rn.ftz.f32 	%f142, %f141, %f52, %f139;
	div.approx.ftz.f32 	%f143, %f142, %f112;
	mul.ftz.f32 	%f144, %f104, %f13;
	mul.ftz.f32 	%f145, %f144, %f13;
	fma.rn.ftz.f32 	%f146, %f145, %f92, %f128;
	mul.ftz.f32 	%f147, %f134, %f64;
	fma.rn.ftz.f32 	%f148, %f146, %f73, %f147;
	fma.rn.ftz.f32 	%f149, %f116, %f52, %f148;
	div.approx.ftz.f32 	%f150, %f149, %f112;
	mul.ftz.f32 	%f268, %f131, %f208;
	mul.ftz.f32 	%f269, %f131, %f209;
	mul.ftz.f32 	%f270, %f131, %f210;
	mul.ftz.f32 	%f284, %f150, %f248;
	mul.ftz.f32 	%f285, %f150, %f249;
	mul.ftz.f32 	%f286, %f150, %f250;
	neg.f32 	%f288, %f150;
	fma.rn.ftz.f32 	%f292, %f288, %f248, %f268;
	fma.rn.ftz.f32 	%f293, %f288, %f249, %f269;
	fma.rn.ftz.f32 	%f294, %f288, %f250, %f270;
	fma.rn.ftz.f32 	%f312, %f292, %f163, %f160;
	fma.rn.ftz.f32 	%f313, %f293, %f163, %f161;
	fma.rn.ftz.f32 	%f314, %f294, %f163, %f162;
	mul.ftz.f32 	%f332, %f143, %f228;
	mul.ftz.f32 	%f333, %f143, %f229;
	mul.ftz.f32 	%f334, %f143, %f230;
	neg.f32 	%f336, %f131;
	fma.rn.ftz.f32 	%f340, %f336, %f208, %f332;
	fma.rn.ftz.f32 	%f341, %f336, %f209, %f333;
	fma.rn.ftz.f32 	%f342, %f336, %f210, %f334;
	fma.rn.ftz.f32 	%f360, %f340, %f167, %f164;
	fma.rn.ftz.f32 	%f361, %f341, %f167, %f165;
	fma.rn.ftz.f32 	%f362, %f342, %f167, %f166;
	neg.f32 	%f368, %f143;
	fma.rn.ftz.f32 	%f372, %f368, %f228, %f284;
	fma.rn.ftz.f32 	%f373, %f368, %f229, %f285;
	fma.rn.ftz.f32 	%f374, %f368, %f230, %f286;
	fma.rn.ftz.f32 	%f392, %f372, %f171, %f168;
	fma.rn.ftz.f32 	%f393, %f373, %f171, %f169;
	fma.rn.ftz.f32 	%f394, %f374, %f171, %f170;
	st.global.v4.f32 	[%r26], {%f312, %f313, %f314, %f163};
	st.global.v4.f32 	[%r27], {%f360, %f361, %f362, %f167};
	st.global.v4.f32 	[%r28], {%f392, %f393, %f394, %f171};
	// inline asm
	mov.u32 	%r13, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r14, %ntid.x;
	// inline asm
	mad.lo.s32 	%r37, %r14, %r13, %r37;
	ld.param.u32 	%r33, [constrailwelocities_param_0];
	setp.lt.s32 	%p2, %r37, %r33;
	@%p2 bra 	BB1_1;

BB1_2:
	ret;
}



//
// Generated by LWPU LWVM Compiler
// Compiler built on Thu May 15 11:00:55 2014 (1400169655)
// Driver 
//

//.version 3.0
//.target sm_30, texmode_independent
//.address_size 32


.entry applyShakeToHydrogens(
	.param .u32 applyShakeToHydrogens_param_0,
	.param .f32 applyShakeToHydrogens_param_1,
	.param .u32 .ptr .global .align 16 applyShakeToHydrogens_param_2,
	.param .u32 .ptr .global .align 16 applyShakeToHydrogens_param_3,
	.param .u32 .ptr .global .align 16 applyShakeToHydrogens_param_4,
	.param .u32 .ptr .global .align 16 applyShakeToHydrogens_param_5,
	.param .u32 .ptr .global .align 16 applyShakeToHydrogens_param_6
)
{
	.reg .f32 	%f<375>;
	.reg .pred 	%p<11>;
	.reg .s32 	%r<62>;


	ld.param.u32 	%r1, [applyShakeToHydrogens_param_0];
	// inline asm
	mov.u32 	%r20, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r21, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r22, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r23, %tid.x;
	// inline asm
	add.s32 	%r24, %r23, %r20;
	mad.lo.s32 	%r59, %r22, %r21, %r24;
	setp.ge.s32 	%p3, %r59, %r1;
	@%p3 bra 	BB0_23;

BB0_1:
	shl.b32 	%r25, %r59, 4;
	ld.param.u32 	%r57, [applyShakeToHydrogens_param_5];
	add.s32 	%r26, %r57, %r25;
	ld.global.v4.u32 	{%r47, %r48, %r49, %r50}, [%r26];
	shl.b32 	%r28, %r47, 4;
	ld.param.u32 	%r54, [applyShakeToHydrogens_param_2];
	add.s32 	%r29, %r54, %r28;
	ld.global.v4.f32 	{%f304, %f305, %f306, %f307}, [%r29];
	ld.param.u32 	%r56, [applyShakeToHydrogens_param_4];
	add.s32 	%r8, %r56, %r28;
	ld.global.v4.f32 	{%f353, %f354, %f355, %f356}, [%r8];
	shl.b32 	%r31, %r48, 4;
	add.s32 	%r32, %r54, %r31;
	ld.global.v4.f32 	{%f308, %f309, %f310, %f311}, [%r32];
	add.s32 	%r9, %r56, %r31;
	ld.global.v4.f32 	{%f365, %f366, %f367, %f368}, [%r9];
	ld.param.u32 	%r58, [applyShakeToHydrogens_param_6];
	add.s32 	%r33, %r58, %r25;
	ld.global.v4.f32 	{%f320, %f321, %f322, %f323}, [%r33];
	setp.eq.s32 	%p1, %r49, -1;
	shl.b32 	%r34, %r49, 4;
	add.s32 	%r11, %r56, %r34;
	@%p1 bra 	BB0_3;

	ld.param.u32 	%r53, [applyShakeToHydrogens_param_2];
	add.s32 	%r36, %r53, %r34;
	ld.global.v4.f32 	{%f372, %f373, %f374, %f339}, [%r36];
	ld.global.v4.f32 	{%f361, %f362, %f363, %f364}, [%r11];
	bra.uni 	BB0_4;

BB0_3:
	mov.f32 	%f26, 0f00000000;
	mov.f32 	%f361, %f26;
	mov.f32 	%f362, %f26;
	mov.f32 	%f363, %f26;
	mov.f32 	%f364, %f26;
	mov.f32 	%f372, %f26;
	mov.f32 	%f373, %f26;
	mov.f32 	%f374, %f26;

BB0_4:
	setp.eq.s32 	%p2, %r50, -1;
	shl.b32 	%r37, %r50, 4;
	ld.param.u32 	%r55, [applyShakeToHydrogens_param_4];
	add.s32 	%r13, %r55, %r37;
	@%p2 bra 	BB0_6;

	ld.param.u32 	%r52, [applyShakeToHydrogens_param_2];
	add.s32 	%r39, %r52, %r37;
	ld.global.v4.f32 	{%f369, %f370, %f371, %f291}, [%r39];
	ld.global.v4.f32 	{%f357, %f358, %f359, %f360}, [%r13];
	bra.uni 	BB0_7;

BB0_6:
	mov.f32 	%f27, 0f00000000;
	mov.f32 	%f357, %f27;
	mov.f32 	%f358, %f27;
	mov.f32 	%f359, %f27;
	mov.f32 	%f360, %f27;
	mov.f32 	%f369, %f27;
	mov.f32 	%f370, %f27;
	mov.f32 	%f371, %f27;

BB0_7:
	sub.ftz.f32 	%f248, %f304, %f308;
	sub.ftz.f32 	%f249, %f305, %f309;
	sub.ftz.f32 	%f250, %f306, %f310;
	mov.u32 	%r60, 0;
	mul.ftz.f32 	%f28, %f249, %f249;
	fma.rn.ftz.f32 	%f29, %f248, %f248, %f28;
	fma.rn.ftz.f32 	%f7, %f250, %f250, %f29;
	sub.ftz.f32 	%f196, %f304, %f372;
	sub.ftz.f32 	%f197, %f305, %f373;
	sub.ftz.f32 	%f198, %f306, %f374;
	mul.ftz.f32 	%f30, %f197, %f197;
	fma.rn.ftz.f32 	%f31, %f196, %f196, %f30;
	fma.rn.ftz.f32 	%f11, %f198, %f198, %f31;
	sub.ftz.f32 	%f136, %f304, %f369;
	sub.ftz.f32 	%f137, %f305, %f370;
	sub.ftz.f32 	%f138, %f306, %f371;
	mul.ftz.f32 	%f32, %f137, %f137;
	fma.rn.ftz.f32 	%f33, %f136, %f136, %f32;
	fma.rn.ftz.f32 	%f15, %f138, %f138, %f33;
	sub.ftz.f32 	%f16, %f322, %f7;
	sub.ftz.f32 	%f17, %f322, %f11;
	sub.ftz.f32 	%f18, %f322, %f15;
	ld.param.f32 	%f352, [applyShakeToHydrogens_param_1];
	mul.ftz.f32 	%f19, %f322, %f352;

BB0_8:
	sub.ftz.f32 	%f280, %f353, %f365;
	sub.ftz.f32 	%f281, %f354, %f366;
	sub.ftz.f32 	%f282, %f355, %f367;
	mul.ftz.f32 	%f38, %f281, %f281;
	fma.rn.ftz.f32 	%f39, %f280, %f280, %f38;
	fma.rn.ftz.f32 	%f41, %f282, %f282, %f39;
	mul.ftz.f32 	%f42, %f249, %f281;
	fma.rn.ftz.f32 	%f43, %f248, %f280, %f42;
	fma.rn.ftz.f32 	%f20, %f250, %f282, %f43;
	fma.rn.ftz.f32 	%f44, %f20, 0fC0000000, %f16;
	sub.ftz.f32 	%f35, %f44, %f41;
	// inline asm
	abs.f32 	%f34, %f35;
	// inline asm
	div.approx.ftz.f32 	%f45, %f34, %f19;
	setp.ltu.ftz.f32 	%p4, %f45, 0f3F800000;
	@%p4 bra 	BB0_10;

	mul.ftz.f32 	%f46, %f35, %f321;
	add.ftz.f32 	%f47, %f20, %f7;
	div.approx.ftz.f32 	%f48, %f46, %f47;
	mov.u32 	%r61, 0;
	mul.ftz.f32 	%f244, %f248, %f48;
	mul.ftz.f32 	%f245, %f249, %f48;
	mul.ftz.f32 	%f246, %f250, %f48;
	fma.rn.ftz.f32 	%f252, %f244, %f320, %f353;
	fma.rn.ftz.f32 	%f253, %f245, %f320, %f354;
	fma.rn.ftz.f32 	%f254, %f246, %f320, %f355;
	mov.f32 	%f353, %f252;
	mov.f32 	%f354, %f253;
	mov.f32 	%f355, %f254;
	mov.f32 	%f356, %f356;
	neg.f32 	%f256, %f244;
	neg.f32 	%f257, %f245;
	neg.f32 	%f258, %f246;
	fma.rn.ftz.f32 	%f260, %f256, %f323, %f365;
	fma.rn.ftz.f32 	%f261, %f257, %f323, %f366;
	fma.rn.ftz.f32 	%f262, %f258, %f323, %f367;
	mov.f32 	%f365, %f260;
	mov.f32 	%f366, %f261;
	mov.f32 	%f367, %f262;
	mov.f32 	%f368, %f368;
	bra.uni 	BB0_11;

BB0_10:
	mov.u32 	%r61, 1;

BB0_11:
	@%p1 bra 	BB0_14;

	sub.ftz.f32 	%f212, %f353, %f361;
	sub.ftz.f32 	%f213, %f354, %f362;
	sub.ftz.f32 	%f214, %f355, %f363;
	mul.ftz.f32 	%f56, %f213, %f213;
	fma.rn.ftz.f32 	%f57, %f212, %f212, %f56;
	fma.rn.ftz.f32 	%f59, %f214, %f214, %f57;
	mul.ftz.f32 	%f60, %f197, %f213;
	fma.rn.ftz.f32 	%f61, %f196, %f212, %f60;
	fma.rn.ftz.f32 	%f22, %f198, %f214, %f61;
	fma.rn.ftz.f32 	%f62, %f22, 0fC0000000, %f17;
	sub.ftz.f32 	%f53, %f62, %f59;
	// inline asm
	abs.f32 	%f52, %f53;
	// inline asm
	div.approx.ftz.f32 	%f63, %f52, %f19;
	setp.ltu.ftz.f32 	%p5, %f63, 0f3F800000;
	@%p5 bra 	BB0_14;

	mul.ftz.f32 	%f64, %f53, %f321;
	add.ftz.f32 	%f65, %f22, %f11;
	div.approx.ftz.f32 	%f66, %f64, %f65;
	mov.u32 	%r61, 0;
	mul.ftz.f32 	%f192, %f196, %f66;
	mul.ftz.f32 	%f193, %f197, %f66;
	mul.ftz.f32 	%f194, %f198, %f66;
	fma.rn.ftz.f32 	%f200, %f192, %f320, %f353;
	fma.rn.ftz.f32 	%f201, %f193, %f320, %f354;
	fma.rn.ftz.f32 	%f202, %f194, %f320, %f355;
	mov.f32 	%f353, %f200;
	mov.f32 	%f354, %f201;
	mov.f32 	%f355, %f202;
	mov.f32 	%f356, %f356;
	neg.f32 	%f204, %f192;
	neg.f32 	%f205, %f193;
	neg.f32 	%f206, %f194;
	fma.rn.ftz.f32 	%f208, %f204, %f323, %f361;
	fma.rn.ftz.f32 	%f209, %f205, %f323, %f362;
	fma.rn.ftz.f32 	%f210, %f206, %f323, %f363;
	mov.f32 	%f361, %f208;
	mov.f32 	%f362, %f209;
	mov.f32 	%f363, %f210;
	mov.f32 	%f364, %f364;

BB0_14:
	@%p2 bra 	BB0_17;

	sub.ftz.f32 	%f160, %f353, %f357;
	sub.ftz.f32 	%f161, %f354, %f358;
	sub.ftz.f32 	%f162, %f355, %f359;
	mul.ftz.f32 	%f74, %f161, %f161;
	fma.rn.ftz.f32 	%f75, %f160, %f160, %f74;
	fma.rn.ftz.f32 	%f77, %f162, %f162, %f75;
	mul.ftz.f32 	%f78, %f137, %f161;
	fma.rn.ftz.f32 	%f79, %f136, %f160, %f78;
	fma.rn.ftz.f32 	%f24, %f138, %f162, %f79;
	fma.rn.ftz.f32 	%f80, %f24, 0fC0000000, %f18;
	sub.ftz.f32 	%f71, %f80, %f77;
	// inline asm
	abs.f32 	%f70, %f71;
	// inline asm
	div.approx.ftz.f32 	%f81, %f70, %f19;
	setp.ltu.ftz.f32 	%p6, %f81, 0f3F800000;
	@%p6 bra 	BB0_17;

	mul.ftz.f32 	%f82, %f71, %f321;
	add.ftz.f32 	%f83, %f24, %f15;
	div.approx.ftz.f32 	%f84, %f82, %f83;
	mov.u32 	%r61, 0;
	mul.ftz.f32 	%f132, %f136, %f84;
	mul.ftz.f32 	%f133, %f137, %f84;
	mul.ftz.f32 	%f134, %f138, %f84;
	fma.rn.ftz.f32 	%f140, %f132, %f320, %f353;
	fma.rn.ftz.f32 	%f141, %f133, %f320, %f354;
	fma.rn.ftz.f32 	%f142, %f134, %f320, %f355;
	mov.f32 	%f353, %f140;
	mov.f32 	%f354, %f141;
	mov.f32 	%f355, %f142;
	mov.f32 	%f356, %f356;
	neg.f32 	%f148, %f132;
	neg.f32 	%f149, %f133;
	neg.f32 	%f150, %f134;
	fma.rn.ftz.f32 	%f152, %f148, %f323, %f357;
	fma.rn.ftz.f32 	%f153, %f149, %f323, %f358;
	fma.rn.ftz.f32 	%f154, %f150, %f323, %f359;
	mov.f32 	%f357, %f152;
	mov.f32 	%f358, %f153;
	mov.f32 	%f359, %f154;
	mov.f32 	%f360, %f360;

BB0_17:
	add.s32 	%r60, %r60, 1;
	setp.lt.s32 	%p7, %r60, 15;
	setp.eq.s32 	%p8, %r61, 0;
	and.pred  	%p9, %p7, %p8;
	@%p9 bra 	BB0_8;

	st.global.v4.f32 	[%r8], {%f353, %f354, %f355, %f356};
	st.global.v4.f32 	[%r9], {%f365, %f366, %f367, %f368};
	@%p1 bra 	BB0_20;

	st.global.v4.f32 	[%r11], {%f361, %f362, %f363, %f364};

BB0_20:
	@%p2 bra 	BB0_22;

	st.global.v4.f32 	[%r13], {%f357, %f358, %f359, %f360};

BB0_22:
	// inline asm
	mov.u32 	%r45, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r46, %ntid.x;
	// inline asm
	mad.lo.s32 	%r59, %r46, %r45, %r59;
	ld.param.u32 	%r51, [applyShakeToHydrogens_param_0];
	setp.lt.s32 	%p10, %r59, %r51;
	@%p10 bra 	BB0_1;

BB0_23:
	ret;
}



//
// Generated by LWPU LWVM Compiler
// Compiler built on Thu May 15 11:00:55 2014 (1400169655)
// Driver 
//

//.version 3.0
//.target sm_30, texmode_independent
//.address_size 32

.visible .shared .align 4 .u32 shr_1_groupColwerged;

.entry computeConstraintDirections(
	.param .u32 .ptr .global .align 8 computeConstraintDirections_param_0,
	.param .u32 .ptr .global .align 16 computeConstraintDirections_param_1,
	.param .u32 .ptr .global .align 16 computeConstraintDirections_param_2,
	.param .u32 .ptr .global .align 16 computeConstraintDirections_param_3,
	.param .u32 .ptr .global .align 4 computeConstraintDirections_param_4
)
{
	.reg .f32 	%f<34>;
	.reg .pred 	%p<4>;
	.reg .s32 	%r<40>;


	// inline asm
	mov.u32 	%r8, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r9, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r10, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r11, %tid.x;
	// inline asm
	add.s32 	%r12, %r11, %r8;
	mad.lo.s32 	%r39, %r10, %r9, %r12;
	setp.gt.s32 	%p1, %r39, 3071;
	@%p1 bra 	BB0_2;

BB0_1:
	shl.b32 	%r15, %r39, 3;
	ld.param.u32 	%r35, [computeConstraintDirections_param_0];
	add.s32 	%r16, %r35, %r15;
	ld.global.v2.u32 	{%r33, %r34}, [%r16];
	shl.b32 	%r18, %r33, 4;
	ld.param.u32 	%r37, [computeConstraintDirections_param_2];
	add.s32 	%r19, %r37, %r18;
	shl.b32 	%r21, %r34, 4;
	add.s32 	%r22, %r37, %r21;
	ld.global.v4.f32 	{%f10, %f11, %f12, %f13}, [%r19];
	ld.global.v4.f32 	{%f14, %f15, %f16, %f17}, [%r22];
	sub.ftz.f32 	%f3, %f10, %f14;
	shl.b32 	%r23, %r39, 4;
	ld.param.u32 	%r36, [computeConstraintDirections_param_1];
	add.s32 	%r24, %r36, %r23;
	ld.global.v4.f32 	{%f18, %f19, %f20, %f21}, [%r24];
	sub.ftz.f32 	%f6, %f11, %f15;
	sub.ftz.f32 	%f9, %f12, %f16;
	st.global.v4.f32 	[%r24], {%f3, %f6, %f9, %f21};
	// inline asm
	mov.u32 	%r13, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r14, %ntid.x;
	// inline asm
	mad.lo.s32 	%r39, %r14, %r13, %r39;
	setp.lt.s32 	%p2, %r39, 3072;
	@%p2 bra 	BB0_1;

BB0_2:
	// inline asm
	mov.u32 	%r25, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r26, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r27, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r29, %r27, %r26, %r25;
	// inline asm
	mov.u32 	%r28, %tid.x;
	// inline asm
	neg.s32 	%r30, %r28;
	setp.eq.s32 	%p3, %r29, %r30;
	@%p3 bra 	BB0_4;

	ret;

BB0_4:
	mov.u32 	%r31, 1;
	ld.param.u32 	%r38, [computeConstraintDirections_param_4];
	st.global.u32 	[%r38], %r31;
	mov.u32 	%r32, 0;
	st.global.u32 	[%r38+4], %r32;
	ret;
}

.entry computeConstraintForce(
	.param .u32 .ptr .global .align 8 computeConstraintForce_param_0,
	.param .u32 .ptr .global .align 16 computeConstraintForce_param_1,
	.param .u32 .ptr .global .align 16 computeConstraintForce_param_2,
	.param .u32 .ptr .global .align 4 computeConstraintForce_param_3,
	.param .u32 .ptr .global .align 4 computeConstraintForce_param_4,
	.param .u32 .ptr .global .align 4 computeConstraintForce_param_5,
	.param .u32 .ptr .global .align 4 computeConstraintForce_param_6,
	.param .f32 computeConstraintForce_param_7,
	.param .u32 computeConstraintForce_param_8
)
{
	.reg .f32 	%f<57>;
	.reg .pred 	%p<10>;
	.reg .s32 	%r<64>;


	ld.param.u32 	%r11, [computeConstraintForce_param_5];
	ld.param.u32 	%r12, [computeConstraintForce_param_8];
	shr.u32 	%r13, %r12, 31;
	add.s32 	%r14, %r12, %r13;
	and.b32  	%r15, %r14, -2;
	sub.s32 	%r16, %r12, %r15;
	mov.u32 	%r17, 1;
	sub.s32 	%r18, %r17, %r16;
	shl.b32 	%r19, %r18, 2;
	add.s32 	%r20, %r11, %r19;
	ldu.global.u32 	%r21, [%r20];
	setp.eq.s32 	%p1, %r21, 0;
	shl.b32 	%r22, %r16, 2;
	add.s32 	%r7, %r11, %r22;
	@%p1 bra 	BB1_3;

	// inline asm
	mov.u32 	%r23, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r24, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r25, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r27, %r25, %r24, %r23;
	// inline asm
	mov.u32 	%r26, %tid.x;
	// inline asm
	neg.s32 	%r28, %r26;
	setp.ne.s32 	%p2, %r27, %r28;
	@%p2 bra 	BB1_14;

	st.global.u32 	[%r7], %r17;
	ld.param.u32 	%r62, [computeConstraintForce_param_6];
	st.global.u32 	[%r62], %r17;
	ret;

BB1_3:
	// inline asm
	mov.u32 	%r30, %tid.x;
	// inline asm
	setp.ne.s32 	%p3, %r30, 0;
	@%p3 bra 	BB1_5;

	st.shared.u32 	[shr_1_groupColwerged], %r17;

BB1_5:
	bar.sync 	0;
	ld.param.f32 	%f55, [computeConstraintForce_param_7];
	add.ftz.f32 	%f10, %f55, %f55;
	mov.f32 	%f11, 0f3F800000;
	sub.ftz.f32 	%f12, %f11, %f10;
	fma.rn.ftz.f32 	%f2, %f55, %f55, %f12;
	add.ftz.f32 	%f13, %f10, 0f3F800000;
	fma.rn.ftz.f32 	%f3, %f55, %f55, %f13;
	// inline asm
	mov.u32 	%r32, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r33, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r34, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r35, %tid.x;
	// inline asm
	add.s32 	%r36, %r35, %r32;
	mad.lo.s32 	%r63, %r34, %r33, %r36;
	setp.gt.s32 	%p4, %r63, 3071;
	@%p4 bra 	BB1_14;

BB1_6:
	shl.b32 	%r37, %r63, 3;
	ld.param.u32 	%r57, [computeConstraintForce_param_0];
	add.s32 	%r38, %r57, %r37;
	ld.global.v2.u32 	{%r55, %r56}, [%r38];
	shl.b32 	%r40, %r55, 4;
	ld.param.u32 	%r59, [computeConstraintForce_param_2];
	add.s32 	%r41, %r59, %r40;
	shl.b32 	%r43, %r56, 4;
	add.s32 	%r44, %r59, %r43;
	ld.global.v4.f32 	{%f35, %f36, %f37, %f38}, [%r44];
	ld.global.v4.f32 	{%f39, %f40, %f41, %f42}, [%r41];
	sub.ftz.f32 	%f43, %f39, %f35;
	sub.ftz.f32 	%f44, %f40, %f36;
	sub.ftz.f32 	%f45, %f41, %f37;
	shl.b32 	%r45, %r63, 4;
	ld.param.u32 	%r58, [computeConstraintForce_param_1];
	add.s32 	%r46, %r58, %r45;
	ld.global.v4.f32 	{%f47, %f48, %f49, %f50}, [%r46];
	add.ftz.f32 	%f51, %f43, %f47;
	add.ftz.f32 	%f52, %f44, %f48;
	add.ftz.f32 	%f53, %f45, %f49;
	mul.ftz.f32 	%f18, %f52, %f48;
	fma.rn.ftz.f32 	%f19, %f51, %f47, %f18;
	fma.rn.ftz.f32 	%f4, %f53, %f49, %f19;
	mul.ftz.f32 	%f22, %f48, %f48;
	fma.rn.ftz.f32 	%f23, %f47, %f47, %f22;
	fma.rn.ftz.f32 	%f24, %f49, %f49, %f23;
	mul.ftz.f32 	%f25, %f52, %f52;
	fma.rn.ftz.f32 	%f26, %f51, %f51, %f25;
	fma.rn.ftz.f32 	%f5, %f53, %f53, %f26;
	mul.ftz.f32 	%f6, %f50, %f50;
	neg.f32 	%f28, %f5;
	fma.rn.ftz.f32 	%f7, %f50, %f50, %f28;
	mul.ftz.f32 	%f29, %f24, 0f358637BD;
	setp.gt.ftz.f32 	%p5, %f4, %f29;
	@%p5 bra 	BB1_8;

	mov.f32 	%f56, 0f00000000;
	bra.uni 	BB1_9;

BB1_8:
	shl.b32 	%r47, %r63, 2;
	ld.param.u32 	%r60, [computeConstraintForce_param_3];
	add.s32 	%r48, %r60, %r47;
	ld.global.f32 	%f31, [%r48];
	mul.ftz.f32 	%f32, %f31, %f7;
	div.approx.ftz.f32 	%f56, %f32, %f4;

BB1_9:
	shl.b32 	%r49, %r63, 2;
	ld.param.u32 	%r61, [computeConstraintForce_param_4];
	add.s32 	%r50, %r61, %r49;
	st.global.f32 	[%r50], %f56;
	ld.shared.u32 	%r51, [shr_1_groupColwerged];
	setp.eq.s32 	%p6, %r51, 0;
	@%p6 bra 	BB1_13;

	mul.ftz.f32 	%f33, %f2, %f6;
	setp.lt.ftz.f32 	%p7, %f5, %f33;
	@%p7 bra 	BB1_12;

	mul.ftz.f32 	%f34, %f3, %f6;
	setp.leu.ftz.f32 	%p8, %f5, %f34;
	@%p8 bra 	BB1_13;

BB1_12:
	mov.u32 	%r52, 0;
	st.shared.u32 	[shr_1_groupColwerged], %r52;
	st.global.u32 	[%r7], %r52;

BB1_13:
	// inline asm
	mov.u32 	%r53, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r54, %ntid.x;
	// inline asm
	mad.lo.s32 	%r63, %r54, %r53, %r63;
	setp.lt.s32 	%p9, %r63, 3072;
	@%p9 bra 	BB1_6;

BB1_14:
	ret;
}

.entry multiplyByConstraintMatrix(
	.param .u32 .ptr .global .align 4 multiplyByConstraintMatrix_param_0,
	.param .u32 .ptr .global .align 4 multiplyByConstraintMatrix_param_1,
	.param .u32 .ptr .global .align 4 multiplyByConstraintMatrix_param_2,
	.param .u32 .ptr .global .align 4 multiplyByConstraintMatrix_param_3,
	.param .u32 .ptr .global .align 4 multiplyByConstraintMatrix_param_4,
	.param .u32 multiplyByConstraintMatrix_param_5
)
{
	.reg .f32 	%f<9>;
	.reg .pred 	%p<6>;
	.reg .s32 	%r<52>;


	ld.param.u32 	%r15, [multiplyByConstraintMatrix_param_4];
	ld.param.u32 	%r16, [multiplyByConstraintMatrix_param_5];
	shr.u32 	%r17, %r16, 31;
	add.s32 	%r18, %r16, %r17;
	and.b32  	%r19, %r18, 1073741822;
	sub.s32 	%r20, %r16, %r19;
	shl.b32 	%r21, %r20, 2;
	add.s32 	%r22, %r15, %r21;
	ldu.global.u32 	%r23, [%r22];
	setp.ne.s32 	%p1, %r23, 0;
	@%p1 bra 	BB2_7;

	// inline asm
	mov.u32 	%r24, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r25, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r26, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r27, %tid.x;
	// inline asm
	add.s32 	%r28, %r27, %r24;
	mad.lo.s32 	%r50, %r26, %r25, %r28;
	setp.gt.s32 	%p2, %r50, 3071;
	@%p2 bra 	BB2_7;

BB2_2:
	mov.u32 	%r48, %r50;
	mov.u32 	%r6, %r48;
	shl.b32 	%r29, %r6, 2;
	ld.param.u32 	%r45, [multiplyByConstraintMatrix_param_2];
	add.s32 	%r30, %r45, %r29;
	ld.global.u32 	%r47, [%r30];
	setp.gt.s32 	%p3, %r47, 3071;
	@%p3 bra 	BB2_5;

	mov.f32 	%f8, 0f00000000;
	mov.u32 	%r51, 0;
	mov.u32 	%r49, %r6;

BB2_4:
	mov.u32 	%r9, %r49;
	shl.b32 	%r32, %r9, 2;
	ld.param.u32 	%r46, [multiplyByConstraintMatrix_param_3];
	add.s32 	%r33, %r46, %r32;
	ld.global.f32 	%f5, [%r33];
	shl.b32 	%r34, %r47, 2;
	ld.param.u32 	%r42, [multiplyByConstraintMatrix_param_0];
	add.s32 	%r35, %r42, %r34;
	ld.global.f32 	%f6, [%r35];
	fma.rn.ftz.f32 	%f8, %f6, %f5, %f8;
	add.s32 	%r51, %r51, 1;
	mad.lo.s32 	%r12, %r51, 3072, %r6;
	shl.b32 	%r36, %r12, 2;
	ld.param.u32 	%r44, [multiplyByConstraintMatrix_param_2];
	add.s32 	%r37, %r44, %r36;
	ld.global.u32 	%r47, [%r37];
	setp.lt.s32 	%p4, %r47, 3072;
	mov.u32 	%r49, %r12;
	@%p4 bra 	BB2_4;
	bra.uni 	BB2_6;

BB2_5:
	mov.f32 	%f8, 0f00000000;

BB2_6:
	ld.param.u32 	%r43, [multiplyByConstraintMatrix_param_1];
	add.s32 	%r41, %r43, %r29;
	st.global.f32 	[%r41], %f8;
	// inline asm
	mov.u32 	%r38, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r39, %ntid.x;
	// inline asm
	mad.lo.s32 	%r14, %r39, %r38, %r6;
	setp.lt.s32 	%p5, %r14, 3072;
	mov.u32 	%r50, %r14;
	@%p5 bra 	BB2_2;

BB2_7:
	ret;
}

.entry updateAtomPositions(
	.param .u32 .ptr .global .align 4 updateAtomPositions_param_0,
	.param .u32 .ptr .global .align 4 updateAtomPositions_param_1,
	.param .u32 .ptr .global .align 16 updateAtomPositions_param_2,
	.param .u32 .ptr .global .align 16 updateAtomPositions_param_3,
	.param .u32 .ptr .global .align 16 updateAtomPositions_param_4,
	.param .u32 .ptr .global .align 4 updateAtomPositions_param_5,
	.param .u32 .ptr .global .align 4 updateAtomPositions_param_6,
	.param .u32 .ptr .global .align 4 updateAtomPositions_param_7,
	.param .u32 updateAtomPositions_param_8
)
{
	.reg .f32 	%f<49>;
	.reg .pred 	%p<9>;
	.reg .s32 	%r<75>;


	// inline asm
	mov.u32 	%r19, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r20, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r21, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r23, %r21, %r20, %r19;
	// inline asm
	mov.u32 	%r22, %tid.x;
	// inline asm
	neg.s32 	%r24, %r22;
	setp.ne.s32 	%p1, %r23, %r24;
	@%p1 bra 	BB3_2;

	ld.param.u32 	%r71, [updateAtomPositions_param_8];
	shr.u32 	%r25, %r71, 31;
	add.s32 	%r26, %r71, %r25;
	and.b32  	%r27, %r26, 1073741822;
	sub.s32 	%r28, %r71, %r27;
	mov.u32 	%r29, 1;
	sub.s32 	%r30, %r29, %r28;
	shl.b32 	%r31, %r30, 2;
	ld.param.u32 	%r68, [updateAtomPositions_param_7];
	add.s32 	%r32, %r68, %r31;
	st.global.u32 	[%r32], %r29;

BB3_2:
	ld.param.u32 	%r70, [updateAtomPositions_param_8];
	shr.u32 	%r33, %r70, 31;
	add.s32 	%r34, %r70, %r33;
	and.b32  	%r35, %r34, 1073741822;
	sub.s32 	%r36, %r70, %r35;
	shl.b32 	%r37, %r36, 2;
	ld.param.u32 	%r67, [updateAtomPositions_param_7];
	add.s32 	%r38, %r67, %r37;
	ld.global.u32 	%r39, [%r38];
	setp.ne.s32 	%p2, %r39, 0;
	@%p2 bra 	BB3_8;

	ld.param.u32 	%r69, [updateAtomPositions_param_8];
	setp.lt.s32 	%p3, %r69, 2;
	selp.f32 	%f1, 0f3F000000, 0f3F800000, %p3;
	// inline asm
	mov.u32 	%r40, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r41, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r42, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r43, %tid.x;
	// inline asm
	add.s32 	%r44, %r43, %r40;
	mad.lo.s32 	%r72, %r42, %r41, %r44;
	setp.gt.s32 	%p4, %r72, 23557;
	@%p4 bra 	BB3_8;

BB3_4:
	shl.b32 	%r45, %r72, 4;
	ld.param.u32 	%r64, [updateAtomPositions_param_3];
	add.s32 	%r11, %r64, %r45;
	ld.global.v4.f32 	{%f45, %f46, %f47, %f48}, [%r11];
	ld.param.u32 	%r65, [updateAtomPositions_param_4];
	add.s32 	%r46, %r65, %r45;
	shl.b32 	%r47, %r72, 2;
	ld.param.u32 	%r61, [updateAtomPositions_param_0];
	add.s32 	%r48, %r61, %r47;
	ld.global.u32 	%r12, [%r48];
	setp.gt.s32 	%p5, %r12, 0;
	ld.global.f32 	%f2, [%r46+12];
	@%p5 bra 	BB3_5;
	bra.uni 	BB3_7;

BB3_5:
	mul.ftz.f32 	%f3, %f1, %f2;
	ld.param.u32 	%r62, [updateAtomPositions_param_1];
	add.s32 	%r73, %r62, %r47;
	mov.u32 	%r74, 0;

BB3_6:
	ld.global.u32 	%r51, [%r73];
	setp.gt.s32 	%p6, %r51, 0;
	add.s32 	%r52, %r51, -1;
	not.b32 	%r53, %r51;
	selp.b32 	%r54, %r52, %r53, %p6;
	shl.b32 	%r55, %r54, 2;
	ld.param.u32 	%r66, [updateAtomPositions_param_6];
	add.s32 	%r56, %r66, %r55;
	ld.global.f32 	%f4, [%r56];
	mul.ftz.f32 	%f5, %f3, %f4;
	neg.ftz.f32 	%f6, %f5;
	selp.f32 	%f7, %f5, %f6, %p6;
	shl.b32 	%r57, %r54, 4;
	ld.param.u32 	%r63, [updateAtomPositions_param_2];
	add.s32 	%r58, %r63, %r57;
	ld.global.v4.f32 	{%f33, %f34, %f35, %f36}, [%r58];
	fma.rn.ftz.f32 	%f10, %f7, %f33, %f45;
	fma.rn.ftz.f32 	%f13, %f7, %f34, %f46;
	fma.rn.ftz.f32 	%f16, %f7, %f35, %f47;
	mov.f32 	%f45, %f10;
	mov.f32 	%f46, %f13;
	mov.f32 	%f47, %f16;
	mov.f32 	%f48, %f48;
	add.s32 	%r73, %r73, 94232;
	add.s32 	%r74, %r74, 1;
	setp.lt.s32 	%p7, %r74, %r12;
	@%p7 bra 	BB3_6;

BB3_7:
	st.global.v4.f32 	[%r11], {%f45, %f46, %f47, %f48};
	// inline asm
	mov.u32 	%r59, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r60, %ntid.x;
	// inline asm
	mad.lo.s32 	%r72, %r60, %r59, %r72;
	setp.lt.s32 	%p8, %r72, 23558;
	@%p8 bra 	BB3_4;

BB3_8:
	ret;
}




//
// Generated by LWPU LWVM Compiler
// Compiler built on Thu May 15 11:00:55 2014 (1400169655)
// Driver 
//

//.version 3.0
//.target sm_30, texmode_independent
//.address_size 32


.entry computeVirtualSites(
	.param .u32 .ptr .global .align 16 computeVirtualSites_param_0,
	.param .u32 .ptr .global .align 16 computeVirtualSites_param_1,
	.param .u32 .ptr .global .align 8 computeVirtualSites_param_2,
	.param .u32 .ptr .global .align 16 computeVirtualSites_param_3,
	.param .u32 .ptr .global .align 16 computeVirtualSites_param_4,
	.param .u32 .ptr .global .align 16 computeVirtualSites_param_5,
	.param .u32 .ptr .global .align 16 computeVirtualSites_param_6
)
{
	.reg .f32 	%f<239>;
	.reg .pred 	%p<7>;
	.reg .s32 	%r<105>;


	// inline asm
	mov.u32 	%r17, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r18, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r19, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r20, %tid.x;
	// inline asm
	add.s32 	%r21, %r20, %r17;
	mad.lo.s32 	%r102, %r19, %r18, %r21;
	setp.gt.s32 	%p1, %r102, -1;
	@%p1 bra 	BB0_2;

BB0_1:
	shl.b32 	%r24, %r102, 4;
	ld.param.u32 	%r96, [computeVirtualSites_param_1];
	add.s32 	%r25, %r96, %r24;
	ld.global.v4.u32 	{%r89, %r90, %r91, %r92}, [%r25];
	shl.b32 	%r27, %r89, 4;
	ld.param.u32 	%r95, [computeVirtualSites_param_0];
	add.s32 	%r28, %r95, %r27;
	shl.b32 	%r30, %r90, 4;
	add.s32 	%r31, %r95, %r30;
	shl.b32 	%r33, %r91, 4;
	add.s32 	%r34, %r95, %r33;
	shl.b32 	%r35, %r102, 3;
	ld.param.u32 	%r97, [computeVirtualSites_param_2];
	add.s32 	%r36, %r97, %r35;
	ld.global.v2.f32 	{%f189, %f190}, [%r36];
	ld.global.v4.f32 	{%f203, %f204, %f205, %f206}, [%r31];
	ld.global.v4.f32 	{%f219, %f220, %f221, %f222}, [%r34];
	mul.ftz.f32 	%f223, %f219, %f190;
	mul.ftz.f32 	%f224, %f220, %f190;
	mul.ftz.f32 	%f225, %f221, %f190;
	fma.rn.ftz.f32 	%f227, %f203, %f189, %f223;
	fma.rn.ftz.f32 	%f228, %f204, %f189, %f224;
	fma.rn.ftz.f32 	%f229, %f205, %f189, %f225;
	ld.global.v4.f32 	{%f231, %f232, %f233, %f234}, [%r28];
	st.global.v4.f32 	[%r28], {%f227, %f228, %f229, %f234};
	// inline asm
	mov.u32 	%r22, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r23, %ntid.x;
	// inline asm
	mad.lo.s32 	%r102, %r23, %r22, %r102;
	setp.lt.s32 	%p2, %r102, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	// inline asm
	mov.u32 	%r37, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r38, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r39, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r40, %tid.x;
	// inline asm
	add.s32 	%r41, %r40, %r37;
	mad.lo.s32 	%r103, %r39, %r38, %r41;
	setp.gt.s32 	%p3, %r103, -1;
	@%p3 bra 	BB0_4;

BB0_3:
	shl.b32 	%r44, %r103, 4;
	ld.param.u32 	%r98, [computeVirtualSites_param_3];
	add.s32 	%r45, %r98, %r44;
	ld.global.v4.u32 	{%r85, %r86, %r87, %r88}, [%r45];
	shl.b32 	%r47, %r85, 4;
	ld.param.u32 	%r94, [computeVirtualSites_param_0];
	add.s32 	%r48, %r94, %r47;
	shl.b32 	%r50, %r86, 4;
	add.s32 	%r51, %r94, %r50;
	shl.b32 	%r53, %r87, 4;
	add.s32 	%r54, %r94, %r53;
	shl.b32 	%r56, %r88, 4;
	add.s32 	%r57, %r94, %r56;
	ld.param.u32 	%r99, [computeVirtualSites_param_4];
	add.s32 	%r58, %r99, %r44;
	ld.global.v4.f32 	{%f113, %f114, %f115, %f116}, [%r58];
	ld.global.v4.f32 	{%f125, %f126, %f127, %f128}, [%r51];
	ld.global.v4.f32 	{%f145, %f146, %f147, %f148}, [%r54];
	mul.ftz.f32 	%f149, %f145, %f114;
	mul.ftz.f32 	%f150, %f146, %f114;
	mul.ftz.f32 	%f151, %f147, %f114;
	fma.rn.ftz.f32 	%f153, %f125, %f113, %f149;
	fma.rn.ftz.f32 	%f154, %f126, %f113, %f150;
	fma.rn.ftz.f32 	%f155, %f127, %f113, %f151;
	ld.global.v4.f32 	{%f173, %f174, %f175, %f176}, [%r57];
	fma.rn.ftz.f32 	%f177, %f173, %f115, %f153;
	fma.rn.ftz.f32 	%f178, %f174, %f115, %f154;
	fma.rn.ftz.f32 	%f179, %f175, %f115, %f155;
	ld.global.v4.f32 	{%f181, %f182, %f183, %f184}, [%r48];
	st.global.v4.f32 	[%r48], {%f177, %f178, %f179, %f184};
	// inline asm
	mov.u32 	%r42, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r43, %ntid.x;
	// inline asm
	mad.lo.s32 	%r103, %r43, %r42, %r103;
	setp.lt.s32 	%p4, %r103, 0;
	@%p4 bra 	BB0_3;

BB0_4:
	// inline asm
	mov.u32 	%r59, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r60, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r61, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r62, %tid.x;
	// inline asm
	add.s32 	%r63, %r62, %r59;
	mad.lo.s32 	%r104, %r61, %r60, %r63;
	setp.gt.s32 	%p5, %r104, -1;
	@%p5 bra 	BB0_6;

BB0_5:
	shl.b32 	%r66, %r104, 4;
	ld.param.u32 	%r100, [computeVirtualSites_param_5];
	add.s32 	%r67, %r100, %r66;
	ld.global.v4.u32 	{%r81, %r82, %r83, %r84}, [%r67];
	shl.b32 	%r69, %r81, 4;
	ld.param.u32 	%r93, [computeVirtualSites_param_0];
	add.s32 	%r70, %r93, %r69;
	shl.b32 	%r72, %r82, 4;
	add.s32 	%r73, %r93, %r72;
	shl.b32 	%r75, %r83, 4;
	add.s32 	%r76, %r93, %r75;
	shl.b32 	%r78, %r84, 4;
	add.s32 	%r79, %r93, %r78;
	ld.global.v4.f32 	{%f25, %f26, %f27, %f28}, [%r76];
	ld.global.v4.f32 	{%f29, %f30, %f31, %f32}, [%r73];
	sub.ftz.f32 	%f33, %f25, %f29;
	sub.ftz.f32 	%f34, %f26, %f30;
	sub.ftz.f32 	%f35, %f27, %f31;
	ld.global.v4.f32 	{%f37, %f38, %f39, %f40}, [%r79];
	sub.ftz.f32 	%f41, %f37, %f29;
	sub.ftz.f32 	%f42, %f38, %f30;
	sub.ftz.f32 	%f43, %f39, %f31;
	ld.param.u32 	%r101, [computeVirtualSites_param_6];
	add.s32 	%r80, %r101, %r66;
	ld.global.v4.f32 	{%f45, %f46, %f47, %f48}, [%r80];
	fma.rn.ftz.f32 	%f57, %f33, %f45, %f29;
	fma.rn.ftz.f32 	%f58, %f34, %f45, %f30;
	fma.rn.ftz.f32 	%f59, %f35, %f45, %f31;
	fma.rn.ftz.f32 	%f77, %f41, %f46, %f57;
	fma.rn.ftz.f32 	%f78, %f42, %f46, %f58;
	fma.rn.ftz.f32 	%f79, %f43, %f46, %f59;
	mul.rn.f32 	%f11, %f34, %f43;
	mul.rn.f32 	%f14, %f35, %f42;
	sub.ftz.f32 	%f15, %f11, %f14;
	mul.rn.f32 	%f17, %f35, %f41;
	mul.rn.f32 	%f19, %f33, %f43;
	sub.ftz.f32 	%f20, %f17, %f19;
	mul.rn.f32 	%f21, %f33, %f42;
	mul.rn.f32 	%f22, %f34, %f41;
	sub.ftz.f32 	%f23, %f21, %f22;
	fma.rn.ftz.f32 	%f101, %f15, %f47, %f77;
	fma.rn.ftz.f32 	%f102, %f20, %f47, %f78;
	fma.rn.ftz.f32 	%f103, %f23, %f47, %f79;
	ld.global.v4.f32 	{%f105, %f106, %f107, %f108}, [%r70];
	st.global.v4.f32 	[%r70], {%f101, %f102, %f103, %f108};
	// inline asm
	mov.u32 	%r64, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r65, %ntid.x;
	// inline asm
	mad.lo.s32 	%r104, %r65, %r64, %r104;
	setp.lt.s32 	%p6, %r104, 0;
	@%p6 bra 	BB0_5;

BB0_6:
	ret;
}

.entry distributeForces(
	.param .u32 .ptr .global .align 16 distributeForces_param_0,
	.param .u32 .ptr .global .align 16 distributeForces_param_1,
	.param .u32 .ptr .global .align 16 distributeForces_param_2,
	.param .u32 .ptr .global .align 8 distributeForces_param_3,
	.param .u32 .ptr .global .align 16 distributeForces_param_4,
	.param .u32 .ptr .global .align 16 distributeForces_param_5,
	.param .u32 .ptr .global .align 16 distributeForces_param_6,
	.param .u32 .ptr .global .align 16 distributeForces_param_7
)
{
	.reg .f32 	%f<270>;
	.reg .pred 	%p<7>;
	.reg .s32 	%r<110>;


	// inline asm
	mov.u32 	%r18, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r19, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r20, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r21, %tid.x;
	// inline asm
	add.s32 	%r22, %r21, %r18;
	mad.lo.s32 	%r107, %r20, %r19, %r22;
	setp.gt.s32 	%p1, %r107, -1;
	@%p1 bra 	BB1_2;

BB1_1:
	shl.b32 	%r25, %r107, 4;
	ld.param.u32 	%r101, [distributeForces_param_2];
	add.s32 	%r26, %r101, %r25;
	ld.global.v4.u32 	{%r93, %r94, %r95, %r96}, [%r26];
	shl.b32 	%r28, %r93, 4;
	ld.param.u32 	%r100, [distributeForces_param_1];
	add.s32 	%r29, %r100, %r28;
	shl.b32 	%r31, %r94, 4;
	add.s32 	%r32, %r100, %r31;
	shl.b32 	%r34, %r95, 4;
	add.s32 	%r35, %r100, %r34;
	shl.b32 	%r36, %r107, 3;
	ld.param.u32 	%r102, [distributeForces_param_3];
	add.s32 	%r37, %r102, %r36;
	ld.global.v2.f32 	{%f216, %f217}, [%r37];
	ld.global.v4.f32 	{%f230, %f231, %f232, %f233}, [%r29];
	ld.global.v4.f32 	{%f234, %f235, %f236, %f237}, [%r32];
	fma.rn.ftz.f32 	%f238, %f230, %f216, %f234;
	fma.rn.ftz.f32 	%f239, %f231, %f216, %f235;
	fma.rn.ftz.f32 	%f240, %f232, %f216, %f236;
	ld.global.v4.f32 	{%f258, %f259, %f260, %f261}, [%r35];
	fma.rn.ftz.f32 	%f262, %f230, %f217, %f258;
	fma.rn.ftz.f32 	%f263, %f231, %f217, %f259;
	fma.rn.ftz.f32 	%f264, %f232, %f217, %f260;
	st.global.v4.f32 	[%r32], {%f238, %f239, %f240, %f237};
	st.global.v4.f32 	[%r35], {%f262, %f263, %f264, %f261};
	// inline asm
	mov.u32 	%r23, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r24, %ntid.x;
	// inline asm
	mad.lo.s32 	%r107, %r24, %r23, %r107;
	setp.lt.s32 	%p2, %r107, 0;
	@%p2 bra 	BB1_1;

BB1_2:
	// inline asm
	mov.u32 	%r38, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r39, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r40, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r41, %tid.x;
	// inline asm
	add.s32 	%r42, %r41, %r38;
	mad.lo.s32 	%r108, %r40, %r39, %r42;
	setp.gt.s32 	%p3, %r108, -1;
	@%p3 bra 	BB1_4;

BB1_3:
	shl.b32 	%r45, %r108, 4;
	ld.param.u32 	%r103, [distributeForces_param_4];
	add.s32 	%r46, %r103, %r45;
	ld.global.v4.u32 	{%r89, %r90, %r91, %r92}, [%r46];
	shl.b32 	%r48, %r89, 4;
	ld.param.u32 	%r99, [distributeForces_param_1];
	add.s32 	%r49, %r99, %r48;
	shl.b32 	%r51, %r90, 4;
	add.s32 	%r52, %r99, %r51;
	shl.b32 	%r54, %r91, 4;
	add.s32 	%r55, %r99, %r54;
	shl.b32 	%r57, %r92, 4;
	add.s32 	%r58, %r99, %r57;
	ld.param.u32 	%r104, [distributeForces_param_5];
	add.s32 	%r59, %r104, %r45;
	ld.global.v4.f32 	{%f132, %f133, %f134, %f135}, [%r59];
	ld.global.v4.f32 	{%f144, %f145, %f146, %f147}, [%r49];
	ld.global.v4.f32 	{%f148, %f149, %f150, %f151}, [%r52];
	fma.rn.ftz.f32 	%f152, %f144, %f132, %f148;
	fma.rn.ftz.f32 	%f153, %f145, %f132, %f149;
	fma.rn.ftz.f32 	%f154, %f146, %f132, %f150;
	ld.global.v4.f32 	{%f176, %f177, %f178, %f179}, [%r55];
	fma.rn.ftz.f32 	%f180, %f144, %f133, %f176;
	fma.rn.ftz.f32 	%f181, %f145, %f133, %f177;
	fma.rn.ftz.f32 	%f182, %f146, %f133, %f178;
	ld.global.v4.f32 	{%f204, %f205, %f206, %f207}, [%r58];
	fma.rn.ftz.f32 	%f208, %f144, %f134, %f204;
	fma.rn.ftz.f32 	%f209, %f145, %f134, %f205;
	fma.rn.ftz.f32 	%f210, %f146, %f134, %f206;
	st.global.v4.f32 	[%r52], {%f152, %f153, %f154, %f151};
	st.global.v4.f32 	[%r55], {%f180, %f181, %f182, %f179};
	st.global.v4.f32 	[%r58], {%f208, %f209, %f210, %f207};
	// inline asm
	mov.u32 	%r43, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r44, %ntid.x;
	// inline asm
	mad.lo.s32 	%r108, %r44, %r43, %r108;
	setp.lt.s32 	%p4, %r108, 0;
	@%p4 bra 	BB1_3;

BB1_4:
	// inline asm
	mov.u32 	%r60, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r61, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r62, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r63, %tid.x;
	// inline asm
	add.s32 	%r64, %r63, %r60;
	mad.lo.s32 	%r109, %r62, %r61, %r64;
	setp.gt.s32 	%p5, %r109, -1;
	@%p5 bra 	BB1_6;

BB1_5:
	shl.b32 	%r67, %r109, 4;
	ld.param.u32 	%r105, [distributeForces_param_6];
	add.s32 	%r68, %r105, %r67;
	ld.global.v4.u32 	{%r85, %r86, %r87, %r88}, [%r68];
	shl.b32 	%r70, %r86, 4;
	ld.param.u32 	%r97, [distributeForces_param_0];
	add.s32 	%r71, %r97, %r70;
	shl.b32 	%r73, %r87, 4;
	add.s32 	%r74, %r97, %r73;
	shl.b32 	%r76, %r88, 4;
	add.s32 	%r77, %r97, %r76;
	ld.global.v4.f32 	{%f52, %f53, %f54, %f55}, [%r74];
	ld.global.v4.f32 	{%f56, %f57, %f58, %f59}, [%r71];
	sub.ftz.f32 	%f60, %f52, %f56;
	sub.ftz.f32 	%f61, %f53, %f57;
	sub.ftz.f32 	%f62, %f54, %f58;
	ld.global.v4.f32 	{%f64, %f65, %f66, %f67}, [%r77];
	sub.ftz.f32 	%f68, %f64, %f56;
	sub.ftz.f32 	%f69, %f65, %f57;
	sub.ftz.f32 	%f70, %f66, %f58;
	shl.b32 	%r79, %r85, 4;
	ld.param.u32 	%r98, [distributeForces_param_1];
	add.s32 	%r80, %r98, %r79;
	add.s32 	%r81, %r98, %r70;
	add.s32 	%r82, %r98, %r73;
	add.s32 	%r83, %r98, %r76;
	ld.param.u32 	%r106, [distributeForces_param_7];
	add.s32 	%r84, %r106, %r67;
	ld.global.v4.f32 	{%f72, %f73, %f74, %f75}, [%r84];
	ld.global.v4.f32 	{%f76, %f77, %f78, %f79}, [%r80];
	mul.ftz.f32 	%f11, %f72, %f76;
	mul.ftz.f32 	%f14, %f74, %f70;
	neg.f32 	%f16, %f14;
	fma.rn.ftz.f32 	%f17, %f16, %f77, %f11;
	mul.ftz.f32 	%f19, %f69, %f74;
	fma.rn.ftz.f32 	%f21, %f19, %f78, %f17;
	mul.ftz.f32 	%f22, %f72, %f77;
	fma.rn.ftz.f32 	%f23, %f14, %f76, %f22;
	mul.ftz.f32 	%f25, %f74, %f68;
	neg.f32 	%f26, %f25;
	fma.rn.ftz.f32 	%f27, %f26, %f78, %f23;
	mul.ftz.f32 	%f28, %f25, %f77;
	neg.f32 	%f29, %f19;
	fma.rn.ftz.f32 	%f30, %f29, %f76, %f28;
	fma.rn.ftz.f32 	%f31, %f72, %f78, %f30;
	mul.ftz.f32 	%f35, %f62, %f74;
	mul.ftz.f32 	%f36, %f35, %f77;
	fma.rn.ftz.f32 	%f37, %f73, %f76, %f36;
	mul.ftz.f32 	%f39, %f74, %f61;
	neg.f32 	%f40, %f39;
	fma.rn.ftz.f32 	%f41, %f40, %f78, %f37;
	mul.ftz.f32 	%f42, %f73, %f77;
	neg.f32 	%f43, %f35;
	fma.rn.ftz.f32 	%f44, %f43, %f76, %f42;
	mul.ftz.f32 	%f46, %f74, %f60;
	fma.rn.ftz.f32 	%f47, %f46, %f78, %f44;
	mul.ftz.f32 	%f48, %f39, %f76;
	neg.f32 	%f49, %f46;
	fma.rn.ftz.f32 	%f50, %f49, %f77, %f48;
	fma.rn.ftz.f32 	%f51, %f73, %f78, %f50;
	sub.ftz.f32 	%f88, %f76, %f21;
	sub.ftz.f32 	%f89, %f77, %f27;
	sub.ftz.f32 	%f90, %f78, %f31;
	sub.ftz.f32 	%f92, %f88, %f41;
	sub.ftz.f32 	%f93, %f89, %f47;
	sub.ftz.f32 	%f94, %f90, %f51;
	ld.global.v4.f32 	{%f96, %f97, %f98, %f99}, [%r81];
	add.ftz.f32 	%f100, %f96, %f92;
	add.ftz.f32 	%f101, %f97, %f93;
	add.ftz.f32 	%f102, %f98, %f94;
	ld.global.v4.f32 	{%f108, %f109, %f110, %f111}, [%r82];
	add.ftz.f32 	%f112, %f108, %f21;
	add.ftz.f32 	%f113, %f109, %f27;
	add.ftz.f32 	%f114, %f110, %f31;
	ld.global.v4.f32 	{%f120, %f121, %f122, %f123}, [%r83];
	add.ftz.f32 	%f124, %f120, %f41;
	add.ftz.f32 	%f125, %f121, %f47;
	add.ftz.f32 	%f126, %f122, %f51;
	st.global.v4.f32 	[%r81], {%f100, %f101, %f102, %f99};
	st.global.v4.f32 	[%r82], {%f112, %f113, %f114, %f111};
	st.global.v4.f32 	[%r83], {%f124, %f125, %f126, %f123};
	// inline asm
	mov.u32 	%r65, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r66, %ntid.x;
	// inline asm
	mad.lo.s32 	%r109, %r66, %r65, %r109;
	setp.lt.s32 	%p6, %r109, 0;
	@%p6 bra 	BB1_5;

BB1_6:
	ret;
}



//
// Generated by LWPU LWVM Compiler
// Compiler built on Thu May 15 11:00:55 2014 (1400169655)
// Driver 
//

//.version 3.0
//.target sm_30, texmode_independent
//.address_size 32


.entry sortShortList(
	.param .u32 .ptr .global .align 8 sortShortList_param_0,
	.param .u32 sortShortList_param_1,
	.param .u32 .ptr .shared .align 8 sortShortList_param_2
)
{
	.reg .pred 	%p<23>;
	.reg .s32 	%r<77>;


	ld.param.u32 	%r2, [sortShortList_param_1];
	// inline asm
	mov.u32 	%r31, %tid.x;
	// inline asm
	setp.ge.u32 	%p6, %r31, %r2;
	mov.u32 	%r69, %r31;
	@%p6 bra 	BB0_2;

BB0_1:
	shl.b32 	%r33, %r69, 3;
	ld.param.u32 	%r68, [sortShortList_param_2];
	add.s32 	%r34, %r68, %r33;
	ld.param.u32 	%r58, [sortShortList_param_0];
	add.s32 	%r35, %r58, %r33;
	ld.global.v2.u32 	{%r55, %r56}, [%r35];
	st.shared.v2.u32 	[%r34], {%r55, %r56};
	// inline asm
	mov.u32 	%r32, %ntid.x;
	// inline asm
	add.s32 	%r69, %r32, %r69;
	ld.param.u32 	%r65, [sortShortList_param_1];
	setp.lt.u32 	%p7, %r69, %r65;
	@%p7 bra 	BB0_1;

BB0_2:
	bar.sync 	0;
	ld.param.u32 	%r64, [sortShortList_param_1];
	shl.b32 	%r7, %r64, 1;
	setp.lt.u32 	%p8, %r7, 3;
	@%p8 bra 	BB0_22;

	mov.u32 	%r70, 2;

BB0_4:
	shr.u32 	%r71, %r70, 1;
	setp.eq.s32 	%p9, %r71, 0;
	@%p9 bra 	BB0_21;

	shl.b32 	%r37, %r70, 1;
	setp.lt.u32 	%p1, %r37, %r7;

BB0_6:
	// inline asm
	mov.u32 	%r38, %tid.x;
	// inline asm
	ld.param.u32 	%r63, [sortShortList_param_1];
	setp.ge.u32 	%p10, %r38, %r63;
	mov.u32 	%r72, %r38;
	@%p10 bra 	BB0_20;

BB0_7:
	xor.b32  	%r13, %r72, %r71;
	setp.gt.u32 	%p11, %r13, %r72;
	ld.param.u32 	%r62, [sortShortList_param_1];
	setp.lt.u32 	%p12, %r13, %r62;
	and.pred  	%p13, %p11, %p12;
	@!%p13 bra 	BB0_19;

	shl.b32 	%r39, %r72, 3;
	ld.param.u32 	%r67, [sortShortList_param_2];
	add.s32 	%r14, %r67, %r39;
	ld.shared.v2.u32 	{%r53, %r54}, [%r14];
	shl.b32 	%r40, %r13, 3;
	add.s32 	%r15, %r67, %r40;
	ld.shared.v2.u32 	{%r51, %r52}, [%r15];
	and.b32  	%r41, %r72, %r70;
	setp.eq.s32 	%p22, %r41, 0;
	@%p1 bra 	BB0_9;
	bra.uni 	BB0_11;

BB0_9:
	mov.u32 	%r73, %r37;

BB0_10:
	mov.u32 	%r17, %r73;
	and.b32  	%r42, %r17, %r72;
	setp.eq.s32 	%p14, %r42, 0;
	xor.pred  	%p22, %p22, %p14;
	shl.b32 	%r18, %r17, 1;
	setp.lt.u32 	%p15, %r18, %r7;
	mov.u32 	%r73, %r18;
	@%p15 bra 	BB0_10;

BB0_11:
	@%p22 bra 	BB0_13;

	mov.u32 	%r74, %r52;
	bra.uni 	BB0_14;

BB0_13:
	mov.u32 	%r74, %r54;

BB0_14:
	@%p22 bra 	BB0_16;

	mov.u32 	%r75, %r54;
	bra.uni 	BB0_17;

BB0_16:
	mov.u32 	%r75, %r52;

BB0_17:
	setp.le.s32 	%p16, %r74, %r75;
	@%p16 bra 	BB0_19;

	st.shared.v2.u32 	[%r14], {%r51, %r52};
	st.shared.v2.u32 	[%r15], {%r53, %r54};

BB0_19:
	// inline asm
	mov.u32 	%r43, %ntid.x;
	// inline asm
	add.s32 	%r72, %r43, %r72;
	ld.param.u32 	%r61, [sortShortList_param_1];
	setp.lt.u32 	%p17, %r72, %r61;
	@%p17 bra 	BB0_7;

BB0_20:
	bar.sync 	0;
	shr.u32 	%r71, %r71, 1;
	setp.ne.s32 	%p18, %r71, 0;
	@%p18 bra 	BB0_6;

BB0_21:
	shl.b32 	%r70, %r70, 1;
	setp.lt.u32 	%p19, %r70, %r7;
	@%p19 bra 	BB0_4;

BB0_22:
	// inline asm
	mov.u32 	%r44, %tid.x;
	// inline asm
	ld.param.u32 	%r60, [sortShortList_param_1];
	setp.ge.u32 	%p20, %r44, %r60;
	mov.u32 	%r76, %r44;
	@%p20 bra 	BB0_24;

BB0_23:
	shl.b32 	%r46, %r76, 3;
	ld.param.u32 	%r57, [sortShortList_param_0];
	add.s32 	%r47, %r57, %r46;
	ld.param.u32 	%r66, [sortShortList_param_2];
	add.s32 	%r48, %r66, %r46;
	ld.shared.v2.u32 	{%r49, %r50}, [%r48];
	st.global.v2.u32 	[%r47], {%r49, %r50};
	// inline asm
	mov.u32 	%r45, %ntid.x;
	// inline asm
	add.s32 	%r76, %r45, %r76;
	ld.param.u32 	%r59, [sortShortList_param_1];
	setp.lt.u32 	%p21, %r76, %r59;
	@%p21 bra 	BB0_23;

BB0_24:
	ret;
}

.entry computeRange(
	.param .u32 .ptr .global .align 8 computeRange_param_0,
	.param .u32 computeRange_param_1,
	.param .u32 .ptr .global .align 4 computeRange_param_2,
	.param .u32 .ptr .shared .align 4 computeRange_param_3
)
{
	.reg .pred 	%p<12>;
	.reg .s32 	%r<99>;


	ld.param.u32 	%r2, [computeRange_param_1];
	// inline asm
	mov.u32 	%r20, %tid.x;
	// inline asm
	setp.lt.u32 	%p1, %r20, %r2;
	mov.u32 	%r94, %r20;
	@%p1 bra 	BB1_2;

	mov.u32 	%r96, 2147483647;
	mov.u32 	%r95, -2147483648;
	bra.uni 	BB1_4;

BB1_2:
	mov.u32 	%r96, 2147483647;
	mov.u32 	%r95, -2147483648;

BB1_3:
	shl.b32 	%r32, %r94, 3;
	ld.param.u32 	%r85, [computeRange_param_0];
	add.s32 	%r33, %r85, %r32;
	ld.global.u32 	%r30, [%r33+4];
	// inline asm
	min.s32 	%r25, %r96, %r30;
	// inline asm
	// inline asm
	max.s32 	%r28, %r95, %r30;
	// inline asm
	// inline asm
	mov.u32 	%r31, %ntid.x;
	// inline asm
	add.s32 	%r94, %r31, %r94;
	ld.param.u32 	%r86, [computeRange_param_1];
	setp.lt.u32 	%p2, %r94, %r86;
	mov.u32 	%r95, %r28;
	mov.u32 	%r96, %r25;
	@%p2 bra 	BB1_3;

BB1_4:
	// inline asm
	mov.u32 	%r34, %tid.x;
	// inline asm
	shl.b32 	%r35, %r34, 2;
	ld.param.u32 	%r93, [computeRange_param_3];
	add.s32 	%r36, %r93, %r35;
	st.shared.u32 	[%r36], %r96;
	bar.sync 	0;
	// inline asm
	mov.u32 	%r37, %ntid.x;
	// inline asm
	setp.lt.u32 	%p3, %r37, 2;
	@%p3 bra 	BB1_10;

	mov.u32 	%r97, 1;

BB1_6:
	// inline asm
	mov.u32 	%r39, %tid.x;
	// inline asm
	add.s32 	%r41, %r39, %r97;
	// inline asm
	mov.u32 	%r40, %ntid.x;
	// inline asm
	setp.ge.u32 	%p4, %r41, %r40;
	@%p4 bra 	BB1_9;

	// inline asm
	mov.u32 	%r42, %tid.x;
	// inline asm
	shl.b32 	%r43, %r97, 1;
	rem.u32 	%r44, %r42, %r43;
	setp.ne.s32 	%p5, %r44, 0;
	@%p5 bra 	BB1_9;

	// inline asm
	mov.u32 	%r45, %tid.x;
	// inline asm
	shl.b32 	%r51, %r45, 2;
	ld.param.u32 	%r92, [computeRange_param_3];
	add.s32 	%r52, %r92, %r51;
	ld.shared.u32 	%r48, [%r52];
	// inline asm
	mov.u32 	%r46, %tid.x;
	// inline asm
	add.s32 	%r53, %r46, %r97;
	shl.b32 	%r54, %r53, 2;
	add.s32 	%r55, %r92, %r54;
	ld.shared.u32 	%r49, [%r55];
	// inline asm
	min.s32 	%r47, %r48, %r49;
	// inline asm
	// inline asm
	mov.u32 	%r50, %tid.x;
	// inline asm
	shl.b32 	%r56, %r50, 2;
	add.s32 	%r57, %r92, %r56;
	st.shared.u32 	[%r57], %r47;

BB1_9:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r58, %ntid.x;
	// inline asm
	shl.b32 	%r97, %r97, 1;
	setp.lt.u32 	%p6, %r97, %r58;
	@%p6 bra 	BB1_6;

BB1_10:
	ld.param.u32 	%r91, [computeRange_param_3];
	ld.shared.u32 	%r16, [%r91];
	bar.sync 	0;
	// inline asm
	mov.u32 	%r59, %tid.x;
	// inline asm
	shl.b32 	%r60, %r59, 2;
	ld.param.u32 	%r90, [computeRange_param_3];
	add.s32 	%r61, %r90, %r60;
	st.shared.u32 	[%r61], %r95;
	bar.sync 	0;
	// inline asm
	mov.u32 	%r62, %ntid.x;
	// inline asm
	setp.lt.u32 	%p7, %r62, 2;
	@%p7 bra 	BB1_16;

	mov.u32 	%r98, 1;

BB1_12:
	// inline asm
	mov.u32 	%r64, %tid.x;
	// inline asm
	add.s32 	%r66, %r64, %r98;
	// inline asm
	mov.u32 	%r65, %ntid.x;
	// inline asm
	setp.ge.u32 	%p8, %r66, %r65;
	@%p8 bra 	BB1_15;

	// inline asm
	mov.u32 	%r67, %tid.x;
	// inline asm
	shl.b32 	%r68, %r98, 1;
	rem.u32 	%r69, %r67, %r68;
	setp.ne.s32 	%p9, %r69, 0;
	@%p9 bra 	BB1_15;

	// inline asm
	mov.u32 	%r70, %tid.x;
	// inline asm
	shl.b32 	%r76, %r70, 2;
	ld.param.u32 	%r89, [computeRange_param_3];
	add.s32 	%r77, %r89, %r76;
	ld.shared.u32 	%r73, [%r77];
	// inline asm
	mov.u32 	%r71, %tid.x;
	// inline asm
	add.s32 	%r78, %r71, %r98;
	shl.b32 	%r79, %r78, 2;
	add.s32 	%r80, %r89, %r79;
	ld.shared.u32 	%r74, [%r80];
	// inline asm
	max.s32 	%r72, %r73, %r74;
	// inline asm
	// inline asm
	mov.u32 	%r75, %tid.x;
	// inline asm
	shl.b32 	%r81, %r75, 2;
	add.s32 	%r82, %r89, %r81;
	st.shared.u32 	[%r82], %r72;

BB1_15:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r83, %ntid.x;
	// inline asm
	shl.b32 	%r98, %r98, 1;
	setp.lt.u32 	%p10, %r98, %r83;
	@%p10 bra 	BB1_12;

BB1_16:
	ld.param.u32 	%r88, [computeRange_param_3];
	ld.shared.u32 	%r19, [%r88];
	// inline asm
	mov.u32 	%r84, %tid.x;
	// inline asm
	setp.eq.s32 	%p11, %r84, 0;
	@%p11 bra 	BB1_18;

	ret;

BB1_18:
	ld.param.u32 	%r87, [computeRange_param_2];
	st.global.u32 	[%r87], %r16;
	st.global.u32 	[%r87+4], %r19;
	ret;
}

.entry assignElementsToBuckets(
	.param .u32 .ptr .global .align 8 assignElementsToBuckets_param_0,
	.param .u32 assignElementsToBuckets_param_1,
	.param .u32 assignElementsToBuckets_param_2,
	.param .u32 .ptr .global .align 4 assignElementsToBuckets_param_3,
	.param .u32 .ptr .global .align 4 assignElementsToBuckets_param_4,
	.param .u32 .ptr .global .align 4 assignElementsToBuckets_param_5,
	.param .u32 .ptr .global .align 4 assignElementsToBuckets_param_6
)
{
	.reg .f32 	%f<9>;
	.reg .pred 	%p<3>;
	.reg .s32 	%r<42>;


	ld.param.u32 	%r2, [assignElementsToBuckets_param_1];
	ld.param.u32 	%r3, [assignElementsToBuckets_param_2];
	ld.param.u32 	%r15, [assignElementsToBuckets_param_3];
	ldu.global.u32 	%r16, [%r15];
	cvt.rn.f32.s32 	%f1, %r16;
	ldu.global.u32 	%r17, [%r15+4];
	cvt.rn.f32.s32 	%f3, %r17;
	sub.ftz.f32 	%f4, %f3, %f1;
	cvt.rn.f32.u32 	%f5, %r3;
	div.approx.ftz.f32 	%f2, %f4, %f5;
	// inline asm
	mov.u32 	%r11, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r12, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r13, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r14, %tid.x;
	// inline asm
	add.s32 	%r18, %r14, %r11;
	mad.lo.s32 	%r41, %r13, %r12, %r18;
	setp.ge.u32 	%p1, %r41, %r2;
	@%p1 bra 	BB2_3;

	ld.param.u32 	%r37, [assignElementsToBuckets_param_2];
	add.s32 	%r8, %r37, -1;

BB2_2:
	shl.b32 	%r24, %r41, 3;
	ld.param.u32 	%r35, [assignElementsToBuckets_param_0];
	add.s32 	%r25, %r35, %r24;
	ld.global.v2.u32 	{%r33, %r34}, [%r25];
	cvt.rn.f32.s32 	%f6, %r34;
	sub.ftz.f32 	%f7, %f6, %f1;
	div.approx.ftz.f32 	%f8, %f7, %f2;
	cvt.rzi.ftz.u32.f32 	%r20, %f8;
	// inline asm
	min.u32 	%r19, %r20, %r8;
	// inline asm
	shl.b32 	%r27, %r19, 2;
	ld.param.u32 	%r38, [assignElementsToBuckets_param_4];
	add.s32 	%r28, %r38, %r27;
	atom.global.add.u32 	%r29, [%r28], 1;
	shl.b32 	%r30, %r41, 2;
	ld.param.u32 	%r40, [assignElementsToBuckets_param_6];
	add.s32 	%r31, %r40, %r30;
	st.global.u32 	[%r31], %r29;
	ld.param.u32 	%r39, [assignElementsToBuckets_param_5];
	add.s32 	%r32, %r39, %r30;
	st.global.u32 	[%r32], %r19;
	// inline asm
	mov.u32 	%r22, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r23, %ntid.x;
	// inline asm
	mad.lo.s32 	%r41, %r23, %r22, %r41;
	ld.param.u32 	%r36, [assignElementsToBuckets_param_1];
	setp.lt.u32 	%p2, %r41, %r36;
	@%p2 bra 	BB2_2;

BB2_3:
	ret;
}

.entry computeBucketPositions(
	.param .u32 computeBucketPositions_param_0,
	.param .u32 .ptr .global .align 4 computeBucketPositions_param_1,
	.param .u32 .ptr .shared .align 4 computeBucketPositions_param_2
)
{
	.reg .pred 	%p<7>;
	.reg .s32 	%r<61>;


	ld.param.u32 	%r1, [computeBucketPositions_param_0];
	setp.eq.s32 	%p2, %r1, 0;
	@%p2 bra 	BB3_14;

	mov.u32 	%r57, 0;
	mov.u32 	%r56, %r57;

BB3_2:
	// inline asm
	mov.u32 	%r17, %tid.x;
	// inline asm
	add.s32 	%r18, %r17, %r56;
	ld.param.u32 	%r49, [computeBucketPositions_param_0];
	setp.lt.u32 	%p1, %r18, %r49;
	shl.b32 	%r19, %r18, 2;
	ld.param.u32 	%r50, [computeBucketPositions_param_1];
	add.s32 	%r6, %r50, %r19;
	@%p1 bra 	BB3_4;

	mov.u32 	%r58, 0;
	bra.uni 	BB3_5;

BB3_4:
	ld.global.u32 	%r58, [%r6];

BB3_5:
	// inline asm
	mov.u32 	%r21, %tid.x;
	// inline asm
	shl.b32 	%r22, %r21, 2;
	ld.param.u32 	%r55, [computeBucketPositions_param_2];
	add.s32 	%r23, %r55, %r22;
	st.shared.u32 	[%r23], %r58;
	bar.sync 	0;
	// inline asm
	mov.u32 	%r24, %ntid.x;
	// inline asm
	setp.lt.u32 	%p3, %r24, 2;
	@%p3 bra 	BB3_11;

	mov.u32 	%r59, 1;

BB3_7:
	// inline asm
	mov.u32 	%r26, %tid.x;
	// inline asm
	setp.lt.u32 	%p4, %r26, %r59;
	@%p4 bra 	BB3_9;

	// inline asm
	mov.u32 	%r27, %tid.x;
	// inline asm
	sub.s32 	%r28, %r27, %r59;
	shl.b32 	%r29, %r28, 2;
	ld.param.u32 	%r54, [computeBucketPositions_param_2];
	add.s32 	%r30, %r54, %r29;
	ld.shared.u32 	%r60, [%r30];
	bra.uni 	BB3_10;

BB3_9:
	mov.u32 	%r60, 0;

BB3_10:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r32, %tid.x;
	// inline asm
	shl.b32 	%r33, %r32, 2;
	ld.param.u32 	%r53, [computeBucketPositions_param_2];
	add.s32 	%r34, %r53, %r33;
	ld.shared.u32 	%r35, [%r34];
	add.s32 	%r36, %r35, %r60;
	st.shared.u32 	[%r34], %r36;
	bar.sync 	0;
	// inline asm
	mov.u32 	%r37, %ntid.x;
	// inline asm
	shl.b32 	%r59, %r59, 1;
	setp.lt.u32 	%p5, %r59, %r37;
	@%p5 bra 	BB3_7;

BB3_11:
	@!%p1 bra 	BB3_13;

	// inline asm
	mov.u32 	%r38, %tid.x;
	// inline asm
	shl.b32 	%r39, %r38, 2;
	ld.param.u32 	%r52, [computeBucketPositions_param_2];
	add.s32 	%r40, %r52, %r39;
	ld.shared.u32 	%r41, [%r40];
	add.s32 	%r42, %r41, %r57;
	st.global.u32 	[%r6], %r42;

BB3_13:
	// inline asm
	mov.u32 	%r43, %ntid.x;
	// inline asm
	shl.b32 	%r45, %r43, 2;
	ld.param.u32 	%r51, [computeBucketPositions_param_2];
	add.s32 	%r46, %r45, %r51;
	ld.shared.u32 	%r47, [%r46+-4];
	add.s32 	%r57, %r47, %r57;
	// inline asm
	mov.u32 	%r44, %ntid.x;
	// inline asm
	add.s32 	%r56, %r44, %r56;
	ld.param.u32 	%r48, [computeBucketPositions_param_0];
	setp.lt.u32 	%p6, %r56, %r48;
	@%p6 bra 	BB3_2;

BB3_14:
	ret;
}

.entry copyDataToBuckets(
	.param .u32 .ptr .global .align 8 copyDataToBuckets_param_0,
	.param .u32 .ptr .global .align 8 copyDataToBuckets_param_1,
	.param .u32 copyDataToBuckets_param_2,
	.param .u32 .ptr .global .align 4 copyDataToBuckets_param_3,
	.param .u32 .ptr .global .align 4 copyDataToBuckets_param_4,
	.param .u32 .ptr .global .align 4 copyDataToBuckets_param_5
)
{
	.reg .pred 	%p<4>;
	.reg .s32 	%r<43>;


	ld.param.u32 	%r3, [copyDataToBuckets_param_2];
	// inline asm
	mov.u32 	%r13, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r14, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r15, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r16, %tid.x;
	// inline asm
	add.s32 	%r17, %r16, %r13;
	mad.lo.s32 	%r41, %r15, %r14, %r17;
	setp.ge.u32 	%p1, %r41, %r3;
	@%p1 bra 	BB4_5;

BB4_1:
	shl.b32 	%r18, %r41, 3;
	ld.param.u32 	%r35, [copyDataToBuckets_param_0];
	add.s32 	%r19, %r35, %r18;
	ld.global.v2.u32 	{%r33, %r34}, [%r19];
	shl.b32 	%r20, %r41, 2;
	ld.param.u32 	%r39, [copyDataToBuckets_param_4];
	add.s32 	%r21, %r39, %r20;
	ld.global.u32 	%r9, [%r21];
	setp.eq.s32 	%p2, %r9, 0;
	@%p2 bra 	BB4_3;

	shl.b32 	%r22, %r9, 2;
	ld.param.u32 	%r38, [copyDataToBuckets_param_3];
	add.s32 	%r23, %r22, %r38;
	ld.global.u32 	%r42, [%r23+-4];
	bra.uni 	BB4_4;

BB4_3:
	mov.u32 	%r42, 0;

BB4_4:
	ld.param.u32 	%r40, [copyDataToBuckets_param_5];
	add.s32 	%r28, %r40, %r20;
	ld.global.u32 	%r29, [%r28];
	add.s32 	%r30, %r29, %r42;
	shl.b32 	%r31, %r30, 3;
	ld.param.u32 	%r36, [copyDataToBuckets_param_1];
	add.s32 	%r32, %r36, %r31;
	st.global.v2.u32 	[%r32], {%r33, %r34};
	// inline asm
	mov.u32 	%r25, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r26, %ntid.x;
	// inline asm
	mad.lo.s32 	%r41, %r26, %r25, %r41;
	ld.param.u32 	%r37, [copyDataToBuckets_param_2];
	setp.lt.u32 	%p3, %r41, %r37;
	@%p3 bra 	BB4_1;

BB4_5:
	ret;
}

.entry sortBuckets(
	.param .u32 .ptr .global .align 8 sortBuckets_param_0,
	.param .u32 .ptr .global .align 8 sortBuckets_param_1,
	.param .u32 sortBuckets_param_2,
	.param .u32 .ptr .global .align 4 sortBuckets_param_3,
	.param .u32 .ptr .shared .align 8 sortBuckets_param_4
)
{
	.reg .pred 	%p<33>;
	.reg .s32 	%r<150>;


	ld.param.u32 	%r3, [sortBuckets_param_2];
	// inline asm
	mov.u32 	%r50, %elwreg0;
	// inline asm
	// inline asm
	mov.u32 	%r51, %ctaid.x;
	// inline asm
	add.s32 	%r137, %r51, %r50;
	setp.ge.u32 	%p8, %r137, %r3;
	@%p8 bra 	BB5_47;

BB5_1:
	setp.eq.s32 	%p9, %r137, 0;
	@%p9 bra 	BB5_3;

	shl.b32 	%r52, %r137, 2;
	ld.param.u32 	%r131, [sortBuckets_param_3];
	add.s32 	%r53, %r52, %r131;
	ldu.global.u32 	%r138, [%r53+-4];
	bra.uni 	BB5_4;

BB5_3:
	mov.u32 	%r138, 0;

BB5_4:
	shl.b32 	%r57, %r137, 2;
	ld.param.u32 	%r130, [sortBuckets_param_3];
	add.s32 	%r58, %r130, %r57;
	ldu.global.u32 	%r59, [%r58];
	sub.s32 	%r10, %r59, %r138;
	// inline asm
	mov.u32 	%r55, %ntid.x;
	// inline asm
	setp.gt.u32 	%p10, %r10, %r55;
	// inline asm
	mov.u32 	%r56, %tid.x;
	// inline asm
	setp.lt.u32 	%p1, %r56, %r10;
	mov.u32 	%r143, %r56;
	@%p10 bra 	BB5_24;

	// inline asm
	mov.u32 	%r60, %tid.x;
	// inline asm
	@%p1 bra 	BB5_7;

	shl.b32 	%r61, %r60, 3;
	ld.param.u32 	%r136, [sortBuckets_param_4];
	add.s32 	%r62, %r136, %r61;
	mov.u32 	%r63, 2147483647;
	st.shared.v2.u32 	[%r62], {%r63, %r63};
	bra.uni 	BB5_8;

BB5_7:
	add.s32 	%r65, %r60, %r138;
	shl.b32 	%r66, %r65, 3;
	ld.param.u32 	%r128, [sortBuckets_param_1];
	add.s32 	%r67, %r128, %r66;
	ld.global.v2.u32 	{%r120, %r121}, [%r67];
	// inline asm
	mov.u32 	%r64, %tid.x;
	// inline asm
	shl.b32 	%r68, %r64, 3;
	ld.param.u32 	%r135, [sortBuckets_param_4];
	add.s32 	%r69, %r135, %r68;
	st.shared.v2.u32 	[%r69], {%r120, %r121};

BB5_8:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r70, %ntid.x;
	// inline asm
	setp.lt.u32 	%p11, %r70, 2;
	@%p11 bra 	BB5_22;

	mov.u32 	%r139, 2;

BB5_10:
	shr.u32 	%r140, %r139, 1;
	setp.eq.s32 	%p12, %r140, 0;
	@%p12 bra 	BB5_21;

BB5_11:
	// inline asm
	mov.u32 	%r72, %tid.x;
	// inline asm
	xor.b32  	%r16, %r72, %r140;
	// inline asm
	mov.u32 	%r73, %tid.x;
	// inline asm
	setp.le.u32 	%p13, %r16, %r73;
	@%p13 bra 	BB5_20;

	// inline asm
	mov.u32 	%r74, %tid.x;
	// inline asm
	shl.b32 	%r76, %r74, 3;
	ld.param.u32 	%r134, [sortBuckets_param_4];
	add.s32 	%r77, %r134, %r76;
	ld.shared.v2.u32 	{%r118, %r119}, [%r77];
	shl.b32 	%r78, %r16, 3;
	add.s32 	%r17, %r134, %r78;
	ld.shared.v2.u32 	{%r116, %r117}, [%r17];
	// inline asm
	mov.u32 	%r75, %tid.x;
	// inline asm
	and.b32  	%r79, %r75, %r139;
	setp.eq.s32 	%p2, %r79, 0;
	@%p2 bra 	BB5_14;

	mov.u32 	%r141, %r117;
	bra.uni 	BB5_15;

BB5_14:
	mov.u32 	%r141, %r119;

BB5_15:
	@%p2 bra 	BB5_17;

	mov.u32 	%r142, %r119;
	bra.uni 	BB5_18;

BB5_17:
	mov.u32 	%r142, %r117;

BB5_18:
	setp.le.s32 	%p14, %r141, %r142;
	@%p14 bra 	BB5_20;

	// inline asm
	mov.u32 	%r80, %tid.x;
	// inline asm
	shl.b32 	%r81, %r80, 3;
	ld.param.u32 	%r133, [sortBuckets_param_4];
	add.s32 	%r82, %r133, %r81;
	st.shared.v2.u32 	[%r82], {%r116, %r117};
	st.shared.v2.u32 	[%r17], {%r118, %r119};

BB5_20:
	bar.sync 	0;
	shr.u32 	%r140, %r140, 1;
	setp.ne.s32 	%p15, %r140, 0;
	@%p15 bra 	BB5_11;

BB5_21:
	shl.b32 	%r139, %r139, 1;
	// inline asm
	mov.u32 	%r83, %ntid.x;
	// inline asm
	setp.le.u32 	%p16, %r139, %r83;
	@%p16 bra 	BB5_10;

BB5_22:
	// inline asm
	mov.u32 	%r84, %tid.x;
	// inline asm
	setp.ge.u32 	%p17, %r84, %r10;
	@%p17 bra 	BB5_46;

	// inline asm
	mov.u32 	%r85, %tid.x;
	// inline asm
	shl.b32 	%r87, %r85, 3;
	ld.param.u32 	%r132, [sortBuckets_param_4];
	add.s32 	%r88, %r132, %r87;
	ld.shared.v2.u32 	{%r114, %r115}, [%r88];
	// inline asm
	mov.u32 	%r86, %tid.x;
	// inline asm
	add.s32 	%r89, %r86, %r138;
	shl.b32 	%r90, %r89, 3;
	ld.param.u32 	%r126, [sortBuckets_param_0];
	add.s32 	%r91, %r126, %r90;
	st.global.v2.u32 	[%r91], {%r114, %r115};
	bra.uni 	BB5_46;

BB5_24:
	@!%p1 bra 	BB5_26;

BB5_25:
	add.s32 	%r93, %r143, %r138;
	shl.b32 	%r94, %r93, 3;
	ld.param.u32 	%r127, [sortBuckets_param_1];
	add.s32 	%r95, %r127, %r94;
	ld.param.u32 	%r125, [sortBuckets_param_0];
	add.s32 	%r96, %r125, %r94;
	ld.global.v2.u32 	{%r112, %r113}, [%r95];
	st.global.v2.u32 	[%r96], {%r112, %r113};
	// inline asm
	mov.u32 	%r92, %ntid.x;
	// inline asm
	add.s32 	%r143, %r92, %r143;
	setp.lt.u32 	%p18, %r143, %r10;
	@%p18 bra 	BB5_25;

BB5_26:
	membar.gl;
	bar.sync 	0;
	shl.b32 	%r28, %r10, 1;
	setp.lt.u32 	%p19, %r28, 3;
	@%p19 bra 	BB5_46;

	mov.u32 	%r144, 2;

BB5_28:
	shr.u32 	%r145, %r144, 1;
	setp.eq.s32 	%p20, %r145, 0;
	@%p20 bra 	BB5_45;

	shl.b32 	%r98, %r144, 1;
	setp.lt.u32 	%p3, %r98, %r28;

BB5_30:
	// inline asm
	mov.u32 	%r99, %tid.x;
	// inline asm
	setp.ge.u32 	%p21, %r99, %r10;
	mov.u32 	%r146, %r99;
	@%p21 bra 	BB5_44;

BB5_31:
	xor.b32  	%r34, %r146, %r145;
	setp.gt.u32 	%p22, %r34, %r146;
	setp.lt.u32 	%p23, %r34, %r10;
	and.pred  	%p24, %p22, %p23;
	@!%p24 bra 	BB5_43;

	add.s32 	%r100, %r146, %r138;
	shl.b32 	%r101, %r100, 3;
	ld.param.u32 	%r124, [sortBuckets_param_0];
	add.s32 	%r35, %r124, %r101;
	ld.global.v2.u32 	{%r110, %r111}, [%r35];
	add.s32 	%r102, %r34, %r138;
	shl.b32 	%r103, %r102, 3;
	add.s32 	%r36, %r124, %r103;
	ld.global.v2.u32 	{%r108, %r109}, [%r36];
	and.b32  	%r104, %r146, %r144;
	setp.eq.s32 	%p32, %r104, 0;
	@%p3 bra 	BB5_33;
	bra.uni 	BB5_35;

BB5_33:
	mov.u32 	%r147, %r98;

BB5_34:
	mov.u32 	%r38, %r147;
	and.b32  	%r105, %r38, %r146;
	setp.eq.s32 	%p25, %r105, 0;
	xor.pred  	%p32, %p32, %p25;
	shl.b32 	%r39, %r38, 1;
	setp.lt.u32 	%p26, %r39, %r28;
	mov.u32 	%r147, %r39;
	@%p26 bra 	BB5_34;

BB5_35:
	@%p32 bra 	BB5_37;

	mov.u32 	%r148, %r109;
	bra.uni 	BB5_38;

BB5_37:
	mov.u32 	%r148, %r111;

BB5_38:
	@%p32 bra 	BB5_40;

	mov.u32 	%r149, %r111;
	bra.uni 	BB5_41;

BB5_40:
	mov.u32 	%r149, %r109;

BB5_41:
	setp.le.s32 	%p27, %r148, %r149;
	@%p27 bra 	BB5_43;

	st.global.v2.u32 	[%r35], {%r108, %r109};
	st.global.v2.u32 	[%r36], {%r110, %r111};

BB5_43:
	// inline asm
	mov.u32 	%r106, %ntid.x;
	// inline asm
	add.s32 	%r146, %r106, %r146;
	setp.lt.u32 	%p28, %r146, %r10;
	@%p28 bra 	BB5_31;

BB5_44:
	membar.gl;
	bar.sync 	0;
	shr.u32 	%r145, %r145, 1;
	setp.ne.s32 	%p29, %r145, 0;
	@%p29 bra 	BB5_30;

BB5_45:
	shl.b32 	%r144, %r144, 1;
	setp.lt.u32 	%p30, %r144, %r28;
	@%p30 bra 	BB5_28;

BB5_46:
	// inline asm
	mov.u32 	%r107, %elwreg6;
	// inline asm
	add.s32 	%r137, %r107, %r137;
	ld.param.u32 	%r129, [sortBuckets_param_2];
	setp.lt.u32 	%p31, %r137, %r129;
	@%p31 bra 	BB5_1;

BB5_47:
	ret;
}



//
// Generated by LWPU LWVM Compiler
// Compiler built on Thu May 15 11:00:55 2014 (1400169655)
// Driver 
//

//.version 3.0
//.target sm_30, texmode_independent
//.address_size 32


.entry execFFT(
	.param .u32 .ptr .global .align 8 execFFT_param_0,
	.param .u32 .ptr .global .align 8 execFFT_param_1,
	.param .u32 execFFT_param_2,
	.param .u32 .ptr .shared .align 8 execFFT_param_3,
	.param .u32 .ptr .shared .align 8 execFFT_param_4,
	.param .u32 .ptr .shared .align 8 execFFT_param_5
)
{
	.reg .f32 	%f<388>;
	.reg .pred 	%p<10>;
	.reg .s32 	%r<221>;


	// inline asm
	mov.u32 	%r16, %tid.x;
	// inline asm
	setp.gt.s32 	%p2, %r16, 62;
	mov.u32 	%r219, %r16;
	@%p2 bra 	BB0_3;

	ld.param.u32 	%r206, [execFFT_param_2];
	shl.b32 	%r17, %r206, 1;
	neg.s32 	%r8, %r17;

BB0_2:
	mul.lo.s32 	%r19, %r8, %r219;
	cvt.rn.f32.s32 	%f5, %r19;
	mul.ftz.f32 	%f6, %f5, 0f40490FDB;
	div.rn.ftz.f32 	%f4, %f6, 0f427C0000;
	// inline asm
	cos.approx.f32 	%f1, %f4;
	// inline asm
	// inline asm
	sin.approx.f32 	%f3, %f4;
	// inline asm
	shl.b32 	%r20, %r219, 3;
	ld.param.u32 	%r210, [execFFT_param_3];
	add.s32 	%r21, %r210, %r20;
	st.shared.v2.f32 	[%r21], {%f1, %f3};
	// inline asm
	mov.u32 	%r18, %ntid.x;
	// inline asm
	add.s32 	%r219, %r18, %r219;
	setp.lt.s32 	%p3, %r219, 63;
	@%p3 bra 	BB0_2;

BB0_3:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r22, %elwreg0;
	// inline asm
	// inline asm
	mov.u32 	%r23, %ctaid.x;
	// inline asm
	add.s32 	%r24, %r23, %r22;
	shl.b32 	%r220, %r24, 2;
	setp.gt.s32 	%p4, %r220, 3968;
	@%p4 bra 	BB0_16;

	ld.param.u32 	%r205, [execFFT_param_2];
	neg.s32 	%r25, %r205;
	cvt.rn.f32.s32 	%f7, %r25;
	mul.ftz.f32 	%f8, %f7, 0f3EE1C552;
	mul.ftz.f32 	%f10, %f7, 0f3EAE86E6;
	mul.ftz.f32 	%f12, %f7, 0fBF08B237;
	mul.ftz.f32 	%f14, %f7, 0f3F5FF5AA;
	cvt.rn.f32.s32 	%f16, %r205;
	mul.ftz.f32 	%f17, %f16, 0f3F5DB3D7;

BB0_5:
	// inline asm
	mov.u32 	%r26, %tid.x;
	// inline asm
	mul.hi.u32 	%r27, %r26, 68174085;
	sub.s32 	%r28, %r26, %r27;
	shr.u32 	%r29, %r28, 1;
	add.s32 	%r30, %r29, %r27;
	shr.u32 	%r31, %r30, 5;
	add.s32 	%r32, %r31, %r220;
	mul.hi.s32 	%r33, %r32, -2113396605;
	add.s32 	%r34, %r33, %r32;
	shr.u32 	%r35, %r34, 31;
	shr.s32 	%r36, %r34, 5;
	add.s32 	%r13, %r36, %r35;
	mul.lo.s32 	%r37, %r13, 63;
	sub.s32 	%r14, %r32, %r37;
	setp.lt.s32 	%p1, %r32, 3969;
	setp.gt.s32 	%p5, %r32, 3968;
	@%p5 bra 	BB0_7;

	mul.lo.s32 	%r40, %r13, 3969;
	// inline asm
	mov.u32 	%r38, %tid.x;
	// inline asm
	mul.hi.u32 	%r41, %r38, 68174085;
	sub.s32 	%r42, %r38, %r41;
	shr.u32 	%r43, %r42, 1;
	add.s32 	%r44, %r43, %r41;
	shr.u32 	%r45, %r44, 5;
	mul.lo.s32 	%r46, %r45, 63;
	sub.s32 	%r47, %r38, %r46;
	mad.lo.s32 	%r48, %r14, 63, %r40;
	add.s32 	%r49, %r48, %r47;
	shl.b32 	%r50, %r49, 3;
	ld.param.u32 	%r203, [execFFT_param_0];
	add.s32 	%r51, %r203, %r50;
	ld.global.v2.f32 	{%f364, %f365}, [%r51];
	// inline asm
	mov.u32 	%r39, %tid.x;
	// inline asm
	shl.b32 	%r52, %r39, 3;
	ld.param.u32 	%r214, [execFFT_param_4];
	add.s32 	%r53, %r214, %r52;
	st.shared.v2.f32 	[%r53], {%f364, %f365};

BB0_7:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r54, %tid.x;
	// inline asm
	setp.gt.u32 	%p6, %r54, 35;
	@%p6 bra 	BB0_9;

	// inline asm
	mov.u32 	%r55, %tid.x;
	// inline asm
	mul.hi.u32 	%r57, %r55, 954437177;
	shr.u32 	%r58, %r57, 1;
	// inline asm
	mov.u32 	%r56, %tid.x;
	// inline asm
	mul.lo.s32 	%r59, %r58, 9;
	sub.s32 	%r60, %r56, %r59;
	mad.lo.s32 	%r61, %r58, 63, %r60;
	shl.b32 	%r62, %r61, 3;
	ld.param.u32 	%r213, [execFFT_param_4];
	add.s32 	%r63, %r213, %r62;
	ld.shared.v2.f32 	{%f212, %f213}, [%r63+432];
	ld.shared.v2.f32 	{%f214, %f215}, [%r63+72];
	add.ftz.f32 	%f216, %f214, %f212;
	add.ftz.f32 	%f217, %f215, %f213;
	sub.ftz.f32 	%f218, %f214, %f212;
	sub.ftz.f32 	%f219, %f215, %f213;
	ld.shared.v2.f32 	{%f220, %f221}, [%r63+360];
	ld.shared.v2.f32 	{%f222, %f223}, [%r63+144];
	add.ftz.f32 	%f224, %f222, %f220;
	add.ftz.f32 	%f225, %f223, %f221;
	sub.ftz.f32 	%f226, %f222, %f220;
	sub.ftz.f32 	%f227, %f223, %f221;
	ld.shared.v2.f32 	{%f228, %f229}, [%r63+288];
	ld.shared.v2.f32 	{%f230, %f231}, [%r63+216];
	add.ftz.f32 	%f232, %f228, %f230;
	add.ftz.f32 	%f233, %f229, %f231;
	sub.ftz.f32 	%f234, %f228, %f230;
	sub.ftz.f32 	%f235, %f229, %f231;
	add.ftz.f32 	%f236, %f224, %f216;
	add.ftz.f32 	%f237, %f225, %f217;
	add.ftz.f32 	%f238, %f234, %f226;
	add.ftz.f32 	%f239, %f235, %f227;
	ld.shared.v2.f32 	{%f240, %f241}, [%r63];
	add.ftz.f32 	%f242, %f240, %f236;
	add.ftz.f32 	%f243, %f241, %f237;
	add.ftz.f32 	%f244, %f242, %f232;
	add.ftz.f32 	%f245, %f243, %f233;
	add.ftz.f32 	%f246, %f236, %f232;
	add.ftz.f32 	%f247, %f237, %f233;
	mov.f32 	%f19, 0fBF955555;
	sub.ftz.f32 	%f250, %f216, %f232;
	sub.ftz.f32 	%f251, %f217, %f233;
	mov.f32 	%f20, 0f3F4A47B2;
	mul.ftz.f32 	%f254, %f250, %f20;
	mul.ftz.f32 	%f255, %f251, %f20;
	sub.ftz.f32 	%f256, %f232, %f224;
	sub.ftz.f32 	%f257, %f233, %f225;
	mov.f32 	%f21, 0f3D64C772;
	mul.ftz.f32 	%f260, %f256, %f21;
	mul.ftz.f32 	%f261, %f257, %f21;
	sub.ftz.f32 	%f262, %f224, %f216;
	sub.ftz.f32 	%f263, %f225, %f217;
	mov.f32 	%f22, 0f3F3BFB3B;
	mul.ftz.f32 	%f266, %f262, %f22;
	mul.ftz.f32 	%f267, %f263, %f22;
	add.ftz.f32 	%f268, %f238, %f218;
	add.ftz.f32 	%f269, %f239, %f219;
	mul.ftz.f32 	%f270, %f8, %f268;
	mul.ftz.f32 	%f271, %f8, %f269;
	sub.ftz.f32 	%f274, %f218, %f234;
	sub.ftz.f32 	%f275, %f219, %f235;
	sub.ftz.f32 	%f276, %f234, %f226;
	sub.ftz.f32 	%f277, %f235, %f227;
	mul.ftz.f32 	%f278, %f12, %f276;
	mul.ftz.f32 	%f279, %f12, %f277;
	sub.ftz.f32 	%f282, %f226, %f218;
	sub.ftz.f32 	%f283, %f227, %f219;
	mul.ftz.f32 	%f284, %f14, %f282;
	mul.ftz.f32 	%f285, %f14, %f283;
	fma.rn.ftz.f32 	%f288, %f246, %f19, %f244;
	fma.rn.ftz.f32 	%f289, %f247, %f19, %f245;
	fma.rn.ftz.f32 	%f290, %f250, %f20, %f260;
	fma.rn.ftz.f32 	%f291, %f251, %f20, %f261;
	neg.f32 	%f292, %f256;
	neg.f32 	%f293, %f257;
	fma.rn.ftz.f32 	%f294, %f292, %f21, %f266;
	fma.rn.ftz.f32 	%f295, %f293, %f21, %f267;
	neg.ftz.f32 	%f296, %f254;
	neg.ftz.f32 	%f297, %f255;
	neg.f32 	%f298, %f262;
	neg.f32 	%f299, %f263;
	fma.rn.ftz.f32 	%f300, %f298, %f22, %f296;
	fma.rn.ftz.f32 	%f301, %f299, %f22, %f297;
	fma.rn.ftz.f32 	%f302, %f10, %f274, %f278;
	fma.rn.ftz.f32 	%f303, %f10, %f275, %f279;
	neg.f32 	%f306, %f12;
	fma.rn.ftz.f32 	%f308, %f306, %f276, %f284;
	fma.rn.ftz.f32 	%f309, %f306, %f277, %f285;
	neg.ftz.f32 	%f310, %f284;
	neg.ftz.f32 	%f311, %f285;
	neg.f32 	%f312, %f10;
	fma.rn.ftz.f32 	%f314, %f312, %f274, %f310;
	fma.rn.ftz.f32 	%f315, %f312, %f275, %f311;
	add.ftz.f32 	%f316, %f288, %f290;
	add.ftz.f32 	%f317, %f289, %f291;
	add.ftz.f32 	%f318, %f288, %f294;
	add.ftz.f32 	%f319, %f289, %f295;
	add.ftz.f32 	%f320, %f288, %f300;
	add.ftz.f32 	%f321, %f289, %f301;
	add.ftz.f32 	%f25, %f303, %f271;
	add.ftz.f32 	%f28, %f302, %f270;
	neg.ftz.f32 	%f29, %f28;
	add.ftz.f32 	%f31, %f309, %f271;
	add.ftz.f32 	%f33, %f308, %f270;
	neg.ftz.f32 	%f34, %f33;
	add.ftz.f32 	%f36, %f315, %f271;
	add.ftz.f32 	%f38, %f314, %f270;
	neg.ftz.f32 	%f39, %f38;
	mad.lo.s32 	%r64, %r60, 6, %r61;
	shl.b32 	%r65, %r64, 3;
	ld.param.u32 	%r218, [execFFT_param_5];
	add.s32 	%r66, %r218, %r65;
	st.shared.v2.f32 	[%r66], {%f244, %f245};
	mul.lo.s32 	%r67, %r60, 63;
	mul.hi.s32 	%r68, %r67, -2113396605;
	mad.lo.s32 	%r69, %r60, 63, %r68;
	shr.u32 	%r70, %r69, 31;
	shr.s32 	%r71, %r69, 5;
	add.s32 	%r72, %r71, %r70;
	shl.b32 	%r73, %r72, 3;
	ld.param.u32 	%r209, [execFFT_param_3];
	add.s32 	%r74, %r209, %r73;
	sub.ftz.f32 	%f328, %f316, %f25;
	sub.ftz.f32 	%f329, %f317, %f29;
	ld.shared.v2.f32 	{%f330, %f331}, [%r74];
	mul.ftz.f32 	%f42, %f330, %f328;
	neg.f32 	%f45, %f331;
	fma.rn.ftz.f32 	%f46, %f45, %f329, %f42;
	mul.ftz.f32 	%f47, %f331, %f328;
	fma.rn.ftz.f32 	%f48, %f330, %f329, %f47;
	st.shared.v2.f32 	[%r66+8], {%f46, %f48};
	mul.lo.s32 	%r75, %r60, 126;
	mul.hi.s32 	%r76, %r75, -2113396605;
	mad.lo.s32 	%r77, %r60, 126, %r76;
	shr.u32 	%r78, %r77, 31;
	shr.s32 	%r79, %r77, 5;
	add.s32 	%r80, %r79, %r78;
	shl.b32 	%r81, %r80, 3;
	add.s32 	%r82, %r209, %r81;
	sub.ftz.f32 	%f334, %f320, %f36;
	sub.ftz.f32 	%f335, %f321, %f39;
	ld.shared.v2.f32 	{%f336, %f337}, [%r82];
	mul.ftz.f32 	%f51, %f336, %f334;
	neg.f32 	%f54, %f337;
	fma.rn.ftz.f32 	%f55, %f54, %f335, %f51;
	mul.ftz.f32 	%f56, %f337, %f334;
	fma.rn.ftz.f32 	%f57, %f336, %f335, %f56;
	st.shared.v2.f32 	[%r66+16], {%f55, %f57};
	mul.lo.s32 	%r83, %r60, 189;
	mul.hi.s32 	%r84, %r83, -2113396605;
	mad.lo.s32 	%r85, %r60, 189, %r84;
	shr.u32 	%r86, %r85, 31;
	shr.s32 	%r87, %r85, 5;
	add.s32 	%r88, %r87, %r86;
	shl.b32 	%r89, %r88, 3;
	add.s32 	%r90, %r209, %r89;
	add.ftz.f32 	%f340, %f318, %f31;
	add.ftz.f32 	%f341, %f319, %f34;
	ld.shared.v2.f32 	{%f342, %f343}, [%r90];
	mul.ftz.f32 	%f60, %f342, %f340;
	neg.f32 	%f63, %f343;
	fma.rn.ftz.f32 	%f64, %f63, %f341, %f60;
	mul.ftz.f32 	%f65, %f343, %f340;
	fma.rn.ftz.f32 	%f66, %f342, %f341, %f65;
	st.shared.v2.f32 	[%r66+24], {%f64, %f66};
	mul.lo.s32 	%r91, %r60, 252;
	mul.hi.s32 	%r92, %r91, -2113396605;
	mad.lo.s32 	%r93, %r60, 252, %r92;
	shr.u32 	%r94, %r93, 31;
	shr.s32 	%r95, %r93, 5;
	add.s32 	%r96, %r95, %r94;
	shl.b32 	%r97, %r96, 3;
	add.s32 	%r98, %r209, %r97;
	sub.ftz.f32 	%f346, %f318, %f31;
	sub.ftz.f32 	%f347, %f319, %f34;
	ld.shared.v2.f32 	{%f348, %f349}, [%r98];
	mul.ftz.f32 	%f69, %f348, %f346;
	neg.f32 	%f72, %f349;
	fma.rn.ftz.f32 	%f73, %f72, %f347, %f69;
	mul.ftz.f32 	%f74, %f349, %f346;
	fma.rn.ftz.f32 	%f75, %f348, %f347, %f74;
	st.shared.v2.f32 	[%r66+32], {%f73, %f75};
	mul.lo.s32 	%r99, %r60, 315;
	mul.hi.s32 	%r100, %r99, -2113396605;
	mad.lo.s32 	%r101, %r60, 315, %r100;
	shr.u32 	%r102, %r101, 31;
	shr.s32 	%r103, %r101, 5;
	add.s32 	%r104, %r103, %r102;
	shl.b32 	%r105, %r104, 3;
	add.s32 	%r106, %r209, %r105;
	add.ftz.f32 	%f352, %f320, %f36;
	add.ftz.f32 	%f353, %f321, %f39;
	ld.shared.v2.f32 	{%f354, %f355}, [%r106];
	mul.ftz.f32 	%f78, %f354, %f352;
	neg.f32 	%f81, %f355;
	fma.rn.ftz.f32 	%f82, %f81, %f353, %f78;
	mul.ftz.f32 	%f83, %f355, %f352;
	fma.rn.ftz.f32 	%f84, %f354, %f353, %f83;
	st.shared.v2.f32 	[%r66+40], {%f82, %f84};
	mul.lo.s32 	%r107, %r60, 378;
	mul.hi.s32 	%r108, %r107, -2113396605;
	mad.lo.s32 	%r109, %r60, 378, %r108;
	shr.u32 	%r110, %r109, 31;
	shr.s32 	%r111, %r109, 5;
	add.s32 	%r112, %r111, %r110;
	shl.b32 	%r113, %r112, 3;
	add.s32 	%r114, %r209, %r113;
	add.ftz.f32 	%f358, %f316, %f25;
	add.ftz.f32 	%f359, %f317, %f29;
	ld.shared.v2.f32 	{%f360, %f361}, [%r114];
	mul.ftz.f32 	%f87, %f360, %f358;
	neg.f32 	%f90, %f361;
	fma.rn.ftz.f32 	%f91, %f90, %f359, %f87;
	mul.ftz.f32 	%f92, %f361, %f358;
	fma.rn.ftz.f32 	%f93, %f360, %f359, %f92;
	st.shared.v2.f32 	[%r66+48], {%f91, %f93};

BB0_9:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r115, %tid.x;
	// inline asm
	setp.gt.u32 	%p7, %r115, 83;
	@%p7 bra 	BB0_11;

	// inline asm
	mov.u32 	%r116, %tid.x;
	// inline asm
	mul.hi.u32 	%r118, %r116, -2045222521;
	sub.s32 	%r119, %r116, %r118;
	shr.u32 	%r120, %r119, 1;
	add.s32 	%r121, %r120, %r118;
	shr.u32 	%r122, %r121, 4;
	// inline asm
	mov.u32 	%r117, %tid.x;
	// inline asm
	mul.lo.s32 	%r123, %r122, 21;
	sub.s32 	%r124, %r117, %r123;
	mad.lo.s32 	%r125, %r122, 63, %r124;
	mul.hi.s32 	%r126, %r124, -1840700269;
	add.s32 	%r127, %r126, %r124;
	shr.u32 	%r128, %r127, 31;
	shr.s32 	%r129, %r127, 2;
	add.s32 	%r130, %r129, %r128;
	shl.b32 	%r131, %r125, 3;
	ld.param.u32 	%r217, [execFFT_param_5];
	add.s32 	%r132, %r217, %r131;
	ld.shared.v2.f32 	{%f180, %f181}, [%r132+336];
	ld.shared.v2.f32 	{%f182, %f183}, [%r132+168];
	add.ftz.f32 	%f184, %f182, %f180;
	add.ftz.f32 	%f185, %f183, %f181;
	mov.f32 	%f94, 0f3F000000;
	ld.shared.v2.f32 	{%f188, %f189}, [%r132];
	neg.f32 	%f190, %f184;
	neg.f32 	%f191, %f185;
	fma.rn.ftz.f32 	%f192, %f190, %f94, %f188;
	fma.rn.ftz.f32 	%f193, %f191, %f94, %f189;
	sub.ftz.f32 	%f97, %f183, %f181;
	sub.ftz.f32 	%f100, %f180, %f182;
	add.ftz.f32 	%f196, %f188, %f184;
	add.ftz.f32 	%f197, %f189, %f185;
	mad.lo.s32 	%r133, %r130, 14, %r125;
	shl.b32 	%r134, %r133, 3;
	ld.param.u32 	%r212, [execFFT_param_4];
	add.s32 	%r135, %r212, %r134;
	st.shared.v2.f32 	[%r135], {%f196, %f197};
	mul.lo.s32 	%r136, %r130, 63;
	mul.hi.s32 	%r137, %r136, 954437177;
	shr.u32 	%r138, %r137, 31;
	shr.u32 	%r139, %r137, 1;
	add.s32 	%r140, %r139, %r138;
	shl.b32 	%r141, %r140, 3;
	ld.param.u32 	%r208, [execFFT_param_3];
	add.s32 	%r142, %r208, %r141;
	fma.rn.ftz.f32 	%f198, %f17, %f97, %f192;
	fma.rn.ftz.f32 	%f199, %f17, %f100, %f193;
	ld.shared.v2.f32 	{%f200, %f201}, [%r142];
	mul.ftz.f32 	%f103, %f200, %f198;
	neg.f32 	%f106, %f201;
	fma.rn.ftz.f32 	%f107, %f106, %f199, %f103;
	mul.ftz.f32 	%f108, %f201, %f198;
	fma.rn.ftz.f32 	%f109, %f200, %f199, %f108;
	st.shared.v2.f32 	[%r135+56], {%f107, %f109};
	mul.lo.s32 	%r143, %r130, 126;
	mul.hi.s32 	%r144, %r143, 954437177;
	shr.u32 	%r145, %r144, 31;
	shr.u32 	%r146, %r144, 1;
	add.s32 	%r147, %r146, %r145;
	shl.b32 	%r148, %r147, 3;
	add.s32 	%r149, %r208, %r148;
	neg.f32 	%f204, %f17;
	fma.rn.ftz.f32 	%f206, %f204, %f97, %f192;
	fma.rn.ftz.f32 	%f207, %f204, %f100, %f193;
	ld.shared.v2.f32 	{%f208, %f209}, [%r149];
	mul.ftz.f32 	%f112, %f208, %f206;
	neg.f32 	%f115, %f209;
	fma.rn.ftz.f32 	%f116, %f115, %f207, %f112;
	mul.ftz.f32 	%f117, %f209, %f206;
	fma.rn.ftz.f32 	%f118, %f208, %f207, %f117;
	st.shared.v2.f32 	[%r135+112], {%f116, %f118};

BB0_11:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r150, %tid.x;
	// inline asm
	setp.gt.u32 	%p8, %r150, 83;
	@%p8 bra 	BB0_13;

	// inline asm
	mov.u32 	%r151, %tid.x;
	// inline asm
	mul.hi.u32 	%r153, %r151, -2045222521;
	sub.s32 	%r154, %r151, %r153;
	shr.u32 	%r155, %r154, 1;
	add.s32 	%r156, %r155, %r153;
	shr.u32 	%r157, %r156, 4;
	// inline asm
	mov.u32 	%r152, %tid.x;
	// inline asm
	mul.lo.s32 	%r158, %r157, 21;
	sub.s32 	%r159, %r152, %r158;
	mad.lo.s32 	%r160, %r157, 63, %r159;
	mul.hi.s32 	%r161, %r159, 818089009;
	shr.u32 	%r162, %r161, 31;
	shr.s32 	%r163, %r161, 2;
	add.s32 	%r164, %r163, %r162;
	shl.b32 	%r165, %r160, 3;
	ld.param.u32 	%r211, [execFFT_param_4];
	add.s32 	%r166, %r211, %r165;
	ld.shared.v2.f32 	{%f146, %f147}, [%r166+336];
	ld.shared.v2.f32 	{%f148, %f149}, [%r166+168];
	add.ftz.f32 	%f150, %f148, %f146;
	add.ftz.f32 	%f151, %f149, %f147;
	mov.f32 	%f119, 0f3F000000;
	ld.shared.v2.f32 	{%f154, %f155}, [%r166];
	neg.f32 	%f156, %f150;
	neg.f32 	%f157, %f151;
	fma.rn.ftz.f32 	%f158, %f156, %f119, %f154;
	fma.rn.ftz.f32 	%f159, %f157, %f119, %f155;
	sub.ftz.f32 	%f122, %f149, %f147;
	sub.ftz.f32 	%f125, %f146, %f148;
	add.ftz.f32 	%f162, %f154, %f150;
	add.ftz.f32 	%f163, %f155, %f151;
	mad.lo.s32 	%r167, %r164, 42, %r160;
	shl.b32 	%r168, %r167, 3;
	ld.param.u32 	%r216, [execFFT_param_5];
	add.s32 	%r169, %r216, %r168;
	st.shared.v2.f32 	[%r169], {%f162, %f163};
	mul.lo.s32 	%r170, %r164, 63;
	mul.hi.s32 	%r171, %r170, -1431655765;
	mad.lo.s32 	%r172, %r164, 63, %r171;
	shr.u32 	%r173, %r172, 31;
	shr.u32 	%r174, %r172, 1;
	add.s32 	%r175, %r174, %r173;
	shl.b32 	%r176, %r175, 3;
	ld.param.u32 	%r207, [execFFT_param_3];
	add.s32 	%r177, %r207, %r176;
	fma.rn.ftz.f32 	%f164, %f17, %f122, %f158;
	fma.rn.ftz.f32 	%f165, %f17, %f125, %f159;
	ld.shared.v2.f32 	{%f168, %f169}, [%r177];
	mul.ftz.f32 	%f128, %f168, %f164;
	neg.f32 	%f131, %f169;
	fma.rn.ftz.f32 	%f132, %f131, %f165, %f128;
	mul.ftz.f32 	%f133, %f169, %f164;
	fma.rn.ftz.f32 	%f134, %f168, %f165, %f133;
	st.shared.v2.f32 	[%r169+168], {%f132, %f134};
	mul.lo.s32 	%r178, %r164, 126;
	mul.hi.s32 	%r179, %r178, -1431655765;
	mad.lo.s32 	%r180, %r164, 126, %r179;
	shr.u32 	%r181, %r180, 31;
	shr.u32 	%r182, %r180, 1;
	add.s32 	%r183, %r182, %r181;
	shl.b32 	%r184, %r183, 3;
	add.s32 	%r185, %r207, %r184;
	neg.f32 	%f172, %f17;
	fma.rn.ftz.f32 	%f174, %f172, %f122, %f158;
	fma.rn.ftz.f32 	%f175, %f172, %f125, %f159;
	ld.shared.v2.f32 	{%f176, %f177}, [%r185];
	mul.ftz.f32 	%f137, %f176, %f174;
	neg.f32 	%f140, %f177;
	fma.rn.ftz.f32 	%f141, %f140, %f175, %f137;
	mul.ftz.f32 	%f142, %f177, %f174;
	fma.rn.ftz.f32 	%f143, %f176, %f175, %f142;
	st.shared.v2.f32 	[%r169+336], {%f141, %f143};

BB0_13:
	bar.sync 	0;
	@!%p1 bra 	BB0_15;

	// inline asm
	mov.u32 	%r186, %tid.x;
	// inline asm
	shl.b32 	%r188, %r186, 3;
	ld.param.u32 	%r215, [execFFT_param_5];
	add.s32 	%r189, %r215, %r188;
	ld.shared.v2.f32 	{%f144, %f145}, [%r189];
	// inline asm
	mov.u32 	%r187, %tid.x;
	// inline asm
	mul.hi.u32 	%r190, %r187, 68174085;
	sub.s32 	%r191, %r187, %r190;
	shr.u32 	%r192, %r191, 1;
	add.s32 	%r193, %r192, %r190;
	shr.u32 	%r194, %r193, 5;
	mul.lo.s32 	%r195, %r194, 63;
	sub.s32 	%r196, %r187, %r195;
	mad.lo.s32 	%r197, %r14, 3969, %r13;
	mad.lo.s32 	%r198, %r196, 63, %r197;
	shl.b32 	%r199, %r198, 3;
	ld.param.u32 	%r204, [execFFT_param_1];
	add.s32 	%r200, %r204, %r199;
	st.global.v2.f32 	[%r200], {%f144, %f145};

BB0_15:
	membar.gl;
	bar.sync 	0;
	// inline asm
	mov.u32 	%r201, %elwreg6;
	// inline asm
	shl.b32 	%r202, %r201, 2;
	add.s32 	%r220, %r202, %r220;
	setp.lt.s32 	%p9, %r220, 3969;
	@%p9 bra 	BB0_5;

BB0_16:
	ret;
}



//
// Generated by LWPU LWVM Compiler
// Compiler built on Thu May 15 11:00:55 2014 (1400169655)
// Driver 
//

//.version 3.0
//.target sm_30, texmode_independent
//.address_size 32


.entry calcCenterOfMassMomentum(
	.param .u32 calcCenterOfMassMomentum_param_0,
	.param .u32 .ptr .global .align 16 calcCenterOfMassMomentum_param_1,
	.param .u32 .ptr .global .align 16 calcCenterOfMassMomentum_param_2,
	.param .u32 .ptr .shared .align 16 calcCenterOfMassMomentum_param_3
)
{
	.reg .f32 	%f<128>;
	.reg .pred 	%p<10>;
	.reg .s32 	%r<31>;


	ld.param.u32 	%r1, [calcCenterOfMassMomentum_param_0];
	// inline asm
	mov.u32 	%r10, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r11, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r12, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r13, %tid.x;
	// inline asm
	add.s32 	%r14, %r13, %r10;
	mad.lo.s32 	%r30, %r12, %r11, %r14;
	setp.lt.s32 	%p1, %r30, %r1;
	@%p1 bra 	BB0_2;

	mov.f32 	%f2, 0f00000000;
	mov.f32 	%f124, %f2;
	mov.f32 	%f125, %f2;
	mov.f32 	%f126, %f2;
	mov.f32 	%f127, %f2;
	bra.uni 	BB0_6;

BB0_2:
	mov.f32 	%f3, 0f00000000;
	mov.f32 	%f124, %f3;
	mov.f32 	%f125, %f3;
	mov.f32 	%f126, %f3;
	mov.f32 	%f127, %f3;

BB0_3:
	shl.b32 	%r15, %r30, 4;
	ld.param.u32 	%r27, [calcCenterOfMassMomentum_param_1];
	add.s32 	%r16, %r27, %r15;
	ld.global.v4.f32 	{%f108, %f109, %f110, %f111}, [%r16];
	setp.neu.ftz.f32 	%p2, %f111, 0f00000000;
	@%p2 bra 	BB0_4;
	bra.uni 	BB0_5;

BB0_4:
	div.approx.ftz.f32 	%f5, %f108, %f111;
	add.ftz.f32 	%f7, %f124, %f5;
	div.approx.ftz.f32 	%f9, %f109, %f111;
	add.ftz.f32 	%f11, %f125, %f9;
	div.approx.ftz.f32 	%f13, %f110, %f111;
	add.ftz.f32 	%f15, %f126, %f13;
	mov.f32 	%f124, %f7;
	mov.f32 	%f125, %f11;
	mov.f32 	%f126, %f15;
	mov.f32 	%f127, %f127;

BB0_5:
	// inline asm
	mov.u32 	%r17, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r18, %ntid.x;
	// inline asm
	mad.lo.s32 	%r30, %r18, %r17, %r30;
	ld.param.u32 	%r26, [calcCenterOfMassMomentum_param_0];
	setp.lt.s32 	%p3, %r30, %r26;
	@%p3 bra 	BB0_3;

BB0_6:
	// inline asm
	mov.u32 	%r19, %tid.x;
	// inline asm
	shl.b32 	%r20, %r19, 4;
	ld.param.u32 	%r29, [calcCenterOfMassMomentum_param_3];
	add.s32 	%r9, %r29, %r20;
	st.volatile.shared.v4.f32 	[%r9], {%f124, %f125, %f126, %f127};
	bar.sync 	0;
	setp.gt.s32 	%p4, %r19, 31;
	@%p4 bra 	BB0_15;

	ld.volatile.shared.v4.f32 	{%f76, %f77, %f78, %f79}, [%r9];
	ld.volatile.shared.v4.f32 	{%f80, %f81, %f82, %f83}, [%r9+512];
	add.ftz.f32 	%f84, %f76, %f80;
	add.ftz.f32 	%f85, %f77, %f81;
	add.ftz.f32 	%f86, %f78, %f82;
	add.ftz.f32 	%f87, %f79, %f83;
	st.volatile.shared.v4.f32 	[%r9], {%f84, %f85, %f86, %f87};
	setp.gt.s32 	%p5, %r19, 15;
	@%p5 bra 	BB0_9;

	ld.volatile.shared.v4.f32 	{%f64, %f65, %f66, %f67}, [%r9];
	ld.volatile.shared.v4.f32 	{%f68, %f69, %f70, %f71}, [%r9+256];
	add.ftz.f32 	%f72, %f64, %f68;
	add.ftz.f32 	%f73, %f65, %f69;
	add.ftz.f32 	%f74, %f66, %f70;
	add.ftz.f32 	%f75, %f67, %f71;
	st.volatile.shared.v4.f32 	[%r9], {%f72, %f73, %f74, %f75};

BB0_9:
	setp.gt.s32 	%p6, %r19, 7;
	@%p6 bra 	BB0_11;

	ld.volatile.shared.v4.f32 	{%f52, %f53, %f54, %f55}, [%r9];
	ld.volatile.shared.v4.f32 	{%f56, %f57, %f58, %f59}, [%r9+128];
	add.ftz.f32 	%f60, %f52, %f56;
	add.ftz.f32 	%f61, %f53, %f57;
	add.ftz.f32 	%f62, %f54, %f58;
	add.ftz.f32 	%f63, %f55, %f59;
	st.volatile.shared.v4.f32 	[%r9], {%f60, %f61, %f62, %f63};

BB0_11:
	setp.gt.s32 	%p7, %r19, 3;
	@%p7 bra 	BB0_13;

	ld.volatile.shared.v4.f32 	{%f40, %f41, %f42, %f43}, [%r9];
	ld.volatile.shared.v4.f32 	{%f44, %f45, %f46, %f47}, [%r9+64];
	add.ftz.f32 	%f48, %f40, %f44;
	add.ftz.f32 	%f49, %f41, %f45;
	add.ftz.f32 	%f50, %f42, %f46;
	add.ftz.f32 	%f51, %f43, %f47;
	st.volatile.shared.v4.f32 	[%r9], {%f48, %f49, %f50, %f51};

BB0_13:
	setp.gt.s32 	%p8, %r19, 1;
	@%p8 bra 	BB0_15;

	ld.volatile.shared.v4.f32 	{%f28, %f29, %f30, %f31}, [%r9];
	ld.volatile.shared.v4.f32 	{%f32, %f33, %f34, %f35}, [%r9+32];
	add.ftz.f32 	%f36, %f28, %f32;
	add.ftz.f32 	%f37, %f29, %f33;
	add.ftz.f32 	%f38, %f30, %f34;
	add.ftz.f32 	%f39, %f31, %f35;
	st.volatile.shared.v4.f32 	[%r9], {%f36, %f37, %f38, %f39};

BB0_15:
	setp.eq.s32 	%p9, %r19, 0;
	@%p9 bra 	BB0_17;

	ret;

BB0_17:
	ld.volatile.shared.v4.f32 	{%f16, %f17, %f18, %f19}, [%r9];
	ld.volatile.shared.v4.f32 	{%f20, %f21, %f22, %f23}, [%r9+16];
	add.ftz.f32 	%f24, %f16, %f20;
	add.ftz.f32 	%f25, %f17, %f21;
	add.ftz.f32 	%f26, %f18, %f22;
	add.ftz.f32 	%f27, %f19, %f23;
	// inline asm
	mov.u32 	%r21, %elwreg0;
	// inline asm
	// inline asm
	mov.u32 	%r22, %ctaid.x;
	// inline asm
	add.s32 	%r23, %r22, %r21;
	shl.b32 	%r24, %r23, 4;
	ld.param.u32 	%r28, [calcCenterOfMassMomentum_param_2];
	add.s32 	%r25, %r28, %r24;
	st.global.v4.f32 	[%r25], {%f24, %f25, %f26, %f27};
	ret;
}

.entry removeCenterOfMassMomentum(
	.param .u32 removeCenterOfMassMomentum_param_0,
	.param .u32 .ptr .global .align 16 removeCenterOfMassMomentum_param_1,
	.param .u32 .ptr .global .align 16 removeCenterOfMassMomentum_param_2,
	.param .u32 .ptr .shared .align 16 removeCenterOfMassMomentum_param_3
)
{
	.reg .f32 	%f<149>;
	.reg .pred 	%p<10>;
	.reg .s32 	%r<38>;


	// inline asm
	mov.u32 	%r13, %tid.x;
	// inline asm
	// inline asm
	mov.u32 	%r14, %elwreg6;
	// inline asm
	setp.lt.u32 	%p1, %r13, %r14;
	mov.u32 	%r36, %r13;
	@%p1 bra 	BB1_2;

	mov.f32 	%f4, 0f00000000;
	mov.f32 	%f145, %f4;
	mov.f32 	%f146, %f4;
	mov.f32 	%f147, %f4;
	mov.f32 	%f148, %f4;
	bra.uni 	BB1_4;

BB1_2:
	mov.f32 	%f5, 0f00000000;
	mov.f32 	%f145, %f5;
	mov.f32 	%f146, %f5;
	mov.f32 	%f147, %f5;
	mov.f32 	%f148, %f5;

BB1_3:
	shl.b32 	%r17, %r36, 4;
	ld.param.u32 	%r33, [removeCenterOfMassMomentum_param_2];
	add.s32 	%r18, %r33, %r17;
	ld.global.v4.f32 	{%f141, %f142, %f143, %f144}, [%r18];
	add.ftz.f32 	%f145, %f145, %f141;
	add.ftz.f32 	%f146, %f146, %f142;
	add.ftz.f32 	%f147, %f147, %f143;
	add.ftz.f32 	%f148, %f148, %f144;
	// inline asm
	mov.u32 	%r15, %ntid.x;
	// inline asm
	add.s32 	%r36, %r15, %r36;
	// inline asm
	mov.u32 	%r16, %elwreg6;
	// inline asm
	setp.lt.u32 	%p2, %r36, %r16;
	@%p2 bra 	BB1_3;

BB1_4:
	// inline asm
	mov.u32 	%r19, %tid.x;
	// inline asm
	shl.b32 	%r20, %r19, 4;
	ld.param.u32 	%r35, [removeCenterOfMassMomentum_param_3];
	add.s32 	%r9, %r35, %r20;
	st.volatile.shared.v4.f32 	[%r9], {%f145, %f146, %f147, %f148};
	bar.sync 	0;
	setp.gt.s32 	%p3, %r19, 31;
	@%p3 bra 	BB1_13;

	ld.volatile.shared.v4.f32 	{%f109, %f110, %f111, %f112}, [%r9];
	ld.volatile.shared.v4.f32 	{%f113, %f114, %f115, %f116}, [%r9+512];
	add.ftz.f32 	%f117, %f109, %f113;
	add.ftz.f32 	%f118, %f110, %f114;
	add.ftz.f32 	%f119, %f111, %f115;
	add.ftz.f32 	%f120, %f112, %f116;
	st.volatile.shared.v4.f32 	[%r9], {%f117, %f118, %f119, %f120};
	setp.gt.s32 	%p4, %r19, 15;
	@%p4 bra 	BB1_7;

	ld.volatile.shared.v4.f32 	{%f97, %f98, %f99, %f100}, [%r9];
	ld.volatile.shared.v4.f32 	{%f101, %f102, %f103, %f104}, [%r9+256];
	add.ftz.f32 	%f105, %f97, %f101;
	add.ftz.f32 	%f106, %f98, %f102;
	add.ftz.f32 	%f107, %f99, %f103;
	add.ftz.f32 	%f108, %f100, %f104;
	st.volatile.shared.v4.f32 	[%r9], {%f105, %f106, %f107, %f108};

BB1_7:
	setp.gt.s32 	%p5, %r19, 7;
	@%p5 bra 	BB1_9;

	ld.volatile.shared.v4.f32 	{%f85, %f86, %f87, %f88}, [%r9];
	ld.volatile.shared.v4.f32 	{%f89, %f90, %f91, %f92}, [%r9+128];
	add.ftz.f32 	%f93, %f85, %f89;
	add.ftz.f32 	%f94, %f86, %f90;
	add.ftz.f32 	%f95, %f87, %f91;
	add.ftz.f32 	%f96, %f88, %f92;
	st.volatile.shared.v4.f32 	[%r9], {%f93, %f94, %f95, %f96};

BB1_9:
	setp.gt.s32 	%p6, %r19, 3;
	@%p6 bra 	BB1_11;

	ld.volatile.shared.v4.f32 	{%f73, %f74, %f75, %f76}, [%r9];
	ld.volatile.shared.v4.f32 	{%f77, %f78, %f79, %f80}, [%r9+64];
	add.ftz.f32 	%f81, %f73, %f77;
	add.ftz.f32 	%f82, %f74, %f78;
	add.ftz.f32 	%f83, %f75, %f79;
	add.ftz.f32 	%f84, %f76, %f80;
	st.volatile.shared.v4.f32 	[%r9], {%f81, %f82, %f83, %f84};

BB1_11:
	setp.gt.s32 	%p7, %r19, 1;
	@%p7 bra 	BB1_13;

	ld.volatile.shared.v4.f32 	{%f61, %f62, %f63, %f64}, [%r9];
	ld.volatile.shared.v4.f32 	{%f65, %f66, %f67, %f68}, [%r9+32];
	add.ftz.f32 	%f69, %f61, %f65;
	add.ftz.f32 	%f70, %f62, %f66;
	add.ftz.f32 	%f71, %f63, %f67;
	add.ftz.f32 	%f72, %f64, %f68;
	st.volatile.shared.v4.f32 	[%r9], {%f69, %f70, %f71, %f72};

BB1_13:
	bar.sync 	0;
	ld.param.u32 	%r34, [removeCenterOfMassMomentum_param_3];
	ld.volatile.shared.v4.f32 	{%f37, %f38, %f39, %f40}, [%r34];
	ld.volatile.shared.v4.f32 	{%f41, %f42, %f43, %f44}, [%r34+16];
	add.ftz.f32 	%f8, %f37, %f41;
	mul.ftz.f32 	%f1, %f8, 0f36E8317B;
	ld.volatile.shared.v4.f32 	{%f45, %f46, %f47, %f48}, [%r34];
	ld.volatile.shared.v4.f32 	{%f49, %f50, %f51, %f52}, [%r34+16];
	add.ftz.f32 	%f11, %f46, %f50;
	mul.ftz.f32 	%f2, %f11, 0f36E8317B;
	ld.volatile.shared.v4.f32 	{%f53, %f54, %f55, %f56}, [%r34];
	ld.volatile.shared.v4.f32 	{%f57, %f58, %f59, %f60}, [%r34+16];
	add.ftz.f32 	%f14, %f55, %f59;
	mul.ftz.f32 	%f3, %f14, 0f36E8317B;
	// inline asm
	mov.u32 	%r21, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r22, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r23, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r24, %tid.x;
	// inline asm
	add.s32 	%r25, %r24, %r21;
	mad.lo.s32 	%r37, %r23, %r22, %r25;
	ld.param.u32 	%r31, [removeCenterOfMassMomentum_param_0];
	setp.ge.u32 	%p8, %r37, %r31;
	@%p8 bra 	BB1_15;

BB1_14:
	shl.b32 	%r28, %r37, 4;
	ld.param.u32 	%r32, [removeCenterOfMassMomentum_param_1];
	add.s32 	%r29, %r32, %r28;
	ld.global.v4.f32 	{%f21, %f22, %f23, %f24}, [%r29];
	sub.ftz.f32 	%f16, %f21, %f1;
	sub.ftz.f32 	%f18, %f22, %f2;
	sub.ftz.f32 	%f20, %f23, %f3;
	st.global.v4.f32 	[%r29], {%f16, %f18, %f20, %f24};
	// inline asm
	mov.u32 	%r26, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r27, %ntid.x;
	// inline asm
	mad.lo.s32 	%r37, %r27, %r26, %r37;
	ld.param.u32 	%r30, [removeCenterOfMassMomentum_param_0];
	setp.lt.u32 	%p9, %r37, %r30;
	@%p9 bra 	BB1_14;

BB1_15:
	ret;
}



//
// Generated by LWPU LWVM Compiler
// Compiler built on Thu May 15 11:00:55 2014 (1400169655)
// Driver 
//

//.version 3.0
//.target sm_30, texmode_independent
//.address_size 32


.entry computeBondedForces(
	.param .u32 .ptr .global .align 8 computeBondedForces_param_0,
	.param .u32 .ptr .global .align 4 computeBondedForces_param_1,
	.param .u32 .ptr .global .align 16 computeBondedForces_param_2,
	.param .u32 computeBondedForces_param_3,
	.param .u32 .ptr .global .align 16 computeBondedForces_param_4,
	.param .u32 .ptr .global .align 16 computeBondedForces_param_5,
	.param .u32 .ptr .global .align 16 computeBondedForces_param_6,
	.param .u32 .ptr .global .align 16 computeBondedForces_param_7,
	.param .u32 .ptr .global .align 8 computeBondedForces_param_8,
	.param .u32 .ptr .global .align 8 computeBondedForces_param_9,
	.param .u32 .ptr .global .align 8 computeBondedForces_param_10,
	.param .u32 .ptr .global .align 16 computeBondedForces_param_11,
	.param .u32 .ptr .global .align 16 computeBondedForces_param_12
)
{
	.reg .f32 	%f<805>;
	.reg .pred 	%p<45>;
	.reg .s32 	%r<160>;
	.reg .s64 	%rl<55>;


	ld.param.u32 	%r4, [computeBondedForces_param_3];
	and.b32  	%r27, %r4, 1;
	setp.eq.s32 	%p1, %r27, 0;
	@%p1 bra 	BB0_7;

	// inline asm
	mov.u32 	%r28, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r29, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r30, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r31, %tid.x;
	// inline asm
	add.s32 	%r32, %r31, %r28;
	mad.lo.s32 	%r157, %r30, %r29, %r32;
	setp.gt.u32 	%p2, %r157, 4011;
	@%p2 bra 	BB0_7;

	mov.f32 	%f796, 0f00000000;

BB0_3:
	shl.b32 	%r33, %r157, 4;
	ld.param.u32 	%r151, [computeBondedForces_param_4];
	add.s32 	%r34, %r151, %r33;
	ld.global.v4.u32 	{%r139, %r140, %r141, %r142}, [%r34];
	shl.b32 	%r35, %r139, 4;
	ld.param.u32 	%r149, [computeBondedForces_param_2];
	add.s32 	%r36, %r149, %r35;
	shl.b32 	%r37, %r140, 4;
	add.s32 	%r38, %r149, %r37;
	shl.b32 	%r39, %r141, 4;
	add.s32 	%r40, %r149, %r39;
	ld.global.v4.f32 	{%f771, %f772, %f773, %f774}, [%r38];
	ld.global.v4.f32 	{%f775, %f776, %f777, %f778}, [%r36];
	sub.ftz.f32 	%f779, %f771, %f775;
	sub.ftz.f32 	%f780, %f772, %f776;
	sub.ftz.f32 	%f781, %f773, %f777;
	ld.global.v4.f32 	{%f783, %f784, %f785, %f786}, [%r40];
	sub.ftz.f32 	%f787, %f771, %f783;
	sub.ftz.f32 	%f788, %f772, %f784;
	sub.ftz.f32 	%f789, %f773, %f785;
	mul.rn.f32 	%f80, %f780, %f789;
	mul.rn.f32 	%f81, %f781, %f788;
	sub.ftz.f32 	%f6, %f80, %f81;
	mul.rn.f32 	%f82, %f781, %f787;
	mul.rn.f32 	%f83, %f779, %f789;
	sub.ftz.f32 	%f9, %f82, %f83;
	mul.rn.f32 	%f84, %f779, %f788;
	mul.rn.f32 	%f85, %f780, %f787;
	sub.ftz.f32 	%f10, %f84, %f85;
	mul.ftz.f32 	%f86, %f9, %f9;
	fma.rn.ftz.f32 	%f87, %f6, %f6, %f86;
	fma.rn.ftz.f32 	%f73, %f10, %f10, %f87;
	// inline asm
	sqrt.approx.f32 	%f72, %f73;
	// inline asm
	mov.f32 	%f88, 0f358637BD;
	max.f32 	%f11, %f72, %f88;
	mul.ftz.f32 	%f89, %f780, %f780;
	fma.rn.ftz.f32 	%f90, %f779, %f779, %f89;
	fma.rn.ftz.f32 	%f12, %f781, %f781, %f90;
	mul.ftz.f32 	%f91, %f788, %f788;
	fma.rn.ftz.f32 	%f92, %f787, %f787, %f91;
	fma.rn.ftz.f32 	%f13, %f789, %f789, %f92;
	mul.ftz.f32 	%f93, %f780, %f788;
	fma.rn.ftz.f32 	%f94, %f779, %f787, %f93;
	fma.rn.ftz.f32 	%f95, %f781, %f789, %f94;
	mul.ftz.f32 	%f75, %f12, %f13;
	// inline asm
	rsqrt.approx.f32 	%f74, %f75;
	// inline asm
	mul.ftz.f32 	%f96, %f95, %f74;
	mov.f32 	%f97, 0fBF800000;
	max.f32 	%f98, %f96, %f97;
	mov.f32 	%f99, 0f3F800000;
	min.f32 	%f77, %f98, %f99;
	// inline asm
	abs.f32 	%f76, %f77;
	// inline asm
	sub.ftz.f32 	%f100, %f99, %f76;
	mov.f32 	%f101, 0f3F000000;
	mul.rn.f32 	%f79, %f101, %f100;
	// inline asm
	sqrt.approx.f32 	%f78, %f79;
	// inline asm
	setp.gt.ftz.f32 	%p3, %f76, 0f3F133333;
	selp.f32 	%f102, %f78, %f76, %p3;
	mul.rn.f32 	%f103, %f102, %f102;
	mov.f32 	%f104, 0fBF004C2C;
	mul.rn.f32 	%f105, %f104, %f103;
	add.ftz.f32 	%f106, %f105, 0f3F6A4AA5;
	mul.rn.f32 	%f107, %f106, %f103;
	mul.rn.f32 	%f108, %f107, %f102;
	add.ftz.f32 	%f109, %f103, 0fC0AF5123;
	mul.rn.f32 	%f110, %f109, %f103;
	add.ftz.f32 	%f111, %f110, 0f40AFB829;
	rcp.approx.ftz.f32 	%f112, %f111;
	mul.rn.f32 	%f113, %f108, %f112;
	add.ftz.f32 	%f15, %f113, %f102;
	@%p3 bra 	BB0_5;

	mov.f32 	%f114, 0f3FC90FDB;
	sub.ftz.f32 	%f791, %f114, %f15;
	bra.uni 	BB0_6;

BB0_5:
	mov.f32 	%f115, 0f40000000;
	mul.rn.f32 	%f791, %f115, %f15;

BB0_6:
	mov.b32 	 %r43, %f77;
	setp.lt.s32 	%p4, %r43, 0;
	mov.f32 	%f116, 0f40490FDB;
	sub.ftz.f32 	%f117, %f116, %f791;
	selp.f32 	%f118, %f117, %f791, %p4;
	shl.b32 	%r44, %r157, 3;
	ld.param.u32 	%r154, [computeBondedForces_param_10];
	add.s32 	%r45, %r154, %r44;
	ld.global.v2.f32 	{%f717, %f718}, [%r45];
	sub.ftz.f32 	%f120, %f118, %f717;
	mul.ftz.f32 	%f122, %f718, 0f3F000000;
	mul.ftz.f32 	%f123, %f122, %f120;
	fma.rn.ftz.f32 	%f796, %f123, %f120, %f796;
	mul.ftz.f32 	%f124, %f718, %f120;
	mul.rn.f32 	%f125, %f781, %f9;
	mul.rn.f32 	%f126, %f780, %f10;
	sub.ftz.f32 	%f127, %f126, %f125;
	mul.rn.f32 	%f128, %f779, %f10;
	mul.rn.f32 	%f129, %f781, %f6;
	sub.ftz.f32 	%f130, %f129, %f128;
	mul.rn.f32 	%f131, %f780, %f6;
	mul.rn.f32 	%f132, %f779, %f9;
	sub.ftz.f32 	%f133, %f132, %f131;
	mul.ftz.f32 	%f135, %f12, %f11;
	div.approx.ftz.f32 	%f136, %f124, %f135;
	mul.ftz.f32 	%f735, %f127, %f136;
	mul.ftz.f32 	%f736, %f130, %f136;
	mul.ftz.f32 	%f737, %f133, %f136;
	mul.rn.f32 	%f140, %f10, %f788;
	mul.rn.f32 	%f141, %f9, %f789;
	sub.ftz.f32 	%f142, %f141, %f140;
	mul.rn.f32 	%f143, %f6, %f789;
	mul.rn.f32 	%f144, %f10, %f787;
	sub.ftz.f32 	%f145, %f144, %f143;
	mul.rn.f32 	%f146, %f9, %f787;
	mul.rn.f32 	%f147, %f6, %f788;
	sub.ftz.f32 	%f148, %f147, %f146;
	mul.ftz.f32 	%f149, %f13, %f11;
	div.approx.ftz.f32 	%f150, %f124, %f149;
	mul.ftz.f32 	%f755, %f142, %f150;
	mul.ftz.f32 	%f756, %f145, %f150;
	mul.ftz.f32 	%f757, %f148, %f150;
	neg.ftz.f32 	%f759, %f735;
	neg.ftz.f32 	%f760, %f736;
	neg.ftz.f32 	%f761, %f737;
	neg.f32 	%f763, %f142;
	neg.f32 	%f764, %f145;
	neg.f32 	%f765, %f148;
	fma.rn.ftz.f32 	%f767, %f763, %f150, %f759;
	fma.rn.ftz.f32 	%f768, %f764, %f150, %f760;
	fma.rn.ftz.f32 	%f769, %f765, %f150, %f761;
	mul.ftz.f32 	%f155, %f735, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl1, %f155;
	shl.b32 	%r46, %r139, 3;
	ld.param.u32 	%r145, [computeBondedForces_param_0];
	add.s32 	%r47, %r145, %r46;
	atom.global.add.u64 	%rl2, [%r47], %rl1;
	add.s32 	%r48, %r47, 188672;
	mul.ftz.f32 	%f157, %f736, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl3, %f157;
	atom.global.add.u64 	%rl4, [%r48], %rl3;
	add.s32 	%r49, %r47, 377344;
	mul.ftz.f32 	%f159, %f737, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl5, %f159;
	atom.global.add.u64 	%rl6, [%r49], %rl5;
	mul.ftz.f32 	%f161, %f767, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl7, %f161;
	shl.b32 	%r50, %r140, 3;
	add.s32 	%r51, %r145, %r50;
	atom.global.add.u64 	%rl8, [%r51], %rl7;
	add.s32 	%r52, %r51, 188672;
	mul.ftz.f32 	%f163, %f768, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl9, %f163;
	atom.global.add.u64 	%rl10, [%r52], %rl9;
	add.s32 	%r53, %r51, 377344;
	mul.ftz.f32 	%f165, %f769, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl11, %f165;
	atom.global.add.u64 	%rl12, [%r53], %rl11;
	mul.ftz.f32 	%f167, %f755, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl13, %f167;
	shl.b32 	%r54, %r141, 3;
	add.s32 	%r55, %r145, %r54;
	atom.global.add.u64 	%rl14, [%r55], %rl13;
	add.s32 	%r56, %r55, 188672;
	mul.ftz.f32 	%f169, %f756, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl15, %f169;
	atom.global.add.u64 	%rl16, [%r56], %rl15;
	add.s32 	%r57, %r55, 377344;
	mul.ftz.f32 	%f171, %f757, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl17, %f171;
	atom.global.add.u64 	%rl18, [%r57], %rl17;
	// inline asm
	mov.u32 	%r41, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r42, %ntid.x;
	// inline asm
	mad.lo.s32 	%r157, %r42, %r41, %r157;
	setp.lt.u32 	%p5, %r157, 4012;
	@%p5 bra 	BB0_3;
	bra.uni 	BB0_8;

BB0_7:
	mov.f32 	%f796, 0f00000000;

BB0_8:
	@%p1 bra 	BB0_36;

	// inline asm
	mov.u32 	%r58, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r59, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r60, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r61, %tid.x;
	// inline asm
	add.s32 	%r62, %r61, %r58;
	mad.lo.s32 	%r158, %r60, %r59, %r62;
	setp.gt.u32 	%p6, %r158, 7309;
	@%p6 bra 	BB0_36;

	mov.f32 	%f173, 0f00000000;
	mul.rn.f32 	%f21, %f173, %f173;

BB0_11:
	shl.b32 	%r63, %r158, 4;
	ld.param.u32 	%r152, [computeBondedForces_param_6];
	add.s32 	%r64, %r152, %r63;
	ld.global.v4.u32 	{%r135, %r136, %r137, %r138}, [%r64];
	shl.b32 	%r65, %r135, 4;
	ld.param.u32 	%r148, [computeBondedForces_param_2];
	add.s32 	%r66, %r148, %r65;
	shl.b32 	%r67, %r136, 4;
	add.s32 	%r68, %r148, %r67;
	shl.b32 	%r69, %r137, 4;
	add.s32 	%r70, %r148, %r69;
	shl.b32 	%r71, %r138, 4;
	add.s32 	%r72, %r148, %r71;
	ld.global.v4.f32 	{%f689, %f690, %f691, %f692}, [%r68];
	ld.global.v4.f32 	{%f693, %f694, %f695, %f696}, [%r66];
	sub.ftz.f32 	%f697, %f693, %f689;
	sub.ftz.f32 	%f698, %f694, %f690;
	sub.ftz.f32 	%f699, %f695, %f691;
	ld.global.v4.f32 	{%f701, %f702, %f703, %f704}, [%r70];
	sub.ftz.f32 	%f705, %f701, %f689;
	sub.ftz.f32 	%f706, %f702, %f690;
	sub.ftz.f32 	%f707, %f703, %f691;
	ld.global.v4.f32 	{%f709, %f710, %f711, %f712}, [%r72];
	sub.ftz.f32 	%f713, %f701, %f709;
	sub.ftz.f32 	%f714, %f702, %f710;
	sub.ftz.f32 	%f715, %f703, %f711;
	mul.rn.f32 	%f182, %f698, %f707;
	mul.rn.f32 	%f183, %f699, %f706;
	sub.ftz.f32 	%f175, %f182, %f183;
	mul.rn.f32 	%f184, %f699, %f705;
	mul.rn.f32 	%f185, %f697, %f707;
	sub.ftz.f32 	%f177, %f184, %f185;
	mul.rn.f32 	%f186, %f697, %f706;
	mul.rn.f32 	%f187, %f698, %f705;
	sub.ftz.f32 	%f179, %f186, %f187;
	mul.rn.f32 	%f188, %f706, %f715;
	mul.rn.f32 	%f189, %f707, %f714;
	sub.ftz.f32 	%f34, %f188, %f189;
	mul.rn.f32 	%f190, %f707, %f713;
	mul.rn.f32 	%f191, %f705, %f715;
	sub.ftz.f32 	%f36, %f190, %f191;
	mul.rn.f32 	%f192, %f705, %f714;
	mul.rn.f32 	%f193, %f706, %f713;
	sub.ftz.f32 	%f37, %f192, %f193;
	// inline asm
	abs.f32 	%f174, %f175;
	// inline asm
	// inline asm
	abs.f32 	%f176, %f177;
	// inline asm
	// inline asm
	abs.f32 	%f178, %f179;
	// inline asm
	// inline asm
	abs.f32 	%f180, %f173;
	// inline asm
	setp.nan.ftz.f32 	%p7, %f174, %f176;
	setp.nan.ftz.f32 	%p8, %f178, %f178;
	or.pred  	%p9, %p7, %p8;
	setp.nan.ftz.f32 	%p10, %f180, %f180;
	or.pred  	%p11, %p9, %p10;
	@%p11 bra 	BB0_19;

	setp.lt.ftz.f32 	%p12, %f174, %f176;
	selp.f32 	%f194, %f176, %f174, %p12;
	setp.lt.ftz.f32 	%p13, %f194, %f178;
	selp.f32 	%f195, %f178, %f194, %p13;
	setp.lt.ftz.f32 	%p14, %f195, %f180;
	selp.f32 	%f42, %f180, %f195, %p14;
	setp.eq.ftz.f32 	%p15, %f42, 0f00000000;
	@%p15 bra 	BB0_18;

	setp.eq.ftz.f32 	%p16, %f42, 0f7F800000;
	@%p16 bra 	BB0_17;

	div.approx.ftz.f32 	%f198, %f174, %f42;
	mul.rn.f32 	%f199, %f198, %f198;
	div.approx.ftz.f32 	%f200, %f176, %f42;
	mul.rn.f32 	%f201, %f200, %f200;
	add.ftz.f32 	%f202, %f199, %f201;
	div.approx.ftz.f32 	%f203, %f178, %f42;
	mul.rn.f32 	%f204, %f203, %f203;
	add.ftz.f32 	%f205, %f202, %f204;
	div.approx.ftz.f32 	%f206, %f180, %f42;
	mul.rn.f32 	%f207, %f206, %f206;
	add.ftz.f32 	%f197, %f205, %f207;
	// inline asm
	sqrt.rn.f32 	%f196, %f197;
	// inline asm
	mul.rn.f32 	%f44, %f196, %f42;
	setp.eq.ftz.f32 	%p17, %f44, 0f7F800000;
	setp.eq.ftz.f32 	%p18, %f44, 0fFF800000;
	or.pred  	%p19, %p17, %p18;
	@%p19 bra 	BB0_16;

	div.approx.ftz.f32 	%f801, %f175, %f44;
	div.approx.ftz.f32 	%f802, %f177, %f44;
	div.approx.ftz.f32 	%f803, %f179, %f44;
	div.approx.ftz.f32 	%f804, %f173, %f44;
	bra.uni 	BB0_20;

BB0_16:
	div.approx.ftz.f32 	%f677, %f175, %f196;
	div.approx.ftz.f32 	%f678, %f177, %f196;
	div.approx.ftz.f32 	%f679, %f179, %f196;
	div.approx.ftz.f32 	%f680, %f173, %f196;
	div.approx.ftz.f32 	%f801, %f677, %f42;
	div.approx.ftz.f32 	%f802, %f678, %f42;
	div.approx.ftz.f32 	%f803, %f679, %f42;
	div.approx.ftz.f32 	%f804, %f680, %f42;
	bra.uni 	BB0_20;

BB0_17:
	mov.f32 	%f208, 0f7F800000;
	div.approx.ftz.f32 	%f801, %f175, %f208;
	div.approx.ftz.f32 	%f802, %f177, %f208;
	div.approx.ftz.f32 	%f803, %f179, %f208;
	div.approx.ftz.f32 	%f804, %f173, %f208;
	bra.uni 	BB0_20;

BB0_18:
	mov.f32 	%f801, %f173;
	mov.f32 	%f802, %f173;
	mov.f32 	%f803, %f173;
	mov.f32 	%f804, %f173;
	bra.uni 	BB0_20;

BB0_19:
	mov.f32 	%f210, 0f7FFFFFFF;
	mov.f32 	%f801, %f210;
	mov.f32 	%f802, %f210;
	mov.f32 	%f803, %f210;
	mov.f32 	%f804, %f210;

BB0_20:
	// inline asm
	abs.f32 	%f211, %f34;
	// inline asm
	// inline asm
	abs.f32 	%f213, %f36;
	// inline asm
	// inline asm
	abs.f32 	%f215, %f37;
	// inline asm
	// inline asm
	abs.f32 	%f217, %f173;
	// inline asm
	setp.nan.ftz.f32 	%p20, %f211, %f213;
	setp.nan.ftz.f32 	%p21, %f215, %f215;
	or.pred  	%p22, %p20, %p21;
	setp.nan.ftz.f32 	%p23, %f217, %f217;
	or.pred  	%p24, %p22, %p23;
	@%p24 bra 	BB0_28;

	setp.lt.ftz.f32 	%p25, %f211, %f213;
	selp.f32 	%f219, %f213, %f211, %p25;
	setp.lt.ftz.f32 	%p26, %f219, %f215;
	selp.f32 	%f220, %f215, %f219, %p26;
	setp.lt.ftz.f32 	%p27, %f220, %f217;
	selp.f32 	%f49, %f217, %f220, %p27;
	setp.eq.ftz.f32 	%p28, %f49, 0f00000000;
	@%p28 bra 	BB0_27;

	setp.eq.ftz.f32 	%p29, %f49, 0f7F800000;
	@%p29 bra 	BB0_26;

	div.approx.ftz.f32 	%f223, %f211, %f49;
	mul.rn.f32 	%f224, %f223, %f223;
	div.approx.ftz.f32 	%f225, %f213, %f49;
	mul.rn.f32 	%f226, %f225, %f225;
	add.ftz.f32 	%f227, %f224, %f226;
	div.approx.ftz.f32 	%f228, %f215, %f49;
	mul.rn.f32 	%f229, %f228, %f228;
	add.ftz.f32 	%f230, %f227, %f229;
	div.approx.ftz.f32 	%f231, %f217, %f49;
	mul.rn.f32 	%f232, %f231, %f231;
	add.ftz.f32 	%f222, %f230, %f232;
	// inline asm
	sqrt.rn.f32 	%f221, %f222;
	// inline asm
	mul.rn.f32 	%f51, %f221, %f49;
	setp.eq.ftz.f32 	%p30, %f51, 0f7F800000;
	setp.eq.ftz.f32 	%p31, %f51, 0fFF800000;
	or.pred  	%p32, %p30, %p31;
	@%p32 bra 	BB0_25;

	div.approx.ftz.f32 	%f797, %f34, %f51;
	div.approx.ftz.f32 	%f798, %f36, %f51;
	div.approx.ftz.f32 	%f799, %f37, %f51;
	div.approx.ftz.f32 	%f800, %f173, %f51;
	bra.uni 	BB0_29;

BB0_25:
	div.approx.ftz.f32 	%f637, %f34, %f221;
	div.approx.ftz.f32 	%f638, %f36, %f221;
	div.approx.ftz.f32 	%f639, %f37, %f221;
	div.approx.ftz.f32 	%f640, %f173, %f221;
	div.approx.ftz.f32 	%f797, %f637, %f49;
	div.approx.ftz.f32 	%f798, %f638, %f49;
	div.approx.ftz.f32 	%f799, %f639, %f49;
	div.approx.ftz.f32 	%f800, %f640, %f49;
	bra.uni 	BB0_29;

BB0_26:
	mov.f32 	%f233, 0f7F800000;
	div.approx.ftz.f32 	%f797, %f34, %f233;
	div.approx.ftz.f32 	%f798, %f36, %f233;
	div.approx.ftz.f32 	%f799, %f37, %f233;
	div.approx.ftz.f32 	%f800, %f173, %f233;
	bra.uni 	BB0_29;

BB0_27:
	mov.f32 	%f797, %f173;
	mov.f32 	%f798, %f173;
	mov.f32 	%f799, %f173;
	mov.f32 	%f800, %f173;
	bra.uni 	BB0_29;

BB0_28:
	mov.f32 	%f235, 0f7FFFFFFF;
	mov.f32 	%f797, %f235;
	mov.f32 	%f798, %f235;
	mov.f32 	%f799, %f235;
	mov.f32 	%f800, %f235;

BB0_29:
	mul.rn.f32 	%f238, %f801, %f797;
	mul.rn.f32 	%f241, %f802, %f798;
	add.ftz.f32 	%f242, %f238, %f241;
	mul.rn.f32 	%f245, %f803, %f799;
	add.ftz.f32 	%f246, %f242, %f245;
	mul.rn.f32 	%f249, %f804, %f800;
	add.ftz.f32 	%f52, %f246, %f249;
	setp.gt.ftz.f32 	%p33, %f52, 0f3F7D70A4;
	setp.lt.ftz.f32 	%p34, %f52, 0fBF7D70A4;
	or.pred  	%p35, %p33, %p34;
	@%p35 bra 	BB0_34;

	// inline asm
	abs.f32 	%f250, %f52;
	// inline asm
	mov.f32 	%f254, 0f3F800000;
	sub.ftz.f32 	%f255, %f254, %f250;
	mov.f32 	%f256, 0f3F000000;
	mul.rn.f32 	%f253, %f256, %f255;
	// inline asm
	sqrt.approx.f32 	%f252, %f253;
	// inline asm
	setp.gt.ftz.f32 	%p36, %f250, 0f3F133333;
	selp.f32 	%f257, %f252, %f250, %p36;
	mul.rn.f32 	%f258, %f257, %f257;
	mov.f32 	%f259, 0fBF004C2C;
	mul.rn.f32 	%f260, %f259, %f258;
	add.ftz.f32 	%f261, %f260, 0f3F6A4AA5;
	mul.rn.f32 	%f262, %f261, %f258;
	mul.rn.f32 	%f263, %f262, %f257;
	add.ftz.f32 	%f264, %f258, 0fC0AF5123;
	mul.rn.f32 	%f265, %f264, %f258;
	add.ftz.f32 	%f266, %f265, 0f40AFB829;
	rcp.approx.ftz.f32 	%f267, %f266;
	mul.rn.f32 	%f268, %f263, %f267;
	add.ftz.f32 	%f53, %f268, %f257;
	@%p36 bra 	BB0_32;

	mov.f32 	%f269, 0f3FC90FDB;
	sub.ftz.f32 	%f792, %f269, %f53;
	bra.uni 	BB0_33;

BB0_32:
	mov.f32 	%f270, 0f40000000;
	mul.rn.f32 	%f792, %f270, %f53;

BB0_33:
	mov.b32 	 %r73, %f52;
	setp.lt.s32 	%p37, %r73, 0;
	mov.f32 	%f271, 0f40490FDB;
	sub.ftz.f32 	%f272, %f271, %f792;
	selp.f32 	%f795, %f272, %f792, %p37;
	mul.rn.f32 	%f273, %f177, %f177;
	mul.rn.f32 	%f274, %f175, %f175;
	add.ftz.f32 	%f275, %f274, %f273;
	mul.rn.f32 	%f276, %f179, %f179;
	add.ftz.f32 	%f277, %f275, %f276;
	add.ftz.f32 	%f794, %f277, %f21;
	mul.rn.f32 	%f278, %f36, %f36;
	mul.rn.f32 	%f279, %f34, %f34;
	add.ftz.f32 	%f280, %f279, %f278;
	mul.rn.f32 	%f281, %f37, %f37;
	add.ftz.f32 	%f282, %f280, %f281;
	add.ftz.f32 	%f793, %f282, %f21;
	bra.uni 	BB0_35;

BB0_34:
	mul.rn.f32 	%f289, %f177, %f37;
	mul.rn.f32 	%f290, %f179, %f36;
	sub.ftz.f32 	%f291, %f289, %f290;
	mul.rn.f32 	%f292, %f175, %f37;
	mul.rn.f32 	%f293, %f179, %f34;
	sub.ftz.f32 	%f294, %f293, %f292;
	mul.rn.f32 	%f295, %f177, %f34;
	mul.rn.f32 	%f296, %f175, %f36;
	sub.ftz.f32 	%f297, %f296, %f295;
	mul.rn.f32 	%f298, %f177, %f177;
	mul.rn.f32 	%f299, %f175, %f175;
	add.ftz.f32 	%f300, %f299, %f298;
	mul.rn.f32 	%f301, %f179, %f179;
	add.ftz.f32 	%f302, %f300, %f301;
	add.ftz.f32 	%f794, %f302, %f21;
	mul.rn.f32 	%f303, %f36, %f36;
	mul.rn.f32 	%f304, %f34, %f34;
	add.ftz.f32 	%f305, %f304, %f303;
	mul.rn.f32 	%f306, %f37, %f37;
	add.ftz.f32 	%f307, %f305, %f306;
	add.ftz.f32 	%f793, %f307, %f21;
	mul.ftz.f32 	%f308, %f794, %f793;
	mul.rn.f32 	%f309, %f291, %f291;
	mul.rn.f32 	%f310, %f294, %f294;
	add.ftz.f32 	%f311, %f309, %f310;
	mul.rn.f32 	%f312, %f297, %f297;
	add.ftz.f32 	%f313, %f311, %f312;
	add.ftz.f32 	%f314, %f313, %f21;
	div.approx.ftz.f32 	%f284, %f314, %f308;
	// inline asm
	sqrt.approx.f32 	%f283, %f284;
	// inline asm
	// inline asm
	abs.f32 	%f285, %f283;
	// inline asm
	mov.f32 	%f315, 0f3F800000;
	sub.ftz.f32 	%f316, %f315, %f285;
	mov.f32 	%f317, 0f3F000000;
	mul.rn.f32 	%f288, %f317, %f316;
	// inline asm
	sqrt.approx.f32 	%f287, %f288;
	// inline asm
	setp.gt.ftz.f32 	%p38, %f285, 0f3F133333;
	selp.f32 	%f318, %f287, %f285, %p38;
	mul.rn.f32 	%f319, %f318, %f318;
	mov.f32 	%f320, 0fBF004C2C;
	mul.rn.f32 	%f321, %f320, %f319;
	add.ftz.f32 	%f322, %f321, 0f3F6A4AA5;
	mul.rn.f32 	%f323, %f322, %f319;
	mul.rn.f32 	%f324, %f323, %f318;
	add.ftz.f32 	%f325, %f319, 0fC0AF5123;
	mul.rn.f32 	%f326, %f325, %f319;
	add.ftz.f32 	%f327, %f326, 0f40AFB829;
	rcp.approx.ftz.f32 	%f328, %f327;
	mul.rn.f32 	%f329, %f324, %f328;
	add.ftz.f32 	%f330, %f329, %f318;
	mov.f32 	%f331, 0fC0000000;
	mul.rn.f32 	%f332, %f331, %f330;
	add.ftz.f32 	%f333, %f332, 0f3FC90FDB;
	selp.f32 	%f334, %f333, %f330, %p38;
	mov.b32 	 %r74, %f283;
	and.b32  	%r75, %r74, -2147483648;
	mov.b32 	 %r76, %f334;
	and.b32  	%r77, %r76, 2147483647;
	or.b32  	%r78, %r77, %r75;
	mov.b32 	 %f335, %r78;
	mov.f32 	%f336, 0f40490FDB;
	sub.ftz.f32 	%f337, %f336, %f335;
	setp.lt.ftz.f32 	%p39, %f52, 0f00000000;
	selp.f32 	%f795, %f337, %f335, %p39;

BB0_35:
	mul.rn.f32 	%f344, %f698, %f36;
	mul.rn.f32 	%f345, %f697, %f34;
	add.ftz.f32 	%f346, %f345, %f344;
	mul.rn.f32 	%f347, %f699, %f37;
	add.ftz.f32 	%f348, %f346, %f347;
	add.ftz.f32 	%f349, %f348, %f21;
	setp.ltu.ftz.f32 	%p40, %f349, 0f00000000;
	neg.ftz.f32 	%f350, %f795;
	selp.f32 	%f351, %f350, %f795, %p40;
	ld.param.u32 	%r155, [computeBondedForces_param_11];
	add.s32 	%r82, %r155, %r63;
	ld.global.v4.f32 	{%f501, %f502, %f503, %f504}, [%r82];
	neg.f32 	%f354, %f502;
	fma.rn.ftz.f32 	%f341, %f503, %f351, %f354;
	// inline asm
	cos.approx.f32 	%f338, %f341;
	// inline asm
	add.ftz.f32 	%f356, %f338, 0f3F800000;
	fma.rn.ftz.f32 	%f796, %f501, %f356, %f796;
	// inline asm
	sin.approx.f32 	%f340, %f341;
	// inline asm
	neg.ftz.f32 	%f357, %f501;
	mul.ftz.f32 	%f358, %f503, %f357;
	mul.ftz.f32 	%f359, %f358, %f340;
	mul.rn.f32 	%f360, %f706, %f706;
	mul.rn.f32 	%f361, %f705, %f705;
	add.ftz.f32 	%f362, %f361, %f360;
	mul.rn.f32 	%f363, %f707, %f707;
	add.ftz.f32 	%f364, %f362, %f363;
	add.ftz.f32 	%f343, %f364, %f21;
	// inline asm
	sqrt.approx.f32 	%f342, %f343;
	// inline asm
	rcp.approx.ftz.f32 	%f365, %f343;
	neg.ftz.f32 	%f366, %f359;
	mul.ftz.f32 	%f367, %f342, %f366;
	div.approx.ftz.f32 	%f368, %f367, %f794;
	mul.rn.f32 	%f369, %f698, %f706;
	mul.rn.f32 	%f370, %f697, %f705;
	add.ftz.f32 	%f371, %f370, %f369;
	mul.rn.f32 	%f372, %f699, %f707;
	add.ftz.f32 	%f373, %f371, %f372;
	add.ftz.f32 	%f374, %f373, %f21;
	mul.ftz.f32 	%f375, %f374, %f365;
	mul.rn.f32 	%f376, %f714, %f706;
	mul.rn.f32 	%f377, %f713, %f705;
	add.ftz.f32 	%f378, %f377, %f376;
	mul.rn.f32 	%f379, %f715, %f707;
	add.ftz.f32 	%f380, %f378, %f379;
	add.ftz.f32 	%f381, %f380, %f21;
	mul.ftz.f32 	%f382, %f381, %f365;
	mul.ftz.f32 	%f383, %f359, %f342;
	div.approx.ftz.f32 	%f384, %f383, %f793;
	mul.ftz.f32 	%f517, %f368, %f175;
	mul.ftz.f32 	%f518, %f368, %f177;
	mul.ftz.f32 	%f519, %f368, %f179;
	mul.ftz.f32 	%f537, %f384, %f34;
	mul.ftz.f32 	%f538, %f384, %f36;
	mul.ftz.f32 	%f539, %f384, %f37;
	mul.ftz.f32 	%f557, %f375, %f517;
	mul.ftz.f32 	%f558, %f375, %f518;
	mul.ftz.f32 	%f559, %f375, %f519;
	neg.f32 	%f573, %f382;
	fma.rn.ftz.f32 	%f577, %f573, %f537, %f557;
	fma.rn.ftz.f32 	%f578, %f573, %f538, %f558;
	fma.rn.ftz.f32 	%f579, %f573, %f539, %f559;
	neg.f32 	%f581, %f368;
	fma.rn.ftz.f32 	%f585, %f581, %f175, %f577;
	fma.rn.ftz.f32 	%f586, %f581, %f177, %f578;
	fma.rn.ftz.f32 	%f587, %f581, %f179, %f579;
	neg.ftz.f32 	%f589, %f577;
	neg.ftz.f32 	%f590, %f578;
	neg.ftz.f32 	%f591, %f579;
	neg.f32 	%f593, %f384;
	fma.rn.ftz.f32 	%f597, %f593, %f34, %f589;
	fma.rn.ftz.f32 	%f598, %f593, %f36, %f590;
	fma.rn.ftz.f32 	%f599, %f593, %f37, %f591;
	mul.ftz.f32 	%f398, %f517, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl19, %f398;
	shl.b32 	%r83, %r135, 3;
	ld.param.u32 	%r144, [computeBondedForces_param_0];
	add.s32 	%r84, %r144, %r83;
	atom.global.add.u64 	%rl20, [%r84], %rl19;
	add.s32 	%r85, %r84, 188672;
	mul.ftz.f32 	%f400, %f518, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl21, %f400;
	atom.global.add.u64 	%rl22, [%r85], %rl21;
	add.s32 	%r86, %r84, 377344;
	mul.ftz.f32 	%f402, %f519, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl23, %f402;
	atom.global.add.u64 	%rl24, [%r86], %rl23;
	mul.ftz.f32 	%f404, %f585, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl25, %f404;
	shl.b32 	%r87, %r136, 3;
	add.s32 	%r88, %r144, %r87;
	atom.global.add.u64 	%rl26, [%r88], %rl25;
	add.s32 	%r89, %r88, 188672;
	mul.ftz.f32 	%f406, %f586, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl27, %f406;
	atom.global.add.u64 	%rl28, [%r89], %rl27;
	add.s32 	%r90, %r88, 377344;
	mul.ftz.f32 	%f408, %f587, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl29, %f408;
	atom.global.add.u64 	%rl30, [%r90], %rl29;
	mul.ftz.f32 	%f410, %f597, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl31, %f410;
	shl.b32 	%r91, %r137, 3;
	add.s32 	%r92, %r144, %r91;
	atom.global.add.u64 	%rl32, [%r92], %rl31;
	add.s32 	%r93, %r92, 188672;
	mul.ftz.f32 	%f412, %f598, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl33, %f412;
	atom.global.add.u64 	%rl34, [%r93], %rl33;
	add.s32 	%r94, %r92, 377344;
	mul.ftz.f32 	%f414, %f599, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl35, %f414;
	atom.global.add.u64 	%rl36, [%r94], %rl35;
	mul.ftz.f32 	%f416, %f537, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl37, %f416;
	shl.b32 	%r95, %r138, 3;
	add.s32 	%r96, %r144, %r95;
	atom.global.add.u64 	%rl38, [%r96], %rl37;
	add.s32 	%r97, %r96, 188672;
	mul.ftz.f32 	%f418, %f538, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl39, %f418;
	atom.global.add.u64 	%rl40, [%r97], %rl39;
	add.s32 	%r98, %r96, 377344;
	mul.ftz.f32 	%f420, %f539, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl41, %f420;
	atom.global.add.u64 	%rl42, [%r98], %rl41;
	// inline asm
	mov.u32 	%r79, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r80, %ntid.x;
	// inline asm
	mad.lo.s32 	%r158, %r80, %r79, %r158;
	setp.lt.u32 	%p41, %r158, 7310;
	@%p41 bra 	BB0_11;

BB0_36:
	ld.param.u32 	%r150, [computeBondedForces_param_3];
	and.b32  	%r99, %r150, 1;
	setp.eq.s32 	%p42, %r99, 0;
	@%p42 bra 	BB0_39;

	// inline asm
	mov.u32 	%r100, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r101, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r102, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r103, %tid.x;
	// inline asm
	add.s32 	%r104, %r103, %r100;
	mad.lo.s32 	%r159, %r102, %r101, %r104;
	setp.gt.u32 	%p43, %r159, 6555;
	@%p43 bra 	BB0_39;

BB0_38:
	shl.b32 	%r107, %r159, 3;
	ld.param.u32 	%r153, [computeBondedForces_param_8];
	add.s32 	%r108, %r153, %r107;
	ld.global.v2.u32 	{%r133, %r134}, [%r108];
	shl.b32 	%r110, %r133, 4;
	ld.param.u32 	%r147, [computeBondedForces_param_2];
	add.s32 	%r111, %r147, %r110;
	shl.b32 	%r113, %r134, 4;
	add.s32 	%r114, %r147, %r113;
	shl.b32 	%r115, %r159, 4;
	ld.param.u32 	%r156, [computeBondedForces_param_12];
	add.s32 	%r116, %r156, %r115;
	ld.global.v4.f32 	{%f461, %f462, %f463, %f464}, [%r116];
	ld.global.v4.f32 	{%f465, %f466, %f467, %f468}, [%r114];
	ld.global.v4.f32 	{%f469, %f470, %f471, %f472}, [%r111];
	sub.ftz.f32 	%f473, %f465, %f469;
	sub.ftz.f32 	%f474, %f466, %f470;
	sub.ftz.f32 	%f475, %f467, %f471;
	mul.ftz.f32 	%f425, %f474, %f474;
	fma.rn.ftz.f32 	%f426, %f473, %f473, %f425;
	fma.rn.ftz.f32 	%f422, %f475, %f475, %f426;
	// inline asm
	rsqrt.approx.f32 	%f421, %f422;
	// inline asm
	mul.ftz.f32 	%f429, %f421, %f462;
	mul.ftz.f32 	%f430, %f429, %f429;
	mul.ftz.f32 	%f431, %f430, %f430;
	mul.ftz.f32 	%f432, %f431, %f430;
	fma.rn.ftz.f32 	%f434, %f432, 0f41400000, 0fC0C00000;
	mul.ftz.f32 	%f435, %f463, %f434;
	fma.rn.ftz.f32 	%f436, %f431, %f430, 0fBF800000;
	mul.ftz.f32 	%f437, %f463, %f436;
	mul.ftz.f32 	%f439, %f461, %f421;
	fma.rn.ftz.f32 	%f440, %f435, %f432, %f439;
	mul.ftz.f32 	%f441, %f421, %f421;
	mul.ftz.f32 	%f442, %f440, %f441;
	fma.rn.ftz.f32 	%f443, %f437, %f432, %f439;
	add.ftz.f32 	%f796, %f796, %f443;
	mul.ftz.f32 	%f489, %f473, %f442;
	mul.ftz.f32 	%f490, %f474, %f442;
	mul.ftz.f32 	%f491, %f475, %f442;
	neg.ftz.f32 	%f497, %f489;
	neg.ftz.f32 	%f498, %f490;
	neg.ftz.f32 	%f499, %f491;
	shl.b32 	%r117, %r133, 3;
	mul.ftz.f32 	%f448, %f497, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl43, %f448;
	ld.param.u32 	%r143, [computeBondedForces_param_0];
	add.s32 	%r118, %r143, %r117;
	atom.global.add.u64 	%rl44, [%r118], %rl43;
	add.s32 	%r119, %r118, 188672;
	mul.ftz.f32 	%f450, %f498, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl45, %f450;
	atom.global.add.u64 	%rl46, [%r119], %rl45;
	add.s32 	%r120, %r118, 377344;
	mul.ftz.f32 	%f452, %f499, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl47, %f452;
	atom.global.add.u64 	%rl48, [%r120], %rl47;
	shl.b32 	%r121, %r134, 3;
	mul.ftz.f32 	%f454, %f489, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl49, %f454;
	add.s32 	%r122, %r143, %r121;
	atom.global.add.u64 	%rl50, [%r122], %rl49;
	add.s32 	%r123, %r122, 188672;
	mul.ftz.f32 	%f456, %f490, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl51, %f456;
	atom.global.add.u64 	%rl52, [%r123], %rl51;
	add.s32 	%r124, %r122, 377344;
	mul.ftz.f32 	%f458, %f491, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl53, %f458;
	atom.global.add.u64 	%rl54, [%r124], %rl53;
	// inline asm
	mov.u32 	%r105, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r106, %ntid.x;
	// inline asm
	mad.lo.s32 	%r159, %r106, %r105, %r159;
	setp.lt.u32 	%p44, %r159, 6556;
	@%p44 bra 	BB0_38;

BB0_39:
	// inline asm
	mov.u32 	%r125, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r126, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r127, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r128, %tid.x;
	// inline asm
	add.s32 	%r129, %r128, %r125;
	mad.lo.s32 	%r130, %r127, %r126, %r129;
	shl.b32 	%r131, %r130, 2;
	ld.param.u32 	%r146, [computeBondedForces_param_1];
	add.s32 	%r132, %r146, %r131;
	ld.global.f32 	%f459, [%r132];
	add.ftz.f32 	%f460, %f459, %f796;
	st.global.f32 	[%r132], %f460;
	ret;
}



//
// Generated by LWPU LWVM Compiler
// Compiler built on Thu May 15 11:00:55 2014 (1400169655)
// Driver 
//

//.version 3.0
//.target sm_30, texmode_independent
//.address_size 32

.visible .shared .align 4 .b8 shr_3_localData[9216];
.visible .shared .align 4 .b8 shr_4_atomIndices[1024];
.visible .shared .align 4 .b8 shr_5_skipTiles[1024];

.entry computeNonbonded(
	.param .u32 .ptr .global .align 8 computeNonbonded_param_0,
	.param .u32 .ptr .global .align 4 computeNonbonded_param_1,
	.param .u32 .ptr .global .align 16 computeNonbonded_param_2,
	.param .u32 .ptr .global .align 4 computeNonbonded_param_3,
	.param .u32 .ptr .global .align 4 computeNonbonded_param_4,
	.param .u32 computeNonbonded_param_5,
	.param .u32 computeNonbonded_param_6,
	.param .u32 .ptr .global .align 4 computeNonbonded_param_7,
	.param .u32 .ptr .global .align 4 computeNonbonded_param_8,
	.param .align 16 .b8 computeNonbonded_param_9[16],
	.param .align 16 .b8 computeNonbonded_param_10[16],
	.param .u32 computeNonbonded_param_11,
	.param .u32 .ptr .global .align 16 computeNonbonded_param_12,
	.param .u32 .ptr .global .align 16 computeNonbonded_param_13,
	.param .u32 .ptr .global .align 4 computeNonbonded_param_14,
	.param .u32 .ptr .global .align 8 computeNonbonded_param_15
)
{
	.reg .f32 	%f<818>;
	.reg .s16 	%rs<9>;
	.reg .pred 	%p<76>;
	.reg .s32 	%r<357>;
	.reg .s64 	%rl<25>;


	ld.param.v4.f32 	{%f535, %f536, %f537, %f538}, [computeNonbonded_param_10];
	ld.param.v4.f32 	{%f551, %f552, %f553, %f554}, [computeNonbonded_param_9];
	// inline asm
	mov.u32 	%r102, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r103, %ntid.x;
	// inline asm
	mul.lo.s32 	%r110, %r103, %r102;
	shr.u32 	%r15, %r110, 5;
	// inline asm
	mov.u32 	%r104, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r105, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r106, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r107, %tid.x;
	// inline asm
	add.s32 	%r111, %r107, %r104;
	mad.lo.s32 	%r112, %r106, %r105, %r111;
	shr.u32 	%r16, %r112, 5;
	// inline asm
	mov.u32 	%r108, %tid.x;
	// inline asm
	and.b32  	%r18, %r108, 31;
	// inline asm
	mov.u32 	%r109, %tid.x;
	// inline asm
	sub.s32 	%r20, %r109, %r18;
	mul.lo.s32 	%r113, %r16, 1253;
	div.u32 	%r324, %r113, %r15;
	mad.lo.s32 	%r114, %r16, 1253, 1253;
	div.u32 	%r22, %r114, %r15;
	setp.lt.u32 	%p16, %r324, %r22;
	@%p16 bra 	BB0_2;

	mov.f32 	%f807, 0f00000000;
	bra.uni 	BB0_26;

BB0_2:
	neg.s32 	%r115, %r108;
	and.b32  	%r23, %r115, 31;
	and.b32  	%r24, %r108, 31;
	sub.s32 	%r116, %r109, %r24;
	mov.u32 	%r117, shr_3_localData;
	mad.lo.s32 	%r25, %r116, 36, %r117;
	mov.f32 	%f807, 0f00000000;

BB0_3:
	shl.b32 	%r119, %r324, 2;
	ld.param.u32 	%r309, [computeNonbonded_param_4];
	add.s32 	%r120, %r309, %r119;
	ld.global.v2.u16 	{%rs7, %rs8}, [%r120];
	cvt.u32.u16 	%r121, %rs7;
	cvt.u32.u16 	%r27, %rs8;
	shl.b32 	%r122, %r121, 5;
	add.s32 	%r28, %r122, %r18;
	shl.b32 	%r123, %r28, 4;
	ld.param.u32 	%r306, [computeNonbonded_param_2];
	add.s32 	%r124, %r306, %r123;
	ld.global.v4.f32 	{%f691, %f692, %f693, %f694}, [%r124];
	shl.b32 	%r125, %r28, 3;
	ld.param.u32 	%r323, [computeNonbonded_param_15];
	add.s32 	%r126, %r323, %r125;
	ld.global.v2.f32 	{%f715, %f716}, [%r126];
	shl.b32 	%r127, %r324, 5;
	add.s32 	%r128, %r127, %r18;
	shl.b32 	%r129, %r128, 2;
	ld.param.u32 	%r307, [computeNonbonded_param_3];
	add.s32 	%r130, %r307, %r129;
	ld.global.u32 	%r328, [%r130];
	setp.eq.s16 	%p1, %rs7, %rs8;
	// inline asm
	mov.u32 	%r118, %tid.x;
	// inline asm
	mad.lo.s32 	%r30, %r118, 36, %r117;
	@%p1 bra 	BB0_14;

	shl.b32 	%r31, %r27, 5;
	add.s32 	%r133, %r31, %r18;
	shl.b32 	%r134, %r133, 4;
	ld.param.u32 	%r305, [computeNonbonded_param_2];
	add.s32 	%r135, %r305, %r134;
	ld.global.v4.f32 	{%f789, %f790, %f791, %f792}, [%r135];
	mov.u32 	%r136, 0;
	st.shared.f32 	[%r30], %f789;
	st.shared.f32 	[%r30+4], %f790;
	st.shared.f32 	[%r30+8], %f791;
	st.shared.f32 	[%r30+12], %f792;
	shl.b32 	%r137, %r133, 3;
	ld.param.u32 	%r322, [computeNonbonded_param_15];
	add.s32 	%r138, %r322, %r137;
	ld.global.v2.f32 	{%f793, %f794}, [%r138];
	st.shared.f32 	[%r30+28], %f793;
	mov.u32 	%r325, 32;
	st.shared.f32 	[%r30+32], %f794;
	st.shared.u32 	[%r30+16], %r136;
	mov.f32 	%f100, 0f00000000;
	st.shared.u32 	[%r30+20], %r136;
	st.shared.u32 	[%r30+24], %r136;
	shl.b32 	%r139, %r328, %r23;
	shr.u32 	%r140, %r328, %r18;
	or.b32  	%r326, %r140, %r139;
	setp.gt.u32 	%p2, %r28, 23557;
	setp.lt.u32 	%p3, %r28, 23558;
	mul.ftz.f32 	%f2, %f694, 0f430AEF7A;
	mov.f32 	%f813, %f100;
	mov.f32 	%f814, %f100;
	mov.f32 	%f815, %f100;
	mov.f32 	%f817, %f100;
	mov.u32 	%r356, %r18;

BB0_5:
	add.s32 	%r141, %r356, %r20;
	mad.lo.s32 	%r36, %r141, 36, %r117;
	ld.shared.f32 	%f108, [%r36];
	ld.shared.f32 	%f109, [%r36+4];
	ld.shared.f32 	%f110, [%r36+8];
	ld.shared.f32 	%f6, [%r36+12];
	sub.ftz.f32 	%f761, %f108, %f691;
	sub.ftz.f32 	%f762, %f109, %f692;
	sub.ftz.f32 	%f763, %f110, %f693;
	mov.f32 	%f112, 0f3F000000;
	fma.rn.ftz.f32 	%f773, %f761, %f535, %f112;
	fma.rn.ftz.f32 	%f774, %f762, %f536, %f112;
	fma.rn.ftz.f32 	%f775, %f763, %f537, %f112;
	// inline asm
	cvt.rmi.f32.f32 	%f102, %f773;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f104, %f774;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f106, %f775;
	// inline asm
	neg.f32 	%f781, %f102;
	neg.f32 	%f782, %f104;
	neg.f32 	%f783, %f106;
	fma.rn.ftz.f32 	%f785, %f781, %f551, %f761;
	fma.rn.ftz.f32 	%f786, %f782, %f552, %f762;
	fma.rn.ftz.f32 	%f787, %f783, %f553, %f763;
	mul.ftz.f32 	%f116, %f786, %f786;
	fma.rn.ftz.f32 	%f117, %f785, %f785, %f116;
	fma.rn.ftz.f32 	%f7, %f787, %f787, %f117;
	setp.lt.ftz.f32 	%p17, %f7, 0f3F23D70A;
	@%p17 bra 	BB0_6;
	bra.uni 	BB0_13;

BB0_6:
	// inline asm
	rsqrt.approx.f32 	%f119, %f7;
	// inline asm
	// inline asm
	div.approx.f32 	%f121, 1.0, %f119;
	// inline asm
	ld.shared.f32 	%f10, [%r36+28];
	ld.shared.f32 	%f11, [%r36+32];
	add.s32 	%r143, %r356, %r31;
	setp.gt.s32 	%p18, %r143, 23557;
	or.pred  	%p19, %p2, %p18;
	and.b32  	%r144, %r326, 1;
	setp.eq.s32 	%p20, %r144, 0;
	or.pred  	%p21, %p19, %p20;
	setp.ne.s32 	%p22, %r28, %r143;
	and.pred  	%p23, %p21, %p22;
	and.pred  	%p24, %p23, %p3;
	setp.lt.s32 	%p25, %r143, 23558;
	and.pred  	%p4, %p24, %p25;
	not.pred 	%p26, %p2;
	and.pred  	%p27, %p26, %p25;
	{
	.reg .b32 temp;
	and.b32	 temp, %r144, 1;
	setp.b32.eq 	 %p28, temp, 1;
	}
	and.pred  	%p29, %p27, %p28;
	or.pred  	%p30, %p4, %p29;
	@%p30 bra 	BB0_8;

	mov.f32 	%f797, %f100;
	mov.f32 	%f798, %f100;
	bra.uni 	BB0_12;

BB0_8:
	mul.ftz.f32 	%f129, %f121, 0f405242C8;
	neg.ftz.f32 	%f130, %f129;
	mul.ftz.f32 	%f126, %f129, %f130;
	// inline asm
	mul.f32 	%f125, %f126, 0f3FB8AA3B;ex2.approx.f32 	%f125, %f125;
	// inline asm
	mul.ftz.f32 	%f131, %f2, %f6;
	mul.ftz.f32 	%f12, %f131, %f119;
	fma.rn.ftz.f32 	%f132, %f129, 0f38349F67, 0f39910039;
	fma.rn.ftz.f32 	%f133, %f132, %f129, 0f391F6607;
	fma.rn.ftz.f32 	%f134, %f133, %f129, 0f3C17E369;
	fma.rn.ftz.f32 	%f135, %f134, %f129, 0f3D2D2FE7;
	fma.rn.ftz.f32 	%f136, %f135, %f129, 0f3D906E67;
	fma.rn.ftz.f32 	%f137, %f136, %f129, 0f3F800000;
	mul.ftz.f32 	%f138, %f137, %f137;
	mul.ftz.f32 	%f139, %f138, %f138;
	mul.ftz.f32 	%f140, %f139, %f139;
	mul.ftz.f32 	%f128, %f140, %f140;
	// inline asm
	div.approx.f32 	%f127, 1.0, %f128;
	// inline asm
	mul.ftz.f32 	%f141, %f129, %f125;
	mul.ftz.f32 	%f14, %f141, 0f3F906EBB;
	@%p4 bra 	BB0_10;

	add.ftz.f32 	%f142, %f715, %f10;
	mul.ftz.f32 	%f143, %f119, %f142;
	mul.ftz.f32 	%f144, %f143, %f143;
	mul.ftz.f32 	%f145, %f144, %f144;
	mul.ftz.f32 	%f146, %f145, %f144;
	mul.ftz.f32 	%f147, %f716, %f11;
	mul.ftz.f32 	%f148, %f146, %f147;
	fma.rn.ftz.f32 	%f149, %f146, 0f41400000, 0fC0C00000;
	add.ftz.f32 	%f150, %f127, %f14;
	mul.ftz.f32 	%f151, %f12, %f150;
	fma.rn.ftz.f32 	%f796, %f148, %f149, %f151;
	fma.rn.ftz.f32 	%f152, %f145, %f144, 0fBF800000;
	mul.ftz.f32 	%f153, %f12, %f127;
	fma.rn.ftz.f32 	%f795, %f148, %f152, %f153;
	bra.uni 	BB0_11;

BB0_10:
	neg.ftz.f32 	%f154, %f12;
	mov.f32 	%f155, 0f3F800000;
	sub.ftz.f32 	%f156, %f155, %f127;
	sub.ftz.f32 	%f157, %f156, %f14;
	mul.ftz.f32 	%f796, %f157, %f154;
	mul.ftz.f32 	%f795, %f156, %f154;

BB0_11:
	add.ftz.f32 	%f21, %f795, 0f00000000;
	mul.ftz.f32 	%f158, %f796, %f119;
	fma.rn.ftz.f32 	%f797, %f158, %f119, 0f00000000;
	mov.f32 	%f798, %f21;

BB0_12:
	mov.f32 	%f24, %f798;
	add.ftz.f32 	%f807, %f807, %f24;
	mul.ftz.f32 	%f737, %f785, %f797;
	mul.ftz.f32 	%f738, %f786, %f797;
	mul.ftz.f32 	%f739, %f787, %f797;
	sub.ftz.f32 	%f749, %f813, %f737;
	sub.ftz.f32 	%f750, %f814, %f738;
	sub.ftz.f32 	%f751, %f815, %f739;
	mov.f32 	%f813, %f749;
	mov.f32 	%f814, %f750;
	mov.f32 	%f815, %f751;
	mov.f32 	%f817, %f817;
	ld.shared.f32 	%f163, [%r36+16];
	add.ftz.f32 	%f164, %f163, %f737;
	st.shared.f32 	[%r36+16], %f164;
	ld.shared.f32 	%f166, [%r36+20];
	add.ftz.f32 	%f167, %f166, %f738;
	st.shared.f32 	[%r36+20], %f167;
	ld.shared.f32 	%f169, [%r36+24];
	add.ftz.f32 	%f170, %f169, %f739;
	st.shared.f32 	[%r36+24], %f170;

BB0_13:
	shr.u32 	%r326, %r326, 1;
	add.s32 	%r145, %r356, 1;
	and.b32  	%r356, %r145, 31;
	add.s32 	%r325, %r325, -1;
	setp.ne.s32 	%p31, %r325, 0;
	@%p31 bra 	BB0_5;
	bra.uni 	BB0_23;

BB0_14:
	mov.u32 	%r329, 0;
	st.shared.f32 	[%r30], %f691;
	st.shared.f32 	[%r30+4], %f692;
	st.shared.f32 	[%r30+8], %f693;
	st.shared.f32 	[%r30+12], %f694;
	st.shared.f32 	[%r30+28], %f715;
	st.shared.f32 	[%r30+32], %f716;
	setp.gt.u32 	%p5, %r28, 23557;
	setp.lt.u32 	%p6, %r28, 23558;
	mul.ftz.f32 	%f29, %f694, 0f430AEF7A;
	add.s32 	%r149, %r24, %r122;
	shl.b32 	%r41, %r27, 5;
	sub.s32 	%r42, %r149, %r41;
	mov.f32 	%f175, 0f00000000;
	mov.f32 	%f813, %f175;
	mov.f32 	%f814, %f175;
	mov.f32 	%f815, %f175;
	mov.f32 	%f816, %f175;
	mov.u32 	%r327, %r25;

BB0_15:
	ld.shared.f32 	%f186, [%r327];
	ld.shared.f32 	%f187, [%r327+4];
	ld.shared.f32 	%f188, [%r327+8];
	ld.shared.f32 	%f31, [%r327+12];
	sub.ftz.f32 	%f687, %f186, %f691;
	sub.ftz.f32 	%f688, %f187, %f692;
	sub.ftz.f32 	%f689, %f188, %f693;
	mov.f32 	%f190, 0f3F000000;
	fma.rn.ftz.f32 	%f703, %f687, %f535, %f190;
	fma.rn.ftz.f32 	%f704, %f688, %f536, %f190;
	fma.rn.ftz.f32 	%f705, %f689, %f537, %f190;
	// inline asm
	cvt.rmi.f32.f32 	%f176, %f703;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f178, %f704;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f180, %f705;
	// inline asm
	neg.f32 	%f711, %f176;
	neg.f32 	%f712, %f178;
	neg.f32 	%f713, %f180;
	fma.rn.ftz.f32 	%f667, %f711, %f551, %f687;
	fma.rn.ftz.f32 	%f668, %f712, %f552, %f688;
	fma.rn.ftz.f32 	%f669, %f713, %f553, %f689;
	mul.ftz.f32 	%f194, %f668, %f668;
	fma.rn.ftz.f32 	%f195, %f667, %f667, %f194;
	fma.rn.ftz.f32 	%f183, %f669, %f669, %f195;
	// inline asm
	rsqrt.approx.f32 	%f182, %f183;
	// inline asm
	// inline asm
	div.approx.f32 	%f184, 1.0, %f182;
	// inline asm
	ld.shared.f32 	%f35, [%r327+28];
	ld.shared.f32 	%f36, [%r327+32];
	add.s32 	%r151, %r41, %r329;
	setp.gt.s32 	%p32, %r151, 23557;
	or.pred  	%p33, %p5, %p32;
	and.b32  	%r152, %r328, 1;
	setp.eq.s32 	%p34, %r152, 0;
	or.pred  	%p35, %p33, %p34;
	setp.ne.s32 	%p36, %r42, %r329;
	and.pred  	%p37, %p35, %p36;
	and.pred  	%p38, %p37, %p6;
	setp.lt.s32 	%p39, %r151, 23558;
	and.pred  	%p7, %p38, %p39;
	not.pred 	%p40, %p5;
	and.pred  	%p41, %p40, %p39;
	{
	.reg .b32 temp;
	and.b32	 temp, %r152, 1;
	setp.b32.eq 	 %p42, temp, 1;
	}
	and.pred  	%p43, %p41, %p42;
	or.pred  	%p44, %p7, %p43;
	@!%p44 bra 	BB0_17;

	setp.lt.ftz.f32 	%p45, %f183, 0f3F23D70A;
	or.pred  	%p46, %p45, %p7;
	@%p46 bra 	BB0_18;

BB0_17:
	mov.f32 	%f801, %f175;
	mov.f32 	%f802, %f175;
	bra.uni 	BB0_22;

BB0_18:
	mul.ftz.f32 	%f203, %f184, 0f405242C8;
	neg.ftz.f32 	%f204, %f203;
	mul.ftz.f32 	%f200, %f203, %f204;
	// inline asm
	mul.f32 	%f199, %f200, 0f3FB8AA3B;ex2.approx.f32 	%f199, %f199;
	// inline asm
	mul.ftz.f32 	%f205, %f29, %f31;
	mul.ftz.f32 	%f37, %f205, %f182;
	fma.rn.ftz.f32 	%f206, %f203, 0f38349F67, 0f39910039;
	fma.rn.ftz.f32 	%f207, %f206, %f203, 0f391F6607;
	fma.rn.ftz.f32 	%f208, %f207, %f203, 0f3C17E369;
	fma.rn.ftz.f32 	%f209, %f208, %f203, 0f3D2D2FE7;
	fma.rn.ftz.f32 	%f210, %f209, %f203, 0f3D906E67;
	fma.rn.ftz.f32 	%f211, %f210, %f203, 0f3F800000;
	mul.ftz.f32 	%f212, %f211, %f211;
	mul.ftz.f32 	%f213, %f212, %f212;
	mul.ftz.f32 	%f214, %f213, %f213;
	mul.ftz.f32 	%f202, %f214, %f214;
	// inline asm
	div.approx.f32 	%f201, 1.0, %f202;
	// inline asm
	mul.ftz.f32 	%f215, %f203, %f199;
	mul.ftz.f32 	%f39, %f215, 0f3F906EBB;
	@%p7 bra 	BB0_20;

	add.ftz.f32 	%f216, %f715, %f35;
	mul.ftz.f32 	%f217, %f182, %f216;
	mul.ftz.f32 	%f218, %f217, %f217;
	mul.ftz.f32 	%f219, %f218, %f218;
	mul.ftz.f32 	%f220, %f219, %f218;
	mul.ftz.f32 	%f221, %f716, %f36;
	mul.ftz.f32 	%f222, %f220, %f221;
	fma.rn.ftz.f32 	%f223, %f220, 0f41400000, 0fC0C00000;
	add.ftz.f32 	%f224, %f201, %f39;
	mul.ftz.f32 	%f225, %f37, %f224;
	fma.rn.ftz.f32 	%f800, %f222, %f223, %f225;
	fma.rn.ftz.f32 	%f226, %f219, %f218, 0fBF800000;
	mul.ftz.f32 	%f227, %f37, %f201;
	fma.rn.ftz.f32 	%f799, %f222, %f226, %f227;
	bra.uni 	BB0_21;

BB0_20:
	neg.ftz.f32 	%f228, %f37;
	mov.f32 	%f229, 0f3F800000;
	sub.ftz.f32 	%f230, %f229, %f201;
	sub.ftz.f32 	%f231, %f230, %f39;
	mul.ftz.f32 	%f800, %f231, %f228;
	mul.ftz.f32 	%f799, %f230, %f228;

BB0_21:
	add.ftz.f32 	%f46, %f799, 0f00000000;
	mul.ftz.f32 	%f232, %f800, %f182;
	fma.rn.ftz.f32 	%f801, %f232, %f182, 0f00000000;
	mov.f32 	%f802, %f46;

BB0_22:
	mov.f32 	%f49, %f802;
	fma.rn.ftz.f32 	%f807, %f49, 0f3F000000, %f807;
	neg.f32 	%f663, %f667;
	neg.f32 	%f664, %f668;
	neg.f32 	%f665, %f669;
	fma.rn.ftz.f32 	%f671, %f663, %f801, %f813;
	fma.rn.ftz.f32 	%f672, %f664, %f801, %f814;
	fma.rn.ftz.f32 	%f673, %f665, %f801, %f815;
	mov.f32 	%f813, %f671;
	mov.f32 	%f814, %f672;
	mov.f32 	%f815, %f673;
	mov.f32 	%f816, %f816;
	shr.u32 	%r328, %r328, 1;
	add.s32 	%r327, %r327, 36;
	add.s32 	%r329, %r329, 1;
	setp.ne.s32 	%p47, %r329, 32;
	@%p47 bra 	BB0_15;

BB0_23:
	mul.ftz.f32 	%f237, %f813, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl1, %f237;
	ld.param.u32 	%r301, [computeNonbonded_param_0];
	add.s32 	%r154, %r301, %r125;
	atom.global.add.u64 	%rl2, [%r154], %rl1;
	add.s32 	%r155, %r154, 188672;
	mul.ftz.f32 	%f239, %f814, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl3, %f239;
	atom.global.add.u64 	%rl4, [%r155], %rl3;
	add.s32 	%r156, %r154, 377344;
	mul.ftz.f32 	%f241, %f815, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl5, %f241;
	atom.global.add.u64 	%rl6, [%r156], %rl5;
	@%p1 bra 	BB0_25;

	shl.b32 	%r160, %r27, 5;
	add.s32 	%r161, %r160, %r18;
	shl.b32 	%r162, %r161, 3;
	// inline asm
	mov.u32 	%r157, %tid.x;
	// inline asm
	mad.lo.s32 	%r164, %r157, 36, %r117;
	ld.shared.f32 	%f242, [%r164+16];
	mul.ftz.f32 	%f243, %f242, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl7, %f243;
	ld.param.u32 	%r300, [computeNonbonded_param_0];
	add.s32 	%r165, %r300, %r162;
	atom.global.add.u64 	%rl8, [%r165], %rl7;
	add.s32 	%r166, %r165, 188672;
	// inline asm
	mov.u32 	%r158, %tid.x;
	// inline asm
	mad.lo.s32 	%r167, %r158, 36, %r117;
	ld.shared.f32 	%f244, [%r167+20];
	mul.ftz.f32 	%f245, %f244, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl9, %f245;
	atom.global.add.u64 	%rl10, [%r166], %rl9;
	add.s32 	%r168, %r165, 377344;
	// inline asm
	mov.u32 	%r159, %tid.x;
	// inline asm
	mad.lo.s32 	%r169, %r159, 36, %r117;
	ld.shared.f32 	%f246, [%r169+24];
	mul.ftz.f32 	%f247, %f246, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl11, %f247;
	atom.global.add.u64 	%rl12, [%r168], %rl11;

BB0_25:
	add.s32 	%r324, %r324, 1;
	setp.lt.u32 	%p48, %r324, %r22;
	@%p48 bra 	BB0_3;

BB0_26:
	ld.param.u32 	%r315, [computeNonbonded_param_8];
	ldu.global.u32 	%r50, [%r315];
	ld.param.u32 	%r316, [computeNonbonded_param_11];
	setp.gt.u32 	%p8, %r50, %r316;
	@%p8 bra 	BB0_28;

	mul.lo.s32 	%r170, %r50, %r16;
	div.u32 	%r332, %r170, %r15;
	bra.uni 	BB0_29;

BB0_28:
	ld.param.u32 	%r313, [computeNonbonded_param_6];
	mul.lo.s32 	%r171, %r16, %r313;
	div.u32 	%r172, %r171, %r15;
	ld.param.u32 	%r311, [computeNonbonded_param_5];
	add.s32 	%r332, %r172, %r311;

BB0_29:
	add.s32 	%r54, %r16, 1;
	@%p8 bra 	BB0_31;

	mul.lo.s32 	%r173, %r50, %r54;
	div.u32 	%r330, %r173, %r15;
	bra.uni 	BB0_32;

BB0_31:
	ld.param.u32 	%r312, [computeNonbonded_param_6];
	mul.lo.s32 	%r174, %r54, %r312;
	div.u32 	%r175, %r174, %r15;
	ld.param.u32 	%r310, [computeNonbonded_param_5];
	add.s32 	%r330, %r175, %r310;

BB0_32:
	// inline asm
	mov.u32 	%r176, %tid.x;
	// inline asm
	shl.b32 	%r177, %r176, 2;
	mov.u32 	%r178, shr_5_skipTiles;
	add.s32 	%r179, %r178, %r177;
	mov.u32 	%r180, -1;
	st.volatile.shared.u32 	[%r179], %r180;
	setp.lt.s32 	%p49, %r332, %r330;
	@%p49 bra 	BB0_33;
	bra.uni 	BB0_77;

BB0_33:
	mov.u32 	%r333, 0;
	mul.ftz.f32 	%f53, %f551, 0f3F000000;
	mul.ftz.f32 	%f54, %f552, 0f3F000000;
	mul.ftz.f32 	%f55, %f553, 0f3F000000;
	shl.b32 	%r183, %r20, 2;
	add.s32 	%r58, %r183, %r178;
	mov.u32 	%r347, %r20;

BB0_34:
	mov.u32 	%r338, %r347;
	mov.u32 	%r344, %r338;
	@%p8 bra 	BB0_39;

	shl.b32 	%r185, %r332, 2;
	ld.param.u32 	%r314, [computeNonbonded_param_7];
	add.s32 	%r186, %r314, %r185;
	ld.global.u16 	%r348, [%r186];
	shl.b32 	%r187, %r348, 4;
	ld.param.u32 	%r318, [computeNonbonded_param_13];
	add.s32 	%r188, %r318, %r187;
	ld.global.v4.f32 	{%f635, %f636, %f637, %f638}, [%r188];
	sub.ftz.f32 	%f252, %f53, %f635;
	setp.ltu.ftz.f32 	%p50, %f252, 0f3F4CCCCD;
	@%p50 bra 	BB0_38;

	sub.ftz.f32 	%f254, %f54, %f636;
	setp.ltu.ftz.f32 	%p51, %f254, 0f3F4CCCCD;
	@%p51 bra 	BB0_38;

	sub.ftz.f32 	%f256, %f55, %f637;
	setp.ge.ftz.f32 	%p75, %f256, 0f3F4CCCCD;
	mov.pred 	%p74, -1;
	bra.uni 	BB0_53;

BB0_38:
	mov.pred 	%p75, 0;
	mov.pred 	%p74, -1;
	bra.uni 	BB0_53;

BB0_39:
	shl.b32 	%r189, %r332, 1;
	cvt.rn.f32.s32 	%f261, %r189;
	mov.f32 	%f262, 0f4904CA24;
	sub.ftz.f32 	%f258, %f262, %f261;
	// inline asm
	sqrt.approx.f32 	%f257, %f258;
	// inline asm
	mov.f32 	%f263, 0f44386000;
	sub.ftz.f32 	%f260, %f263, %f257;
	// inline asm
	cvt.rmi.f32.f32 	%f259, %f260;
	// inline asm
	cvt.rzi.ftz.u32.f32 	%r331, %f259;
	mul.lo.s32 	%r190, %r331, 737;
	sub.s32 	%r191, %r332, %r190;
	add.s32 	%r192, %r331, 1;
	mul.lo.s32 	%r193, %r192, %r331;
	shr.u32 	%r194, %r193, 1;
	add.s32 	%r348, %r194, %r191;
	setp.lt.u32 	%p10, %r348, %r331;
	setp.gt.u32 	%p55, %r348, 736;
	or.pred  	%p56, %p10, %p55;
	@%p56 bra 	BB0_40;
	bra.uni 	BB0_41;

BB0_40:
	selp.b32 	%r195, -1, 1, %p10;
	add.s32 	%r331, %r195, %r331;
	mul.lo.s32 	%r196, %r331, 737;
	add.s32 	%r197, %r331, 1;
	mul.lo.s32 	%r198, %r197, %r331;
	shr.u32 	%r199, %r198, 1;
	sub.s32 	%r200, %r332, %r196;
	add.s32 	%r348, %r200, %r199;

BB0_41:
	ld.volatile.shared.u32 	%r201, [%r58+124];
	setp.lt.s32 	%p57, %r201, %r332;
	@%p57 bra 	BB0_43;

	mov.u32 	%r346, %r344;
	bra.uni 	BB0_48;

BB0_43:
	add.s32 	%r71, %r333, %r18;
	setp.lt.u32 	%p58, %r71, 1253;
	@%p58 bra 	BB0_45;

	// inline asm
	mov.u32 	%r202, %tid.x;
	// inline asm
	shl.b32 	%r203, %r202, 2;
	add.s32 	%r205, %r178, %r203;
	st.volatile.shared.u32 	[%r205], %r330;
	bra.uni 	BB0_46;

BB0_45:
	shl.b32 	%r207, %r71, 2;
	ld.param.u32 	%r308, [computeNonbonded_param_4];
	add.s32 	%r208, %r308, %r207;
	ld.global.v2.u16 	{%rs5, %rs6}, [%r208];
	cvt.u32.u16 	%r209, %rs5;
	cvt.u32.u16 	%r210, %rs6;
	add.s32 	%r211, %r210, 1;
	mul.lo.s32 	%r212, %r211, %r210;
	shr.u32 	%r213, %r212, 31;
	mad.lo.s32 	%r214, %r211, %r210, %r213;
	shr.s32 	%r215, %r214, 1;
	sub.s32 	%r216, %r209, %r215;
	mad.lo.s32 	%r217, %r210, 737, %r216;
	// inline asm
	mov.u32 	%r206, %tid.x;
	// inline asm
	shl.b32 	%r218, %r206, 2;
	add.s32 	%r220, %r178, %r218;
	st.volatile.shared.u32 	[%r220], %r217;

BB0_46:
	add.s32 	%r333, %r333, 32;
	ld.volatile.shared.u32 	%r221, [%r58+124];
	setp.lt.s32 	%p59, %r221, %r332;
	@%p59 bra 	BB0_43;

	mov.u32 	%r346, %r20;

BB0_48:
	mov.u32 	%r343, %r346;
	shl.b32 	%r222, %r343, 2;
	add.s32 	%r224, %r178, %r222;
	ld.volatile.shared.u32 	%r225, [%r224];
	setp.lt.s32 	%p60, %r225, %r332;
	@%p60 bra 	BB0_49;
	bra.uni 	BB0_52;

BB0_49:
	mov.u32 	%r345, %r343;

BB0_50:
	add.s32 	%r345, %r345, 1;
	shl.b32 	%r226, %r345, 2;
	add.s32 	%r228, %r178, %r226;
	ld.volatile.shared.u32 	%r229, [%r228];
	setp.lt.s32 	%p61, %r229, %r332;
	@%p61 bra 	BB0_50;

	mov.u32 	%r343, %r345;

BB0_52:
	mov.u32 	%r344, %r343;
	shl.b32 	%r230, %r344, 2;
	add.s32 	%r232, %r178, %r230;
	ld.volatile.shared.u32 	%r233, [%r232];
	setp.ne.s32 	%p74, %r233, %r332;
	mov.pred 	%p75, 0;

BB0_53:
	mov.u32 	%r79, %r344;
	@%p74 bra 	BB0_54;
	bra.uni 	BB0_76;

BB0_54:
	shl.b32 	%r235, %r348, 5;
	add.s32 	%r82, %r235, %r18;
	shl.b32 	%r236, %r82, 4;
	ld.param.u32 	%r304, [computeNonbonded_param_2];
	add.s32 	%r237, %r304, %r236;
	ld.global.v4.f32 	{%f523, %f524, %f525, %f526}, [%r237];
	shl.b32 	%r238, %r82, 3;
	ld.param.u32 	%r321, [computeNonbonded_param_15];
	add.s32 	%r239, %r321, %r238;
	ld.global.v2.f32 	{%f555, %f556}, [%r239];
	// inline asm
	mov.u32 	%r234, %tid.x;
	// inline asm
	@%p8 bra 	BB0_56;

	shl.b32 	%r240, %r332, 5;
	add.s32 	%r241, %r240, %r18;
	shl.b32 	%r242, %r241, 2;
	ld.param.u32 	%r319, [computeNonbonded_param_14];
	add.s32 	%r243, %r319, %r242;
	ld.global.u32 	%r349, [%r243];
	bra.uni 	BB0_57;

BB0_56:
	shl.b32 	%r244, %r331, 5;
	add.s32 	%r349, %r244, %r18;

BB0_57:
	// inline asm
	mov.u32 	%r245, %tid.x;
	// inline asm
	shl.b32 	%r246, %r245, 2;
	mov.u32 	%r247, shr_4_atomIndices;
	add.s32 	%r248, %r247, %r246;
	st.shared.u32 	[%r248], %r349;
	mov.u32 	%r249, shr_3_localData;
	mad.lo.s32 	%r87, %r234, 36, %r249;
	setp.gt.u32 	%p63, %r349, 23583;
	@%p63 bra 	BB0_59;

	shl.b32 	%r250, %r349, 4;
	ld.param.u32 	%r303, [computeNonbonded_param_2];
	add.s32 	%r251, %r303, %r250;
	ld.global.v4.f32 	{%f629, %f630, %f631, %f632}, [%r251];
	mov.u32 	%r252, 0;
	st.shared.f32 	[%r87], %f629;
	st.shared.f32 	[%r87+4], %f630;
	st.shared.f32 	[%r87+8], %f631;
	st.shared.f32 	[%r87+12], %f632;
	shl.b32 	%r253, %r349, 3;
	ld.param.u32 	%r320, [computeNonbonded_param_15];
	add.s32 	%r254, %r320, %r253;
	ld.global.v2.f32 	{%f633, %f634}, [%r254];
	st.shared.f32 	[%r87+28], %f633;
	st.shared.f32 	[%r87+32], %f634;
	st.shared.u32 	[%r87+16], %r252;
	st.shared.u32 	[%r87+20], %r252;
	st.shared.u32 	[%r87+24], %r252;

BB0_59:
	@%p75 bra 	BB0_67;

	setp.lt.u32 	%p14, %r82, 23558;
	mul.ftz.f32 	%f57, %f526, 0f430AEF7A;
	mov.f32 	%f271, 0f00000000;
	mov.f32 	%f808, %f271;
	mov.f32 	%f809, %f271;
	mov.f32 	%f810, %f271;
	mov.f32 	%f812, %f271;
	mov.u32 	%r350, 32;
	mov.u32 	%r355, %r18;

BB0_61:
	add.s32 	%r90, %r355, %r20;
	mad.lo.s32 	%r91, %r90, 36, %r249;
	ld.shared.f32 	%f278, [%r91];
	ld.shared.f32 	%f279, [%r91+4];
	ld.shared.f32 	%f280, [%r91+8];
	ld.shared.f32 	%f61, [%r91+12];
	sub.ftz.f32 	%f601, %f278, %f523;
	sub.ftz.f32 	%f602, %f279, %f524;
	sub.ftz.f32 	%f603, %f280, %f525;
	mov.f32 	%f282, 0f3F000000;
	fma.rn.ftz.f32 	%f613, %f601, %f535, %f282;
	fma.rn.ftz.f32 	%f614, %f602, %f536, %f282;
	fma.rn.ftz.f32 	%f615, %f603, %f537, %f282;
	// inline asm
	cvt.rmi.f32.f32 	%f272, %f613;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f274, %f614;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f276, %f615;
	// inline asm
	neg.f32 	%f621, %f272;
	neg.f32 	%f622, %f274;
	neg.f32 	%f623, %f276;
	fma.rn.ftz.f32 	%f625, %f621, %f551, %f601;
	fma.rn.ftz.f32 	%f626, %f622, %f552, %f602;
	fma.rn.ftz.f32 	%f627, %f623, %f553, %f603;
	mul.ftz.f32 	%f286, %f626, %f626;
	fma.rn.ftz.f32 	%f287, %f625, %f625, %f286;
	fma.rn.ftz.f32 	%f62, %f627, %f627, %f287;
	setp.lt.ftz.f32 	%p64, %f62, 0f3F23D70A;
	@%p64 bra 	BB0_62;
	bra.uni 	BB0_66;

BB0_62:
	// inline asm
	rsqrt.approx.f32 	%f289, %f62;
	// inline asm
	// inline asm
	div.approx.f32 	%f291, 1.0, %f289;
	// inline asm
	ld.shared.f32 	%f65, [%r91+28];
	ld.shared.f32 	%f66, [%r91+32];
	shl.b32 	%r257, %r90, 2;
	add.s32 	%r259, %r247, %r257;
	ld.shared.u32 	%r260, [%r259];
	setp.lt.s32 	%p65, %r260, 23558;
	and.pred  	%p66, %p65, %p14;
	@%p66 bra 	BB0_64;

	mov.f32 	%f803, %f271;
	mov.f32 	%f804, %f271;
	bra.uni 	BB0_65;

BB0_64:
	mul.ftz.f32 	%f299, %f291, 0f405242C8;
	neg.ftz.f32 	%f300, %f299;
	mul.ftz.f32 	%f296, %f299, %f300;
	// inline asm
	mul.f32 	%f295, %f296, 0f3FB8AA3B;ex2.approx.f32 	%f295, %f295;
	// inline asm
	mul.ftz.f32 	%f301, %f57, %f61;
	mul.ftz.f32 	%f302, %f301, %f289;
	fma.rn.ftz.f32 	%f303, %f299, 0f38349F67, 0f39910039;
	fma.rn.ftz.f32 	%f304, %f303, %f299, 0f391F6607;
	fma.rn.ftz.f32 	%f305, %f304, %f299, 0f3C17E369;
	fma.rn.ftz.f32 	%f306, %f305, %f299, 0f3D2D2FE7;
	fma.rn.ftz.f32 	%f307, %f306, %f299, 0f3D906E67;
	fma.rn.ftz.f32 	%f308, %f307, %f299, 0f3F800000;
	mul.ftz.f32 	%f309, %f308, %f308;
	mul.ftz.f32 	%f310, %f309, %f309;
	mul.ftz.f32 	%f311, %f310, %f310;
	mul.ftz.f32 	%f298, %f311, %f311;
	// inline asm
	div.approx.f32 	%f297, 1.0, %f298;
	// inline asm
	add.ftz.f32 	%f312, %f555, %f65;
	mul.ftz.f32 	%f313, %f289, %f312;
	mul.ftz.f32 	%f314, %f313, %f313;
	mul.ftz.f32 	%f315, %f314, %f314;
	mul.ftz.f32 	%f316, %f315, %f314;
	mul.ftz.f32 	%f317, %f556, %f66;
	mul.ftz.f32 	%f318, %f316, %f317;
	fma.rn.ftz.f32 	%f319, %f316, 0f41400000, 0fC0C00000;
	mul.ftz.f32 	%f320, %f299, %f295;
	fma.rn.ftz.f32 	%f321, %f320, 0f3F906EBB, %f297;
	mul.ftz.f32 	%f322, %f302, %f321;
	fma.rn.ftz.f32 	%f323, %f318, %f319, %f322;
	fma.rn.ftz.f32 	%f324, %f315, %f314, 0fBF800000;
	mul.ftz.f32 	%f325, %f302, %f297;
	fma.rn.ftz.f32 	%f326, %f318, %f324, %f325;
	add.ftz.f32 	%f67, %f326, 0f00000000;
	mul.ftz.f32 	%f327, %f323, %f289;
	fma.rn.ftz.f32 	%f803, %f327, %f289, 0f00000000;
	mov.f32 	%f804, %f67;

BB0_65:
	mov.f32 	%f70, %f804;
	add.ftz.f32 	%f807, %f807, %f70;
	mul.ftz.f32 	%f577, %f625, %f803;
	mul.ftz.f32 	%f578, %f626, %f803;
	mul.ftz.f32 	%f579, %f627, %f803;
	sub.ftz.f32 	%f589, %f808, %f577;
	sub.ftz.f32 	%f590, %f809, %f578;
	sub.ftz.f32 	%f591, %f810, %f579;
	mov.f32 	%f808, %f589;
	mov.f32 	%f809, %f590;
	mov.f32 	%f810, %f591;
	mov.f32 	%f812, %f812;
	ld.shared.f32 	%f332, [%r91+16];
	add.ftz.f32 	%f333, %f332, %f577;
	st.shared.f32 	[%r91+16], %f333;
	ld.shared.f32 	%f335, [%r91+20];
	add.ftz.f32 	%f336, %f335, %f578;
	st.shared.f32 	[%r91+20], %f336;
	ld.shared.f32 	%f338, [%r91+24];
	add.ftz.f32 	%f339, %f338, %f579;
	st.shared.f32 	[%r91+24], %f339;

BB0_66:
	add.s32 	%r261, %r355, 1;
	and.b32  	%r355, %r261, 31;
	add.s32 	%r350, %r350, -1;
	setp.ne.s32 	%p67, %r350, 0;
	@%p67 bra 	BB0_61;
	bra.uni 	BB0_74;

BB0_67:
	shl.b32 	%r263, %r348, 4;
	ld.param.u32 	%r317, [computeNonbonded_param_12];
	add.s32 	%r264, %r317, %r263;
	ld.global.v4.f32 	{%f515, %f516, %f517, %f518}, [%r264];
	sub.ftz.f32 	%f519, %f523, %f515;
	sub.ftz.f32 	%f520, %f524, %f516;
	sub.ftz.f32 	%f521, %f525, %f517;
	mov.f32 	%f352, 0f3F000000;
	fma.rn.ftz.f32 	%f531, %f519, %f535, %f352;
	fma.rn.ftz.f32 	%f532, %f520, %f536, %f352;
	fma.rn.ftz.f32 	%f533, %f521, %f537, %f352;
	// inline asm
	cvt.rmi.f32.f32 	%f340, %f531;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f342, %f532;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f344, %f533;
	// inline asm
	neg.f32 	%f543, %f340;
	neg.f32 	%f544, %f342;
	neg.f32 	%f545, %f344;
	fma.rn.ftz.f32 	%f547, %f543, %f551, %f523;
	fma.rn.ftz.f32 	%f548, %f544, %f552, %f524;
	fma.rn.ftz.f32 	%f549, %f545, %f553, %f525;
	ld.shared.f32 	%f355, [%r87];
	sub.ftz.f32 	%f356, %f355, %f515;
	fma.rn.ftz.f32 	%f347, %f356, %f535, 0f3F000000;
	// inline asm
	cvt.rmi.f32.f32 	%f346, %f347;
	// inline asm
	neg.f32 	%f359, %f346;
	fma.rn.ftz.f32 	%f360, %f359, %f551, %f355;
	st.shared.f32 	[%r87], %f360;
	ld.shared.f32 	%f362, [%r87+4];
	sub.ftz.f32 	%f363, %f362, %f516;
	fma.rn.ftz.f32 	%f349, %f363, %f536, 0f3F000000;
	// inline asm
	cvt.rmi.f32.f32 	%f348, %f349;
	// inline asm
	neg.f32 	%f366, %f348;
	fma.rn.ftz.f32 	%f367, %f366, %f552, %f362;
	st.shared.f32 	[%r87+4], %f367;
	ld.shared.f32 	%f369, [%r87+8];
	sub.ftz.f32 	%f370, %f369, %f517;
	fma.rn.ftz.f32 	%f351, %f370, %f537, 0f3F000000;
	// inline asm
	cvt.rmi.f32.f32 	%f350, %f351;
	// inline asm
	neg.f32 	%f373, %f350;
	fma.rn.ftz.f32 	%f374, %f373, %f553, %f369;
	st.shared.f32 	[%r87+8], %f374;
	setp.lt.u32 	%p15, %r82, 23558;
	mul.ftz.f32 	%f73, %f526, 0f430AEF7A;
	mov.f32 	%f376, 0f00000000;
	mov.f32 	%f808, %f376;
	mov.f32 	%f809, %f376;
	mov.f32 	%f810, %f376;
	mov.f32 	%f811, %f376;
	mov.u32 	%r351, 32;
	mov.u32 	%r354, %r18;

BB0_68:
	mov.u32 	%r95, %r354;
	add.s32 	%r96, %r95, %r20;
	mad.lo.s32 	%r97, %r96, 36, %r249;
	ld.shared.f32 	%f377, [%r97];
	ld.shared.f32 	%f378, [%r97+4];
	ld.shared.f32 	%f379, [%r97+8];
	ld.shared.f32 	%f77, [%r97+12];
	sub.ftz.f32 	%f507, %f377, %f547;
	sub.ftz.f32 	%f508, %f378, %f548;
	sub.ftz.f32 	%f509, %f379, %f549;
	mul.ftz.f32 	%f383, %f508, %f508;
	fma.rn.ftz.f32 	%f384, %f507, %f507, %f383;
	fma.rn.ftz.f32 	%f78, %f509, %f509, %f384;
	setp.lt.ftz.f32 	%p68, %f78, 0f3F23D70A;
	@%p68 bra 	BB0_69;
	bra.uni 	BB0_73;

BB0_69:
	// inline asm
	rsqrt.approx.f32 	%f386, %f78;
	// inline asm
	// inline asm
	div.approx.f32 	%f388, 1.0, %f386;
	// inline asm
	ld.shared.f32 	%f81, [%r97+28];
	ld.shared.f32 	%f82, [%r97+32];
	shl.b32 	%r266, %r96, 2;
	add.s32 	%r268, %r247, %r266;
	ld.shared.u32 	%r269, [%r268];
	setp.lt.s32 	%p69, %r269, 23558;
	and.pred  	%p70, %p69, %p15;
	@%p70 bra 	BB0_71;

	mov.f32 	%f805, %f376;
	mov.f32 	%f806, %f376;
	bra.uni 	BB0_72;

BB0_71:
	mul.ftz.f32 	%f396, %f388, 0f405242C8;
	neg.ftz.f32 	%f397, %f396;
	mul.ftz.f32 	%f393, %f396, %f397;
	// inline asm
	mul.f32 	%f392, %f393, 0f3FB8AA3B;ex2.approx.f32 	%f392, %f392;
	// inline asm
	mul.ftz.f32 	%f398, %f73, %f77;
	mul.ftz.f32 	%f399, %f398, %f386;
	fma.rn.ftz.f32 	%f400, %f396, 0f38349F67, 0f39910039;
	fma.rn.ftz.f32 	%f401, %f400, %f396, 0f391F6607;
	fma.rn.ftz.f32 	%f402, %f401, %f396, 0f3C17E369;
	fma.rn.ftz.f32 	%f403, %f402, %f396, 0f3D2D2FE7;
	fma.rn.ftz.f32 	%f404, %f403, %f396, 0f3D906E67;
	fma.rn.ftz.f32 	%f405, %f404, %f396, 0f3F800000;
	mul.ftz.f32 	%f406, %f405, %f405;
	mul.ftz.f32 	%f407, %f406, %f406;
	mul.ftz.f32 	%f408, %f407, %f407;
	mul.ftz.f32 	%f395, %f408, %f408;
	// inline asm
	div.approx.f32 	%f394, 1.0, %f395;
	// inline asm
	add.ftz.f32 	%f409, %f555, %f81;
	mul.ftz.f32 	%f410, %f386, %f409;
	mul.ftz.f32 	%f411, %f410, %f410;
	mul.ftz.f32 	%f412, %f411, %f411;
	mul.ftz.f32 	%f413, %f412, %f411;
	mul.ftz.f32 	%f414, %f556, %f82;
	mul.ftz.f32 	%f415, %f413, %f414;
	fma.rn.ftz.f32 	%f416, %f413, 0f41400000, 0fC0C00000;
	mul.ftz.f32 	%f417, %f396, %f392;
	fma.rn.ftz.f32 	%f418, %f417, 0f3F906EBB, %f394;
	mul.ftz.f32 	%f419, %f399, %f418;
	fma.rn.ftz.f32 	%f420, %f415, %f416, %f419;
	fma.rn.ftz.f32 	%f421, %f412, %f411, 0fBF800000;
	mul.ftz.f32 	%f422, %f399, %f394;
	fma.rn.ftz.f32 	%f423, %f415, %f421, %f422;
	add.ftz.f32 	%f83, %f423, 0f00000000;
	mul.ftz.f32 	%f424, %f420, %f386;
	fma.rn.ftz.f32 	%f805, %f424, %f386, 0f00000000;
	mov.f32 	%f806, %f83;

BB0_72:
	mov.f32 	%f86, %f806;
	add.ftz.f32 	%f807, %f807, %f86;
	mul.ftz.f32 	%f483, %f507, %f805;
	mul.ftz.f32 	%f484, %f508, %f805;
	mul.ftz.f32 	%f485, %f509, %f805;
	sub.ftz.f32 	%f495, %f808, %f483;
	sub.ftz.f32 	%f496, %f809, %f484;
	sub.ftz.f32 	%f497, %f810, %f485;
	mov.f32 	%f808, %f495;
	mov.f32 	%f809, %f496;
	mov.f32 	%f810, %f497;
	mov.f32 	%f811, %f811;
	ld.shared.f32 	%f429, [%r97+16];
	add.ftz.f32 	%f430, %f429, %f483;
	st.shared.f32 	[%r97+16], %f430;
	ld.shared.f32 	%f432, [%r97+20];
	add.ftz.f32 	%f433, %f432, %f484;
	st.shared.f32 	[%r97+20], %f433;
	ld.shared.f32 	%f435, [%r97+24];
	add.ftz.f32 	%f436, %f435, %f485;
	st.shared.f32 	[%r97+24], %f436;

BB0_73:
	add.s32 	%r270, %r95, 1;
	and.b32  	%r98, %r270, 31;
	add.s32 	%r351, %r351, -1;
	setp.ne.s32 	%p71, %r351, 0;
	mov.u32 	%r354, %r98;
	@%p71 bra 	BB0_68;

BB0_74:
	// inline asm
	mov.u32 	%r271, %tid.x;
	// inline asm
	shl.b32 	%r272, %r271, 2;
	add.s32 	%r274, %r247, %r272;
	ld.shared.u32 	%r100, [%r274];
	mul.ftz.f32 	%f438, %f808, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl13, %f438;
	ld.param.u32 	%r299, [computeNonbonded_param_0];
	add.s32 	%r276, %r299, %r238;
	atom.global.add.u64 	%rl14, [%r276], %rl13;
	add.s32 	%r277, %r276, 188672;
	mul.ftz.f32 	%f440, %f809, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl15, %f440;
	atom.global.add.u64 	%rl16, [%r277], %rl15;
	add.s32 	%r278, %r276, 377344;
	mul.ftz.f32 	%f442, %f810, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl17, %f442;
	atom.global.add.u64 	%rl18, [%r278], %rl17;
	setp.lt.u32 	%p72, %r100, 23584;
	@%p72 bra 	BB0_75;
	bra.uni 	BB0_76;

BB0_75:
	shl.b32 	%r282, %r100, 3;
	// inline asm
	mov.u32 	%r279, %tid.x;
	// inline asm
	mad.lo.s32 	%r284, %r279, 36, %r249;
	ld.shared.f32 	%f443, [%r284+16];
	mul.ftz.f32 	%f444, %f443, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl19, %f444;
	ld.param.u32 	%r298, [computeNonbonded_param_0];
	add.s32 	%r285, %r298, %r282;
	atom.global.add.u64 	%rl20, [%r285], %rl19;
	add.s32 	%r286, %r285, 188672;
	// inline asm
	mov.u32 	%r280, %tid.x;
	// inline asm
	mad.lo.s32 	%r287, %r280, 36, %r249;
	ld.shared.f32 	%f445, [%r287+20];
	mul.ftz.f32 	%f446, %f445, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl21, %f446;
	atom.global.add.u64 	%rl22, [%r286], %rl21;
	add.s32 	%r288, %r285, 377344;
	// inline asm
	mov.u32 	%r281, %tid.x;
	// inline asm
	mad.lo.s32 	%r289, %r281, 36, %r249;
	ld.shared.f32 	%f447, [%r289+24];
	mul.ftz.f32 	%f448, %f447, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl23, %f448;
	atom.global.add.u64 	%rl24, [%r288], %rl23;

BB0_76:
	add.s32 	%r332, %r332, 1;
	setp.lt.s32 	%p73, %r332, %r330;
	mov.u32 	%r347, %r79;
	@%p73 bra 	BB0_34;

BB0_77:
	// inline asm
	mov.u32 	%r290, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r291, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r292, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r293, %tid.x;
	// inline asm
	add.s32 	%r294, %r293, %r290;
	mad.lo.s32 	%r295, %r292, %r291, %r294;
	shl.b32 	%r296, %r295, 2;
	ld.param.u32 	%r302, [computeNonbonded_param_1];
	add.s32 	%r297, %r302, %r296;
	ld.global.f32 	%f449, [%r297];
	add.ftz.f32 	%f450, %f449, %f807;
	st.global.f32 	[%r297], %f450;
	ret;
}



//
// Generated by LWPU LWVM Compiler
// Compiler built on Thu May 15 11:00:55 2014 (1400169655)
// Driver 
//

//.version 3.0
//.target sm_30, texmode_independent
//.address_size 32

.visible .shared .align 2 .b8 shr_6_buffer[512];
.visible .shared .align 2 .b8 shr_7_sum[512];
.visible .shared .align 4 .b8 shr_8_temp[1024];
.visible .shared .align 4 .b8 shr_9_atoms[1152];
.visible .shared .align 16 .b8 shr_10_posBuffer[512];
.visible .shared .align 4 .b8 shr_11_exclusionsForX[12];
.visible .shared .align 4 .u32 shr_12_bufferFull;
.visible .shared .align 4 .u32 shr_13_globalIndex;
.visible .shared .align 4 .u32 shr_14_numAtoms;

.entry findBlockBounds(
	.param .u32 findBlockBounds_param_0,
	.param .align 16 .b8 findBlockBounds_param_1[16],
	.param .align 16 .b8 findBlockBounds_param_2[16],
	.param .u32 .ptr .global .align 16 findBlockBounds_param_3,
	.param .u32 .ptr .global .align 16 findBlockBounds_param_4,
	.param .u32 .ptr .global .align 16 findBlockBounds_param_5,
	.param .u32 .ptr .global .align 4 findBlockBounds_param_6,
	.param .u32 .ptr .global .align 8 findBlockBounds_param_7
)
{
	.reg .f32 	%f<185>;
	.reg .pred 	%p<6>;
	.reg .s32 	%r<58>;


	ld.param.u32 	%r1, [findBlockBounds_param_0];
	ld.param.v4.f32 	{%f109, %f110, %f111, %f112}, [findBlockBounds_param_2];
	ld.param.v4.f32 	{%f125, %f126, %f127, %f128}, [findBlockBounds_param_1];
	// inline asm
	mov.u32 	%r21, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r22, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r23, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r24, %tid.x;
	// inline asm
	add.s32 	%r25, %r24, %r21;
	mad.lo.s32 	%r55, %r23, %r22, %r25;
	shl.b32 	%r54, %r55, 5;
	setp.ge.s32 	%p1, %r54, %r1;
	@%p1 bra 	BB0_8;

	ld.param.u32 	%r49, [findBlockBounds_param_3];
	add.s32 	%r9, %r49, 16;

BB0_2:
	mov.u32 	%r10, %r54;
	shl.b32 	%r29, %r10, 4;
	ld.param.u32 	%r48, [findBlockBounds_param_3];
	add.s32 	%r30, %r48, %r29;
	ld.global.v4.f32 	{%f129, %f130, %f131, %f132}, [%r30];
	mul.ftz.f32 	%f133, %f129, %f109;
	mul.ftz.f32 	%f134, %f130, %f110;
	mul.ftz.f32 	%f135, %f131, %f111;
	// inline asm
	cvt.rmi.f32.f32 	%f1, %f133;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f3, %f134;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f5, %f135;
	// inline asm
	neg.f32 	%f141, %f1;
	neg.f32 	%f142, %f3;
	neg.f32 	%f143, %f5;
	fma.rn.ftz.f32 	%f145, %f141, %f125, %f129;
	fma.rn.ftz.f32 	%f146, %f142, %f126, %f130;
	fma.rn.ftz.f32 	%f147, %f143, %f127, %f131;
	mov.f32 	%f156, %f145;
	mov.f32 	%f165, %f146;
	mov.f32 	%f174, %f147;
	mov.f32 	%f183, %f132;
	add.s32 	%r27, %r10, 32;
	ld.param.u32 	%r46, [findBlockBounds_param_0];
	// inline asm
	min.s32 	%r26, %r27, %r46;
	// inline asm
	add.s32 	%r57, %r10, 1;
	setp.lt.s32 	%p2, %r57, %r26;
	@%p2 bra 	BB0_4;

	mov.f32 	%f154, %f156;
	mov.f32 	%f155, %f156;
	mov.f32 	%f163, %f165;
	mov.f32 	%f164, %f165;
	mov.f32 	%f172, %f174;
	mov.f32 	%f173, %f174;
	mov.f32 	%f181, %f183;
	mov.f32 	%f182, %f183;
	bra.uni 	BB0_7;

BB0_4:
	add.s32 	%r56, %r9, %r29;
	mov.f32 	%f157, %f156;
	mov.f32 	%f166, %f165;
	mov.f32 	%f175, %f174;
	mov.f32 	%f184, %f183;

BB0_5:
	ld.global.v4.f32 	{%f93, %f94, %f95, %f96}, [%r56];
	sub.ftz.f32 	%f97, %f93, %f145;
	sub.ftz.f32 	%f98, %f94, %f146;
	sub.ftz.f32 	%f99, %f95, %f147;
	mov.f32 	%f14, 0f3F000000;
	fma.rn.ftz.f32 	%f105, %f97, %f109, %f14;
	fma.rn.ftz.f32 	%f106, %f98, %f110, %f14;
	fma.rn.ftz.f32 	%f107, %f99, %f111, %f14;
	// inline asm
	cvt.rmi.f32.f32 	%f8, %f105;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f10, %f106;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f12, %f107;
	// inline asm
	neg.f32 	%f117, %f8;
	neg.f32 	%f118, %f10;
	neg.f32 	%f119, %f12;
	fma.rn.ftz.f32 	%f121, %f117, %f125, %f93;
	fma.rn.ftz.f32 	%f122, %f118, %f126, %f94;
	fma.rn.ftz.f32 	%f123, %f119, %f127, %f95;
	min.f32 	%f18, %f156, %f121;
	min.f32 	%f21, %f165, %f122;
	min.f32 	%f24, %f174, %f123;
	min.f32 	%f27, %f183, %f96;
	mov.f32 	%f156, %f18;
	mov.f32 	%f165, %f21;
	mov.f32 	%f174, %f24;
	mov.f32 	%f183, %f27;
	max.f32 	%f29, %f157, %f121;
	max.f32 	%f31, %f166, %f122;
	max.f32 	%f33, %f175, %f123;
	max.f32 	%f35, %f184, %f96;
	mov.f32 	%f157, %f29;
	mov.f32 	%f166, %f31;
	mov.f32 	%f175, %f33;
	mov.f32 	%f184, %f35;
	add.s32 	%r56, %r56, 16;
	add.s32 	%r57, %r57, 1;
	setp.lt.s32 	%p3, %r57, %r26;
	@%p3 bra 	BB0_5;

	mov.f32 	%f154, %f156;
	mov.f32 	%f155, %f157;
	mov.f32 	%f163, %f165;
	mov.f32 	%f164, %f166;
	mov.f32 	%f172, %f174;
	mov.f32 	%f173, %f175;
	mov.f32 	%f181, %f183;
	mov.f32 	%f182, %f184;

BB0_7:
	sub.ftz.f32 	%f63, %f155, %f154;
	sub.ftz.f32 	%f64, %f164, %f163;
	sub.ftz.f32 	%f65, %f173, %f172;
	sub.ftz.f32 	%f66, %f182, %f181;
	mov.f32 	%f36, 0f3F000000;
	mul.ftz.f32 	%f71, %f63, %f36;
	mul.ftz.f32 	%f72, %f64, %f36;
	mul.ftz.f32 	%f73, %f65, %f36;
	mul.ftz.f32 	%f74, %f66, %f36;
	shl.b32 	%r34, %r55, 4;
	ld.param.u32 	%r51, [findBlockBounds_param_5];
	add.s32 	%r35, %r51, %r34;
	st.global.v4.f32 	[%r35], {%f71, %f72, %f73, %f74};
	add.ftz.f32 	%f75, %f155, %f154;
	add.ftz.f32 	%f76, %f164, %f163;
	add.ftz.f32 	%f77, %f173, %f172;
	add.ftz.f32 	%f78, %f182, %f181;
	mul.ftz.f32 	%f79, %f75, %f36;
	mul.ftz.f32 	%f80, %f76, %f36;
	mul.ftz.f32 	%f81, %f77, %f36;
	mul.ftz.f32 	%f82, %f78, %f36;
	ld.param.u32 	%r50, [findBlockBounds_param_4];
	add.s32 	%r36, %r50, %r34;
	st.global.v4.f32 	[%r36], {%f79, %f80, %f81, %f82};
	add.ftz.f32 	%f39, %f71, %f72;
	add.ftz.f32 	%f41, %f39, %f73;
	cvt.rn.f32.s32 	%f42, %r55;
	shl.b32 	%r37, %r55, 3;
	ld.param.u32 	%r53, [findBlockBounds_param_7];
	add.s32 	%r38, %r53, %r37;
	st.global.v2.f32 	[%r38], {%f41, %f42};
	// inline asm
	mov.u32 	%r32, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r33, %ntid.x;
	// inline asm
	mad.lo.s32 	%r55, %r33, %r32, %r55;
	shl.b32 	%r20, %r55, 5;
	ld.param.u32 	%r47, [findBlockBounds_param_0];
	setp.lt.s32 	%p4, %r20, %r47;
	mov.u32 	%r54, %r20;
	@%p4 bra 	BB0_2;

BB0_8:
	// inline asm
	mov.u32 	%r39, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r40, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r41, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r43, %r41, %r40, %r39;
	// inline asm
	mov.u32 	%r42, %tid.x;
	// inline asm
	neg.s32 	%r44, %r42;
	setp.eq.s32 	%p5, %r43, %r44;
	@%p5 bra 	BB0_10;

	ret;

BB0_10:
	mov.u32 	%r45, 0;
	ld.param.u32 	%r52, [findBlockBounds_param_6];
	st.global.u32 	[%r52], %r45;
	ret;
}

.entry sortBoxData(
	.param .u32 .ptr .global .align 8 sortBoxData_param_0,
	.param .u32 .ptr .global .align 16 sortBoxData_param_1,
	.param .u32 .ptr .global .align 16 sortBoxData_param_2,
	.param .u32 .ptr .global .align 16 sortBoxData_param_3,
	.param .u32 .ptr .global .align 16 sortBoxData_param_4,
	.param .u32 .ptr .global .align 16 sortBoxData_param_5,
	.param .u32 .ptr .global .align 16 sortBoxData_param_6,
	.param .u32 .ptr .global .align 4 sortBoxData_param_7,
	.param .u32 .ptr .global .align 4 sortBoxData_param_8
)
{
	.reg .f32 	%f<30>;
	.reg .pred 	%p<10>;
	.reg .s32 	%r<55>;


	// inline asm
	mov.u32 	%r16, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r17, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r18, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r19, %tid.x;
	// inline asm
	add.s32 	%r20, %r19, %r16;
	mad.lo.s32 	%r53, %r18, %r17, %r20;
	setp.gt.s32 	%p3, %r53, 736;
	@%p3 bra 	BB1_2;

BB1_1:
	shl.b32 	%r23, %r53, 3;
	ld.param.u32 	%r44, [sortBoxData_param_0];
	add.s32 	%r24, %r44, %r23;
	ld.global.v2.f32 	{%f20, %f21}, [%r24];
	cvt.rzi.ftz.s32.f32 	%r25, %f21;
	shl.b32 	%r26, %r25, 4;
	ld.param.u32 	%r45, [sortBoxData_param_1];
	add.s32 	%r27, %r45, %r26;
	shl.b32 	%r28, %r53, 4;
	ld.param.u32 	%r47, [sortBoxData_param_3];
	add.s32 	%r29, %r47, %r28;
	ld.global.v4.f32 	{%f22, %f23, %f24, %f25}, [%r27];
	st.global.v4.f32 	[%r29], {%f22, %f23, %f24, %f25};
	ld.param.u32 	%r46, [sortBoxData_param_2];
	add.s32 	%r30, %r46, %r26;
	ld.param.u32 	%r48, [sortBoxData_param_4];
	add.s32 	%r31, %r48, %r28;
	ld.global.v4.f32 	{%f26, %f27, %f28, %f29}, [%r30];
	st.global.v4.f32 	[%r31], {%f26, %f27, %f28, %f29};
	// inline asm
	mov.u32 	%r21, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r22, %ntid.x;
	// inline asm
	mad.lo.s32 	%r53, %r22, %r21, %r53;
	setp.lt.s32 	%p4, %r53, 737;
	@%p4 bra 	BB1_1;

BB1_2:
	// inline asm
	mov.u32 	%r32, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r33, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r34, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r35, %tid.x;
	// inline asm
	add.s32 	%r36, %r35, %r32;
	mad.lo.s32 	%r54, %r34, %r33, %r36;
	setp.gt.s32 	%p5, %r54, 23557;
	@%p5 bra 	BB1_6;

	mov.pred 	%p9, 0;

BB1_4:
	shl.b32 	%r39, %r54, 4;
	ld.param.u32 	%r49, [sortBoxData_param_5];
	add.s32 	%r40, %r49, %r39;
	ld.global.v4.f32 	{%f8, %f9, %f10, %f11}, [%r40];
	ld.param.u32 	%r50, [sortBoxData_param_6];
	add.s32 	%r41, %r50, %r39;
	ld.global.v4.f32 	{%f12, %f13, %f14, %f15}, [%r41];
	sub.ftz.f32 	%f16, %f12, %f8;
	sub.ftz.f32 	%f17, %f13, %f9;
	sub.ftz.f32 	%f18, %f14, %f10;
	mul.ftz.f32 	%f4, %f17, %f17;
	fma.rn.ftz.f32 	%f5, %f16, %f16, %f4;
	fma.rn.ftz.f32 	%f7, %f18, %f18, %f5;
	setp.gt.ftz.f32 	%p7, %f7, 0f3AD1B717;
	or.pred  	%p9, %p7, %p9;
	// inline asm
	mov.u32 	%r37, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r38, %ntid.x;
	// inline asm
	mad.lo.s32 	%r54, %r38, %r37, %r54;
	setp.lt.s32 	%p8, %r54, 23558;
	@%p8 bra 	BB1_4;

	@%p9 bra 	BB1_7;

BB1_6:
	ret;

BB1_7:
	mov.u32 	%r42, 1;
	ld.param.u32 	%r52, [sortBoxData_param_8];
	st.global.u32 	[%r52], %r42;
	mov.u32 	%r43, 0;
	ld.param.u32 	%r51, [sortBoxData_param_7];
	st.global.u32 	[%r51], %r43;
	ret;
}

.entry findBlocksWithInteractions(
	.param .align 16 .b8 findBlocksWithInteractions_param_0[16],
	.param .align 16 .b8 findBlocksWithInteractions_param_1[16],
	.param .u32 .ptr .global .align 16 findBlocksWithInteractions_param_2,
	.param .u32 .ptr .global .align 16 findBlocksWithInteractions_param_3,
	.param .u32 .ptr .global .align 4 findBlocksWithInteractions_param_4,
	.param .u32 .ptr .global .align 4 findBlocksWithInteractions_param_5,
	.param .u32 .ptr .global .align 4 findBlocksWithInteractions_param_6,
	.param .u32 .ptr .global .align 16 findBlocksWithInteractions_param_7,
	.param .u32 findBlocksWithInteractions_param_8,
	.param .u32 findBlocksWithInteractions_param_9,
	.param .u32 findBlocksWithInteractions_param_10,
	.param .u32 .ptr .global .align 8 findBlocksWithInteractions_param_11,
	.param .u32 .ptr .global .align 16 findBlocksWithInteractions_param_12,
	.param .u32 .ptr .global .align 16 findBlocksWithInteractions_param_13,
	.param .u32 .ptr .global .align 4 findBlocksWithInteractions_param_14,
	.param .u32 .ptr .global .align 4 findBlocksWithInteractions_param_15,
	.param .u32 .ptr .global .align 16 findBlocksWithInteractions_param_16,
	.param .u32 .ptr .global .align 4 findBlocksWithInteractions_param_17
)
{
	.reg .f32 	%f<848>;
	.reg .s16 	%rs<145>;
	.reg .pred 	%p<222>;
	.reg .s32 	%r<850>;
	.reg .s16 	%rc<39>;


	ld.param.u32 	%r238, [findBlocksWithInteractions_param_17];
	ld.param.v4.f32 	{%f389, %f390, %f391, %f392}, [findBlocksWithInteractions_param_1];
	ld.param.v4.f32 	{%f405, %f406, %f407, %f408}, [findBlocksWithInteractions_param_0];
	ldu.global.u32 	%r239, [%r238];
	setp.eq.s32 	%p30, %r239, 0;
	@%p30 bra 	BB2_220;

	// inline asm
	mov.u32 	%r240, %tid.x;
	// inline asm
	setp.ne.s32 	%p31, %r240, 0;
	@%p31 bra 	BB2_3;

	mov.u32 	%r241, 0;
	st.shared.u32 	[shr_12_bufferFull], %r241;

BB2_3:
	// inline asm
	mov.u32 	%r242, %tid.x;
	// inline asm
	shl.b32 	%r244, %r242, 1;
	mov.u32 	%r245, shr_6_buffer;
	add.s32 	%r246, %r245, %r244;
	mov.u16 	%rs31, -1;
	st.shared.u16 	[%r246], %rs31;
	// inline asm
	mov.u32 	%r243, %tid.x;
	// inline asm
	shl.b32 	%r247, %r243, 1;
	add.s32 	%r248, %r247, %r245;
	st.shared.u16 	[%r248+256], %rs31;
	bar.sync 	0;
	// inline asm
	mov.u32 	%r249, %elwreg0;
	// inline asm
	// inline asm
	mov.u32 	%r250, %ctaid.x;
	// inline asm
	ld.param.u32 	%r773, [findBlocksWithInteractions_param_9];
	add.s32 	%r251, %r249, %r773;
	add.s32 	%r783, %r251, %r250;
	ld.param.u32 	%r775, [findBlocksWithInteractions_param_10];
	add.s32 	%r252, %r775, %r773;
	setp.ge.u32 	%p32, %r783, %r252;
	@%p32 bra 	BB2_218;

	mov.u32 	%r788, 0;
	mul.ftz.f32 	%f1, %f405, 0f3F000000;
	mul.ftz.f32 	%f2, %f406, 0f3F000000;
	mul.ftz.f32 	%f3, %f407, 0f3F000000;

BB2_5:
	// inline asm
	mov.u32 	%r254, %tid.x;
	// inline asm
	// inline asm
	mov.u32 	%r255, %ntid.x;
	// inline asm
	add.s32 	%r256, %r255, -1;
	setp.ne.s32 	%p33, %r254, %r256;
	@%p33 bra 	BB2_7;

	mov.u32 	%r257, 0;
	st.shared.u32 	[shr_14_numAtoms], %r257;

BB2_7:
	shl.b32 	%r259, %r783, 3;
	ld.param.u32 	%r777, [findBlocksWithInteractions_param_11];
	add.s32 	%r260, %r777, %r259;
	ld.global.f32 	%f10, [%r260+4];
	cvt.rzi.ftz.u16.f32 	%rs1, %f10;
	cvt.u32.u16 	%r19, %rs1;
	shl.b32 	%r261, %r19, 4;
	ld.param.u32 	%r753, [findBlocksWithInteractions_param_2];
	add.s32 	%r262, %r753, %r261;
	ld.global.v4.f32 	{%f493, %f494, %f495, %f496}, [%r262];
	ld.param.u32 	%r754, [findBlocksWithInteractions_param_3];
	add.s32 	%r263, %r754, %r261;
	ld.global.v4.f32 	{%f553, %f554, %f555, %f556}, [%r263];
	shl.b32 	%r264, %r19, 2;
	ld.param.u32 	%r781, [findBlocksWithInteractions_param_15];
	add.s32 	%r265, %r781, %r264;
	ldu.global.u32 	%r20, [%r265];
	ldu.global.u32 	%r266, [%r265+4];
	sub.s32 	%r21, %r266, %r20;
	// inline asm
	mov.u32 	%r258, %tid.x;
	// inline asm
	setp.ge.s32 	%p34, %r258, %r21;
	mov.u32 	%r784, %r258;
	@%p34 bra 	BB2_9;

BB2_8:
	add.s32 	%r268, %r784, %r20;
	shl.b32 	%r269, %r268, 2;
	ld.param.u32 	%r780, [findBlocksWithInteractions_param_14];
	add.s32 	%r270, %r780, %r269;
	shl.b32 	%r271, %r784, 2;
	mov.u32 	%r272, shr_11_exclusionsForX;
	add.s32 	%r273, %r272, %r271;
	ld.global.u32 	%r274, [%r270];
	st.shared.u32 	[%r273], %r274;
	// inline asm
	mov.u32 	%r267, %ntid.x;
	// inline asm
	add.s32 	%r784, %r267, %r784;
	setp.lt.s32 	%p35, %r784, %r21;
	@%p35 bra 	BB2_8;

BB2_9:
	bar.sync 	0;
	add.s32 	%r785, %r783, 1;
	setp.lt.s32 	%p36, %r785, 737;
	@%p36 bra 	BB2_10;
	bra.uni 	BB2_118;

BB2_10:
	setp.gt.s32 	%p1, %r21, 0;

BB2_11:
	// inline asm
	mov.u32 	%r275, %tid.x;
	// inline asm
	add.s32 	%r28, %r275, %r785;
	setp.lt.s32 	%p2, %r28, 737;
	@%p2 bra 	BB2_13;

	mov.f32 	%f11, 0f00000000;
	mov.f32 	%f823, %f11;
	mov.f32 	%f844, %f11;
	bra.uni 	BB2_14;

BB2_13:
	shl.b32 	%r276, %r28, 3;
	ld.param.u32 	%r776, [findBlocksWithInteractions_param_11];
	add.s32 	%r277, %r776, %r276;
	ld.global.v2.f32 	{%f825, %f844}, [%r277];

BB2_14:
	@%p2 bra 	BB2_16;

	mov.f32 	%f12, 0f00000000;
	mov.f32 	%f845, %f12;
	mov.f32 	%f846, %f12;
	mov.f32 	%f847, %f12;
	mov.f32 	%f818, %f12;
	bra.uni 	BB2_17;

BB2_16:
	shl.b32 	%r278, %r28, 4;
	ld.param.u32 	%r778, [findBlocksWithInteractions_param_12];
	add.s32 	%r279, %r778, %r278;
	ld.global.v4.f32 	{%f845, %f846, %f847, %f822}, [%r279];

BB2_17:
	@%p2 bra 	BB2_19;

	mov.f32 	%f13, 0f00000000;
	mov.f32 	%f841, %f13;
	mov.f32 	%f842, %f13;
	mov.f32 	%f843, %f13;
	mov.f32 	%f800, %f13;
	bra.uni 	BB2_20;

BB2_19:
	shl.b32 	%r280, %r28, 4;
	ld.param.u32 	%r779, [findBlocksWithInteractions_param_13];
	add.s32 	%r281, %r779, %r280;
	ld.global.v4.f32 	{%f841, %f842, %f843, %f804}, [%r281];

BB2_20:
	cvt.rzi.ftz.u16.f32 	%rs2, %f844;
	sub.ftz.f32 	%f807, %f493, %f845;
	sub.ftz.f32 	%f808, %f494, %f846;
	sub.ftz.f32 	%f809, %f495, %f847;
	fma.rn.ftz.f32 	%f15, %f807, %f389, 0f3F000000;
	// inline asm
	cvt.rmi.f32.f32 	%f14, %f15;
	// inline asm
	neg.f32 	%f30, %f14;
	fma.rn.ftz.f32 	%f21, %f30, %f405, %f807;
	fma.rn.ftz.f32 	%f17, %f808, %f390, 0f3F000000;
	// inline asm
	cvt.rmi.f32.f32 	%f16, %f17;
	// inline asm
	neg.f32 	%f34, %f16;
	fma.rn.ftz.f32 	%f23, %f34, %f406, %f808;
	fma.rn.ftz.f32 	%f19, %f809, %f391, 0f3F000000;
	// inline asm
	cvt.rmi.f32.f32 	%f18, %f19;
	// inline asm
	neg.f32 	%f38, %f18;
	fma.rn.ftz.f32 	%f25, %f38, %f407, %f809;
	// inline asm
	abs.f32 	%f20, %f21;
	// inline asm
	sub.ftz.f32 	%f40, %f20, %f553;
	sub.ftz.f32 	%f42, %f40, %f841;
	mov.f32 	%f43, 0f00000000;
	max.f32 	%f4, %f43, %f42;
	// inline asm
	abs.f32 	%f22, %f23;
	// inline asm
	sub.ftz.f32 	%f45, %f22, %f554;
	sub.ftz.f32 	%f47, %f45, %f842;
	max.f32 	%f5, %f43, %f47;
	// inline asm
	abs.f32 	%f24, %f25;
	// inline asm
	sub.ftz.f32 	%f49, %f24, %f555;
	sub.ftz.f32 	%f51, %f49, %f843;
	max.f32 	%f6, %f43, %f51;
	@%p1 bra 	BB2_22;

	mov.pred 	%p214, 0;
	bra.uni 	BB2_24;

BB2_22:
	cvt.u32.u16 	%r29, %rs2;
	mov.pred 	%p214, 0;
	mov.u32 	%r787, 0;
	mov.u32 	%r786, shr_11_exclusionsForX;

BB2_23:
	ld.shared.u32 	%r284, [%r786];
	setp.eq.s32 	%p39, %r284, %r29;
	or.pred  	%p214, %p214, %p39;
	add.s32 	%r786, %r786, 4;
	add.s32 	%r787, %r787, 1;
	setp.lt.s32 	%p40, %r787, %r21;
	@%p40 bra 	BB2_23;

BB2_24:
	@!%p2 bra 	BB2_28;

	mul.ftz.f32 	%f52, %f5, %f5;
	fma.rn.ftz.f32 	%f53, %f4, %f4, %f52;
	fma.rn.ftz.f32 	%f54, %f6, %f6, %f53;
	setp.geu.ftz.f32 	%p41, %f54, 0f3F463F14;
	or.pred  	%p42, %p41, %p214;
	@%p42 bra 	BB2_28;

	shl.b32 	%r286, %r788, 7;
	// inline asm
	mov.u32 	%r285, %tid.x;
	// inline asm
	add.s32 	%r287, %r285, %r286;
	shl.b32 	%r288, %r287, 1;
	add.s32 	%r290, %r245, %r288;
	st.shared.u16 	[%r290], %rs2;
	ld.shared.u32 	%r291, [shr_12_bufferFull];
	setp.eq.s32 	%p43, %r291, 0;
	add.s32 	%r788, %r788, 1;
	setp.eq.s32 	%p44, %r788, 2;
	and.pred  	%p45, %p43, %p44;
	@%p45 bra 	BB2_27;
	bra.uni 	BB2_28;

BB2_27:
	mov.u32 	%r292, 1;
	st.shared.u32 	[shr_12_bufferFull], %r292;

BB2_28:
	bar.sync 	0;
	ld.shared.u32 	%r293, [shr_12_bufferFull];
	setp.eq.s32 	%p46, %r293, 0;
	@%p46 bra 	BB2_117;

	sub.ftz.f32 	%f56, %f1, %f553;
	setp.ge.ftz.f32 	%p47, %f56, 0f3F6147AE;
	sub.ftz.f32 	%f58, %f2, %f554;
	setp.ge.ftz.f32 	%p48, %f58, 0f3F6147AE;
	and.pred  	%p49, %p48, %p47;
	sub.ftz.f32 	%f60, %f3, %f555;
	setp.ge.ftz.f32 	%p50, %f60, 0f3F6147AE;
	and.pred  	%p6, %p50, %p49;
	// inline asm
	mov.u32 	%r294, %tid.x;
	// inline asm
	setp.gt.u32 	%p51, %r294, 31;
	@%p51 bra 	BB2_33;

	// inline asm
	mov.u32 	%r295, %tid.x;
	// inline asm
	shl.b32 	%r296, %r19, 5;
	add.s32 	%r297, %r295, %r296;
	shl.b32 	%r298, %r297, 4;
	ld.param.u32 	%r768, [findBlocksWithInteractions_param_7];
	add.s32 	%r299, %r768, %r298;
	ld.global.v4.f32 	{%f837, %f838, %f839, %f840}, [%r299];
	@%p6 bra 	BB2_31;
	bra.uni 	BB2_32;

BB2_31:
	sub.ftz.f32 	%f769, %f837, %f493;
	sub.ftz.f32 	%f770, %f838, %f494;
	sub.ftz.f32 	%f771, %f839, %f495;
	mov.f32 	%f67, 0f3F000000;
	fma.rn.ftz.f32 	%f777, %f769, %f389, %f67;
	fma.rn.ftz.f32 	%f778, %f770, %f390, %f67;
	fma.rn.ftz.f32 	%f779, %f771, %f391, %f67;
	// inline asm
	cvt.rmi.f32.f32 	%f61, %f777;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f63, %f778;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f65, %f779;
	// inline asm
	neg.f32 	%f785, %f61;
	neg.f32 	%f786, %f63;
	neg.f32 	%f787, %f65;
	fma.rn.ftz.f32 	%f789, %f785, %f405, %f837;
	fma.rn.ftz.f32 	%f790, %f786, %f406, %f838;
	fma.rn.ftz.f32 	%f791, %f787, %f407, %f839;
	mov.f32 	%f837, %f789;
	mov.f32 	%f838, %f790;
	mov.f32 	%f839, %f791;
	mov.f32 	%f840, %f840;

BB2_32:
	// inline asm
	mov.u32 	%r300, %tid.x;
	// inline asm
	shl.b32 	%r301, %r300, 4;
	mov.u32 	%r302, shr_10_posBuffer;
	add.s32 	%r303, %r302, %r301;
	st.shared.v4.f32 	[%r303], {%f837, %f838, %f839, %f840};

BB2_33:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r304, %tid.x;
	// inline asm
	setp.gt.s32 	%p52, %r304, 255;
	mov.u32 	%r789, %r304;
	@%p52 bra 	BB2_35;

BB2_34:
	shl.b32 	%r306, %r789, 1;
	add.s32 	%r308, %r245, %r306;
	ld.shared.u16 	%rs32, [%r308];
	setp.ne.s16 	%p53, %rs32, -1;
	selp.u16 	%rs33, 1, 0, %p53;
	mov.u32 	%r309, shr_7_sum;
	add.s32 	%r310, %r309, %r306;
	st.shared.u16 	[%r310], %rs33;
	// inline asm
	mov.u32 	%r305, %ntid.x;
	// inline asm
	add.s32 	%r789, %r305, %r789;
	setp.lt.s32 	%p54, %r789, 256;
	@%p54 bra 	BB2_34;

BB2_35:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r311, %tid.x;
	// inline asm
	setp.gt.s32 	%p55, %r311, 255;
	mov.u32 	%r790, %r311;
	@%p55 bra 	BB2_37;

BB2_36:
	shl.b32 	%r313, %r790, 2;
	mov.u32 	%r314, shr_8_temp;
	add.s32 	%r315, %r314, %r313;
	ld.shared.v2.u16 	{%rs133, %rs134}, [%r315];
	shl.b32 	%r316, %r790, 1;
	mov.u32 	%r317, shr_7_sum;
	add.s32 	%r318, %r317, %r316;
	ld.shared.u16 	%rs34, [%r318];
	st.shared.v2.u16 	[%r315], {%rs34, %rs134};
	// inline asm
	mov.u32 	%r312, %ntid.x;
	// inline asm
	add.s32 	%r790, %r312, %r790;
	setp.lt.s32 	%p56, %r790, 256;
	@%p56 bra 	BB2_36;

BB2_37:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r319, %tid.x;
	// inline asm
	mov.u32 	%r793, 0;
	mov.u32 	%r792, 1;
	mov.pred 	%p215, -1;
	mov.u32 	%r791, %r793;
	mov.u32 	%r794, %r319;

BB2_38:
	mov.u32 	%r46, %r793;
	mov.pred 	%p7, %p215;
	setp.lt.s32 	%p8, %r794, 256;
	@%p7 bra 	BB2_43;

	@!%p8 bra 	BB2_47;

BB2_40:
	shl.b32 	%r323, %r794, 2;
	mov.u32 	%r324, shr_8_temp;
	add.s32 	%r48, %r324, %r323;
	ld.shared.v2.u16 	{%rs131, %rs132}, [%r48];
	mov.u16 	%rs137, %rs132;
	setp.lt.s32 	%p58, %r794, %r792;
	@%p58 bra 	BB2_42;

	sub.s32 	%r325, %r794, %r792;
	shl.b32 	%r326, %r325, 2;
	add.s32 	%r328, %r324, %r326;
	ld.shared.u16 	%rs35, [%r328+2];
	add.s16 	%rs137, %rs35, %rs132;

BB2_42:
	st.shared.v2.u16 	[%r48], {%rs137, %rs132};
	// inline asm
	mov.u32 	%r329, %ntid.x;
	// inline asm
	add.s32 	%r794, %r329, %r794;
	setp.lt.s32 	%p59, %r794, 256;
	@%p59 bra 	BB2_40;
	bra.uni 	BB2_47;

BB2_43:
	@!%p8 bra 	BB2_47;

BB2_44:
	shl.b32 	%r330, %r794, 2;
	mov.u32 	%r331, shr_8_temp;
	add.s32 	%r51, %r331, %r330;
	ld.shared.v2.u16 	{%rs127, %rs128}, [%r51];
	mov.u16 	%rs138, %rs127;
	setp.lt.s32 	%p60, %r794, %r792;
	@%p60 bra 	BB2_46;

	sub.s32 	%r332, %r794, %r792;
	shl.b32 	%r333, %r332, 2;
	add.s32 	%r335, %r331, %r333;
	ld.shared.u16 	%rs36, [%r335];
	add.s16 	%rs138, %rs36, %rs127;

BB2_46:
	st.shared.v2.u16 	[%r51], {%rs127, %rs138};
	// inline asm
	mov.u32 	%r336, %ntid.x;
	// inline asm
	add.s32 	%r794, %r336, %r794;
	setp.lt.s32 	%p61, %r794, 256;
	@%p61 bra 	BB2_44;

BB2_47:
	mov.u32 	%r337, 1;
	sub.s32 	%r53, %r337, %r46;
	bar.sync 	0;
	shl.b32 	%r792, %r792, 1;
	setp.eq.s32 	%p9, %r46, 1;
	// inline asm
	mov.u32 	%r338, %tid.x;
	// inline asm
	add.s32 	%r791, %r791, 1;
	setp.ne.s32 	%p62, %r791, 8;
	mov.u32 	%r794, %r338;
	mov.pred 	%p215, %p9;
	mov.u32 	%r793, %r53;
	@%p62 bra 	BB2_38;

	setp.gt.s32 	%p63, %r338, 255;
	@%p63 bra 	BB2_50;

BB2_49:
	shl.b32 	%r340, %r794, 2;
	mov.u32 	%r341, shr_8_temp;
	add.s32 	%r342, %r341, %r340;
	ld.shared.v2.u16 	{%rs123, %rs124}, [%r342];
	shl.b32 	%r343, %r794, 1;
	mov.u32 	%r344, shr_7_sum;
	add.s32 	%r345, %r344, %r343;
	st.shared.u16 	[%r345], %rs123;
	// inline asm
	mov.u32 	%r339, %ntid.x;
	// inline asm
	add.s32 	%r794, %r339, %r794;
	setp.lt.s32 	%p64, %r794, 256;
	@%p64 bra 	BB2_49;

BB2_50:
	bar.sync 	0;
	ld.shared.u16 	%rs9, [shr_7_sum+510];
	cvt.s32.s16 	%r59, %rs9;
	// inline asm
	mov.u32 	%r346, %tid.x;
	// inline asm
	setp.gt.s32 	%p65, %r346, 255;
	mov.u32 	%r795, %r346;
	@%p65 bra 	BB2_54;

BB2_51:
	shl.b32 	%r347, %r795, 1;
	add.s32 	%r349, %r245, %r347;
	ld.shared.u16 	%rs10, [%r349];
	setp.eq.s16 	%p66, %rs10, -1;
	@%p66 bra 	BB2_53;

	mov.u32 	%r351, shr_7_sum;
	add.s32 	%r352, %r351, %r347;
	ld.shared.s16 	%r353, [%r352];
	shl.b32 	%r354, %r353, 2;
	mov.u32 	%r355, shr_8_temp;
	add.s32 	%r356, %r354, %r355;
	ld.shared.v2.u16 	{%rs119, %rs120}, [%r356+-4];
	st.shared.v2.u16 	[%r356+-4], {%rs10, %rs120};

BB2_53:
	// inline asm
	mov.u32 	%r357, %ntid.x;
	// inline asm
	add.s32 	%r795, %r357, %r795;
	setp.lt.s32 	%p67, %r795, 256;
	@%p67 bra 	BB2_51;

BB2_54:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r358, %tid.x;
	// inline asm
	setp.gt.s32 	%p68, %r358, 255;
	mov.u32 	%r796, %r358;
	@%p68 bra 	BB2_56;

BB2_55:
	shl.b32 	%r360, %r796, 2;
	mov.u32 	%r361, shr_8_temp;
	add.s32 	%r362, %r361, %r360;
	ld.shared.v2.u16 	{%rs117, %rs118}, [%r362];
	shl.b32 	%r363, %r796, 1;
	add.s32 	%r365, %r245, %r363;
	st.shared.u16 	[%r365], %rs117;
	// inline asm
	mov.u32 	%r359, %ntid.x;
	// inline asm
	add.s32 	%r796, %r359, %r796;
	setp.lt.s32 	%p69, %r796, 256;
	@%p69 bra 	BB2_55;

BB2_56:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r366, %tid.x;
	// inline asm
	and.b32  	%r67, %r366, 31;
	// inline asm
	mov.u32 	%r367, %tid.x;
	// inline asm
	setp.gt.s16 	%p70, %rs9, 0;
	mov.u32 	%r819, %r367;
	@%p70 bra 	BB2_57;
	bra.uni 	BB2_112;

BB2_57:
	selp.u16 	%rs39, 1, 0, %p6;
	mov.u32 	%r798, 0;
	mov.u32 	%r797, %r59;
	mov.u32 	%r820, %r819;

BB2_58:
	mov.u32 	%r72, %r820;
	mov.u32 	%r71, %r797;
	shr.u32 	%r799, %r72, 5;
	setp.lt.u32 	%p71, %r799, 8;
	add.s32 	%r369, %r799, %r798;
	setp.lt.s32 	%p72, %r369, %r59;
	and.pred  	%p73, %p71, %p72;
	@!%p73 bra 	BB2_68;

BB2_59:
	add.s32 	%r370, %r799, %r798;
	shl.b32 	%r371, %r370, 1;
	add.s32 	%r373, %r245, %r371;
	ld.shared.u16 	%r374, [%r373];
	shl.b32 	%r375, %r374, 5;
	add.s32 	%r376, %r375, %r67;
	shl.b32 	%r377, %r376, 4;
	ld.param.u32 	%r767, [findBlocksWithInteractions_param_7];
	add.s32 	%r378, %r767, %r377;
	ld.global.v4.f32 	{%f834, %f835, %f836, %f728}, [%r378];
	@%p6 bra 	BB2_60;
	bra.uni 	BB2_61;

BB2_60:
	sub.ftz.f32 	%f733, %f834, %f493;
	sub.ftz.f32 	%f734, %f835, %f494;
	sub.ftz.f32 	%f735, %f836, %f495;
	mov.f32 	%f75, 0f3F000000;
	fma.rn.ftz.f32 	%f741, %f733, %f389, %f75;
	fma.rn.ftz.f32 	%f742, %f734, %f390, %f75;
	fma.rn.ftz.f32 	%f743, %f735, %f391, %f75;
	// inline asm
	cvt.rmi.f32.f32 	%f69, %f741;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f71, %f742;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f73, %f743;
	// inline asm
	neg.f32 	%f749, %f69;
	neg.f32 	%f750, %f71;
	neg.f32 	%f751, %f73;
	fma.rn.ftz.f32 	%f753, %f749, %f405, %f834;
	fma.rn.ftz.f32 	%f754, %f750, %f406, %f835;
	fma.rn.ftz.f32 	%f755, %f751, %f407, %f836;
	mov.f32 	%f834, %f753;
	mov.f32 	%f835, %f754;
	mov.f32 	%f836, %f755;
	mov.f32 	%f732, %f728;

BB2_61:
	@%p6 bra 	BB2_64;

	mov.pred 	%p216, 0;
	mov.u32 	%r801, 32;
	mov.u32 	%r800, shr_10_posBuffer;

BB2_63:
	ld.shared.v4.f32 	{%f625, %f626, %f627, %f628}, [%r800];
	sub.ftz.f32 	%f629, %f834, %f625;
	sub.ftz.f32 	%f630, %f835, %f626;
	sub.ftz.f32 	%f631, %f836, %f627;
	mov.f32 	%f101, 0f3F000000;
	fma.rn.ftz.f32 	%f637, %f629, %f389, %f101;
	fma.rn.ftz.f32 	%f638, %f630, %f390, %f101;
	fma.rn.ftz.f32 	%f639, %f631, %f391, %f101;
	// inline asm
	cvt.rmi.f32.f32 	%f77, %f637;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f79, %f638;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f81, %f639;
	// inline asm
	neg.f32 	%f645, %f77;
	neg.f32 	%f646, %f79;
	neg.f32 	%f647, %f81;
	fma.rn.ftz.f32 	%f649, %f645, %f405, %f629;
	fma.rn.ftz.f32 	%f650, %f646, %f406, %f630;
	fma.rn.ftz.f32 	%f651, %f647, %f407, %f631;
	mul.ftz.f32 	%f105, %f650, %f650;
	fma.rn.ftz.f32 	%f106, %f649, %f649, %f105;
	fma.rn.ftz.f32 	%f108, %f651, %f651, %f106;
	setp.lt.ftz.f32 	%p75, %f108, 0f3F463F14;
	or.pred  	%p76, %p216, %p75;
	ld.shared.v4.f32 	{%f653, %f654, %f655, %f656}, [%r800+16];
	sub.ftz.f32 	%f657, %f834, %f653;
	sub.ftz.f32 	%f658, %f835, %f654;
	sub.ftz.f32 	%f659, %f836, %f655;
	fma.rn.ftz.f32 	%f661, %f657, %f389, %f101;
	fma.rn.ftz.f32 	%f662, %f658, %f390, %f101;
	fma.rn.ftz.f32 	%f663, %f659, %f391, %f101;
	// inline asm
	cvt.rmi.f32.f32 	%f83, %f661;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f85, %f662;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f87, %f663;
	// inline asm
	neg.f32 	%f669, %f83;
	neg.f32 	%f670, %f85;
	neg.f32 	%f671, %f87;
	fma.rn.ftz.f32 	%f673, %f669, %f405, %f657;
	fma.rn.ftz.f32 	%f674, %f670, %f406, %f658;
	fma.rn.ftz.f32 	%f675, %f671, %f407, %f659;
	mul.ftz.f32 	%f112, %f674, %f674;
	fma.rn.ftz.f32 	%f113, %f673, %f673, %f112;
	fma.rn.ftz.f32 	%f115, %f675, %f675, %f113;
	setp.lt.ftz.f32 	%p77, %f115, 0f3F463F14;
	or.pred  	%p78, %p76, %p77;
	ld.shared.v4.f32 	{%f677, %f678, %f679, %f680}, [%r800+32];
	sub.ftz.f32 	%f681, %f834, %f677;
	sub.ftz.f32 	%f682, %f835, %f678;
	sub.ftz.f32 	%f683, %f836, %f679;
	fma.rn.ftz.f32 	%f685, %f681, %f389, %f101;
	fma.rn.ftz.f32 	%f686, %f682, %f390, %f101;
	fma.rn.ftz.f32 	%f687, %f683, %f391, %f101;
	// inline asm
	cvt.rmi.f32.f32 	%f89, %f685;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f91, %f686;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f93, %f687;
	// inline asm
	neg.f32 	%f693, %f89;
	neg.f32 	%f694, %f91;
	neg.f32 	%f695, %f93;
	fma.rn.ftz.f32 	%f697, %f693, %f405, %f681;
	fma.rn.ftz.f32 	%f698, %f694, %f406, %f682;
	fma.rn.ftz.f32 	%f699, %f695, %f407, %f683;
	mul.ftz.f32 	%f119, %f698, %f698;
	fma.rn.ftz.f32 	%f120, %f697, %f697, %f119;
	fma.rn.ftz.f32 	%f122, %f699, %f699, %f120;
	setp.lt.ftz.f32 	%p79, %f122, 0f3F463F14;
	or.pred  	%p80, %p78, %p79;
	ld.shared.v4.f32 	{%f701, %f702, %f703, %f704}, [%r800+48];
	sub.ftz.f32 	%f705, %f834, %f701;
	sub.ftz.f32 	%f706, %f835, %f702;
	sub.ftz.f32 	%f707, %f836, %f703;
	fma.rn.ftz.f32 	%f709, %f705, %f389, %f101;
	fma.rn.ftz.f32 	%f710, %f706, %f390, %f101;
	fma.rn.ftz.f32 	%f711, %f707, %f391, %f101;
	// inline asm
	cvt.rmi.f32.f32 	%f95, %f709;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f97, %f710;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f99, %f711;
	// inline asm
	neg.f32 	%f717, %f95;
	neg.f32 	%f718, %f97;
	neg.f32 	%f719, %f99;
	fma.rn.ftz.f32 	%f721, %f717, %f405, %f705;
	fma.rn.ftz.f32 	%f722, %f718, %f406, %f706;
	fma.rn.ftz.f32 	%f723, %f719, %f407, %f707;
	mul.ftz.f32 	%f126, %f722, %f722;
	fma.rn.ftz.f32 	%f127, %f721, %f721, %f126;
	fma.rn.ftz.f32 	%f129, %f723, %f723, %f127;
	setp.lt.ftz.f32 	%p81, %f129, 0f3F463F14;
	or.pred  	%p216, %p80, %p81;
	add.s32 	%r800, %r800, 64;
	add.s32 	%r801, %r801, -4;
	setp.ne.s32 	%p82, %r801, 0;
	@%p82 bra 	BB2_63;
	bra.uni 	BB2_67;

BB2_64:
	mov.u16 	%rc37, 0;
	mov.u32 	%r803, 32;
	mov.u32 	%r802, shr_10_posBuffer;

BB2_65:
	ld.shared.v4.f32 	{%f557, %f558, %f559, %f560}, [%r802];
	sub.ftz.f32 	%f561, %f834, %f557;
	sub.ftz.f32 	%f562, %f835, %f558;
	sub.ftz.f32 	%f563, %f836, %f559;
	mul.ftz.f32 	%f132, %f562, %f562;
	fma.rn.ftz.f32 	%f133, %f561, %f561, %f132;
	fma.rn.ftz.f32 	%f135, %f563, %f563, %f133;
	setp.lt.ftz.f32 	%p83, %f135, 0f3F463F14;
	selp.u16 	%rc6, 1, 0, %p83;
	or.b16  	%rc7, %rc6, %rc37;
	ld.shared.v4.f32 	{%f569, %f570, %f571, %f572}, [%r802+16];
	sub.ftz.f32 	%f573, %f834, %f569;
	sub.ftz.f32 	%f574, %f835, %f570;
	sub.ftz.f32 	%f575, %f836, %f571;
	mul.ftz.f32 	%f138, %f574, %f574;
	fma.rn.ftz.f32 	%f139, %f573, %f573, %f138;
	fma.rn.ftz.f32 	%f141, %f575, %f575, %f139;
	setp.lt.ftz.f32 	%p84, %f141, 0f3F463F14;
	selp.u16 	%rc8, 1, 0, %p84;
	or.b16  	%rc9, %rc8, %rc7;
	ld.shared.v4.f32 	{%f577, %f578, %f579, %f580}, [%r802+32];
	sub.ftz.f32 	%f581, %f834, %f577;
	sub.ftz.f32 	%f582, %f835, %f578;
	sub.ftz.f32 	%f583, %f836, %f579;
	mul.ftz.f32 	%f144, %f582, %f582;
	fma.rn.ftz.f32 	%f145, %f581, %f581, %f144;
	fma.rn.ftz.f32 	%f147, %f583, %f583, %f145;
	setp.lt.ftz.f32 	%p85, %f147, 0f3F463F14;
	selp.u16 	%rc10, 1, 0, %p85;
	or.b16  	%rc11, %rc10, %rc9;
	ld.shared.v4.f32 	{%f585, %f586, %f587, %f588}, [%r802+48];
	sub.ftz.f32 	%f589, %f834, %f585;
	sub.ftz.f32 	%f590, %f835, %f586;
	sub.ftz.f32 	%f591, %f836, %f587;
	mul.ftz.f32 	%f150, %f590, %f590;
	fma.rn.ftz.f32 	%f151, %f589, %f589, %f150;
	fma.rn.ftz.f32 	%f153, %f591, %f591, %f151;
	setp.lt.ftz.f32 	%p86, %f153, 0f3F463F14;
	selp.u16 	%rc12, 1, 0, %p86;
	or.b16  	%rc13, %rc12, %rc11;
	ld.shared.v4.f32 	{%f593, %f594, %f595, %f596}, [%r802+64];
	sub.ftz.f32 	%f597, %f834, %f593;
	sub.ftz.f32 	%f598, %f835, %f594;
	sub.ftz.f32 	%f599, %f836, %f595;
	mul.ftz.f32 	%f156, %f598, %f598;
	fma.rn.ftz.f32 	%f157, %f597, %f597, %f156;
	fma.rn.ftz.f32 	%f159, %f599, %f599, %f157;
	setp.lt.ftz.f32 	%p87, %f159, 0f3F463F14;
	selp.u16 	%rc14, 1, 0, %p87;
	or.b16  	%rc15, %rc14, %rc13;
	ld.shared.v4.f32 	{%f601, %f602, %f603, %f604}, [%r802+80];
	sub.ftz.f32 	%f605, %f834, %f601;
	sub.ftz.f32 	%f606, %f835, %f602;
	sub.ftz.f32 	%f607, %f836, %f603;
	mul.ftz.f32 	%f162, %f606, %f606;
	fma.rn.ftz.f32 	%f163, %f605, %f605, %f162;
	fma.rn.ftz.f32 	%f165, %f607, %f607, %f163;
	setp.lt.ftz.f32 	%p88, %f165, 0f3F463F14;
	selp.u16 	%rc16, 1, 0, %p88;
	or.b16  	%rc17, %rc16, %rc15;
	ld.shared.v4.f32 	{%f609, %f610, %f611, %f612}, [%r802+96];
	sub.ftz.f32 	%f613, %f834, %f609;
	sub.ftz.f32 	%f614, %f835, %f610;
	sub.ftz.f32 	%f615, %f836, %f611;
	mul.ftz.f32 	%f168, %f614, %f614;
	fma.rn.ftz.f32 	%f169, %f613, %f613, %f168;
	fma.rn.ftz.f32 	%f171, %f615, %f615, %f169;
	setp.lt.ftz.f32 	%p89, %f171, 0f3F463F14;
	selp.u16 	%rc18, 1, 0, %p89;
	or.b16  	%rc19, %rc18, %rc17;
	ld.shared.v4.f32 	{%f617, %f618, %f619, %f620}, [%r802+112];
	sub.ftz.f32 	%f621, %f834, %f617;
	sub.ftz.f32 	%f622, %f835, %f618;
	sub.ftz.f32 	%f623, %f836, %f619;
	mul.ftz.f32 	%f174, %f622, %f622;
	fma.rn.ftz.f32 	%f175, %f621, %f621, %f174;
	fma.rn.ftz.f32 	%f177, %f623, %f623, %f175;
	setp.lt.ftz.f32 	%p90, %f177, 0f3F463F14;
	selp.u16 	%rc20, 1, 0, %p90;
	or.b16  	%rc37, %rc20, %rc19;
	add.s32 	%r802, %r802, 128;
	add.s32 	%r803, %r803, -8;
	setp.ne.s32 	%p91, %r803, 0;
	@%p91 bra 	BB2_65;

	{
	.reg .s16 	%temp1;
	.reg .s16 	%temp2;
	cvt.s16.s8 	%temp1, %rc37;
	mov.b16 	%temp2, 0;
	cvt.s16.s8 	%temp2, %temp2;
	setp.ne.s16 	%p216, %temp1, %temp2;
	}

BB2_67:
	shl.b32 	%r383, %r799, 5;
	add.s32 	%r384, %r383, %r67;
	shl.b32 	%r385, %r384, 1;
	mov.u32 	%r386, shr_7_sum;
	add.s32 	%r387, %r386, %r385;
	selp.u16 	%rs40, 1, 0, %p216;
	st.shared.u16 	[%r387], %rs40;
	add.s32 	%r799, %r799, 4;
	setp.lt.s32 	%p92, %r799, 8;
	add.s32 	%r388, %r799, %r798;
	setp.lt.s32 	%p93, %r388, %r59;
	and.pred  	%p94, %p92, %p93;
	@%p94 bra 	BB2_59;

BB2_68:
	// inline asm
	mov.u32 	%r389, %tid.x;
	// inline asm
	shr.u32 	%r390, %r389, 5;
	sub.s32 	%r391, %r59, %r798;
	add.s32 	%r805, %r391, %r390;
	setp.gt.s32 	%p95, %r805, 7;
	@%p95 bra 	BB2_71;

	add.s32 	%r393, %r71, %r390;
	shl.b32 	%r394, %r393, 5;
	add.s32 	%r395, %r67, %r394;
	shl.b32 	%r396, %r395, 1;
	mov.u32 	%r397, shr_7_sum;
	add.s32 	%r804, %r397, %r396;

BB2_70:
	mov.u16 	%rs41, 0;
	st.shared.u16 	[%r804], %rs41;
	add.s32 	%r804, %r804, 256;
	add.s32 	%r805, %r805, 4;
	setp.lt.s32 	%p96, %r805, 8;
	@%p96 bra 	BB2_70;

BB2_71:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r398, %tid.x;
	// inline asm
	setp.gt.s32 	%p97, %r398, 255;
	mov.u32 	%r806, %r398;
	@%p97 bra 	BB2_73;

BB2_72:
	shl.b32 	%r400, %r806, 2;
	mov.u32 	%r401, shr_8_temp;
	add.s32 	%r402, %r401, %r400;
	ld.shared.v2.u16 	{%rs113, %rs114}, [%r402];
	shl.b32 	%r403, %r806, 1;
	mov.u32 	%r404, shr_7_sum;
	add.s32 	%r405, %r404, %r403;
	ld.shared.u16 	%rs42, [%r405];
	st.shared.v2.u16 	[%r402], {%rs42, %rs114};
	// inline asm
	mov.u32 	%r399, %ntid.x;
	// inline asm
	add.s32 	%r806, %r399, %r806;
	setp.lt.s32 	%p98, %r806, 256;
	@%p98 bra 	BB2_72;

BB2_73:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r406, %tid.x;
	// inline asm
	mov.u32 	%r809, 0;
	mov.u32 	%r808, 1;
	mov.pred 	%p217, -1;
	mov.u32 	%r807, %r809;
	mov.u32 	%r810, %r406;

BB2_74:
	mov.u32 	%r99, %r809;
	mov.pred 	%p14, %p217;
	setp.lt.s32 	%p15, %r810, 256;
	@%p14 bra 	BB2_79;

	@!%p15 bra 	BB2_83;

BB2_76:
	shl.b32 	%r410, %r810, 2;
	mov.u32 	%r411, shr_8_temp;
	add.s32 	%r101, %r411, %r410;
	ld.shared.v2.u16 	{%rs111, %rs112}, [%r101];
	mov.u16 	%rs139, %rs112;
	setp.lt.s32 	%p100, %r810, %r808;
	@%p100 bra 	BB2_78;

	sub.s32 	%r412, %r810, %r808;
	shl.b32 	%r413, %r412, 2;
	add.s32 	%r415, %r411, %r413;
	ld.shared.u16 	%rs43, [%r415+2];
	add.s16 	%rs139, %rs43, %rs112;

BB2_78:
	st.shared.v2.u16 	[%r101], {%rs139, %rs112};
	// inline asm
	mov.u32 	%r416, %ntid.x;
	// inline asm
	add.s32 	%r810, %r416, %r810;
	setp.lt.s32 	%p101, %r810, 256;
	@%p101 bra 	BB2_76;
	bra.uni 	BB2_83;

BB2_79:
	@!%p15 bra 	BB2_83;

BB2_80:
	shl.b32 	%r417, %r810, 2;
	mov.u32 	%r418, shr_8_temp;
	add.s32 	%r104, %r418, %r417;
	ld.shared.v2.u16 	{%rs107, %rs108}, [%r104];
	mov.u16 	%rs140, %rs107;
	setp.lt.s32 	%p102, %r810, %r808;
	@%p102 bra 	BB2_82;

	sub.s32 	%r419, %r810, %r808;
	shl.b32 	%r420, %r419, 2;
	add.s32 	%r422, %r418, %r420;
	ld.shared.u16 	%rs44, [%r422];
	add.s16 	%rs140, %rs44, %rs107;

BB2_82:
	st.shared.v2.u16 	[%r104], {%rs107, %rs140};
	// inline asm
	mov.u32 	%r423, %ntid.x;
	// inline asm
	add.s32 	%r810, %r423, %r810;
	setp.lt.s32 	%p103, %r810, 256;
	@%p103 bra 	BB2_80;

BB2_83:
	mov.u32 	%r424, 1;
	sub.s32 	%r106, %r424, %r99;
	bar.sync 	0;
	shl.b32 	%r808, %r808, 1;
	setp.eq.s32 	%p16, %r99, 1;
	// inline asm
	mov.u32 	%r425, %tid.x;
	// inline asm
	add.s32 	%r807, %r807, 1;
	setp.ne.s32 	%p104, %r807, 8;
	mov.u32 	%r810, %r425;
	mov.pred 	%p217, %p16;
	mov.u32 	%r809, %r106;
	@%p104 bra 	BB2_74;

	setp.gt.s32 	%p105, %r425, 255;
	@%p105 bra 	BB2_86;

BB2_85:
	shl.b32 	%r427, %r810, 2;
	mov.u32 	%r428, shr_8_temp;
	add.s32 	%r429, %r428, %r427;
	ld.shared.v2.u16 	{%rs103, %rs104}, [%r429];
	shl.b32 	%r430, %r810, 1;
	mov.u32 	%r431, shr_7_sum;
	add.s32 	%r432, %r431, %r430;
	st.shared.u16 	[%r432], %rs103;
	// inline asm
	mov.u32 	%r426, %ntid.x;
	// inline asm
	add.s32 	%r810, %r426, %r810;
	setp.lt.s32 	%p106, %r810, 256;
	@%p106 bra 	BB2_85;

BB2_86:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r433, %tid.x;
	// inline asm
	setp.gt.s32 	%p107, %r433, 255;
	mov.u32 	%r811, %r433;
	@%p107 bra 	BB2_93;

BB2_87:
	shl.b32 	%r434, %r811, 1;
	mov.u32 	%r435, shr_7_sum;
	add.s32 	%r114, %r435, %r434;
	setp.eq.s32 	%p108, %r811, 0;
	ld.shared.s16 	%r115, [%r114];
	@%p108 bra 	BB2_89;

	ld.shared.s16 	%r812, [%r114+-2];
	bra.uni 	BB2_90;

BB2_89:
	mov.u32 	%r812, 0;

BB2_90:
	setp.eq.s32 	%p109, %r115, %r812;
	@%p109 bra 	BB2_92;

	shr.s32 	%r437, %r811, 31;
	shr.u32 	%r438, %r437, 27;
	add.s32 	%r439, %r811, %r438;
	shr.s32 	%r440, %r439, 5;
	add.s32 	%r441, %r440, %r798;
	shl.b32 	%r442, %r441, 1;
	add.s32 	%r444, %r245, %r442;
	ld.shared.u16 	%r445, [%r444];
	shl.b32 	%r446, %r445, 5;
	add.s32 	%r447, %r446, %r67;
	ld.shared.u32 	%r448, [shr_14_numAtoms];
	add.s32 	%r449, %r448, %r115;
	shl.b32 	%r450, %r449, 2;
	mov.u32 	%r451, shr_9_atoms;
	add.s32 	%r452, %r450, %r451;
	st.shared.u32 	[%r452+-4], %r447;

BB2_92:
	// inline asm
	mov.u32 	%r453, %ntid.x;
	// inline asm
	add.s32 	%r811, %r453, %r811;
	setp.lt.s32 	%p110, %r811, 256;
	@%p110 bra 	BB2_87;

BB2_93:
	ld.shared.u32 	%r454, [shr_14_numAtoms];
	ld.shared.s16 	%r455, [shr_7_sum+510];
	add.s32 	%r119, %r455, %r454;
	shr.s32 	%r456, %r119, 31;
	shr.u32 	%r457, %r456, 27;
	add.s32 	%r458, %r119, %r457;
	shr.s32 	%r120, %r458, 5;
	setp.gt.s32 	%p111, %r119, 31;
	@%p111 bra 	BB2_96;

	bar.sync 	0;
	// inline asm
	mov.u32 	%r459, %tid.x;
	// inline asm
	setp.ne.s32 	%p112, %r459, 0;
	@%p112 bra 	BB2_108;

	ld.shared.u32 	%r460, [shr_14_numAtoms];
	ld.shared.s16 	%r461, [shr_7_sum+510];
	add.s32 	%r462, %r460, %r461;
	st.shared.u32 	[shr_14_numAtoms], %r462;
	bra.uni 	BB2_108;

BB2_96:
	// inline asm
	mov.u32 	%r463, %tid.x;
	// inline asm
	setp.ne.s32 	%p113, %r463, 0;
	@%p113 bra 	BB2_98;

	ld.param.u32 	%r757, [findBlocksWithInteractions_param_4];
	atom.global.add.u32 	%r464, [%r757], %r120;
	st.shared.u32 	[shr_13_globalIndex], %r464;

BB2_98:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r465, %tid.x;
	// inline asm
	setp.ne.s32 	%p114, %r465, 0;
	@%p114 bra 	BB2_100;

	shl.b32 	%r466, %r120, 5;
	sub.s32 	%r467, %r119, %r466;
	st.shared.u32 	[shr_14_numAtoms], %r467;

BB2_100:
	ld.shared.u32 	%r468, [shr_13_globalIndex];
	add.s32 	%r469, %r468, %r120;
	ld.param.u32 	%r771, [findBlocksWithInteractions_param_8];
	setp.gt.u32 	%p115, %r469, %r771;
	@%p115 bra 	BB2_108;

	// inline asm
	mov.u32 	%r470, %tid.x;
	// inline asm
	setp.ge.u32 	%p116, %r470, %r120;
	@%p116 bra 	BB2_103;

	ld.shared.u32 	%r472, [shr_13_globalIndex];
	// inline asm
	mov.u32 	%r471, %tid.x;
	// inline asm
	add.s32 	%r473, %r471, %r472;
	shl.b32 	%r474, %r473, 2;
	ld.param.u32 	%r760, [findBlocksWithInteractions_param_5];
	add.s32 	%r475, %r760, %r474;
	st.global.v2.u16 	[%r475], {%rs1, %rs39};

BB2_103:
	// inline asm
	mov.u32 	%r476, %tid.x;
	// inline asm
	shl.b32 	%r122, %r120, 5;
	setp.ge.s32 	%p117, %r476, %r122;
	mov.u32 	%r813, %r476;
	@%p117 bra 	BB2_108;

BB2_104:
	setp.lt.s32 	%p118, %r813, %r119;
	@%p118 bra 	BB2_106;

	mov.u32 	%r814, 23558;
	bra.uni 	BB2_107;

BB2_106:
	shl.b32 	%r478, %r813, 2;
	mov.u32 	%r479, shr_9_atoms;
	add.s32 	%r480, %r479, %r478;
	ld.shared.u32 	%r814, [%r480];

BB2_107:
	ld.shared.u32 	%r482, [shr_13_globalIndex];
	shl.b32 	%r483, %r482, 5;
	add.s32 	%r484, %r483, %r813;
	shl.b32 	%r485, %r484, 2;
	ld.param.u32 	%r763, [findBlocksWithInteractions_param_6];
	add.s32 	%r486, %r763, %r485;
	st.global.u32 	[%r486], %r814;
	// inline asm
	mov.u32 	%r481, %ntid.x;
	// inline asm
	add.s32 	%r813, %r481, %r813;
	setp.lt.s32 	%p119, %r813, %r122;
	@%p119 bra 	BB2_104;

BB2_108:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r487, %tid.x;
	// inline asm
	ld.shared.u32 	%r488, [shr_14_numAtoms];
	setp.ge.u32 	%p120, %r487, %r488;
	@%p120 bra 	BB2_110;

	shl.b32 	%r491, %r120, 5;
	// inline asm
	mov.u32 	%r489, %tid.x;
	// inline asm
	add.s32 	%r492, %r489, %r491;
	shl.b32 	%r493, %r492, 2;
	mov.u32 	%r494, shr_9_atoms;
	add.s32 	%r495, %r494, %r493;
	ld.shared.u32 	%r496, [%r495];
	// inline asm
	mov.u32 	%r490, %tid.x;
	// inline asm
	shl.b32 	%r497, %r490, 2;
	add.s32 	%r498, %r494, %r497;
	st.shared.u32 	[%r498], %r496;

BB2_110:
	add.s32 	%r798, %r798, 8;
	setp.lt.s32 	%p121, %r798, %r59;
	// inline asm
	mov.u32 	%r499, %tid.x;
	// inline asm
	add.s32 	%r129, %r71, -8;
	mov.u32 	%r128, %r499;
	mov.u32 	%r797, %r129;
	mov.u32 	%r820, %r128;
	@%p121 bra 	BB2_58;

	mov.u32 	%r819, %r128;

BB2_112:
	mov.u32 	%r818, %r819;
	setp.gt.s32 	%p122, %r818, 255;
	@%p122 bra 	BB2_114;

BB2_113:
	shl.b32 	%r501, %r818, 1;
	add.s32 	%r503, %r245, %r501;
	st.shared.u16 	[%r503], %rs31;
	// inline asm
	mov.u32 	%r500, %ntid.x;
	// inline asm
	add.s32 	%r818, %r500, %r818;
	setp.lt.s32 	%p123, %r818, 256;
	@%p123 bra 	BB2_113;

BB2_114:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r504, %tid.x;
	// inline asm
	setp.eq.s32 	%p124, %r504, 0;
	@%p124 bra 	BB2_116;

	mov.u32 	%r788, 0;
	bra.uni 	BB2_117;

BB2_116:
	mov.u32 	%r788, 0;
	st.shared.u32 	[shr_12_bufferFull], %r788;

BB2_117:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r507, %ntid.x;
	// inline asm
	add.s32 	%r785, %r507, %r785;
	setp.lt.s32 	%p125, %r785, 737;
	@%p125 bra 	BB2_11;

BB2_118:
	sub.ftz.f32 	%f179, %f1, %f553;
	setp.ltu.ftz.f32 	%p126, %f179, 0f3F6147AE;
	@%p126 bra 	BB2_121;

	sub.ftz.f32 	%f181, %f2, %f554;
	setp.ltu.ftz.f32 	%p127, %f181, 0f3F6147AE;
	@%p127 bra 	BB2_121;

	sub.ftz.f32 	%f183, %f3, %f555;
	setp.ge.ftz.f32 	%p218, %f183, 0f3F6147AE;
	bra.uni 	BB2_122;

BB2_121:
	mov.pred 	%p218, 0;

BB2_122:
	// inline asm
	mov.u32 	%r508, %tid.x;
	// inline asm
	setp.gt.u32 	%p129, %r508, 31;
	@%p129 bra 	BB2_126;

	shl.b32 	%r510, %r19, 5;
	// inline asm
	mov.u32 	%r509, %tid.x;
	// inline asm
	add.s32 	%r511, %r509, %r510;
	shl.b32 	%r512, %r511, 4;
	ld.param.u32 	%r766, [findBlocksWithInteractions_param_7];
	add.s32 	%r513, %r766, %r512;
	ld.global.v4.f32 	{%f830, %f831, %f832, %f833}, [%r513];
	@%p218 bra 	BB2_124;
	bra.uni 	BB2_125;

BB2_124:
	sub.ftz.f32 	%f529, %f830, %f493;
	sub.ftz.f32 	%f530, %f831, %f494;
	sub.ftz.f32 	%f531, %f832, %f495;
	mov.f32 	%f190, 0f3F000000;
	fma.rn.ftz.f32 	%f537, %f529, %f389, %f190;
	fma.rn.ftz.f32 	%f538, %f530, %f390, %f190;
	fma.rn.ftz.f32 	%f539, %f531, %f391, %f190;
	// inline asm
	cvt.rmi.f32.f32 	%f184, %f537;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f186, %f538;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f188, %f539;
	// inline asm
	neg.f32 	%f545, %f184;
	neg.f32 	%f546, %f186;
	neg.f32 	%f547, %f188;
	fma.rn.ftz.f32 	%f549, %f545, %f405, %f830;
	fma.rn.ftz.f32 	%f550, %f546, %f406, %f831;
	fma.rn.ftz.f32 	%f551, %f547, %f407, %f832;
	mov.f32 	%f830, %f549;
	mov.f32 	%f831, %f550;
	mov.f32 	%f832, %f551;
	mov.f32 	%f833, %f833;

BB2_125:
	// inline asm
	mov.u32 	%r514, %tid.x;
	// inline asm
	shl.b32 	%r515, %r514, 4;
	mov.u32 	%r516, shr_10_posBuffer;
	add.s32 	%r517, %r516, %r515;
	st.shared.v4.f32 	[%r517], {%f830, %f831, %f832, %f833};

BB2_126:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r518, %tid.x;
	// inline asm
	setp.gt.s32 	%p130, %r518, 255;
	mov.u32 	%r821, %r518;
	@%p130 bra 	BB2_128;

BB2_127:
	shl.b32 	%r520, %r821, 1;
	add.s32 	%r522, %r245, %r520;
	ld.shared.u16 	%rs47, [%r522];
	setp.ne.s16 	%p131, %rs47, -1;
	selp.u16 	%rs48, 1, 0, %p131;
	mov.u32 	%r523, shr_7_sum;
	add.s32 	%r524, %r523, %r520;
	st.shared.u16 	[%r524], %rs48;
	// inline asm
	mov.u32 	%r519, %ntid.x;
	// inline asm
	add.s32 	%r821, %r519, %r821;
	setp.lt.s32 	%p132, %r821, 256;
	@%p132 bra 	BB2_127;

BB2_128:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r525, %tid.x;
	// inline asm
	setp.gt.s32 	%p133, %r525, 255;
	mov.u32 	%r822, %r525;
	@%p133 bra 	BB2_130;

BB2_129:
	shl.b32 	%r527, %r822, 2;
	mov.u32 	%r528, shr_8_temp;
	add.s32 	%r529, %r528, %r527;
	ld.shared.v2.u16 	{%rs97, %rs98}, [%r529];
	shl.b32 	%r530, %r822, 1;
	mov.u32 	%r531, shr_7_sum;
	add.s32 	%r532, %r531, %r530;
	ld.shared.u16 	%rs49, [%r532];
	st.shared.v2.u16 	[%r529], {%rs49, %rs98};
	// inline asm
	mov.u32 	%r526, %ntid.x;
	// inline asm
	add.s32 	%r822, %r526, %r822;
	setp.lt.s32 	%p134, %r822, 256;
	@%p134 bra 	BB2_129;

BB2_130:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r533, %tid.x;
	// inline asm
	mov.u32 	%r825, 1;
	mov.u32 	%r824, 0;
	mov.pred 	%p219, -1;
	mov.u32 	%r823, %r824;
	mov.u32 	%r826, %r533;

BB2_131:
	mov.u32 	%r145, %r824;
	mov.pred 	%p19, %p219;
	setp.lt.s32 	%p20, %r826, 256;
	@%p19 bra 	BB2_136;

	@!%p20 bra 	BB2_140;

BB2_133:
	shl.b32 	%r537, %r826, 2;
	mov.u32 	%r538, shr_8_temp;
	add.s32 	%r148, %r538, %r537;
	ld.shared.v2.u16 	{%rs95, %rs96}, [%r148];
	mov.u16 	%rs141, %rs96;
	setp.lt.s32 	%p136, %r826, %r825;
	@%p136 bra 	BB2_135;

	sub.s32 	%r539, %r826, %r825;
	shl.b32 	%r540, %r539, 2;
	add.s32 	%r542, %r538, %r540;
	ld.shared.u16 	%rs50, [%r542+2];
	add.s16 	%rs141, %rs50, %rs96;

BB2_135:
	st.shared.v2.u16 	[%r148], {%rs141, %rs96};
	// inline asm
	mov.u32 	%r543, %ntid.x;
	// inline asm
	add.s32 	%r826, %r543, %r826;
	setp.lt.s32 	%p137, %r826, 256;
	@%p137 bra 	BB2_133;
	bra.uni 	BB2_140;

BB2_136:
	@!%p20 bra 	BB2_140;

BB2_137:
	shl.b32 	%r544, %r826, 2;
	mov.u32 	%r545, shr_8_temp;
	add.s32 	%r151, %r545, %r544;
	ld.shared.v2.u16 	{%rs91, %rs92}, [%r151];
	mov.u16 	%rs142, %rs91;
	setp.lt.s32 	%p138, %r826, %r825;
	@%p138 bra 	BB2_139;

	sub.s32 	%r546, %r826, %r825;
	shl.b32 	%r547, %r546, 2;
	add.s32 	%r549, %r545, %r547;
	ld.shared.u16 	%rs51, [%r549];
	add.s16 	%rs142, %rs51, %rs91;

BB2_139:
	st.shared.v2.u16 	[%r151], {%rs91, %rs142};
	// inline asm
	mov.u32 	%r550, %ntid.x;
	// inline asm
	add.s32 	%r826, %r550, %r826;
	setp.lt.s32 	%p139, %r826, 256;
	@%p139 bra 	BB2_137;

BB2_140:
	mov.u32 	%r551, 1;
	sub.s32 	%r153, %r551, %r145;
	bar.sync 	0;
	shl.b32 	%r825, %r825, 1;
	setp.eq.s32 	%p21, %r145, 1;
	// inline asm
	mov.u32 	%r552, %tid.x;
	// inline asm
	add.s32 	%r823, %r823, 1;
	ld.param.u32 	%r772, [findBlocksWithInteractions_param_9];
	ld.param.u32 	%r774, [findBlocksWithInteractions_param_10];
	add.s32 	%r157, %r774, %r772;
	setp.ne.s32 	%p140, %r823, 8;
	mov.u32 	%r826, %r552;
	mov.pred 	%p219, %p21;
	mov.u32 	%r824, %r153;
	@%p140 bra 	BB2_131;

	setp.gt.s32 	%p141, %r552, 255;
	@%p141 bra 	BB2_143;

BB2_142:
	shl.b32 	%r554, %r826, 2;
	mov.u32 	%r555, shr_8_temp;
	add.s32 	%r556, %r555, %r554;
	ld.shared.v2.u16 	{%rs87, %rs88}, [%r556];
	shl.b32 	%r557, %r826, 1;
	mov.u32 	%r558, shr_7_sum;
	add.s32 	%r559, %r558, %r557;
	st.shared.u16 	[%r559], %rs87;
	// inline asm
	mov.u32 	%r553, %ntid.x;
	// inline asm
	add.s32 	%r826, %r553, %r826;
	setp.lt.s32 	%p142, %r826, 256;
	@%p142 bra 	BB2_142;

BB2_143:
	bar.sync 	0;
	ld.shared.u16 	%rs23, [shr_7_sum+510];
	cvt.s32.s16 	%r160, %rs23;
	// inline asm
	mov.u32 	%r560, %tid.x;
	// inline asm
	setp.gt.s32 	%p143, %r560, 255;
	mov.u32 	%r827, %r560;
	@%p143 bra 	BB2_147;

BB2_144:
	shl.b32 	%r561, %r827, 1;
	add.s32 	%r563, %r245, %r561;
	ld.shared.u16 	%rs24, [%r563];
	setp.eq.s16 	%p144, %rs24, -1;
	@%p144 bra 	BB2_146;

	mov.u32 	%r565, shr_7_sum;
	add.s32 	%r566, %r565, %r561;
	ld.shared.s16 	%r567, [%r566];
	shl.b32 	%r568, %r567, 2;
	mov.u32 	%r569, shr_8_temp;
	add.s32 	%r570, %r568, %r569;
	ld.shared.v2.u16 	{%rs83, %rs84}, [%r570+-4];
	st.shared.v2.u16 	[%r570+-4], {%rs24, %rs84};

BB2_146:
	// inline asm
	mov.u32 	%r571, %ntid.x;
	// inline asm
	add.s32 	%r827, %r571, %r827;
	setp.lt.s32 	%p145, %r827, 256;
	@%p145 bra 	BB2_144;

BB2_147:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r572, %tid.x;
	// inline asm
	setp.gt.s32 	%p146, %r572, 255;
	mov.u32 	%r828, %r572;
	@%p146 bra 	BB2_149;

BB2_148:
	shl.b32 	%r574, %r828, 2;
	mov.u32 	%r575, shr_8_temp;
	add.s32 	%r576, %r575, %r574;
	ld.shared.v2.u16 	{%rs81, %rs82}, [%r576];
	shl.b32 	%r577, %r828, 1;
	add.s32 	%r579, %r245, %r577;
	st.shared.u16 	[%r579], %rs81;
	// inline asm
	mov.u32 	%r573, %ntid.x;
	// inline asm
	add.s32 	%r828, %r573, %r828;
	setp.lt.s32 	%p147, %r828, 256;
	@%p147 bra 	BB2_148;

BB2_149:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r580, %tid.x;
	// inline asm
	and.b32  	%r168, %r580, 31;
	setp.lt.s16 	%p148, %rs23, 1;
	@%p148 bra 	BB2_204;

	add.s32 	%r169, %r160, -8;
	selp.u16 	%rs54, 1, 0, %p218;
	mov.u32 	%r830, 0;
	mov.u32 	%r829, %r160;

BB2_151:
	mov.u32 	%r172, %r829;
	// inline asm
	mov.u32 	%r582, %tid.x;
	// inline asm
	shr.u32 	%r831, %r582, 5;
	setp.lt.u32 	%p149, %r831, 8;
	add.s32 	%r583, %r831, %r830;
	setp.lt.s32 	%p150, %r583, %r160;
	and.pred  	%p151, %p149, %p150;
	@!%p151 bra 	BB2_161;

BB2_152:
	add.s32 	%r584, %r831, %r830;
	shl.b32 	%r585, %r584, 1;
	add.s32 	%r587, %r245, %r585;
	ld.shared.u16 	%r588, [%r587];
	shl.b32 	%r589, %r588, 5;
	add.s32 	%r590, %r589, %r168;
	shl.b32 	%r591, %r590, 4;
	ld.param.u32 	%r765, [findBlocksWithInteractions_param_7];
	add.s32 	%r592, %r765, %r591;
	ld.global.v4.f32 	{%f827, %f828, %f829, %f484}, [%r592];
	@%p218 bra 	BB2_153;
	bra.uni 	BB2_154;

BB2_153:
	sub.ftz.f32 	%f489, %f827, %f493;
	sub.ftz.f32 	%f490, %f828, %f494;
	sub.ftz.f32 	%f491, %f829, %f495;
	mov.f32 	%f198, 0f3F000000;
	fma.rn.ftz.f32 	%f501, %f489, %f389, %f198;
	fma.rn.ftz.f32 	%f502, %f490, %f390, %f198;
	fma.rn.ftz.f32 	%f503, %f491, %f391, %f198;
	// inline asm
	cvt.rmi.f32.f32 	%f192, %f501;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f194, %f502;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f196, %f503;
	// inline asm
	neg.f32 	%f509, %f192;
	neg.f32 	%f510, %f194;
	neg.f32 	%f511, %f196;
	fma.rn.ftz.f32 	%f513, %f509, %f405, %f827;
	fma.rn.ftz.f32 	%f514, %f510, %f406, %f828;
	fma.rn.ftz.f32 	%f515, %f511, %f407, %f829;
	mov.f32 	%f827, %f513;
	mov.f32 	%f828, %f514;
	mov.f32 	%f829, %f515;
	mov.f32 	%f488, %f484;

BB2_154:
	@%p218 bra 	BB2_157;

	mov.pred 	%p220, 0;
	mov.u32 	%r833, 32;
	mov.u32 	%r832, shr_10_posBuffer;

BB2_156:
	ld.shared.v4.f32 	{%f373, %f374, %f375, %f376}, [%r832];
	sub.ftz.f32 	%f377, %f827, %f373;
	sub.ftz.f32 	%f378, %f828, %f374;
	sub.ftz.f32 	%f379, %f829, %f375;
	mov.f32 	%f224, 0f3F000000;
	fma.rn.ftz.f32 	%f385, %f377, %f389, %f224;
	fma.rn.ftz.f32 	%f386, %f378, %f390, %f224;
	fma.rn.ftz.f32 	%f387, %f379, %f391, %f224;
	// inline asm
	cvt.rmi.f32.f32 	%f200, %f385;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f202, %f386;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f204, %f387;
	// inline asm
	neg.f32 	%f397, %f200;
	neg.f32 	%f398, %f202;
	neg.f32 	%f399, %f204;
	fma.rn.ftz.f32 	%f401, %f397, %f405, %f377;
	fma.rn.ftz.f32 	%f402, %f398, %f406, %f378;
	fma.rn.ftz.f32 	%f403, %f399, %f407, %f379;
	mul.ftz.f32 	%f228, %f402, %f402;
	fma.rn.ftz.f32 	%f229, %f401, %f401, %f228;
	fma.rn.ftz.f32 	%f231, %f403, %f403, %f229;
	setp.lt.ftz.f32 	%p153, %f231, 0f3F463F14;
	or.pred  	%p154, %p220, %p153;
	ld.shared.v4.f32 	{%f409, %f410, %f411, %f412}, [%r832+16];
	sub.ftz.f32 	%f413, %f827, %f409;
	sub.ftz.f32 	%f414, %f828, %f410;
	sub.ftz.f32 	%f415, %f829, %f411;
	fma.rn.ftz.f32 	%f417, %f413, %f389, %f224;
	fma.rn.ftz.f32 	%f418, %f414, %f390, %f224;
	fma.rn.ftz.f32 	%f419, %f415, %f391, %f224;
	// inline asm
	cvt.rmi.f32.f32 	%f206, %f417;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f208, %f418;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f210, %f419;
	// inline asm
	neg.f32 	%f425, %f206;
	neg.f32 	%f426, %f208;
	neg.f32 	%f427, %f210;
	fma.rn.ftz.f32 	%f429, %f425, %f405, %f413;
	fma.rn.ftz.f32 	%f430, %f426, %f406, %f414;
	fma.rn.ftz.f32 	%f431, %f427, %f407, %f415;
	mul.ftz.f32 	%f235, %f430, %f430;
	fma.rn.ftz.f32 	%f236, %f429, %f429, %f235;
	fma.rn.ftz.f32 	%f238, %f431, %f431, %f236;
	setp.lt.ftz.f32 	%p155, %f238, 0f3F463F14;
	or.pred  	%p156, %p154, %p155;
	ld.shared.v4.f32 	{%f433, %f434, %f435, %f436}, [%r832+32];
	sub.ftz.f32 	%f437, %f827, %f433;
	sub.ftz.f32 	%f438, %f828, %f434;
	sub.ftz.f32 	%f439, %f829, %f435;
	fma.rn.ftz.f32 	%f441, %f437, %f389, %f224;
	fma.rn.ftz.f32 	%f442, %f438, %f390, %f224;
	fma.rn.ftz.f32 	%f443, %f439, %f391, %f224;
	// inline asm
	cvt.rmi.f32.f32 	%f212, %f441;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f214, %f442;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f216, %f443;
	// inline asm
	neg.f32 	%f449, %f212;
	neg.f32 	%f450, %f214;
	neg.f32 	%f451, %f216;
	fma.rn.ftz.f32 	%f453, %f449, %f405, %f437;
	fma.rn.ftz.f32 	%f454, %f450, %f406, %f438;
	fma.rn.ftz.f32 	%f455, %f451, %f407, %f439;
	mul.ftz.f32 	%f242, %f454, %f454;
	fma.rn.ftz.f32 	%f243, %f453, %f453, %f242;
	fma.rn.ftz.f32 	%f245, %f455, %f455, %f243;
	setp.lt.ftz.f32 	%p157, %f245, 0f3F463F14;
	or.pred  	%p158, %p156, %p157;
	ld.shared.v4.f32 	{%f457, %f458, %f459, %f460}, [%r832+48];
	sub.ftz.f32 	%f461, %f827, %f457;
	sub.ftz.f32 	%f462, %f828, %f458;
	sub.ftz.f32 	%f463, %f829, %f459;
	fma.rn.ftz.f32 	%f465, %f461, %f389, %f224;
	fma.rn.ftz.f32 	%f466, %f462, %f390, %f224;
	fma.rn.ftz.f32 	%f467, %f463, %f391, %f224;
	// inline asm
	cvt.rmi.f32.f32 	%f218, %f465;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f220, %f466;
	// inline asm
	// inline asm
	cvt.rmi.f32.f32 	%f222, %f467;
	// inline asm
	neg.f32 	%f473, %f218;
	neg.f32 	%f474, %f220;
	neg.f32 	%f475, %f222;
	fma.rn.ftz.f32 	%f477, %f473, %f405, %f461;
	fma.rn.ftz.f32 	%f478, %f474, %f406, %f462;
	fma.rn.ftz.f32 	%f479, %f475, %f407, %f463;
	mul.ftz.f32 	%f249, %f478, %f478;
	fma.rn.ftz.f32 	%f250, %f477, %f477, %f249;
	fma.rn.ftz.f32 	%f252, %f479, %f479, %f250;
	setp.lt.ftz.f32 	%p159, %f252, 0f3F463F14;
	or.pred  	%p220, %p158, %p159;
	add.s32 	%r832, %r832, 64;
	add.s32 	%r833, %r833, -4;
	setp.ne.s32 	%p160, %r833, 0;
	@%p160 bra 	BB2_156;
	bra.uni 	BB2_160;

BB2_157:
	mov.u16 	%rc38, 0;
	mov.u32 	%r835, 32;
	mov.u32 	%r834, shr_10_posBuffer;

BB2_158:
	ld.shared.v4.f32 	{%f305, %f306, %f307, %f308}, [%r834];
	sub.ftz.f32 	%f309, %f827, %f305;
	sub.ftz.f32 	%f310, %f828, %f306;
	sub.ftz.f32 	%f311, %f829, %f307;
	mul.ftz.f32 	%f255, %f310, %f310;
	fma.rn.ftz.f32 	%f256, %f309, %f309, %f255;
	fma.rn.ftz.f32 	%f258, %f311, %f311, %f256;
	setp.lt.ftz.f32 	%p161, %f258, 0f3F463F14;
	selp.u16 	%rc22, 1, 0, %p161;
	or.b16  	%rc23, %rc22, %rc38;
	ld.shared.v4.f32 	{%f317, %f318, %f319, %f320}, [%r834+16];
	sub.ftz.f32 	%f321, %f827, %f317;
	sub.ftz.f32 	%f322, %f828, %f318;
	sub.ftz.f32 	%f323, %f829, %f319;
	mul.ftz.f32 	%f261, %f322, %f322;
	fma.rn.ftz.f32 	%f262, %f321, %f321, %f261;
	fma.rn.ftz.f32 	%f264, %f323, %f323, %f262;
	setp.lt.ftz.f32 	%p162, %f264, 0f3F463F14;
	selp.u16 	%rc24, 1, 0, %p162;
	or.b16  	%rc25, %rc24, %rc23;
	ld.shared.v4.f32 	{%f325, %f326, %f327, %f328}, [%r834+32];
	sub.ftz.f32 	%f329, %f827, %f325;
	sub.ftz.f32 	%f330, %f828, %f326;
	sub.ftz.f32 	%f331, %f829, %f327;
	mul.ftz.f32 	%f267, %f330, %f330;
	fma.rn.ftz.f32 	%f268, %f329, %f329, %f267;
	fma.rn.ftz.f32 	%f270, %f331, %f331, %f268;
	setp.lt.ftz.f32 	%p163, %f270, 0f3F463F14;
	selp.u16 	%rc26, 1, 0, %p163;
	or.b16  	%rc27, %rc26, %rc25;
	ld.shared.v4.f32 	{%f333, %f334, %f335, %f336}, [%r834+48];
	sub.ftz.f32 	%f337, %f827, %f333;
	sub.ftz.f32 	%f338, %f828, %f334;
	sub.ftz.f32 	%f339, %f829, %f335;
	mul.ftz.f32 	%f273, %f338, %f338;
	fma.rn.ftz.f32 	%f274, %f337, %f337, %f273;
	fma.rn.ftz.f32 	%f276, %f339, %f339, %f274;
	setp.lt.ftz.f32 	%p164, %f276, 0f3F463F14;
	selp.u16 	%rc28, 1, 0, %p164;
	or.b16  	%rc29, %rc28, %rc27;
	ld.shared.v4.f32 	{%f341, %f342, %f343, %f344}, [%r834+64];
	sub.ftz.f32 	%f345, %f827, %f341;
	sub.ftz.f32 	%f346, %f828, %f342;
	sub.ftz.f32 	%f347, %f829, %f343;
	mul.ftz.f32 	%f279, %f346, %f346;
	fma.rn.ftz.f32 	%f280, %f345, %f345, %f279;
	fma.rn.ftz.f32 	%f282, %f347, %f347, %f280;
	setp.lt.ftz.f32 	%p165, %f282, 0f3F463F14;
	selp.u16 	%rc30, 1, 0, %p165;
	or.b16  	%rc31, %rc30, %rc29;
	ld.shared.v4.f32 	{%f349, %f350, %f351, %f352}, [%r834+80];
	sub.ftz.f32 	%f353, %f827, %f349;
	sub.ftz.f32 	%f354, %f828, %f350;
	sub.ftz.f32 	%f355, %f829, %f351;
	mul.ftz.f32 	%f285, %f354, %f354;
	fma.rn.ftz.f32 	%f286, %f353, %f353, %f285;
	fma.rn.ftz.f32 	%f288, %f355, %f355, %f286;
	setp.lt.ftz.f32 	%p166, %f288, 0f3F463F14;
	selp.u16 	%rc32, 1, 0, %p166;
	or.b16  	%rc33, %rc32, %rc31;
	ld.shared.v4.f32 	{%f357, %f358, %f359, %f360}, [%r834+96];
	sub.ftz.f32 	%f361, %f827, %f357;
	sub.ftz.f32 	%f362, %f828, %f358;
	sub.ftz.f32 	%f363, %f829, %f359;
	mul.ftz.f32 	%f291, %f362, %f362;
	fma.rn.ftz.f32 	%f292, %f361, %f361, %f291;
	fma.rn.ftz.f32 	%f294, %f363, %f363, %f292;
	setp.lt.ftz.f32 	%p167, %f294, 0f3F463F14;
	selp.u16 	%rc34, 1, 0, %p167;
	or.b16  	%rc35, %rc34, %rc33;
	ld.shared.v4.f32 	{%f365, %f366, %f367, %f368}, [%r834+112];
	sub.ftz.f32 	%f369, %f827, %f365;
	sub.ftz.f32 	%f370, %f828, %f366;
	sub.ftz.f32 	%f371, %f829, %f367;
	mul.ftz.f32 	%f297, %f370, %f370;
	fma.rn.ftz.f32 	%f298, %f369, %f369, %f297;
	fma.rn.ftz.f32 	%f300, %f371, %f371, %f298;
	setp.lt.ftz.f32 	%p168, %f300, 0f3F463F14;
	selp.u16 	%rc36, 1, 0, %p168;
	or.b16  	%rc38, %rc36, %rc35;
	add.s32 	%r834, %r834, 128;
	add.s32 	%r835, %r835, -8;
	setp.ne.s32 	%p169, %r835, 0;
	@%p169 bra 	BB2_158;

	{
	.reg .s16 	%temp1;
	.reg .s16 	%temp2;
	cvt.s16.s8 	%temp1, %rc38;
	mov.b16 	%temp2, 0;
	cvt.s16.s8 	%temp2, %temp2;
	setp.ne.s16 	%p220, %temp1, %temp2;
	}

BB2_160:
	shl.b32 	%r597, %r831, 5;
	add.s32 	%r598, %r597, %r168;
	shl.b32 	%r599, %r598, 1;
	mov.u32 	%r600, shr_7_sum;
	add.s32 	%r601, %r600, %r599;
	selp.u16 	%rs55, 1, 0, %p220;
	st.shared.u16 	[%r601], %rs55;
	add.s32 	%r831, %r831, 4;
	setp.lt.s32 	%p170, %r831, 8;
	add.s32 	%r602, %r831, %r830;
	setp.lt.s32 	%p171, %r602, %r160;
	and.pred  	%p172, %p170, %p171;
	@%p172 bra 	BB2_152;

BB2_161:
	// inline asm
	mov.u32 	%r603, %tid.x;
	// inline asm
	shr.u32 	%r604, %r603, 5;
	sub.s32 	%r605, %r160, %r830;
	add.s32 	%r837, %r605, %r604;
	setp.gt.s32 	%p173, %r837, 7;
	@%p173 bra 	BB2_164;

	add.s32 	%r607, %r172, %r604;
	shl.b32 	%r608, %r607, 5;
	add.s32 	%r609, %r168, %r608;
	shl.b32 	%r610, %r609, 1;
	mov.u32 	%r611, shr_7_sum;
	add.s32 	%r836, %r611, %r610;

BB2_163:
	mov.u16 	%rs56, 0;
	st.shared.u16 	[%r836], %rs56;
	add.s32 	%r836, %r836, 256;
	add.s32 	%r837, %r837, 4;
	setp.lt.s32 	%p174, %r837, 8;
	@%p174 bra 	BB2_163;

BB2_164:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r612, %tid.x;
	// inline asm
	setp.gt.s32 	%p175, %r612, 255;
	mov.u32 	%r838, %r612;
	@%p175 bra 	BB2_166;

BB2_165:
	shl.b32 	%r614, %r838, 2;
	mov.u32 	%r615, shr_8_temp;
	add.s32 	%r616, %r615, %r614;
	ld.shared.v2.u16 	{%rs77, %rs78}, [%r616];
	shl.b32 	%r617, %r838, 1;
	mov.u32 	%r618, shr_7_sum;
	add.s32 	%r619, %r618, %r617;
	ld.shared.u16 	%rs57, [%r619];
	st.shared.v2.u16 	[%r616], {%rs57, %rs78};
	// inline asm
	mov.u32 	%r613, %ntid.x;
	// inline asm
	add.s32 	%r838, %r613, %r838;
	setp.lt.s32 	%p176, %r838, 256;
	@%p176 bra 	BB2_165;

BB2_166:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r620, %tid.x;
	// inline asm
	mov.u32 	%r841, 1;
	mov.u32 	%r840, 0;
	mov.pred 	%p221, -1;
	mov.u32 	%r839, %r840;
	mov.u32 	%r842, %r620;

BB2_167:
	mov.u32 	%r198, %r840;
	mov.pred 	%p26, %p221;
	setp.lt.s32 	%p27, %r842, 256;
	@%p26 bra 	BB2_172;

	@!%p27 bra 	BB2_176;

BB2_169:
	shl.b32 	%r624, %r842, 2;
	mov.u32 	%r625, shr_8_temp;
	add.s32 	%r201, %r625, %r624;
	ld.shared.v2.u16 	{%rs75, %rs76}, [%r201];
	mov.u16 	%rs143, %rs76;
	setp.lt.s32 	%p178, %r842, %r841;
	@%p178 bra 	BB2_171;

	sub.s32 	%r626, %r842, %r841;
	shl.b32 	%r627, %r626, 2;
	add.s32 	%r629, %r625, %r627;
	ld.shared.u16 	%rs58, [%r629+2];
	add.s16 	%rs143, %rs58, %rs76;

BB2_171:
	st.shared.v2.u16 	[%r201], {%rs143, %rs76};
	// inline asm
	mov.u32 	%r630, %ntid.x;
	// inline asm
	add.s32 	%r842, %r630, %r842;
	setp.lt.s32 	%p179, %r842, 256;
	@%p179 bra 	BB2_169;
	bra.uni 	BB2_176;

BB2_172:
	@!%p27 bra 	BB2_176;

BB2_173:
	shl.b32 	%r631, %r842, 2;
	mov.u32 	%r632, shr_8_temp;
	add.s32 	%r204, %r632, %r631;
	ld.shared.v2.u16 	{%rs71, %rs72}, [%r204];
	mov.u16 	%rs144, %rs71;
	setp.lt.s32 	%p180, %r842, %r841;
	@%p180 bra 	BB2_175;

	sub.s32 	%r633, %r842, %r841;
	shl.b32 	%r634, %r633, 2;
	add.s32 	%r636, %r632, %r634;
	ld.shared.u16 	%rs59, [%r636];
	add.s16 	%rs144, %rs59, %rs71;

BB2_175:
	st.shared.v2.u16 	[%r204], {%rs71, %rs144};
	// inline asm
	mov.u32 	%r637, %ntid.x;
	// inline asm
	add.s32 	%r842, %r637, %r842;
	setp.lt.s32 	%p181, %r842, 256;
	@%p181 bra 	BB2_173;

BB2_176:
	mov.u32 	%r638, 1;
	sub.s32 	%r206, %r638, %r198;
	bar.sync 	0;
	shl.b32 	%r841, %r841, 1;
	setp.eq.s32 	%p28, %r198, 1;
	// inline asm
	mov.u32 	%r639, %tid.x;
	// inline asm
	add.s32 	%r839, %r839, 1;
	setp.ne.s32 	%p182, %r839, 8;
	mov.u32 	%r842, %r639;
	mov.pred 	%p221, %p28;
	mov.u32 	%r840, %r206;
	@%p182 bra 	BB2_167;

	setp.gt.s32 	%p183, %r639, 255;
	@%p183 bra 	BB2_179;

BB2_178:
	shl.b32 	%r641, %r842, 2;
	mov.u32 	%r642, shr_8_temp;
	add.s32 	%r643, %r642, %r641;
	ld.shared.v2.u16 	{%rs67, %rs68}, [%r643];
	shl.b32 	%r644, %r842, 1;
	mov.u32 	%r645, shr_7_sum;
	add.s32 	%r646, %r645, %r644;
	st.shared.u16 	[%r646], %rs67;
	// inline asm
	mov.u32 	%r640, %ntid.x;
	// inline asm
	add.s32 	%r842, %r640, %r842;
	setp.lt.s32 	%p184, %r842, 256;
	@%p184 bra 	BB2_178;

BB2_179:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r647, %tid.x;
	// inline asm
	setp.gt.s32 	%p185, %r647, 255;
	mov.u32 	%r843, %r647;
	@%p185 bra 	BB2_186;

BB2_180:
	shl.b32 	%r648, %r843, 1;
	mov.u32 	%r649, shr_7_sum;
	add.s32 	%r214, %r649, %r648;
	setp.eq.s32 	%p186, %r843, 0;
	ld.shared.s16 	%r215, [%r214];
	@%p186 bra 	BB2_182;

	ld.shared.s16 	%r844, [%r214+-2];
	bra.uni 	BB2_183;

BB2_182:
	mov.u32 	%r844, 0;

BB2_183:
	setp.eq.s32 	%p187, %r215, %r844;
	@%p187 bra 	BB2_185;

	shr.s32 	%r651, %r843, 31;
	shr.u32 	%r652, %r651, 27;
	add.s32 	%r653, %r843, %r652;
	shr.s32 	%r654, %r653, 5;
	add.s32 	%r655, %r654, %r830;
	shl.b32 	%r656, %r655, 1;
	add.s32 	%r658, %r245, %r656;
	ld.shared.u16 	%r659, [%r658];
	shl.b32 	%r660, %r659, 5;
	add.s32 	%r661, %r660, %r168;
	ld.shared.u32 	%r662, [shr_14_numAtoms];
	add.s32 	%r663, %r662, %r215;
	shl.b32 	%r664, %r663, 2;
	mov.u32 	%r665, shr_9_atoms;
	add.s32 	%r666, %r664, %r665;
	st.shared.u32 	[%r666+-4], %r661;

BB2_185:
	// inline asm
	mov.u32 	%r667, %ntid.x;
	// inline asm
	add.s32 	%r843, %r667, %r843;
	setp.lt.s32 	%p188, %r843, 256;
	@%p188 bra 	BB2_180;

BB2_186:
	ld.shared.u32 	%r668, [shr_14_numAtoms];
	ld.shared.s16 	%r669, [shr_7_sum+510];
	add.s32 	%r219, %r669, %r668;
	add.s32 	%r670, %r219, 31;
	setp.ge.s32 	%p29, %r830, %r169;
	selp.b32 	%r671, %r670, %r219, %p29;
	shr.s32 	%r672, %r671, 31;
	shr.u32 	%r673, %r672, 27;
	add.s32 	%r674, %r671, %r673;
	shr.s32 	%r220, %r674, 5;
	setp.gt.s32 	%p189, %r671, 31;
	@%p189 bra 	BB2_189;

	bar.sync 	0;
	// inline asm
	mov.u32 	%r675, %tid.x;
	// inline asm
	setp.ne.s32 	%p190, %r675, 0;
	@%p190 bra 	BB2_201;

	ld.shared.u32 	%r676, [shr_14_numAtoms];
	ld.shared.s16 	%r677, [shr_7_sum+510];
	add.s32 	%r678, %r676, %r677;
	st.shared.u32 	[shr_14_numAtoms], %r678;
	bra.uni 	BB2_201;

BB2_189:
	// inline asm
	mov.u32 	%r679, %tid.x;
	// inline asm
	setp.ne.s32 	%p191, %r679, 0;
	@%p191 bra 	BB2_191;

	ld.param.u32 	%r756, [findBlocksWithInteractions_param_4];
	atom.global.add.u32 	%r680, [%r756], %r220;
	st.shared.u32 	[shr_13_globalIndex], %r680;

BB2_191:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r681, %tid.x;
	// inline asm
	setp.ne.s32 	%p192, %r681, 0;
	@%p192 bra 	BB2_193;

	shl.b32 	%r682, %r220, 5;
	sub.s32 	%r683, %r219, %r682;
	st.shared.u32 	[shr_14_numAtoms], %r683;

BB2_193:
	ld.shared.u32 	%r684, [shr_13_globalIndex];
	add.s32 	%r685, %r684, %r220;
	ld.param.u32 	%r770, [findBlocksWithInteractions_param_8];
	setp.gt.u32 	%p193, %r685, %r770;
	@%p193 bra 	BB2_201;

	// inline asm
	mov.u32 	%r686, %tid.x;
	// inline asm
	setp.ge.u32 	%p194, %r686, %r220;
	@%p194 bra 	BB2_196;

	ld.shared.u32 	%r688, [shr_13_globalIndex];
	// inline asm
	mov.u32 	%r687, %tid.x;
	// inline asm
	add.s32 	%r689, %r687, %r688;
	shl.b32 	%r690, %r689, 2;
	ld.param.u32 	%r759, [findBlocksWithInteractions_param_5];
	add.s32 	%r691, %r759, %r690;
	st.global.v2.u16 	[%r691], {%rs1, %rs54};

BB2_196:
	// inline asm
	mov.u32 	%r692, %tid.x;
	// inline asm
	shl.b32 	%r222, %r220, 5;
	setp.ge.s32 	%p195, %r692, %r222;
	mov.u32 	%r845, %r692;
	@%p195 bra 	BB2_201;

BB2_197:
	setp.lt.s32 	%p196, %r845, %r219;
	@%p196 bra 	BB2_199;

	mov.u32 	%r846, 23558;
	bra.uni 	BB2_200;

BB2_199:
	shl.b32 	%r694, %r845, 2;
	mov.u32 	%r695, shr_9_atoms;
	add.s32 	%r696, %r695, %r694;
	ld.shared.u32 	%r846, [%r696];

BB2_200:
	ld.shared.u32 	%r698, [shr_13_globalIndex];
	shl.b32 	%r699, %r698, 5;
	add.s32 	%r700, %r699, %r845;
	shl.b32 	%r701, %r700, 2;
	ld.param.u32 	%r762, [findBlocksWithInteractions_param_6];
	add.s32 	%r702, %r762, %r701;
	st.global.u32 	[%r702], %r846;
	// inline asm
	mov.u32 	%r697, %ntid.x;
	// inline asm
	add.s32 	%r845, %r697, %r845;
	setp.lt.s32 	%p197, %r845, %r222;
	@%p197 bra 	BB2_197;

BB2_201:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r703, %tid.x;
	// inline asm
	ld.shared.u32 	%r704, [shr_14_numAtoms];
	setp.ge.u32 	%p198, %r703, %r704;
	or.pred  	%p199, %p198, %p29;
	@%p199 bra 	BB2_203;

	shl.b32 	%r707, %r220, 5;
	// inline asm
	mov.u32 	%r705, %tid.x;
	// inline asm
	add.s32 	%r708, %r705, %r707;
	shl.b32 	%r709, %r708, 2;
	mov.u32 	%r710, shr_9_atoms;
	add.s32 	%r711, %r710, %r709;
	ld.shared.u32 	%r712, [%r711];
	// inline asm
	mov.u32 	%r706, %tid.x;
	// inline asm
	shl.b32 	%r713, %r706, 2;
	add.s32 	%r714, %r710, %r713;
	st.shared.u32 	[%r714], %r712;

BB2_203:
	add.s32 	%r830, %r830, 8;
	setp.lt.s32 	%p200, %r830, %r160;
	add.s32 	%r228, %r172, -8;
	mov.u32 	%r829, %r228;
	@%p200 bra 	BB2_151;

BB2_204:
	setp.eq.s16 	%p201, %rs23, 0;
	ld.shared.u32 	%r715, [shr_14_numAtoms];
	setp.gt.s32 	%p202, %r715, 0;
	and.pred  	%p203, %p201, %p202;
	@!%p203 bra 	BB2_215;

	// inline asm
	mov.u32 	%r716, %tid.x;
	// inline asm
	setp.ne.s32 	%p204, %r716, 0;
	@%p204 bra 	BB2_207;

	ld.param.u32 	%r755, [findBlocksWithInteractions_param_4];
	atom.global.add.u32 	%r717, [%r755], 1;
	st.shared.u32 	[shr_13_globalIndex], %r717;

BB2_207:
	bar.sync 	0;
	ld.shared.u32 	%r718, [shr_13_globalIndex];
	ld.param.u32 	%r769, [findBlocksWithInteractions_param_8];
	setp.ge.u32 	%p205, %r718, %r769;
	@%p205 bra 	BB2_215;

	// inline asm
	mov.u32 	%r719, %tid.x;
	// inline asm
	setp.ne.s32 	%p206, %r719, 0;
	@%p206 bra 	BB2_210;

	selp.u16 	%rs61, 1, 0, %p218;
	ld.shared.u32 	%r720, [shr_13_globalIndex];
	shl.b32 	%r721, %r720, 2;
	ld.param.u32 	%r758, [findBlocksWithInteractions_param_5];
	add.s32 	%r722, %r758, %r721;
	st.global.v2.u16 	[%r722], {%rs1, %rs61};

BB2_210:
	// inline asm
	mov.u32 	%r723, %tid.x;
	// inline asm
	setp.gt.u32 	%p207, %r723, 31;
	@%p207 bra 	BB2_215;

	// inline asm
	mov.u32 	%r724, %tid.x;
	// inline asm
	ld.shared.u32 	%r725, [shr_14_numAtoms];
	setp.lt.u32 	%p208, %r724, %r725;
	@%p208 bra 	BB2_213;

	mov.u32 	%r847, 23558;
	bra.uni 	BB2_214;

BB2_213:
	// inline asm
	mov.u32 	%r727, %tid.x;
	// inline asm
	shl.b32 	%r728, %r727, 2;
	mov.u32 	%r729, shr_9_atoms;
	add.s32 	%r730, %r729, %r728;
	ld.shared.u32 	%r847, [%r730];

BB2_214:
	ld.shared.u32 	%r732, [shr_13_globalIndex];
	shl.b32 	%r733, %r732, 5;
	// inline asm
	mov.u32 	%r731, %tid.x;
	// inline asm
	add.s32 	%r734, %r733, %r731;
	shl.b32 	%r735, %r734, 2;
	ld.param.u32 	%r761, [findBlocksWithInteractions_param_6];
	add.s32 	%r736, %r761, %r735;
	st.global.u32 	[%r736], %r847;

BB2_215:
	// inline asm
	mov.u32 	%r737, %tid.x;
	// inline asm
	setp.gt.s32 	%p209, %r737, 255;
	mov.u32 	%r848, %r737;
	@%p209 bra 	BB2_217;

BB2_216:
	shl.b32 	%r739, %r848, 1;
	add.s32 	%r741, %r245, %r739;
	st.shared.u16 	[%r741], %rs31;
	// inline asm
	mov.u32 	%r738, %ntid.x;
	// inline asm
	add.s32 	%r848, %r738, %r848;
	setp.lt.s32 	%p210, %r848, 256;
	@%p210 bra 	BB2_216;

BB2_217:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r742, %elwreg6;
	// inline asm
	add.s32 	%r783, %r742, %r783;
	setp.lt.u32 	%p211, %r783, %r157;
	@%p211 bra 	BB2_5;

BB2_218:
	// inline asm
	mov.u32 	%r743, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r744, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r745, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r746, %tid.x;
	// inline asm
	add.s32 	%r747, %r746, %r743;
	mad.lo.s32 	%r849, %r745, %r744, %r747;
	setp.gt.s32 	%p212, %r849, 23557;
	@%p212 bra 	BB2_220;

BB2_219:
	shl.b32 	%r750, %r849, 4;
	ld.param.u32 	%r782, [findBlocksWithInteractions_param_16];
	add.s32 	%r751, %r782, %r750;
	ld.param.u32 	%r764, [findBlocksWithInteractions_param_7];
	add.s32 	%r752, %r764, %r750;
	ld.global.v4.f32 	{%f301, %f302, %f303, %f304}, [%r752];
	st.global.v4.f32 	[%r751], {%f301, %f302, %f303, %f304};
	// inline asm
	mov.u32 	%r748, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r749, %ntid.x;
	// inline asm
	mad.lo.s32 	%r849, %r749, %r748, %r849;
	setp.lt.s32 	%p213, %r849, 23558;
	@%p213 bra 	BB2_219;

BB2_220:
	ret;
}



//
// Generated by LWPU LWVM Compiler
// Compiler built on Thu May 15 11:00:55 2014 (1400169655)
// Driver 
//

//.version 3.0
//.target sm_30, texmode_independent
//.address_size 32


.entry integrateVerletPart1(
	.param .u32 integrateVerletPart1_param_0,
	.param .u32 .ptr .global .align 8 integrateVerletPart1_param_1,
	.param .u32 .ptr .global .align 16 integrateVerletPart1_param_2,
	.param .u32 .ptr .global .align 16 integrateVerletPart1_param_3,
	.param .u32 .ptr .global .align 16 integrateVerletPart1_param_4,
	.param .u32 .ptr .global .align 16 integrateVerletPart1_param_5,
	.param .u32 .ptr .global .align 16 integrateVerletPart1_param_6
)
{
	.reg .f32 	%f<67>;
	.reg .f64 	%fd<2>;
	.reg .pred 	%p<4>;
	.reg .s32 	%r<29>;


	ld.param.u32 	%r1, [integrateVerletPart1_param_0];
	ld.param.u32 	%r14, [integrateVerletPart1_param_1];
	ld.global.v2.f32 	{%f65, %f66}, [%r14];
	add.f32 	%f5, %f65, %f66;
	mul.f32 	%f2, %f5, 0f3F000000;
	// inline asm
	mov.u32 	%r10, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r11, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r12, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r13, %tid.x;
	// inline asm
	add.s32 	%r15, %r13, %r10;
	mad.lo.s32 	%r28, %r12, %r11, %r15;
	setp.ge.s32 	%p1, %r28, %r1;
	@%p1 bra 	BB0_4;

BB0_1:
	shl.b32 	%r16, %r28, 4;
	ld.param.u32 	%r25, [integrateVerletPart1_param_4];
	add.s32 	%r8, %r25, %r16;
	ld.global.v4.f32 	{%f25, %f26, %f27, %f28}, [%r8];
	cvt.f64.f32 	%fd1, %f28;
	setp.eq.f64 	%p2, %fd1, 0d0000000000000000;
	@%p2 bra 	BB0_3;

	ld.param.u32 	%r24, [integrateVerletPart1_param_2];
	add.s32 	%r18, %r24, %r16;
	ld.param.u32 	%r26, [integrateVerletPart1_param_5];
	add.s32 	%r19, %r26, %r16;
	ld.global.v4.f32 	{%f21, %f22, %f23, %f24}, [%r19];
	mul.f32 	%f10, %f21, %f2;
	fma.rn.f32 	%f12, %f10, %f28, %f25;
	mul.f32 	%f14, %f22, %f2;
	fma.rn.f32 	%f16, %f14, %f28, %f26;
	mul.f32 	%f18, %f23, %f2;
	fma.rn.f32 	%f20, %f18, %f28, %f27;
	mul.f32 	%f41, %f12, %f66;
	mul.f32 	%f42, %f16, %f66;
	mul.f32 	%f43, %f20, %f66;
	ld.global.v4.f32 	{%f49, %f50, %f51, %f52}, [%r18];
	ld.param.u32 	%r27, [integrateVerletPart1_param_6];
	add.s32 	%r20, %r27, %r16;
	st.global.v4.f32 	[%r20], {%f41, %f42, %f43, %f52};
	st.global.v4.f32 	[%r8], {%f12, %f16, %f20, %f28};

BB0_3:
	// inline asm
	mov.u32 	%r21, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r22, %ntid.x;
	// inline asm
	mad.lo.s32 	%r28, %r22, %r21, %r28;
	ld.param.u32 	%r23, [integrateVerletPart1_param_0];
	setp.lt.s32 	%p3, %r28, %r23;
	@%p3 bra 	BB0_1;

BB0_4:
	ret;
}

.entry integrateVerletPart2(
	.param .u32 integrateVerletPart2_param_0,
	.param .u32 .ptr .global .align 8 integrateVerletPart2_param_1,
	.param .u32 .ptr .global .align 16 integrateVerletPart2_param_2,
	.param .u32 .ptr .global .align 16 integrateVerletPart2_param_3,
	.param .u32 .ptr .global .align 16 integrateVerletPart2_param_4,
	.param .u32 .ptr .global .align 16 integrateVerletPart2_param_5
)
{
	.reg .f32 	%f<46>;
	.reg .f64 	%fd<29>;
	.reg .pred 	%p<5>;
	.reg .s32 	%r<34>;


	ld.param.u32 	%r2, [integrateVerletPart2_param_1];
	ld.global.v2.f32 	{%f44, %f45}, [%r2];
	cvt.f64.f32 	%fd2, %f45;
	rcp.rn.f64 	%fd1, %fd2;
	// inline asm
	mov.u32 	%r10, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r11, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r12, %ctaid.x;
	// inline asm
	mad.lo.s32 	%r14, %r12, %r11, %r10;
	// inline asm
	mov.u32 	%r13, %tid.x;
	// inline asm
	neg.s32 	%r15, %r13;
	setp.ne.s32 	%p1, %r14, %r15;
	@%p1 bra 	BB1_2;

	ld.param.u32 	%r29, [integrateVerletPart2_param_1];
	st.global.v2.f32 	[%r29], {%f45, %f45};

BB1_2:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r16, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r17, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r18, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r19, %tid.x;
	// inline asm
	add.s32 	%r20, %r19, %r16;
	mad.lo.s32 	%r33, %r18, %r17, %r20;
	ld.param.u32 	%r28, [integrateVerletPart2_param_0];
	setp.ge.s32 	%p2, %r33, %r28;
	@%p2 bra 	BB1_6;

BB1_3:
	shl.b32 	%r21, %r33, 4;
	ld.param.u32 	%r31, [integrateVerletPart2_param_4];
	add.s32 	%r8, %r31, %r21;
	ld.global.v4.f32 	{%f36, %f37, %f38, %f39}, [%r8];
	cvt.f64.f32 	%fd4, %f39;
	setp.eq.f64 	%p3, %fd4, 0d0000000000000000;
	@%p3 bra 	BB1_5;

	ld.param.u32 	%r30, [integrateVerletPart2_param_2];
	add.s32 	%r23, %r30, %r21;
	ld.param.u32 	%r32, [integrateVerletPart2_param_5];
	add.s32 	%r24, %r32, %r21;
	ld.global.v4.f32 	{%f12, %f13, %f14, %f15}, [%r24];
	ld.global.v4.f32 	{%f16, %f17, %f18, %f19}, [%r23];
	add.f32 	%f20, %f16, %f12;
	add.f32 	%f21, %f17, %f13;
	add.f32 	%f22, %f18, %f14;
	// inline asm
	cvt.f64.f32 	%fd5, %f12;
	// inline asm
	// inline asm
	cvt.f64.f32 	%fd6, %f13;
	// inline asm
	// inline asm
	cvt.f64.f32 	%fd7, %f14;
	// inline asm
	// inline asm
	cvt.f64.f32 	%fd8, %f15;
	// inline asm
	mul.f64 	%fd15, %fd5, %fd1;
	mul.f64 	%fd16, %fd6, %fd1;
	// inline asm
	cvt.rn.f32.f64 	%f7, %fd15;
	// inline asm
	// inline asm
	cvt.rn.f32.f64 	%f8, %fd16;
	// inline asm
	mul.f64 	%fd21, %fd7, %fd1;
	// inline asm
	cvt.rn.f32.f64 	%f9, %fd21;
	// inline asm
	st.global.v4.f32 	[%r23], {%f20, %f21, %f22, %f19};
	st.global.v4.f32 	[%r8], {%f7, %f8, %f9, %f39};

BB1_5:
	// inline asm
	mov.u32 	%r25, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r26, %ntid.x;
	// inline asm
	mad.lo.s32 	%r33, %r26, %r25, %r33;
	ld.param.u32 	%r27, [integrateVerletPart2_param_0];
	setp.lt.s32 	%p4, %r33, %r27;
	@%p4 bra 	BB1_3;

BB1_6:
	ret;
}

.entry selectVerletStepSize(
	.param .u32 selectVerletStepSize_param_0,
	.param .f32 selectVerletStepSize_param_1,
	.param .f32 selectVerletStepSize_param_2,
	.param .u32 .ptr .global .align 8 selectVerletStepSize_param_3,
	.param .u32 .ptr .global .align 16 selectVerletStepSize_param_4,
	.param .u32 .ptr .global .align 16 selectVerletStepSize_param_5,
	.param .u32 .ptr .shared .align 4 selectVerletStepSize_param_6
)
{
	.reg .f32 	%f<44>;
	.reg .pred 	%p<13>;
	.reg .s32 	%r<58>;


	ld.param.u32 	%r1, [selectVerletStepSize_param_0];
	// inline asm
	mov.u32 	%r15, %tid.x;
	// inline asm
	setp.lt.s32 	%p1, %r15, %r1;
	mov.u32 	%r52, %r15;
	@%p1 bra 	BB2_2;

	mov.f32 	%f42, 0f00000000;
	bra.uni 	BB2_4;

BB2_2:
	mov.f32 	%f42, 0f00000000;

BB2_3:
	shl.b32 	%r18, %r52, 4;
	ld.param.u32 	%r47, [selectVerletStepSize_param_4];
	add.s32 	%r19, %r47, %r18;
	ld.param.u32 	%r48, [selectVerletStepSize_param_5];
	add.s32 	%r20, %r48, %r18;
	ld.global.v4.f32 	{%f36, %f37, %f38, %f39}, [%r20];
	mul.f32 	%f14, %f37, %f37;
	fma.rn.f32 	%f15, %f36, %f36, %f14;
	fma.rn.f32 	%f17, %f38, %f38, %f15;
	ld.global.f32 	%f18, [%r19+12];
	fma.rn.f32 	%f42, %f17, %f18, %f42;
	// inline asm
	mov.u32 	%r16, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r17, %ntid.x;
	// inline asm
	mad.lo.s32 	%r52, %r17, %r16, %r52;
	ld.param.u32 	%r44, [selectVerletStepSize_param_0];
	setp.lt.s32 	%p2, %r52, %r44;
	@%p2 bra 	BB2_3;

BB2_4:
	// inline asm
	mov.u32 	%r21, %tid.x;
	// inline asm
	shl.b32 	%r22, %r21, 2;
	ld.param.u32 	%r51, [selectVerletStepSize_param_6];
	add.s32 	%r23, %r51, %r22;
	st.shared.f32 	[%r23], %f42;
	bar.sync 	0;
	// inline asm
	mov.u32 	%r24, %ntid.x;
	// inline asm
	setp.gt.u32 	%p3, %r24, 1;
	// inline asm
	mov.u32 	%r25, %tid.x;
	// inline asm
	mov.u32 	%r56, %r25;
	@%p3 bra 	BB2_5;
	bra.uni 	BB2_11;

BB2_5:
	mov.u32 	%r53, 1;
	mov.u32 	%r57, %r56;

BB2_6:
	mov.u32 	%r10, %r57;
	// inline asm
	mov.u32 	%r27, %ntid.x;
	// inline asm
	add.s32 	%r28, %r10, %r53;
	setp.ge.u32 	%p4, %r28, %r27;
	@%p4 bra 	BB2_9;

	// inline asm
	mov.u32 	%r29, %tid.x;
	// inline asm
	shl.b32 	%r30, %r53, 1;
	add.s32 	%r31, %r30, -1;
	and.b32  	%r32, %r29, %r31;
	setp.ne.s32 	%p5, %r32, 0;
	@%p5 bra 	BB2_9;

	// inline asm
	mov.u32 	%r33, %tid.x;
	// inline asm
	add.s32 	%r35, %r33, %r53;
	shl.b32 	%r36, %r35, 2;
	ld.param.u32 	%r50, [selectVerletStepSize_param_6];
	add.s32 	%r37, %r50, %r36;
	ld.shared.f32 	%f19, [%r37];
	// inline asm
	mov.u32 	%r34, %tid.x;
	// inline asm
	shl.b32 	%r38, %r34, 2;
	add.s32 	%r39, %r50, %r38;
	ld.shared.f32 	%f20, [%r39];
	add.f32 	%f21, %f20, %f19;
	st.shared.f32 	[%r39], %f21;

BB2_9:
	bar.sync 	0;
	// inline asm
	mov.u32 	%r40, %ntid.x;
	// inline asm
	shl.b32 	%r53, %r53, 1;
	setp.lt.u32 	%p6, %r53, %r40;
	// inline asm
	mov.u32 	%r41, %tid.x;
	// inline asm
	mov.u32 	%r13, %r41;
	mov.u32 	%r57, %r13;
	@%p6 bra 	BB2_6;

	mov.u32 	%r56, %r13;

BB2_11:
	setp.eq.s32 	%p7, %r56, 0;
	@%p7 bra 	BB2_13;

	ret;

BB2_13:
	ld.param.u32 	%r49, [selectVerletStepSize_param_6];
	ld.shared.f32 	%f26, [%r49];
	ld.param.u32 	%r43, [selectVerletStepSize_param_0];
	mul.lo.s32 	%r42, %r43, 3;
	cvt.rn.f32.s32 	%f27, %r42;
	div.full.f32 	%f23, %f26, %f27;
	// inline asm
	sqrt.approx.f32 	%f22, %f23;
	// inline asm
	ld.param.f32 	%f41, [selectVerletStepSize_param_2];
	div.full.f32 	%f25, %f41, %f22;
	// inline asm
	sqrt.approx.f32 	%f24, %f25;
	// inline asm
	ld.param.u32 	%r46, [selectVerletStepSize_param_3];
	ld.global.v2.f32 	{%f34, %f35}, [%r46];
	setp.gt.f32 	%p8, %f35, 0f00000000;
	mov.f32 	%f43, %f24;
	@%p8 bra 	BB2_14;
	bra.uni 	BB2_15;

BB2_14:
	add.f32 	%f28, %f35, %f35;
	min.f32 	%f43, %f24, %f28;

BB2_15:
	mul.f32 	%f29, %f35, 0f3F8CCCCD;
	setp.lt.f32 	%p9, %f43, %f29;
	setp.gt.f32 	%p10, %f43, %f35;
	and.pred  	%p11, %p10, %p9;
	selp.f32 	%f30, %f35, %f43, %p11;
	ld.param.f32 	%f40, [selectVerletStepSize_param_1];
	setp.gt.f32 	%p12, %f30, %f40;
	selp.f32 	%f31, %f40, %f30, %p12;
	ld.param.u32 	%r45, [selectVerletStepSize_param_3];
	st.global.v2.f32 	[%r45], {%f34, %f31};
	ret;
}



//
// Generated by LWPU LWVM Compiler
// Compiler built on Thu May 15 11:00:55 2014 (1400169655)
// Driver 
//

//.version 3.0
//.target sm_30, texmode_independent
//.address_size 32


.entry updateBsplines(
	.param .u32 .ptr .global .align 16 updateBsplines_param_0,
	.param .u32 .ptr .global .align 16 updateBsplines_param_1,
	.param .u32 .ptr .shared .align 16 updateBsplines_param_2,
	.param .u32 .ptr .global .align 8 updateBsplines_param_3,
	.param .align 16 .b8 updateBsplines_param_4[16],
	.param .align 16 .b8 updateBsplines_param_5[16]
)
{
	.reg .f32 	%f<40>;
	.reg .pred 	%p<3>;
	.reg .s32 	%r<49>;


	ld.param.v4.f32 	{%f32, %f33, %f34, %f35}, [updateBsplines_param_5];
	ld.param.v4.f32 	{%f36, %f37, %f38, %f39}, [updateBsplines_param_4];
	// inline asm
	mov.u32 	%r6, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r7, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r8, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r9, %tid.x;
	// inline asm
	add.s32 	%r10, %r9, %r6;
	mad.lo.s32 	%r48, %r8, %r7, %r10;
	setp.gt.s32 	%p1, %r48, 23557;
	@%p1 bra 	BB0_2;

BB0_1:
	shl.b32 	%r14, %r48, 4;
	ld.param.u32 	%r46, [updateBsplines_param_0];
	add.s32 	%r15, %r46, %r14;
	ld.global.v4.f32 	{%f28, %f29, %f30, %f31}, [%r15];
	mul.ftz.f32 	%f8, %f28, %f32;
	// inline asm
	cvt.rmi.f32.f32 	%f7, %f8;
	// inline asm
	neg.f32 	%f14, %f7;
	fma.rn.ftz.f32 	%f15, %f14, %f36, %f28;
	mul.ftz.f32 	%f10, %f29, %f33;
	// inline asm
	cvt.rmi.f32.f32 	%f9, %f10;
	// inline asm
	neg.f32 	%f17, %f9;
	fma.rn.ftz.f32 	%f18, %f17, %f37, %f29;
	mul.ftz.f32 	%f12, %f30, %f34;
	// inline asm
	cvt.rmi.f32.f32 	%f11, %f12;
	// inline asm
	neg.f32 	%f20, %f11;
	fma.rn.ftz.f32 	%f21, %f20, %f38, %f30;
	mul.ftz.f32 	%f22, %f15, %f32;
	mul.ftz.f32 	%f23, %f22, 0f427C0000;
	mul.ftz.f32 	%f24, %f18, %f33;
	mul.ftz.f32 	%f25, %f24, 0f427C0000;
	mul.ftz.f32 	%f26, %f21, %f34;
	mul.ftz.f32 	%f27, %f26, 0f427C0000;
	cvt.rzi.ftz.s32.f32 	%r16, %f23;
	mul.hi.s32 	%r17, %r16, -2113396605;
	add.s32 	%r18, %r17, %r16;
	shr.u32 	%r19, %r18, 31;
	shr.s32 	%r20, %r18, 5;
	add.s32 	%r21, %r20, %r19;
	mul.lo.s32 	%r22, %r21, 63;
	sub.s32 	%r23, %r16, %r22;
	cvt.rzi.ftz.s32.f32 	%r24, %f25;
	mul.hi.s32 	%r25, %r24, -2113396605;
	add.s32 	%r26, %r25, %r24;
	shr.u32 	%r27, %r26, 31;
	shr.s32 	%r28, %r26, 5;
	add.s32 	%r29, %r28, %r27;
	mul.lo.s32 	%r30, %r29, 63;
	sub.s32 	%r31, %r24, %r30;
	cvt.rzi.ftz.s32.f32 	%r32, %f27;
	mul.hi.s32 	%r33, %r32, -2113396605;
	add.s32 	%r34, %r33, %r32;
	shr.u32 	%r35, %r34, 31;
	shr.s32 	%r36, %r34, 5;
	add.s32 	%r37, %r36, %r35;
	mul.lo.s32 	%r38, %r37, 63;
	sub.s32 	%r39, %r32, %r38;
	mad.lo.s32 	%r40, %r23, 3969, %r39;
	mad.lo.s32 	%r41, %r31, 63, %r40;
	shl.b32 	%r42, %r48, 3;
	ld.param.u32 	%r47, [updateBsplines_param_3];
	add.s32 	%r43, %r47, %r42;
	st.global.v2.u32 	[%r43], {%r48, %r41};
	// inline asm
	mov.u32 	%r12, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r13, %ntid.x;
	// inline asm
	mad.lo.s32 	%r48, %r13, %r12, %r48;
	setp.lt.s32 	%p2, %r48, 23558;
	@%p2 bra 	BB0_1;

BB0_2:
	ret;
}

.entry findAtomRangeForGrid(
	.param .u32 .ptr .global .align 8 findAtomRangeForGrid_param_0,
	.param .u32 .ptr .global .align 4 findAtomRangeForGrid_param_1,
	.param .u32 .ptr .global .align 16 findAtomRangeForGrid_param_2,
	.param .align 16 .b8 findAtomRangeForGrid_param_3[16],
	.param .align 16 .b8 findAtomRangeForGrid_param_4[16]
)
{
	.reg .pred 	%p<10>;
	.reg .s32 	%r<79>;


	// inline asm
	mov.u32 	%r22, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r23, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r24, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r25, %tid.x;
	// inline asm
	add.s32 	%r34, %r25, %r22;
	mad.lo.s32 	%r35, %r24, %r23, %r34;
	mul.lo.s32 	%r36, %r35, 23558;
	// inline asm
	mov.u32 	%r26, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r27, %ntid.x;
	// inline asm
	mul.lo.s32 	%r37, %r27, %r26;
	div.u32 	%r66, %r36, %r37;
	// inline asm
	mov.u32 	%r28, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r29, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r30, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r31, %tid.x;
	// inline asm
	add.s32 	%r38, %r31, %r28;
	mad.lo.s32 	%r39, %r30, %r29, %r38;
	mad.lo.s32 	%r40, %r39, 23558, 23558;
	// inline asm
	mov.u32 	%r32, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r33, %ntid.x;
	// inline asm
	mul.lo.s32 	%r41, %r33, %r32;
	div.u32 	%r4, %r40, %r41;
	setp.eq.s32 	%p1, %r66, 0;
	@%p1 bra 	BB1_2;

	shl.b32 	%r42, %r66, 3;
	ld.param.u32 	%r63, [findAtomRangeForGrid_param_0];
	add.s32 	%r43, %r42, %r63;
	add.s32 	%r44, %r43, -8;
	ld.global.u32 	%r76, [%r44+4];
	bra.uni 	BB1_3;

BB1_2:
	mov.u32 	%r76, -1;

BB1_3:
	mov.u32 	%r73, %r76;
	setp.lt.s32 	%p2, %r66, %r4;
	@%p2 bra 	BB1_4;
	bra.uni 	BB1_12;

BB1_4:
	mov.u32 	%r74, %r73;

BB1_5:
	mov.u32 	%r68, %r74;
	mov.u32 	%r8, %r68;
	shl.b32 	%r46, %r66, 3;
	ld.param.u32 	%r62, [findAtomRangeForGrid_param_0];
	add.s32 	%r47, %r62, %r46;
	ld.global.u32 	%r9, [%r47+4];
	setp.eq.s32 	%p3, %r9, %r8;
	@%p3 bra 	BB1_9;

	add.s32 	%r67, %r8, 1;
	setp.gt.s32 	%p4, %r67, %r9;
	@%p4 bra 	BB1_8;

BB1_7:
	shl.b32 	%r48, %r67, 2;
	ld.param.u32 	%r65, [findAtomRangeForGrid_param_1];
	add.s32 	%r49, %r65, %r48;
	st.global.u32 	[%r49], %r66;
	add.s32 	%r67, %r67, 1;
	setp.le.s32 	%p5, %r67, %r9;
	@%p5 bra 	BB1_7;

BB1_8:
	mov.u32 	%r75, %r9;
	bra.uni 	BB1_10;

BB1_9:
	mov.u32 	%r75, %r8;

BB1_10:
	mov.u32 	%r13, %r75;
	add.s32 	%r66, %r66, 1;
	setp.lt.s32 	%p6, %r66, %r4;
	mov.u32 	%r74, %r13;
	@%p6 bra 	BB1_5;

	mov.u32 	%r73, %r13;

BB1_12:
	// inline asm
	mov.u32 	%r50, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r51, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r52, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r53, %tid.x;
	// inline asm
	add.s32 	%r56, %r53, %r50;
	mad.lo.s32 	%r57, %r52, %r51, %r56;
	// inline asm
	mov.u32 	%r54, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r55, %ntid.x;
	// inline asm
	mad.lo.s32 	%r58, %r55, %r54, -1;
	setp.ne.s32 	%p7, %r57, %r58;
	@%p7 bra 	BB1_16;

	add.s32 	%r78, %r73, 1;
	setp.gt.s32 	%p8, %r78, 250047;
	@%p8 bra 	BB1_16;

	shl.b32 	%r59, %r73, 2;
	ld.param.u32 	%r64, [findAtomRangeForGrid_param_1];
	add.s32 	%r60, %r59, %r64;
	add.s32 	%r77, %r60, 4;

BB1_15:
	mov.u32 	%r61, 23558;
	st.global.u32 	[%r77], %r61;
	add.s32 	%r77, %r77, 4;
	add.s32 	%r78, %r78, 1;
	setp.lt.s32 	%p9, %r78, 250048;
	@%p9 bra 	BB1_15;

BB1_16:
	ret;
}

.entry recordZIndex(
	.param .u32 .ptr .global .align 8 recordZIndex_param_0,
	.param .u32 .ptr .global .align 16 recordZIndex_param_1,
	.param .align 16 .b8 recordZIndex_param_2[16],
	.param .align 16 .b8 recordZIndex_param_3[16]
)
{
	.reg .f32 	%f<22>;
	.reg .pred 	%p<3>;
	.reg .s32 	%r<61>;


	ld.param.v4.f32 	{%f14, %f15, %f16, %f17}, [recordZIndex_param_3];
	ld.param.v4.f32 	{%f18, %f19, %f20, %f21}, [recordZIndex_param_2];
	// inline asm
	mov.u32 	%r16, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r17, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r18, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r19, %tid.x;
	// inline asm
	add.s32 	%r28, %r19, %r16;
	mad.lo.s32 	%r29, %r18, %r17, %r28;
	mul.lo.s32 	%r30, %r29, 23558;
	// inline asm
	mov.u32 	%r20, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r21, %ntid.x;
	// inline asm
	mul.lo.s32 	%r31, %r21, %r20;
	div.u32 	%r60, %r30, %r31;
	// inline asm
	mov.u32 	%r22, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r23, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r24, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r25, %tid.x;
	// inline asm
	add.s32 	%r32, %r25, %r22;
	mad.lo.s32 	%r33, %r24, %r23, %r32;
	mad.lo.s32 	%r34, %r33, 23558, 23558;
	// inline asm
	mov.u32 	%r26, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r27, %ntid.x;
	// inline asm
	mul.lo.s32 	%r35, %r27, %r26;
	div.u32 	%r10, %r34, %r35;
	setp.ge.s32 	%p1, %r60, %r10;
	@%p1 bra 	BB2_3;

	div.u32 	%r40, %r30, %r31;
	shl.b32 	%r41, %r40, 3;
	ld.param.u32 	%r57, [recordZIndex_param_0];
	add.s32 	%r59, %r57, %r41;

BB2_2:
	ld.global.v2.u32 	{%r53, %r54}, [%r59];
	shl.b32 	%r43, %r53, 4;
	ld.param.u32 	%r58, [recordZIndex_param_1];
	add.s32 	%r44, %r58, %r43;
	ld.global.v4.f32 	{%f10, %f11, %f12, %f13}, [%r44];
	mul.ftz.f32 	%f4, %f12, %f16;
	// inline asm
	cvt.rmi.f32.f32 	%f3, %f4;
	// inline asm
	neg.f32 	%f6, %f3;
	fma.rn.ftz.f32 	%f7, %f6, %f20, %f12;
	mul.ftz.f32 	%f8, %f7, %f16;
	mul.ftz.f32 	%f9, %f8, 0f427C0000;
	cvt.rzi.ftz.s32.f32 	%r45, %f9;
	mul.hi.s32 	%r46, %r45, -2113396605;
	add.s32 	%r47, %r46, %r45;
	shr.u32 	%r48, %r47, 31;
	shr.s32 	%r49, %r47, 5;
	add.s32 	%r50, %r49, %r48;
	mul.lo.s32 	%r51, %r50, 63;
	sub.s32 	%r52, %r45, %r51;
	st.global.v2.u32 	[%r59], {%r53, %r52};
	add.s32 	%r59, %r59, 8;
	add.s32 	%r60, %r60, 1;
	setp.lt.s32 	%p2, %r60, %r10;
	@%p2 bra 	BB2_2;

BB2_3:
	ret;
}

.entry gridSpreadCharge(
	.param .u32 .ptr .global .align 16 gridSpreadCharge_param_0,
	.param .u32 .ptr .global .align 8 gridSpreadCharge_param_1,
	.param .u32 .ptr .global .align 4 gridSpreadCharge_param_2,
	.param .u32 .ptr .global .align 8 gridSpreadCharge_param_3,
	.param .u32 .ptr .global .align 16 gridSpreadCharge_param_4,
	.param .align 16 .b8 gridSpreadCharge_param_5[16],
	.param .align 16 .b8 gridSpreadCharge_param_6[16]
)
{
	.local .align 16 .b8 	__local_depot3[80];
	.reg .b32 	%SP;
	.reg .f32 	%f<908>;
	.reg .pred 	%p<20>;
	.reg .s32 	%r<622>;
	.reg .s64 	%rl<251>;


	mov.u32 	%SP, __local_depot3;
	ld.param.v4.f32 	{%f860, %f861, %f862, %f863}, [gridSpreadCharge_param_6];
	ld.param.v4.f32 	{%f864, %f865, %f866, %f867}, [gridSpreadCharge_param_5];
	// inline asm
	mov.u32 	%r25, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r26, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r27, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r28, %tid.x;
	// inline asm
	add.s32 	%r29, %r28, %r25;
	mad.lo.s32 	%r613, %r27, %r26, %r29;
	setp.gt.s32 	%p1, %r613, 23557;
	@%p1 bra 	BB3_7;

	mov.f32 	%f1, 0f3F800000;
	mov.f32 	%f5, 0f40800000;
	mov.f32 	%f9, 0f40000000;
	mov.f32 	%f13, 0f40400000;

BB3_2:
	shl.b32 	%r32, %r613, 3;
	ld.param.u32 	%r611, [gridSpreadCharge_param_1];
	add.s32 	%r33, %r611, %r32;
	ld.global.v2.u32 	{%r608, %r609}, [%r33];
	mov.u32 	%r614, 0;
	shl.b32 	%r35, %r608, 4;
	ld.param.u32 	%r610, [gridSpreadCharge_param_0];
	add.s32 	%r36, %r610, %r35;
	ld.global.v4.f32 	{%f564, %f565, %f566, %f567}, [%r36];
	mul.ftz.f32 	%f18, %f564, %f860;
	// inline asm
	cvt.rmi.f32.f32 	%f17, %f18;
	// inline asm
	neg.f32 	%f26, %f17;
	fma.rn.ftz.f32 	%f27, %f26, %f864, %f564;
	mul.ftz.f32 	%f20, %f565, %f861;
	// inline asm
	cvt.rmi.f32.f32 	%f19, %f20;
	// inline asm
	neg.f32 	%f31, %f19;
	fma.rn.ftz.f32 	%f32, %f31, %f865, %f565;
	mov.u32 	%r620, 2;
	mul.ftz.f32 	%f22, %f566, %f862;
	// inline asm
	cvt.rmi.f32.f32 	%f21, %f22;
	// inline asm
	neg.f32 	%f36, %f21;
	fma.rn.ftz.f32 	%f37, %f36, %f866, %f566;
	mul.ftz.f32 	%f38, %f27, %f860;
	mul.ftz.f32 	%f39, %f38, 0f427C0000;
	mov.f32 	%f40, 0f427C0000;
	mul.ftz.f32 	%f41, %f32, %f861;
	mul.ftz.f32 	%f42, %f41, 0f427C0000;
	mul.ftz.f32 	%f43, %f37, %f862;
	mul.ftz.f32 	%f44, %f43, 0f427C0000;
	cvt.rzi.ftz.s32.f32 	%r37, %f39;
	mul.hi.s32 	%r38, %r37, -2113396605;
	add.s32 	%r39, %r38, %r37;
	shr.u32 	%r40, %r39, 31;
	shr.s32 	%r41, %r39, 5;
	add.s32 	%r42, %r41, %r40;
	mul.lo.s32 	%r43, %r42, 63;
	sub.s32 	%r7, %r37, %r43;
	cvt.rzi.ftz.s32.f32 	%r44, %f42;
	mul.hi.s32 	%r45, %r44, -2113396605;
	add.s32 	%r46, %r45, %r44;
	shr.u32 	%r47, %r46, 31;
	shr.s32 	%r48, %r46, 5;
	add.s32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, 63;
	sub.s32 	%r8, %r44, %r50;
	cvt.rzi.ftz.s32.f32 	%r51, %f44;
	mul.hi.s32 	%r52, %r51, -2113396605;
	add.s32 	%r53, %r52, %r51;
	shr.u32 	%r54, %r53, 31;
	shr.s32 	%r55, %r53, 5;
	add.s32 	%r56, %r55, %r54;
	mul.lo.s32 	%r57, %r56, 63;
	sub.s32 	%r9, %r51, %r57;
	cvt.rn.f32.s32 	%f45, %r37;
	neg.f32 	%f46, %f45;
	fma.rn.ftz.f32 	%f47, %f38, %f40, %f46;
	cvt.rn.f32.s32 	%f48, %r44;
	neg.f32 	%f49, %f48;
	fma.rn.ftz.f32 	%f50, %f41, %f40, %f49;
	cvt.rn.f32.s32 	%f51, %r51;
	neg.f32 	%f52, %f51;
	fma.rn.ftz.f32 	%f53, %f43, %f40, %f52;
	mov.f32 	%f54, 0f00000000;
	add.u32 	%r58, %SP, 0;
	st.local.v4.f32 	[%SP+64], {%f54, %f54, %f54, %f54};
	add.s32 	%r617, %r58, 16;
	st.local.v4.f32 	[%SP+16], {%f47, %f50, %f53, %f54};
	sub.ftz.f32 	%f776, %f1, %f47;
	sub.ftz.f32 	%f777, %f1, %f50;
	sub.ftz.f32 	%f778, %f1, %f53;
	sub.ftz.f32 	%f779, %f1, %f54;
	st.local.v4.f32 	[%SP+0], {%f776, %f777, %f778, %f779};
	neg.ftz.f32 	%f820, %f47;
	neg.ftz.f32 	%f821, %f50;
	neg.ftz.f32 	%f822, %f53;
	neg.ftz.f32 	%f823, %f54;

BB3_3:
	mov.u32 	%r618, %r620;
	mov.u32 	%r11, %r618;
	mov.u32 	%r615, %r617;
	mov.u32 	%r10, %r615;
	mov.u32 	%r12, %r614;
	add.s32 	%r13, %r12, 2;
	add.s32 	%r14, %r12, 1;
	mov.u32 	%r621, 1;
	shl.b32 	%r60, %r14, 4;
	add.s32 	%r62, %r12, 3;
	cvt.rn.f32.s32 	%f58, %r62;
	add.ftz.f32 	%f57, %f58, 0fBF800000;
	// inline asm
	div.approx.f32 	%f56, 1.0, %f57;
	// inline asm
	mul.ftz.f32 	%f848, %f56, %f47;
	mul.ftz.f32 	%f849, %f56, %f50;
	mul.ftz.f32 	%f850, %f56, %f53;
	mul.ftz.f32 	%f851, %f56, %f54;
	add.s32 	%r63, %r58, %r60;
	ld.local.v4.f32 	{%f852, %f853, %f854, %f855}, [%r63];
	mul.ftz.f32 	%f856, %f848, %f852;
	mul.ftz.f32 	%f857, %f849, %f853;
	mul.ftz.f32 	%f858, %f850, %f854;
	mul.ftz.f32 	%f859, %f851, %f855;
	st.local.v4.f32 	[%r63+16], {%f856, %f857, %f858, %f859};
	mov.u32 	%r616, %r10;
	mov.u32 	%r619, %r11;

BB3_4:
	mov.u32 	%r16, %r619;
	mov.u32 	%r15, %r616;
	cvt.rn.f32.s32 	%f62, %r621;
	add.ftz.f32 	%f796, %f47, %f62;
	add.ftz.f32 	%f797, %f50, %f62;
	add.ftz.f32 	%f798, %f53, %f62;
	add.ftz.f32 	%f799, %f54, %f62;
	add.s32 	%r19, %r15, -16;
	ld.local.v4.f32 	{%f800, %f801, %f802, %f803}, [%r15+-16];
	cvt.rn.f32.s32 	%f66, %r16;
	add.ftz.f32 	%f816, %f820, %f66;
	add.ftz.f32 	%f817, %f821, %f66;
	add.ftz.f32 	%f818, %f822, %f66;
	add.ftz.f32 	%f819, %f823, %f66;
	ld.local.v4.f32 	{%f824, %f825, %f826, %f827}, [%r15];
	mul.ftz.f32 	%f828, %f816, %f824;
	mul.ftz.f32 	%f829, %f817, %f825;
	mul.ftz.f32 	%f830, %f818, %f826;
	mul.ftz.f32 	%f831, %f819, %f827;
	fma.rn.ftz.f32 	%f832, %f796, %f800, %f828;
	fma.rn.ftz.f32 	%f833, %f797, %f801, %f829;
	fma.rn.ftz.f32 	%f834, %f798, %f802, %f830;
	fma.rn.ftz.f32 	%f835, %f799, %f803, %f831;
	mul.ftz.f32 	%f836, %f56, %f832;
	mul.ftz.f32 	%f837, %f56, %f833;
	mul.ftz.f32 	%f838, %f56, %f834;
	mul.ftz.f32 	%f839, %f56, %f835;
	st.local.v4.f32 	[%r15], {%f836, %f837, %f838, %f839};
	add.s32 	%r18, %r16, -1;
	add.s32 	%r621, %r621, 1;
	setp.lt.s32 	%p2, %r621, %r13;
	mov.u32 	%r616, %r19;
	mov.u32 	%r619, %r18;
	@%p2 bra 	BB3_4;

	mul.ftz.f32 	%f768, %f56, %f776;
	mul.ftz.f32 	%f769, %f56, %f777;
	mul.ftz.f32 	%f770, %f56, %f778;
	mul.ftz.f32 	%f771, %f56, %f779;
	ld.local.v4.f32 	{%f780, %f781, %f782, %f783}, [%r58];
	mul.ftz.f32 	%f540, %f768, %f780;
	mul.ftz.f32 	%f541, %f769, %f781;
	mul.ftz.f32 	%f542, %f770, %f782;
	mul.ftz.f32 	%f543, %f771, %f783;
	st.local.v4.f32 	[%r58], {%f540, %f541, %f542, %f543};
	add.s32 	%r22, %r11, 1;
	add.s32 	%r23, %r10, 16;
	setp.ne.s32 	%p3, %r14, 2;
	mov.u32 	%r614, %r14;
	mov.u32 	%r617, %r23;
	mov.u32 	%r620, %r22;
	@%p3 bra 	BB3_3;

	mov.f32 	%f70, 0f3E800000;
	mul.ftz.f32 	%f444, %f47, %f70;
	mul.ftz.f32 	%f445, %f50, %f70;
	mul.ftz.f32 	%f446, %f53, %f70;
	mul.ftz.f32 	%f447, %f54, %f70;
	ld.local.v4.f32 	{%f452, %f453, %f454, %f455}, [%r58+48];
	mul.ftz.f32 	%f456, %f444, %f452;
	mul.ftz.f32 	%f457, %f445, %f453;
	mul.ftz.f32 	%f458, %f446, %f454;
	mul.ftz.f32 	%f459, %f447, %f455;
	st.local.v4.f32 	[%r58+64], {%f456, %f457, %f458, %f459};
	ld.local.v4.f32 	{%f460, %f461, %f462, %f463}, [%r58+32];
	add.ftz.f32 	%f464, %f47, %f1;
	add.ftz.f32 	%f465, %f50, %f1;
	add.ftz.f32 	%f466, %f53, %f1;
	add.ftz.f32 	%f467, %f54, %f1;
	sub.ftz.f32 	%f472, %f5, %f47;
	sub.ftz.f32 	%f473, %f5, %f50;
	sub.ftz.f32 	%f474, %f5, %f53;
	sub.ftz.f32 	%f475, %f5, %f54;
	mul.ftz.f32 	%f480, %f472, %f452;
	mul.ftz.f32 	%f481, %f473, %f453;
	mul.ftz.f32 	%f482, %f474, %f454;
	mul.ftz.f32 	%f483, %f475, %f455;
	fma.rn.ftz.f32 	%f484, %f464, %f460, %f480;
	fma.rn.ftz.f32 	%f485, %f465, %f461, %f481;
	fma.rn.ftz.f32 	%f486, %f466, %f462, %f482;
	fma.rn.ftz.f32 	%f487, %f467, %f463, %f483;
	mul.ftz.f32 	%f488, %f484, %f70;
	mul.ftz.f32 	%f489, %f485, %f70;
	mul.ftz.f32 	%f490, %f486, %f70;
	mul.ftz.f32 	%f491, %f487, %f70;
	st.local.v4.f32 	[%r58+48], {%f488, %f489, %f490, %f491};
	ld.local.v4.f32 	{%f492, %f493, %f494, %f495}, [%r58+16];
	add.ftz.f32 	%f496, %f47, %f9;
	add.ftz.f32 	%f497, %f50, %f9;
	add.ftz.f32 	%f498, %f53, %f9;
	add.ftz.f32 	%f499, %f54, %f9;
	sub.ftz.f32 	%f504, %f13, %f47;
	sub.ftz.f32 	%f505, %f13, %f50;
	sub.ftz.f32 	%f506, %f13, %f53;
	sub.ftz.f32 	%f507, %f13, %f54;
	mul.ftz.f32 	%f512, %f504, %f460;
	mul.ftz.f32 	%f513, %f505, %f461;
	mul.ftz.f32 	%f514, %f506, %f462;
	mul.ftz.f32 	%f515, %f507, %f463;
	fma.rn.ftz.f32 	%f516, %f496, %f492, %f512;
	fma.rn.ftz.f32 	%f517, %f497, %f493, %f513;
	fma.rn.ftz.f32 	%f518, %f498, %f494, %f514;
	fma.rn.ftz.f32 	%f519, %f499, %f495, %f515;
	mul.ftz.f32 	%f520, %f516, %f70;
	mul.ftz.f32 	%f521, %f517, %f70;
	mul.ftz.f32 	%f522, %f518, %f70;
	mul.ftz.f32 	%f523, %f519, %f70;
	st.local.v4.f32 	[%r58+32], {%f520, %f521, %f522, %f523};
	add.ftz.f32 	%f524, %f47, %f13;
	add.ftz.f32 	%f525, %f50, %f13;
	add.ftz.f32 	%f526, %f53, %f13;
	add.ftz.f32 	%f527, %f54, %f13;
	sub.ftz.f32 	%f528, %f9, %f47;
	sub.ftz.f32 	%f529, %f9, %f50;
	sub.ftz.f32 	%f530, %f9, %f53;
	sub.ftz.f32 	%f531, %f9, %f54;
	mul.ftz.f32 	%f532, %f528, %f492;
	mul.ftz.f32 	%f533, %f529, %f493;
	mul.ftz.f32 	%f534, %f530, %f494;
	mul.ftz.f32 	%f535, %f531, %f495;
	fma.rn.ftz.f32 	%f536, %f524, %f540, %f532;
	fma.rn.ftz.f32 	%f537, %f525, %f541, %f533;
	fma.rn.ftz.f32 	%f538, %f526, %f542, %f534;
	fma.rn.ftz.f32 	%f539, %f527, %f543, %f535;
	mul.ftz.f32 	%f544, %f536, %f70;
	mul.ftz.f32 	%f545, %f537, %f70;
	mul.ftz.f32 	%f546, %f538, %f70;
	mul.ftz.f32 	%f547, %f539, %f70;
	st.local.v4.f32 	[%r58+16], {%f544, %f545, %f546, %f547};
	mul.ftz.f32 	%f556, %f776, %f70;
	mul.ftz.f32 	%f557, %f777, %f70;
	mul.ftz.f32 	%f558, %f778, %f70;
	mul.ftz.f32 	%f559, %f779, %f70;
	mul.ftz.f32 	%f560, %f556, %f540;
	mul.ftz.f32 	%f561, %f557, %f541;
	mul.ftz.f32 	%f562, %f558, %f542;
	mul.ftz.f32 	%f563, %f559, %f543;
	st.local.v4.f32 	[%r58], {%f560, %f561, %f562, %f563};
	setp.gt.s32 	%p4, %r7, 62;
	selp.b32 	%r66, 63, 0, %p4;
	sub.s32 	%r67, %r7, %r66;
	mad.lo.s32 	%r68, %r67, 3969, %r9;
	setp.gt.s32 	%p5, %r8, 62;
	selp.b32 	%r69, 63, 0, %p5;
	mul.ftz.f32 	%f74, %f567, %f560;
	mul.ftz.f32 	%f76, %f74, %f561;
	sub.s32 	%r70, %r8, %r69;
	mad.lo.s32 	%r71, %r70, 63, %r68;
	setp.gt.s32 	%p6, %r9, 62;
	selp.b32 	%r72, -63, 0, %p6;
	mul.ftz.f32 	%f78, %f76, %f562;
	add.s32 	%r73, %r72, %r71;
	shl.b32 	%r74, %r73, 3;
	ld.param.u32 	%r612, [gridSpreadCharge_param_3];
	add.s32 	%r75, %r612, %r74;
	mul.ftz.f32 	%f79, %f78, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl1, %f79;
	atom.global.add.u64 	%rl2, [%r75], %rl1;
	add.s32 	%r76, %r9, 1;
	setp.gt.s32 	%p7, %r76, 62;
	selp.b32 	%r77, -63, 0, %p7;
	ld.local.v4.f32 	{%f568, %f569, %f570, %f571}, [%r58+16];
	mul.ftz.f32 	%f81, %f76, %f570;
	add.s32 	%r78, %r71, %r77;
	shl.b32 	%r79, %r78, 3;
	add.s32 	%r80, %r79, %r612;
	add.s32 	%r81, %r80, 8;
	mul.ftz.f32 	%f82, %f81, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl3, %f82;
	atom.global.add.u64 	%rl4, [%r81], %rl3;
	add.s32 	%r82, %r9, 2;
	setp.gt.s32 	%p8, %r82, 62;
	selp.b32 	%r83, -63, 0, %p8;
	ld.local.v4.f32 	{%f572, %f573, %f574, %f575}, [%r58+32];
	mul.ftz.f32 	%f84, %f76, %f574;
	add.s32 	%r84, %r71, %r83;
	shl.b32 	%r85, %r84, 3;
	add.s32 	%r86, %r85, %r612;
	add.s32 	%r87, %r86, 16;
	mul.ftz.f32 	%f85, %f84, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl5, %f85;
	atom.global.add.u64 	%rl6, [%r87], %rl5;
	add.s32 	%r88, %r9, 3;
	setp.gt.s32 	%p9, %r88, 62;
	selp.b32 	%r89, -63, 0, %p9;
	mul.ftz.f32 	%f87, %f76, %f490;
	add.s32 	%r90, %r71, %r89;
	shl.b32 	%r91, %r90, 3;
	add.s32 	%r92, %r91, %r612;
	add.s32 	%r93, %r92, 24;
	mul.ftz.f32 	%f88, %f87, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl7, %f88;
	atom.global.add.u64 	%rl8, [%r93], %rl7;
	add.s32 	%r94, %r9, 4;
	setp.gt.s32 	%p10, %r94, 62;
	selp.b32 	%r95, -63, 0, %p10;
	mul.ftz.f32 	%f90, %f76, %f458;
	add.s32 	%r96, %r71, %r95;
	shl.b32 	%r97, %r96, 3;
	add.s32 	%r98, %r97, %r612;
	add.s32 	%r99, %r98, 32;
	mul.ftz.f32 	%f91, %f90, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl9, %f91;
	atom.global.add.u64 	%rl10, [%r99], %rl9;
	add.s32 	%r100, %r8, 1;
	setp.gt.s32 	%p11, %r100, 62;
	selp.b32 	%r101, 63, 0, %p11;
	ld.local.v4.f32 	{%f576, %f577, %f578, %f579}, [%r58+16];
	mul.ftz.f32 	%f93, %f74, %f577;
	sub.s32 	%r102, %r100, %r101;
	mad.lo.s32 	%r103, %r102, 63, %r68;
	mul.ftz.f32 	%f94, %f93, %f562;
	add.s32 	%r104, %r72, %r103;
	shl.b32 	%r105, %r104, 3;
	add.s32 	%r106, %r612, %r105;
	mul.ftz.f32 	%f95, %f94, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl11, %f95;
	atom.global.add.u64 	%rl12, [%r106], %rl11;
	mul.ftz.f32 	%f97, %f93, %f578;
	add.s32 	%r107, %r103, %r77;
	shl.b32 	%r108, %r107, 3;
	add.s32 	%r109, %r108, %r612;
	add.s32 	%r110, %r109, 8;
	mul.ftz.f32 	%f98, %f97, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl13, %f98;
	atom.global.add.u64 	%rl14, [%r110], %rl13;
	ld.local.v4.f32 	{%f580, %f581, %f582, %f583}, [%r58+32];
	mul.ftz.f32 	%f100, %f93, %f582;
	add.s32 	%r111, %r103, %r83;
	shl.b32 	%r112, %r111, 3;
	add.s32 	%r113, %r112, %r612;
	add.s32 	%r114, %r113, 16;
	mul.ftz.f32 	%f101, %f100, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl15, %f101;
	atom.global.add.u64 	%rl16, [%r114], %rl15;
	mul.ftz.f32 	%f102, %f93, %f490;
	add.s32 	%r115, %r103, %r89;
	shl.b32 	%r116, %r115, 3;
	add.s32 	%r117, %r116, %r612;
	add.s32 	%r118, %r117, 24;
	mul.ftz.f32 	%f103, %f102, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl17, %f103;
	atom.global.add.u64 	%rl18, [%r118], %rl17;
	mul.ftz.f32 	%f104, %f93, %f458;
	add.s32 	%r119, %r103, %r95;
	shl.b32 	%r120, %r119, 3;
	add.s32 	%r121, %r120, %r612;
	add.s32 	%r122, %r121, 32;
	mul.ftz.f32 	%f105, %f104, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl19, %f105;
	atom.global.add.u64 	%rl20, [%r122], %rl19;
	add.s32 	%r123, %r8, 2;
	setp.gt.s32 	%p12, %r123, 62;
	selp.b32 	%r124, 63, 0, %p12;
	ld.local.v4.f32 	{%f584, %f585, %f586, %f587}, [%r58+32];
	mul.ftz.f32 	%f107, %f74, %f585;
	sub.s32 	%r125, %r123, %r124;
	mad.lo.s32 	%r126, %r125, 63, %r68;
	mul.ftz.f32 	%f108, %f107, %f562;
	add.s32 	%r127, %r72, %r126;
	shl.b32 	%r128, %r127, 3;
	add.s32 	%r129, %r612, %r128;
	mul.ftz.f32 	%f109, %f108, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl21, %f109;
	atom.global.add.u64 	%rl22, [%r129], %rl21;
	ld.local.v4.f32 	{%f588, %f589, %f590, %f591}, [%r58+16];
	mul.ftz.f32 	%f111, %f107, %f590;
	add.s32 	%r130, %r126, %r77;
	shl.b32 	%r131, %r130, 3;
	add.s32 	%r132, %r131, %r612;
	add.s32 	%r133, %r132, 8;
	mul.ftz.f32 	%f112, %f111, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl23, %f112;
	atom.global.add.u64 	%rl24, [%r133], %rl23;
	mul.ftz.f32 	%f114, %f107, %f586;
	add.s32 	%r134, %r126, %r83;
	shl.b32 	%r135, %r134, 3;
	add.s32 	%r136, %r135, %r612;
	add.s32 	%r137, %r136, 16;
	mul.ftz.f32 	%f115, %f114, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl25, %f115;
	atom.global.add.u64 	%rl26, [%r137], %rl25;
	mul.ftz.f32 	%f116, %f107, %f490;
	add.s32 	%r138, %r126, %r89;
	shl.b32 	%r139, %r138, 3;
	add.s32 	%r140, %r139, %r612;
	add.s32 	%r141, %r140, 24;
	mul.ftz.f32 	%f117, %f116, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl27, %f117;
	atom.global.add.u64 	%rl28, [%r141], %rl27;
	mul.ftz.f32 	%f118, %f107, %f458;
	add.s32 	%r142, %r126, %r95;
	shl.b32 	%r143, %r142, 3;
	add.s32 	%r144, %r143, %r612;
	add.s32 	%r145, %r144, 32;
	mul.ftz.f32 	%f119, %f118, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl29, %f119;
	atom.global.add.u64 	%rl30, [%r145], %rl29;
	add.s32 	%r146, %r8, 3;
	setp.gt.s32 	%p13, %r146, 62;
	selp.b32 	%r147, 63, 0, %p13;
	mul.ftz.f32 	%f121, %f74, %f489;
	sub.s32 	%r148, %r146, %r147;
	mad.lo.s32 	%r149, %r148, 63, %r68;
	mul.ftz.f32 	%f122, %f121, %f562;
	add.s32 	%r150, %r72, %r149;
	shl.b32 	%r151, %r150, 3;
	add.s32 	%r152, %r612, %r151;
	mul.ftz.f32 	%f123, %f122, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl31, %f123;
	atom.global.add.u64 	%rl32, [%r152], %rl31;
	ld.local.v4.f32 	{%f592, %f593, %f594, %f595}, [%r58+16];
	mul.ftz.f32 	%f125, %f121, %f594;
	add.s32 	%r153, %r149, %r77;
	shl.b32 	%r154, %r153, 3;
	add.s32 	%r155, %r154, %r612;
	add.s32 	%r156, %r155, 8;
	mul.ftz.f32 	%f126, %f125, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl33, %f126;
	atom.global.add.u64 	%rl34, [%r156], %rl33;
	ld.local.v4.f32 	{%f596, %f597, %f598, %f599}, [%r58+32];
	mul.ftz.f32 	%f128, %f121, %f598;
	add.s32 	%r157, %r149, %r83;
	shl.b32 	%r158, %r157, 3;
	add.s32 	%r159, %r158, %r612;
	add.s32 	%r160, %r159, 16;
	mul.ftz.f32 	%f129, %f128, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl35, %f129;
	atom.global.add.u64 	%rl36, [%r160], %rl35;
	mul.ftz.f32 	%f130, %f121, %f490;
	add.s32 	%r161, %r149, %r89;
	shl.b32 	%r162, %r161, 3;
	add.s32 	%r163, %r162, %r612;
	add.s32 	%r164, %r163, 24;
	mul.ftz.f32 	%f131, %f130, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl37, %f131;
	atom.global.add.u64 	%rl38, [%r164], %rl37;
	mul.ftz.f32 	%f132, %f121, %f458;
	add.s32 	%r165, %r149, %r95;
	shl.b32 	%r166, %r165, 3;
	add.s32 	%r167, %r166, %r612;
	add.s32 	%r168, %r167, 32;
	mul.ftz.f32 	%f133, %f132, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl39, %f133;
	atom.global.add.u64 	%rl40, [%r168], %rl39;
	add.s32 	%r169, %r8, 4;
	setp.gt.s32 	%p14, %r169, 62;
	selp.b32 	%r170, 63, 0, %p14;
	mul.ftz.f32 	%f135, %f74, %f457;
	sub.s32 	%r171, %r169, %r170;
	mad.lo.s32 	%r172, %r171, 63, %r68;
	mul.ftz.f32 	%f136, %f135, %f562;
	add.s32 	%r173, %r72, %r172;
	shl.b32 	%r174, %r173, 3;
	add.s32 	%r175, %r612, %r174;
	mul.ftz.f32 	%f137, %f136, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl41, %f137;
	atom.global.add.u64 	%rl42, [%r175], %rl41;
	ld.local.v4.f32 	{%f600, %f601, %f602, %f603}, [%r58+16];
	mul.ftz.f32 	%f139, %f135, %f602;
	add.s32 	%r176, %r172, %r77;
	shl.b32 	%r177, %r176, 3;
	add.s32 	%r178, %r177, %r612;
	add.s32 	%r179, %r178, 8;
	mul.ftz.f32 	%f140, %f139, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl43, %f140;
	atom.global.add.u64 	%rl44, [%r179], %rl43;
	ld.local.v4.f32 	{%f604, %f605, %f606, %f607}, [%r58+32];
	mul.ftz.f32 	%f142, %f135, %f606;
	add.s32 	%r180, %r172, %r83;
	shl.b32 	%r181, %r180, 3;
	add.s32 	%r182, %r181, %r612;
	add.s32 	%r183, %r182, 16;
	mul.ftz.f32 	%f143, %f142, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl45, %f143;
	atom.global.add.u64 	%rl46, [%r183], %rl45;
	mul.ftz.f32 	%f144, %f135, %f490;
	add.s32 	%r184, %r172, %r89;
	shl.b32 	%r185, %r184, 3;
	add.s32 	%r186, %r185, %r612;
	add.s32 	%r187, %r186, 24;
	mul.ftz.f32 	%f145, %f144, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl47, %f145;
	atom.global.add.u64 	%rl48, [%r187], %rl47;
	mul.ftz.f32 	%f146, %f135, %f458;
	add.s32 	%r188, %r172, %r95;
	shl.b32 	%r189, %r188, 3;
	add.s32 	%r190, %r189, %r612;
	add.s32 	%r191, %r190, 32;
	mul.ftz.f32 	%f147, %f146, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl49, %f147;
	atom.global.add.u64 	%rl50, [%r191], %rl49;
	add.s32 	%r192, %r7, 1;
	setp.gt.s32 	%p15, %r192, 62;
	selp.b32 	%r193, 63, 0, %p15;
	sub.s32 	%r194, %r192, %r193;
	mad.lo.s32 	%r195, %r194, 3969, %r9;
	ld.local.v4.f32 	{%f608, %f609, %f610, %f611}, [%r58+16];
	mul.ftz.f32 	%f149, %f567, %f608;
	mul.ftz.f32 	%f150, %f149, %f561;
	mad.lo.s32 	%r196, %r70, 63, %r195;
	mul.ftz.f32 	%f151, %f150, %f562;
	add.s32 	%r197, %r72, %r196;
	shl.b32 	%r198, %r197, 3;
	add.s32 	%r199, %r612, %r198;
	mul.ftz.f32 	%f152, %f151, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl51, %f152;
	atom.global.add.u64 	%rl52, [%r199], %rl51;
	mul.ftz.f32 	%f154, %f150, %f610;
	add.s32 	%r200, %r196, %r77;
	shl.b32 	%r201, %r200, 3;
	add.s32 	%r202, %r201, %r612;
	add.s32 	%r203, %r202, 8;
	mul.ftz.f32 	%f155, %f154, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl53, %f155;
	atom.global.add.u64 	%rl54, [%r203], %rl53;
	ld.local.v4.f32 	{%f612, %f613, %f614, %f615}, [%r58+32];
	mul.ftz.f32 	%f157, %f150, %f614;
	add.s32 	%r204, %r196, %r83;
	shl.b32 	%r205, %r204, 3;
	add.s32 	%r206, %r205, %r612;
	add.s32 	%r207, %r206, 16;
	mul.ftz.f32 	%f158, %f157, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl55, %f158;
	atom.global.add.u64 	%rl56, [%r207], %rl55;
	mul.ftz.f32 	%f159, %f150, %f490;
	add.s32 	%r208, %r196, %r89;
	shl.b32 	%r209, %r208, 3;
	add.s32 	%r210, %r209, %r612;
	add.s32 	%r211, %r210, 24;
	mul.ftz.f32 	%f160, %f159, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl57, %f160;
	atom.global.add.u64 	%rl58, [%r211], %rl57;
	mul.ftz.f32 	%f161, %f150, %f458;
	add.s32 	%r212, %r196, %r95;
	shl.b32 	%r213, %r212, 3;
	add.s32 	%r214, %r213, %r612;
	add.s32 	%r215, %r214, 32;
	mul.ftz.f32 	%f162, %f161, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl59, %f162;
	atom.global.add.u64 	%rl60, [%r215], %rl59;
	ld.local.v4.f32 	{%f616, %f617, %f618, %f619}, [%r58+16];
	mul.ftz.f32 	%f164, %f567, %f616;
	mul.ftz.f32 	%f166, %f164, %f617;
	mad.lo.s32 	%r216, %r102, 63, %r195;
	mul.ftz.f32 	%f167, %f166, %f562;
	add.s32 	%r217, %r72, %r216;
	shl.b32 	%r218, %r217, 3;
	add.s32 	%r219, %r612, %r218;
	mul.ftz.f32 	%f168, %f167, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl61, %f168;
	atom.global.add.u64 	%rl62, [%r219], %rl61;
	mul.ftz.f32 	%f170, %f166, %f618;
	add.s32 	%r220, %r216, %r77;
	shl.b32 	%r221, %r220, 3;
	add.s32 	%r222, %r221, %r612;
	add.s32 	%r223, %r222, 8;
	mul.ftz.f32 	%f171, %f170, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl63, %f171;
	atom.global.add.u64 	%rl64, [%r223], %rl63;
	ld.local.v4.f32 	{%f620, %f621, %f622, %f623}, [%r58+32];
	mul.ftz.f32 	%f173, %f166, %f622;
	add.s32 	%r224, %r216, %r83;
	shl.b32 	%r225, %r224, 3;
	add.s32 	%r226, %r225, %r612;
	add.s32 	%r227, %r226, 16;
	mul.ftz.f32 	%f174, %f173, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl65, %f174;
	atom.global.add.u64 	%rl66, [%r227], %rl65;
	mul.ftz.f32 	%f175, %f166, %f490;
	add.s32 	%r228, %r216, %r89;
	shl.b32 	%r229, %r228, 3;
	add.s32 	%r230, %r229, %r612;
	add.s32 	%r231, %r230, 24;
	mul.ftz.f32 	%f176, %f175, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl67, %f176;
	atom.global.add.u64 	%rl68, [%r231], %rl67;
	mul.ftz.f32 	%f177, %f166, %f458;
	add.s32 	%r232, %r216, %r95;
	shl.b32 	%r233, %r232, 3;
	add.s32 	%r234, %r233, %r612;
	add.s32 	%r235, %r234, 32;
	mul.ftz.f32 	%f178, %f177, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl69, %f178;
	atom.global.add.u64 	%rl70, [%r235], %rl69;
	ld.local.v4.f32 	{%f624, %f625, %f626, %f627}, [%r58+16];
	mul.ftz.f32 	%f180, %f567, %f624;
	ld.local.v4.f32 	{%f628, %f629, %f630, %f631}, [%r58+32];
	mul.ftz.f32 	%f182, %f180, %f629;
	mad.lo.s32 	%r236, %r125, 63, %r195;
	mul.ftz.f32 	%f183, %f182, %f562;
	add.s32 	%r237, %r72, %r236;
	shl.b32 	%r238, %r237, 3;
	add.s32 	%r239, %r612, %r238;
	mul.ftz.f32 	%f184, %f183, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl71, %f184;
	atom.global.add.u64 	%rl72, [%r239], %rl71;
	mul.ftz.f32 	%f186, %f182, %f626;
	add.s32 	%r240, %r236, %r77;
	shl.b32 	%r241, %r240, 3;
	add.s32 	%r242, %r241, %r612;
	add.s32 	%r243, %r242, 8;
	mul.ftz.f32 	%f187, %f186, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl73, %f187;
	atom.global.add.u64 	%rl74, [%r243], %rl73;
	mul.ftz.f32 	%f189, %f182, %f630;
	add.s32 	%r244, %r236, %r83;
	shl.b32 	%r245, %r244, 3;
	add.s32 	%r246, %r245, %r612;
	add.s32 	%r247, %r246, 16;
	mul.ftz.f32 	%f190, %f189, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl75, %f190;
	atom.global.add.u64 	%rl76, [%r247], %rl75;
	mul.ftz.f32 	%f191, %f182, %f490;
	add.s32 	%r248, %r236, %r89;
	shl.b32 	%r249, %r248, 3;
	add.s32 	%r250, %r249, %r612;
	add.s32 	%r251, %r250, 24;
	mul.ftz.f32 	%f192, %f191, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl77, %f192;
	atom.global.add.u64 	%rl78, [%r251], %rl77;
	mul.ftz.f32 	%f193, %f182, %f458;
	add.s32 	%r252, %r236, %r95;
	shl.b32 	%r253, %r252, 3;
	add.s32 	%r254, %r253, %r612;
	add.s32 	%r255, %r254, 32;
	mul.ftz.f32 	%f194, %f193, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl79, %f194;
	atom.global.add.u64 	%rl80, [%r255], %rl79;
	ld.local.v4.f32 	{%f632, %f633, %f634, %f635}, [%r58+16];
	mul.ftz.f32 	%f196, %f567, %f632;
	mul.ftz.f32 	%f197, %f196, %f489;
	mad.lo.s32 	%r256, %r148, 63, %r195;
	mul.ftz.f32 	%f198, %f197, %f562;
	add.s32 	%r257, %r72, %r256;
	shl.b32 	%r258, %r257, 3;
	add.s32 	%r259, %r612, %r258;
	mul.ftz.f32 	%f199, %f198, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl81, %f199;
	atom.global.add.u64 	%rl82, [%r259], %rl81;
	mul.ftz.f32 	%f201, %f197, %f634;
	add.s32 	%r260, %r256, %r77;
	shl.b32 	%r261, %r260, 3;
	add.s32 	%r262, %r261, %r612;
	add.s32 	%r263, %r262, 8;
	mul.ftz.f32 	%f202, %f201, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl83, %f202;
	atom.global.add.u64 	%rl84, [%r263], %rl83;
	ld.local.v4.f32 	{%f636, %f637, %f638, %f639}, [%r58+32];
	mul.ftz.f32 	%f204, %f197, %f638;
	add.s32 	%r264, %r256, %r83;
	shl.b32 	%r265, %r264, 3;
	add.s32 	%r266, %r265, %r612;
	add.s32 	%r267, %r266, 16;
	mul.ftz.f32 	%f205, %f204, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl85, %f205;
	atom.global.add.u64 	%rl86, [%r267], %rl85;
	mul.ftz.f32 	%f206, %f197, %f490;
	add.s32 	%r268, %r256, %r89;
	shl.b32 	%r269, %r268, 3;
	add.s32 	%r270, %r269, %r612;
	add.s32 	%r271, %r270, 24;
	mul.ftz.f32 	%f207, %f206, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl87, %f207;
	atom.global.add.u64 	%rl88, [%r271], %rl87;
	mul.ftz.f32 	%f208, %f197, %f458;
	add.s32 	%r272, %r256, %r95;
	shl.b32 	%r273, %r272, 3;
	add.s32 	%r274, %r273, %r612;
	add.s32 	%r275, %r274, 32;
	mul.ftz.f32 	%f209, %f208, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl89, %f209;
	atom.global.add.u64 	%rl90, [%r275], %rl89;
	ld.local.v4.f32 	{%f640, %f641, %f642, %f643}, [%r58+16];
	mul.ftz.f32 	%f211, %f567, %f640;
	mul.ftz.f32 	%f212, %f211, %f457;
	mad.lo.s32 	%r276, %r171, 63, %r195;
	mul.ftz.f32 	%f213, %f212, %f562;
	add.s32 	%r277, %r72, %r276;
	shl.b32 	%r278, %r277, 3;
	add.s32 	%r279, %r612, %r278;
	mul.ftz.f32 	%f214, %f213, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl91, %f214;
	atom.global.add.u64 	%rl92, [%r279], %rl91;
	mul.ftz.f32 	%f216, %f212, %f642;
	add.s32 	%r280, %r276, %r77;
	shl.b32 	%r281, %r280, 3;
	add.s32 	%r282, %r281, %r612;
	add.s32 	%r283, %r282, 8;
	mul.ftz.f32 	%f217, %f216, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl93, %f217;
	atom.global.add.u64 	%rl94, [%r283], %rl93;
	ld.local.v4.f32 	{%f644, %f645, %f646, %f647}, [%r58+32];
	mul.ftz.f32 	%f219, %f212, %f646;
	add.s32 	%r284, %r276, %r83;
	shl.b32 	%r285, %r284, 3;
	add.s32 	%r286, %r285, %r612;
	add.s32 	%r287, %r286, 16;
	mul.ftz.f32 	%f220, %f219, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl95, %f220;
	atom.global.add.u64 	%rl96, [%r287], %rl95;
	mul.ftz.f32 	%f221, %f212, %f490;
	add.s32 	%r288, %r276, %r89;
	shl.b32 	%r289, %r288, 3;
	add.s32 	%r290, %r289, %r612;
	add.s32 	%r291, %r290, 24;
	mul.ftz.f32 	%f222, %f221, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl97, %f222;
	atom.global.add.u64 	%rl98, [%r291], %rl97;
	mul.ftz.f32 	%f223, %f212, %f458;
	add.s32 	%r292, %r276, %r95;
	shl.b32 	%r293, %r292, 3;
	add.s32 	%r294, %r293, %r612;
	add.s32 	%r295, %r294, 32;
	mul.ftz.f32 	%f224, %f223, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl99, %f224;
	atom.global.add.u64 	%rl100, [%r295], %rl99;
	add.s32 	%r296, %r7, 2;
	setp.gt.s32 	%p16, %r296, 62;
	selp.b32 	%r297, 63, 0, %p16;
	sub.s32 	%r298, %r296, %r297;
	mad.lo.s32 	%r299, %r298, 3969, %r9;
	ld.local.v4.f32 	{%f648, %f649, %f650, %f651}, [%r58+32];
	mul.ftz.f32 	%f226, %f567, %f648;
	mul.ftz.f32 	%f227, %f226, %f561;
	mad.lo.s32 	%r300, %r70, 63, %r299;
	mul.ftz.f32 	%f228, %f227, %f562;
	add.s32 	%r301, %r72, %r300;
	shl.b32 	%r302, %r301, 3;
	add.s32 	%r303, %r612, %r302;
	mul.ftz.f32 	%f229, %f228, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl101, %f229;
	atom.global.add.u64 	%rl102, [%r303], %rl101;
	ld.local.v4.f32 	{%f652, %f653, %f654, %f655}, [%r58+16];
	mul.ftz.f32 	%f231, %f227, %f654;
	add.s32 	%r304, %r300, %r77;
	shl.b32 	%r305, %r304, 3;
	add.s32 	%r306, %r305, %r612;
	add.s32 	%r307, %r306, 8;
	mul.ftz.f32 	%f232, %f231, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl103, %f232;
	atom.global.add.u64 	%rl104, [%r307], %rl103;
	mul.ftz.f32 	%f234, %f227, %f650;
	add.s32 	%r308, %r300, %r83;
	shl.b32 	%r309, %r308, 3;
	add.s32 	%r310, %r309, %r612;
	add.s32 	%r311, %r310, 16;
	mul.ftz.f32 	%f235, %f234, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl105, %f235;
	atom.global.add.u64 	%rl106, [%r311], %rl105;
	mul.ftz.f32 	%f236, %f227, %f490;
	add.s32 	%r312, %r300, %r89;
	shl.b32 	%r313, %r312, 3;
	add.s32 	%r314, %r313, %r612;
	add.s32 	%r315, %r314, 24;
	mul.ftz.f32 	%f237, %f236, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl107, %f237;
	atom.global.add.u64 	%rl108, [%r315], %rl107;
	mul.ftz.f32 	%f238, %f227, %f458;
	add.s32 	%r316, %r300, %r95;
	shl.b32 	%r317, %r316, 3;
	add.s32 	%r318, %r317, %r612;
	add.s32 	%r319, %r318, 32;
	mul.ftz.f32 	%f239, %f238, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl109, %f239;
	atom.global.add.u64 	%rl110, [%r319], %rl109;
	ld.local.v4.f32 	{%f656, %f657, %f658, %f659}, [%r58+32];
	mul.ftz.f32 	%f241, %f567, %f656;
	ld.local.v4.f32 	{%f660, %f661, %f662, %f663}, [%r58+16];
	mul.ftz.f32 	%f243, %f241, %f661;
	mad.lo.s32 	%r320, %r102, 63, %r299;
	mul.ftz.f32 	%f244, %f243, %f562;
	add.s32 	%r321, %r72, %r320;
	shl.b32 	%r322, %r321, 3;
	add.s32 	%r323, %r612, %r322;
	mul.ftz.f32 	%f245, %f244, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl111, %f245;
	atom.global.add.u64 	%rl112, [%r323], %rl111;
	mul.ftz.f32 	%f247, %f243, %f662;
	add.s32 	%r324, %r320, %r77;
	shl.b32 	%r325, %r324, 3;
	add.s32 	%r326, %r325, %r612;
	add.s32 	%r327, %r326, 8;
	mul.ftz.f32 	%f248, %f247, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl113, %f248;
	atom.global.add.u64 	%rl114, [%r327], %rl113;
	mul.ftz.f32 	%f250, %f243, %f658;
	add.s32 	%r328, %r320, %r83;
	shl.b32 	%r329, %r328, 3;
	add.s32 	%r330, %r329, %r612;
	add.s32 	%r331, %r330, 16;
	mul.ftz.f32 	%f251, %f250, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl115, %f251;
	atom.global.add.u64 	%rl116, [%r331], %rl115;
	mul.ftz.f32 	%f252, %f243, %f490;
	add.s32 	%r332, %r320, %r89;
	shl.b32 	%r333, %r332, 3;
	add.s32 	%r334, %r333, %r612;
	add.s32 	%r335, %r334, 24;
	mul.ftz.f32 	%f253, %f252, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl117, %f253;
	atom.global.add.u64 	%rl118, [%r335], %rl117;
	mul.ftz.f32 	%f254, %f243, %f458;
	add.s32 	%r336, %r320, %r95;
	shl.b32 	%r337, %r336, 3;
	add.s32 	%r338, %r337, %r612;
	add.s32 	%r339, %r338, 32;
	mul.ftz.f32 	%f255, %f254, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl119, %f255;
	atom.global.add.u64 	%rl120, [%r339], %rl119;
	ld.local.v4.f32 	{%f664, %f665, %f666, %f667}, [%r58+32];
	mul.ftz.f32 	%f257, %f567, %f664;
	mul.ftz.f32 	%f259, %f257, %f665;
	mad.lo.s32 	%r340, %r125, 63, %r299;
	mul.ftz.f32 	%f260, %f259, %f562;
	add.s32 	%r341, %r72, %r340;
	shl.b32 	%r342, %r341, 3;
	add.s32 	%r343, %r612, %r342;
	mul.ftz.f32 	%f261, %f260, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl121, %f261;
	atom.global.add.u64 	%rl122, [%r343], %rl121;
	ld.local.v4.f32 	{%f668, %f669, %f670, %f671}, [%r58+16];
	mul.ftz.f32 	%f263, %f259, %f670;
	add.s32 	%r344, %r340, %r77;
	shl.b32 	%r345, %r344, 3;
	add.s32 	%r346, %r345, %r612;
	add.s32 	%r347, %r346, 8;
	mul.ftz.f32 	%f264, %f263, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl123, %f264;
	atom.global.add.u64 	%rl124, [%r347], %rl123;
	mul.ftz.f32 	%f266, %f259, %f666;
	add.s32 	%r348, %r340, %r83;
	shl.b32 	%r349, %r348, 3;
	add.s32 	%r350, %r349, %r612;
	add.s32 	%r351, %r350, 16;
	mul.ftz.f32 	%f267, %f266, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl125, %f267;
	atom.global.add.u64 	%rl126, [%r351], %rl125;
	mul.ftz.f32 	%f268, %f259, %f490;
	add.s32 	%r352, %r340, %r89;
	shl.b32 	%r353, %r352, 3;
	add.s32 	%r354, %r353, %r612;
	add.s32 	%r355, %r354, 24;
	mul.ftz.f32 	%f269, %f268, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl127, %f269;
	atom.global.add.u64 	%rl128, [%r355], %rl127;
	mul.ftz.f32 	%f270, %f259, %f458;
	add.s32 	%r356, %r340, %r95;
	shl.b32 	%r357, %r356, 3;
	add.s32 	%r358, %r357, %r612;
	add.s32 	%r359, %r358, 32;
	mul.ftz.f32 	%f271, %f270, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl129, %f271;
	atom.global.add.u64 	%rl130, [%r359], %rl129;
	ld.local.v4.f32 	{%f672, %f673, %f674, %f675}, [%r58+32];
	mul.ftz.f32 	%f273, %f567, %f672;
	mul.ftz.f32 	%f274, %f273, %f489;
	mad.lo.s32 	%r360, %r148, 63, %r299;
	mul.ftz.f32 	%f275, %f274, %f562;
	add.s32 	%r361, %r72, %r360;
	shl.b32 	%r362, %r361, 3;
	add.s32 	%r363, %r612, %r362;
	mul.ftz.f32 	%f276, %f275, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl131, %f276;
	atom.global.add.u64 	%rl132, [%r363], %rl131;
	ld.local.v4.f32 	{%f676, %f677, %f678, %f679}, [%r58+16];
	mul.ftz.f32 	%f278, %f274, %f678;
	add.s32 	%r364, %r360, %r77;
	shl.b32 	%r365, %r364, 3;
	add.s32 	%r366, %r365, %r612;
	add.s32 	%r367, %r366, 8;
	mul.ftz.f32 	%f279, %f278, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl133, %f279;
	atom.global.add.u64 	%rl134, [%r367], %rl133;
	mul.ftz.f32 	%f281, %f274, %f674;
	add.s32 	%r368, %r360, %r83;
	shl.b32 	%r369, %r368, 3;
	add.s32 	%r370, %r369, %r612;
	add.s32 	%r371, %r370, 16;
	mul.ftz.f32 	%f282, %f281, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl135, %f282;
	atom.global.add.u64 	%rl136, [%r371], %rl135;
	mul.ftz.f32 	%f283, %f274, %f490;
	add.s32 	%r372, %r360, %r89;
	shl.b32 	%r373, %r372, 3;
	add.s32 	%r374, %r373, %r612;
	add.s32 	%r375, %r374, 24;
	mul.ftz.f32 	%f284, %f283, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl137, %f284;
	atom.global.add.u64 	%rl138, [%r375], %rl137;
	mul.ftz.f32 	%f285, %f274, %f458;
	add.s32 	%r376, %r360, %r95;
	shl.b32 	%r377, %r376, 3;
	add.s32 	%r378, %r377, %r612;
	add.s32 	%r379, %r378, 32;
	mul.ftz.f32 	%f286, %f285, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl139, %f286;
	atom.global.add.u64 	%rl140, [%r379], %rl139;
	ld.local.v4.f32 	{%f680, %f681, %f682, %f683}, [%r58+32];
	mul.ftz.f32 	%f288, %f567, %f680;
	mul.ftz.f32 	%f289, %f288, %f457;
	mad.lo.s32 	%r380, %r171, 63, %r299;
	mul.ftz.f32 	%f290, %f289, %f562;
	add.s32 	%r381, %r72, %r380;
	shl.b32 	%r382, %r381, 3;
	add.s32 	%r383, %r612, %r382;
	mul.ftz.f32 	%f291, %f290, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl141, %f291;
	atom.global.add.u64 	%rl142, [%r383], %rl141;
	ld.local.v4.f32 	{%f684, %f685, %f686, %f687}, [%r58+16];
	mul.ftz.f32 	%f293, %f289, %f686;
	add.s32 	%r384, %r380, %r77;
	shl.b32 	%r385, %r384, 3;
	add.s32 	%r386, %r385, %r612;
	add.s32 	%r387, %r386, 8;
	mul.ftz.f32 	%f294, %f293, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl143, %f294;
	atom.global.add.u64 	%rl144, [%r387], %rl143;
	mul.ftz.f32 	%f296, %f289, %f682;
	add.s32 	%r388, %r380, %r83;
	shl.b32 	%r389, %r388, 3;
	add.s32 	%r390, %r389, %r612;
	add.s32 	%r391, %r390, 16;
	mul.ftz.f32 	%f297, %f296, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl145, %f297;
	atom.global.add.u64 	%rl146, [%r391], %rl145;
	mul.ftz.f32 	%f298, %f289, %f490;
	add.s32 	%r392, %r380, %r89;
	shl.b32 	%r393, %r392, 3;
	add.s32 	%r394, %r393, %r612;
	add.s32 	%r395, %r394, 24;
	mul.ftz.f32 	%f299, %f298, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl147, %f299;
	atom.global.add.u64 	%rl148, [%r395], %rl147;
	mul.ftz.f32 	%f300, %f289, %f458;
	add.s32 	%r396, %r380, %r95;
	shl.b32 	%r397, %r396, 3;
	add.s32 	%r398, %r397, %r612;
	add.s32 	%r399, %r398, 32;
	mul.ftz.f32 	%f301, %f300, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl149, %f301;
	atom.global.add.u64 	%rl150, [%r399], %rl149;
	add.s32 	%r400, %r7, 3;
	setp.gt.s32 	%p17, %r400, 62;
	selp.b32 	%r401, 63, 0, %p17;
	sub.s32 	%r402, %r400, %r401;
	mad.lo.s32 	%r403, %r402, 3969, %r9;
	mul.ftz.f32 	%f303, %f567, %f488;
	mul.ftz.f32 	%f304, %f303, %f561;
	mad.lo.s32 	%r404, %r70, 63, %r403;
	mul.ftz.f32 	%f305, %f304, %f562;
	add.s32 	%r405, %r72, %r404;
	shl.b32 	%r406, %r405, 3;
	add.s32 	%r407, %r612, %r406;
	mul.ftz.f32 	%f306, %f305, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl151, %f306;
	atom.global.add.u64 	%rl152, [%r407], %rl151;
	ld.local.v4.f32 	{%f688, %f689, %f690, %f691}, [%r58+16];
	mul.ftz.f32 	%f308, %f304, %f690;
	add.s32 	%r408, %r404, %r77;
	shl.b32 	%r409, %r408, 3;
	add.s32 	%r410, %r409, %r612;
	add.s32 	%r411, %r410, 8;
	mul.ftz.f32 	%f309, %f308, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl153, %f309;
	atom.global.add.u64 	%rl154, [%r411], %rl153;
	ld.local.v4.f32 	{%f692, %f693, %f694, %f695}, [%r58+32];
	mul.ftz.f32 	%f311, %f304, %f694;
	add.s32 	%r412, %r404, %r83;
	shl.b32 	%r413, %r412, 3;
	add.s32 	%r414, %r413, %r612;
	add.s32 	%r415, %r414, 16;
	mul.ftz.f32 	%f312, %f311, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl155, %f312;
	atom.global.add.u64 	%rl156, [%r415], %rl155;
	mul.ftz.f32 	%f313, %f304, %f490;
	add.s32 	%r416, %r404, %r89;
	shl.b32 	%r417, %r416, 3;
	add.s32 	%r418, %r417, %r612;
	add.s32 	%r419, %r418, 24;
	mul.ftz.f32 	%f314, %f313, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl157, %f314;
	atom.global.add.u64 	%rl158, [%r419], %rl157;
	mul.ftz.f32 	%f315, %f304, %f458;
	add.s32 	%r420, %r404, %r95;
	shl.b32 	%r421, %r420, 3;
	add.s32 	%r422, %r421, %r612;
	add.s32 	%r423, %r422, 32;
	mul.ftz.f32 	%f316, %f315, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl159, %f316;
	atom.global.add.u64 	%rl160, [%r423], %rl159;
	ld.local.v4.f32 	{%f696, %f697, %f698, %f699}, [%r58+16];
	mul.ftz.f32 	%f318, %f303, %f697;
	mad.lo.s32 	%r424, %r102, 63, %r403;
	mul.ftz.f32 	%f319, %f318, %f562;
	add.s32 	%r425, %r72, %r424;
	shl.b32 	%r426, %r425, 3;
	add.s32 	%r427, %r612, %r426;
	mul.ftz.f32 	%f320, %f319, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl161, %f320;
	atom.global.add.u64 	%rl162, [%r427], %rl161;
	mul.ftz.f32 	%f322, %f318, %f698;
	add.s32 	%r428, %r424, %r77;
	shl.b32 	%r429, %r428, 3;
	add.s32 	%r430, %r429, %r612;
	add.s32 	%r431, %r430, 8;
	mul.ftz.f32 	%f323, %f322, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl163, %f323;
	atom.global.add.u64 	%rl164, [%r431], %rl163;
	ld.local.v4.f32 	{%f700, %f701, %f702, %f703}, [%r58+32];
	mul.ftz.f32 	%f325, %f318, %f702;
	add.s32 	%r432, %r424, %r83;
	shl.b32 	%r433, %r432, 3;
	add.s32 	%r434, %r433, %r612;
	add.s32 	%r435, %r434, 16;
	mul.ftz.f32 	%f326, %f325, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl165, %f326;
	atom.global.add.u64 	%rl166, [%r435], %rl165;
	mul.ftz.f32 	%f327, %f318, %f490;
	add.s32 	%r436, %r424, %r89;
	shl.b32 	%r437, %r436, 3;
	add.s32 	%r438, %r437, %r612;
	add.s32 	%r439, %r438, 24;
	mul.ftz.f32 	%f328, %f327, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl167, %f328;
	atom.global.add.u64 	%rl168, [%r439], %rl167;
	mul.ftz.f32 	%f329, %f318, %f458;
	add.s32 	%r440, %r424, %r95;
	shl.b32 	%r441, %r440, 3;
	add.s32 	%r442, %r441, %r612;
	add.s32 	%r443, %r442, 32;
	mul.ftz.f32 	%f330, %f329, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl169, %f330;
	atom.global.add.u64 	%rl170, [%r443], %rl169;
	ld.local.v4.f32 	{%f704, %f705, %f706, %f707}, [%r58+32];
	mul.ftz.f32 	%f332, %f303, %f705;
	mad.lo.s32 	%r444, %r125, 63, %r403;
	mul.ftz.f32 	%f333, %f332, %f562;
	add.s32 	%r445, %r72, %r444;
	shl.b32 	%r446, %r445, 3;
	add.s32 	%r447, %r612, %r446;
	mul.ftz.f32 	%f334, %f333, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl171, %f334;
	atom.global.add.u64 	%rl172, [%r447], %rl171;
	ld.local.v4.f32 	{%f708, %f709, %f710, %f711}, [%r58+16];
	mul.ftz.f32 	%f336, %f332, %f710;
	add.s32 	%r448, %r444, %r77;
	shl.b32 	%r449, %r448, 3;
	add.s32 	%r450, %r449, %r612;
	add.s32 	%r451, %r450, 8;
	mul.ftz.f32 	%f337, %f336, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl173, %f337;
	atom.global.add.u64 	%rl174, [%r451], %rl173;
	mul.ftz.f32 	%f339, %f332, %f706;
	add.s32 	%r452, %r444, %r83;
	shl.b32 	%r453, %r452, 3;
	add.s32 	%r454, %r453, %r612;
	add.s32 	%r455, %r454, 16;
	mul.ftz.f32 	%f340, %f339, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl175, %f340;
	atom.global.add.u64 	%rl176, [%r455], %rl175;
	mul.ftz.f32 	%f341, %f332, %f490;
	add.s32 	%r456, %r444, %r89;
	shl.b32 	%r457, %r456, 3;
	add.s32 	%r458, %r457, %r612;
	add.s32 	%r459, %r458, 24;
	mul.ftz.f32 	%f342, %f341, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl177, %f342;
	atom.global.add.u64 	%rl178, [%r459], %rl177;
	mul.ftz.f32 	%f343, %f332, %f458;
	add.s32 	%r460, %r444, %r95;
	shl.b32 	%r461, %r460, 3;
	add.s32 	%r462, %r461, %r612;
	add.s32 	%r463, %r462, 32;
	mul.ftz.f32 	%f344, %f343, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl179, %f344;
	atom.global.add.u64 	%rl180, [%r463], %rl179;
	mul.ftz.f32 	%f345, %f303, %f489;
	mad.lo.s32 	%r464, %r148, 63, %r403;
	mul.ftz.f32 	%f346, %f345, %f562;
	add.s32 	%r465, %r72, %r464;
	shl.b32 	%r466, %r465, 3;
	add.s32 	%r467, %r612, %r466;
	mul.ftz.f32 	%f347, %f346, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl181, %f347;
	atom.global.add.u64 	%rl182, [%r467], %rl181;
	ld.local.v4.f32 	{%f712, %f713, %f714, %f715}, [%r58+16];
	mul.ftz.f32 	%f349, %f345, %f714;
	add.s32 	%r468, %r464, %r77;
	shl.b32 	%r469, %r468, 3;
	add.s32 	%r470, %r469, %r612;
	add.s32 	%r471, %r470, 8;
	mul.ftz.f32 	%f350, %f349, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl183, %f350;
	atom.global.add.u64 	%rl184, [%r471], %rl183;
	ld.local.v4.f32 	{%f716, %f717, %f718, %f719}, [%r58+32];
	mul.ftz.f32 	%f352, %f345, %f718;
	add.s32 	%r472, %r464, %r83;
	shl.b32 	%r473, %r472, 3;
	add.s32 	%r474, %r473, %r612;
	add.s32 	%r475, %r474, 16;
	mul.ftz.f32 	%f353, %f352, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl185, %f353;
	atom.global.add.u64 	%rl186, [%r475], %rl185;
	mul.ftz.f32 	%f354, %f345, %f490;
	add.s32 	%r476, %r464, %r89;
	shl.b32 	%r477, %r476, 3;
	add.s32 	%r478, %r477, %r612;
	add.s32 	%r479, %r478, 24;
	mul.ftz.f32 	%f355, %f354, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl187, %f355;
	atom.global.add.u64 	%rl188, [%r479], %rl187;
	mul.ftz.f32 	%f356, %f345, %f458;
	add.s32 	%r480, %r464, %r95;
	shl.b32 	%r481, %r480, 3;
	add.s32 	%r482, %r481, %r612;
	add.s32 	%r483, %r482, 32;
	mul.ftz.f32 	%f357, %f356, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl189, %f357;
	atom.global.add.u64 	%rl190, [%r483], %rl189;
	mul.ftz.f32 	%f358, %f303, %f457;
	mad.lo.s32 	%r484, %r171, 63, %r403;
	mul.ftz.f32 	%f359, %f358, %f562;
	add.s32 	%r485, %r72, %r484;
	shl.b32 	%r486, %r485, 3;
	add.s32 	%r487, %r612, %r486;
	mul.ftz.f32 	%f360, %f359, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl191, %f360;
	atom.global.add.u64 	%rl192, [%r487], %rl191;
	ld.local.v4.f32 	{%f720, %f721, %f722, %f723}, [%r58+16];
	mul.ftz.f32 	%f362, %f358, %f722;
	add.s32 	%r488, %r484, %r77;
	shl.b32 	%r489, %r488, 3;
	add.s32 	%r490, %r489, %r612;
	add.s32 	%r491, %r490, 8;
	mul.ftz.f32 	%f363, %f362, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl193, %f363;
	atom.global.add.u64 	%rl194, [%r491], %rl193;
	ld.local.v4.f32 	{%f724, %f725, %f726, %f727}, [%r58+32];
	mul.ftz.f32 	%f365, %f358, %f726;
	add.s32 	%r492, %r484, %r83;
	shl.b32 	%r493, %r492, 3;
	add.s32 	%r494, %r493, %r612;
	add.s32 	%r495, %r494, 16;
	mul.ftz.f32 	%f366, %f365, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl195, %f366;
	atom.global.add.u64 	%rl196, [%r495], %rl195;
	mul.ftz.f32 	%f367, %f358, %f490;
	add.s32 	%r496, %r484, %r89;
	shl.b32 	%r497, %r496, 3;
	add.s32 	%r498, %r497, %r612;
	add.s32 	%r499, %r498, 24;
	mul.ftz.f32 	%f368, %f367, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl197, %f368;
	atom.global.add.u64 	%rl198, [%r499], %rl197;
	mul.ftz.f32 	%f369, %f358, %f458;
	add.s32 	%r500, %r484, %r95;
	shl.b32 	%r501, %r500, 3;
	add.s32 	%r502, %r501, %r612;
	add.s32 	%r503, %r502, 32;
	mul.ftz.f32 	%f370, %f369, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl199, %f370;
	atom.global.add.u64 	%rl200, [%r503], %rl199;
	add.s32 	%r504, %r7, 4;
	setp.gt.s32 	%p18, %r504, 62;
	selp.b32 	%r505, 63, 0, %p18;
	sub.s32 	%r506, %r504, %r505;
	mad.lo.s32 	%r507, %r506, 3969, %r9;
	mul.ftz.f32 	%f372, %f567, %f456;
	mul.ftz.f32 	%f373, %f372, %f561;
	mad.lo.s32 	%r508, %r70, 63, %r507;
	mul.ftz.f32 	%f374, %f373, %f562;
	add.s32 	%r509, %r72, %r508;
	shl.b32 	%r510, %r509, 3;
	add.s32 	%r511, %r612, %r510;
	mul.ftz.f32 	%f375, %f374, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl201, %f375;
	atom.global.add.u64 	%rl202, [%r511], %rl201;
	ld.local.v4.f32 	{%f728, %f729, %f730, %f731}, [%r58+16];
	mul.ftz.f32 	%f377, %f373, %f730;
	add.s32 	%r512, %r508, %r77;
	shl.b32 	%r513, %r512, 3;
	add.s32 	%r514, %r513, %r612;
	add.s32 	%r515, %r514, 8;
	mul.ftz.f32 	%f378, %f377, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl203, %f378;
	atom.global.add.u64 	%rl204, [%r515], %rl203;
	ld.local.v4.f32 	{%f732, %f733, %f734, %f735}, [%r58+32];
	mul.ftz.f32 	%f380, %f373, %f734;
	add.s32 	%r516, %r508, %r83;
	shl.b32 	%r517, %r516, 3;
	add.s32 	%r518, %r517, %r612;
	add.s32 	%r519, %r518, 16;
	mul.ftz.f32 	%f381, %f380, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl205, %f381;
	atom.global.add.u64 	%rl206, [%r519], %rl205;
	mul.ftz.f32 	%f382, %f373, %f490;
	add.s32 	%r520, %r508, %r89;
	shl.b32 	%r521, %r520, 3;
	add.s32 	%r522, %r521, %r612;
	add.s32 	%r523, %r522, 24;
	mul.ftz.f32 	%f383, %f382, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl207, %f383;
	atom.global.add.u64 	%rl208, [%r523], %rl207;
	mul.ftz.f32 	%f384, %f373, %f458;
	add.s32 	%r524, %r508, %r95;
	shl.b32 	%r525, %r524, 3;
	add.s32 	%r526, %r525, %r612;
	add.s32 	%r527, %r526, 32;
	mul.ftz.f32 	%f385, %f384, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl209, %f385;
	atom.global.add.u64 	%rl210, [%r527], %rl209;
	ld.local.v4.f32 	{%f736, %f737, %f738, %f739}, [%r58+16];
	mul.ftz.f32 	%f387, %f372, %f737;
	mad.lo.s32 	%r528, %r102, 63, %r507;
	mul.ftz.f32 	%f388, %f387, %f562;
	add.s32 	%r529, %r72, %r528;
	shl.b32 	%r530, %r529, 3;
	add.s32 	%r531, %r612, %r530;
	mul.ftz.f32 	%f389, %f388, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl211, %f389;
	atom.global.add.u64 	%rl212, [%r531], %rl211;
	mul.ftz.f32 	%f391, %f387, %f738;
	add.s32 	%r532, %r528, %r77;
	shl.b32 	%r533, %r532, 3;
	add.s32 	%r534, %r533, %r612;
	add.s32 	%r535, %r534, 8;
	mul.ftz.f32 	%f392, %f391, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl213, %f392;
	atom.global.add.u64 	%rl214, [%r535], %rl213;
	ld.local.v4.f32 	{%f740, %f741, %f742, %f743}, [%r58+32];
	mul.ftz.f32 	%f394, %f387, %f742;
	add.s32 	%r536, %r528, %r83;
	shl.b32 	%r537, %r536, 3;
	add.s32 	%r538, %r537, %r612;
	add.s32 	%r539, %r538, 16;
	mul.ftz.f32 	%f395, %f394, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl215, %f395;
	atom.global.add.u64 	%rl216, [%r539], %rl215;
	mul.ftz.f32 	%f396, %f387, %f490;
	add.s32 	%r540, %r528, %r89;
	shl.b32 	%r541, %r540, 3;
	add.s32 	%r542, %r541, %r612;
	add.s32 	%r543, %r542, 24;
	mul.ftz.f32 	%f397, %f396, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl217, %f397;
	atom.global.add.u64 	%rl218, [%r543], %rl217;
	mul.ftz.f32 	%f398, %f387, %f458;
	add.s32 	%r544, %r528, %r95;
	shl.b32 	%r545, %r544, 3;
	add.s32 	%r546, %r545, %r612;
	add.s32 	%r547, %r546, 32;
	mul.ftz.f32 	%f399, %f398, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl219, %f399;
	atom.global.add.u64 	%rl220, [%r547], %rl219;
	ld.local.v4.f32 	{%f744, %f745, %f746, %f747}, [%r58+32];
	mul.ftz.f32 	%f401, %f372, %f745;
	mad.lo.s32 	%r548, %r125, 63, %r507;
	mul.ftz.f32 	%f402, %f401, %f562;
	add.s32 	%r549, %r72, %r548;
	shl.b32 	%r550, %r549, 3;
	add.s32 	%r551, %r612, %r550;
	mul.ftz.f32 	%f403, %f402, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl221, %f403;
	atom.global.add.u64 	%rl222, [%r551], %rl221;
	ld.local.v4.f32 	{%f748, %f749, %f750, %f751}, [%r58+16];
	mul.ftz.f32 	%f405, %f401, %f750;
	add.s32 	%r552, %r548, %r77;
	shl.b32 	%r553, %r552, 3;
	add.s32 	%r554, %r553, %r612;
	add.s32 	%r555, %r554, 8;
	mul.ftz.f32 	%f406, %f405, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl223, %f406;
	atom.global.add.u64 	%rl224, [%r555], %rl223;
	mul.ftz.f32 	%f408, %f401, %f746;
	add.s32 	%r556, %r548, %r83;
	shl.b32 	%r557, %r556, 3;
	add.s32 	%r558, %r557, %r612;
	add.s32 	%r559, %r558, 16;
	mul.ftz.f32 	%f409, %f408, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl225, %f409;
	atom.global.add.u64 	%rl226, [%r559], %rl225;
	mul.ftz.f32 	%f410, %f401, %f490;
	add.s32 	%r560, %r548, %r89;
	shl.b32 	%r561, %r560, 3;
	add.s32 	%r562, %r561, %r612;
	add.s32 	%r563, %r562, 24;
	mul.ftz.f32 	%f411, %f410, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl227, %f411;
	atom.global.add.u64 	%rl228, [%r563], %rl227;
	mul.ftz.f32 	%f412, %f401, %f458;
	add.s32 	%r564, %r548, %r95;
	shl.b32 	%r565, %r564, 3;
	add.s32 	%r566, %r565, %r612;
	add.s32 	%r567, %r566, 32;
	mul.ftz.f32 	%f413, %f412, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl229, %f413;
	atom.global.add.u64 	%rl230, [%r567], %rl229;
	mul.ftz.f32 	%f414, %f372, %f489;
	mad.lo.s32 	%r568, %r148, 63, %r507;
	mul.ftz.f32 	%f415, %f414, %f562;
	add.s32 	%r569, %r72, %r568;
	shl.b32 	%r570, %r569, 3;
	add.s32 	%r571, %r612, %r570;
	mul.ftz.f32 	%f416, %f415, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl231, %f416;
	atom.global.add.u64 	%rl232, [%r571], %rl231;
	ld.local.v4.f32 	{%f752, %f753, %f754, %f755}, [%r58+16];
	mul.ftz.f32 	%f418, %f414, %f754;
	add.s32 	%r572, %r568, %r77;
	shl.b32 	%r573, %r572, 3;
	add.s32 	%r574, %r573, %r612;
	add.s32 	%r575, %r574, 8;
	mul.ftz.f32 	%f419, %f418, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl233, %f419;
	atom.global.add.u64 	%rl234, [%r575], %rl233;
	ld.local.v4.f32 	{%f756, %f757, %f758, %f759}, [%r58+32];
	mul.ftz.f32 	%f421, %f414, %f758;
	add.s32 	%r576, %r568, %r83;
	shl.b32 	%r577, %r576, 3;
	add.s32 	%r578, %r577, %r612;
	add.s32 	%r579, %r578, 16;
	mul.ftz.f32 	%f422, %f421, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl235, %f422;
	atom.global.add.u64 	%rl236, [%r579], %rl235;
	mul.ftz.f32 	%f423, %f414, %f490;
	add.s32 	%r580, %r568, %r89;
	shl.b32 	%r581, %r580, 3;
	add.s32 	%r582, %r581, %r612;
	add.s32 	%r583, %r582, 24;
	mul.ftz.f32 	%f424, %f423, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl237, %f424;
	atom.global.add.u64 	%rl238, [%r583], %rl237;
	mul.ftz.f32 	%f425, %f414, %f458;
	add.s32 	%r584, %r568, %r95;
	shl.b32 	%r585, %r584, 3;
	add.s32 	%r586, %r585, %r612;
	add.s32 	%r587, %r586, 32;
	mul.ftz.f32 	%f426, %f425, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl239, %f426;
	atom.global.add.u64 	%rl240, [%r587], %rl239;
	mul.ftz.f32 	%f427, %f372, %f457;
	mad.lo.s32 	%r588, %r171, 63, %r507;
	mul.ftz.f32 	%f428, %f427, %f562;
	add.s32 	%r589, %r72, %r588;
	shl.b32 	%r590, %r589, 3;
	add.s32 	%r591, %r612, %r590;
	mul.ftz.f32 	%f429, %f428, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl241, %f429;
	atom.global.add.u64 	%rl242, [%r591], %rl241;
	ld.local.v4.f32 	{%f760, %f761, %f762, %f763}, [%r58+16];
	mul.ftz.f32 	%f431, %f427, %f762;
	add.s32 	%r592, %r588, %r77;
	shl.b32 	%r593, %r592, 3;
	add.s32 	%r594, %r593, %r612;
	add.s32 	%r595, %r594, 8;
	mul.ftz.f32 	%f432, %f431, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl243, %f432;
	atom.global.add.u64 	%rl244, [%r595], %rl243;
	ld.local.v4.f32 	{%f764, %f765, %f766, %f767}, [%r58+32];
	mul.ftz.f32 	%f434, %f427, %f766;
	add.s32 	%r596, %r588, %r83;
	shl.b32 	%r597, %r596, 3;
	add.s32 	%r598, %r597, %r612;
	add.s32 	%r599, %r598, 16;
	mul.ftz.f32 	%f435, %f434, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl245, %f435;
	atom.global.add.u64 	%rl246, [%r599], %rl245;
	mul.ftz.f32 	%f436, %f427, %f490;
	add.s32 	%r600, %r588, %r89;
	shl.b32 	%r601, %r600, 3;
	add.s32 	%r602, %r601, %r612;
	add.s32 	%r603, %r602, 24;
	mul.ftz.f32 	%f437, %f436, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl247, %f437;
	atom.global.add.u64 	%rl248, [%r603], %rl247;
	mul.ftz.f32 	%f438, %f427, %f458;
	add.s32 	%r604, %r588, %r95;
	shl.b32 	%r605, %r604, 3;
	add.s32 	%r606, %r605, %r612;
	add.s32 	%r607, %r606, 32;
	mul.ftz.f32 	%f439, %f438, 0f4F800000;
	cvt.rzi.ftz.s64.f32 	%rl249, %f439;
	atom.global.add.u64 	%rl250, [%r607], %rl249;
	// inline asm
	mov.u32 	%r64, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r65, %ntid.x;
	// inline asm
	mad.lo.s32 	%r613, %r65, %r64, %r613;
	setp.lt.s32 	%p19, %r613, 23558;
	@%p19 bra 	BB3_2;

BB3_7:
	ret;
}

.entry finishSpreadCharge(
	.param .u32 .ptr .global .align 8 finishSpreadCharge_param_0
)
{
	.reg .f32 	%f<6>;
	.reg .pred 	%p<3>;
	.reg .s32 	%r<16>;
	.reg .s64 	%rl<2>;


	// inline asm
	mov.u32 	%r5, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r6, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r7, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r8, %tid.x;
	// inline asm
	add.s32 	%r9, %r8, %r5;
	mad.lo.s32 	%r15, %r7, %r6, %r9;
	setp.gt.u32 	%p1, %r15, 250046;
	@%p1 bra 	BB4_2;

BB4_1:
	shl.b32 	%r12, %r15, 3;
	ld.param.u32 	%r14, [finishSpreadCharge_param_0];
	add.s32 	%r13, %r14, %r12;
	ld.global.u64 	%rl1, [%r13];
	cvt.rn.f32.s64 	%f1, %rl1;
	mul.ftz.f32 	%f2, %f1, 0f313C97EA;
	mov.f32 	%f3, 0f00000000;
	st.global.v2.f32 	[%r13], {%f2, %f3};
	// inline asm
	mov.u32 	%r10, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r11, %ntid.x;
	// inline asm
	mad.lo.s32 	%r15, %r11, %r10, %r15;
	setp.lt.u32 	%p2, %r15, 250047;
	@%p2 bra 	BB4_1;

BB4_2:
	ret;
}

.entry reciprocalColwolution(
	.param .u32 .ptr .global .align 8 reciprocalColwolution_param_0,
	.param .u32 .ptr .global .align 4 reciprocalColwolution_param_1,
	.param .u32 .ptr .global .align 4 reciprocalColwolution_param_2,
	.param .u32 .ptr .global .align 4 reciprocalColwolution_param_3,
	.param .u32 .ptr .global .align 4 reciprocalColwolution_param_4,
	.param .align 16 .b8 reciprocalColwolution_param_5[16],
	.param .f32 reciprocalColwolution_param_6
)
{
	.reg .f32 	%f<48>;
	.reg .pred 	%p<10>;
	.reg .s32 	%r<60>;


	ld.param.v4.f32 	{%f42, %f43, %f44, %f45}, [reciprocalColwolution_param_5];
	// inline asm
	mov.u32 	%r14, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r15, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r16, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r17, %tid.x;
	// inline asm
	add.s32 	%r18, %r17, %r14;
	mad.lo.s32 	%r59, %r16, %r15, %r18;
	setp.lt.u32 	%p1, %r59, 250047;
	@%p1 bra 	BB5_2;

	mov.f32 	%f47, 0f00000000;
	bra.uni 	BB5_7;

BB5_2:
	mov.f32 	%f47, 0f00000000;

BB5_3:
	mul.hi.s32 	%r19, %r59, -2078768499;
	add.s32 	%r20, %r19, %r59;
	shr.u32 	%r21, %r20, 31;
	shr.s32 	%r22, %r20, 11;
	add.s32 	%r8, %r22, %r21;
	mul.lo.s32 	%r23, %r8, 3969;
	sub.s32 	%r9, %r59, %r23;
	mul.hi.s32 	%r24, %r9, -2113396605;
	add.s32 	%r25, %r24, %r9;
	shr.u32 	%r26, %r25, 31;
	shr.s32 	%r27, %r25, 5;
	add.s32 	%r10, %r27, %r26;
	mul.lo.s32 	%r11, %r10, 63;
	sub.s32 	%r12, %r9, %r11;
	add.s32 	%r28, %r59, 3968;
	setp.gt.u32 	%p2, %r28, 7936;
	@%p2 bra 	BB5_5;

	add.s32 	%r29, %r9, 62;
	setp.lt.u32 	%p3, %r29, 125;
	setp.eq.s32 	%p4, %r9, %r11;
	and.pred  	%p5, %p3, %p4;
	@%p5 bra 	BB5_6;

BB5_5:
	add.s32 	%r30, %r8, -63;
	setp.lt.s32 	%p6, %r59, 127008;
	selp.b32 	%r31, %r8, %r30, %p6;
	setp.lt.s32 	%p7, %r9, 2016;
	add.s32 	%r32, %r10, -63;
	selp.b32 	%r33, %r10, %r32, %p7;
	setp.lt.s32 	%p8, %r12, 32;
	add.s32 	%r34, %r12, -63;
	selp.b32 	%r35, %r12, %r34, %p8;
	cvt.rn.f32.s32 	%f13, %r31;
	mul.ftz.f32 	%f14, %f13, %f42;
	cvt.rn.f32.s32 	%f15, %r33;
	mul.ftz.f32 	%f16, %f15, %f43;
	cvt.rn.f32.s32 	%f17, %r35;
	mul.ftz.f32 	%f18, %f17, %f44;
	shl.b32 	%r36, %r59, 3;
	ld.param.u32 	%r54, [reciprocalColwolution_param_0];
	add.s32 	%r37, %r54, %r36;
	ld.global.v2.f32 	{%f38, %f39}, [%r37];
	mul.ftz.f32 	%f19, %f16, %f16;
	fma.rn.ftz.f32 	%f20, %f14, %f14, %f19;
	fma.rn.ftz.f32 	%f21, %f18, %f18, %f20;
	shl.b32 	%r38, %r8, 2;
	ld.param.u32 	%r56, [reciprocalColwolution_param_2];
	add.s32 	%r39, %r56, %r38;
	ld.global.f32 	%f22, [%r39];
	mul.ftz.f32 	%f23, %f21, %f22;
	shl.b32 	%r40, %r10, 2;
	ld.param.u32 	%r57, [reciprocalColwolution_param_3];
	add.s32 	%r41, %r57, %r40;
	ld.global.f32 	%f24, [%r41];
	mul.ftz.f32 	%f25, %f23, %f24;
	shl.b32 	%r42, %r12, 2;
	ld.param.u32 	%r58, [reciprocalColwolution_param_4];
	add.s32 	%r43, %r58, %r42;
	ld.global.f32 	%f26, [%r43];
	mul.ftz.f32 	%f27, %f25, %f26;
	mul.ftz.f32 	%f12, %f21, 0fBF6A1706;
	// inline asm
	mul.f32 	%f11, %f12, 0f3FB8AA3B;ex2.approx.f32 	%f11, %f11;
	// inline asm
	ld.param.f32 	%f46, [reciprocalColwolution_param_6];
	mul.ftz.f32 	%f28, %f11, %f46;
	div.approx.ftz.f32 	%f29, %f28, %f27;
	mul.ftz.f32 	%f31, %f38, %f29;
	mul.ftz.f32 	%f33, %f39, %f29;
	st.global.v2.f32 	[%r37], {%f31, %f33};
	mul.ftz.f32 	%f34, %f39, %f39;
	fma.rn.ftz.f32 	%f35, %f38, %f38, %f34;
	fma.rn.ftz.f32 	%f47, %f29, %f35, %f47;

BB5_6:
	// inline asm
	mov.u32 	%r44, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r45, %ntid.x;
	// inline asm
	mad.lo.s32 	%r59, %r45, %r44, %r59;
	setp.lt.u32 	%p9, %r59, 250047;
	@%p9 bra 	BB5_3;

BB5_7:
	// inline asm
	mov.u32 	%r46, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r47, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r48, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r49, %tid.x;
	// inline asm
	add.s32 	%r50, %r49, %r46;
	mad.lo.s32 	%r51, %r48, %r47, %r50;
	shl.b32 	%r52, %r51, 2;
	ld.param.u32 	%r55, [reciprocalColwolution_param_1];
	add.s32 	%r53, %r55, %r52;
	ld.global.f32 	%f36, [%r53];
	fma.rn.ftz.f32 	%f37, %f47, 0f3F000000, %f36;
	st.global.f32 	[%r53], %f37;
	ret;
}

.entry gridInterpolateForce(
	.param .u32 .ptr .global .align 16 gridInterpolateForce_param_0,
	.param .u32 .ptr .global .align 16 gridInterpolateForce_param_1,
	.param .u32 .ptr .global .align 8 gridInterpolateForce_param_2,
	.param .align 16 .b8 gridInterpolateForce_param_3[16],
	.param .align 16 .b8 gridInterpolateForce_param_4[16],
	.param .u32 .ptr .global .align 8 gridInterpolateForce_param_5
)
{
	.local .align 16 .b8 	__local_depot6[160];
	.reg .b32 	%SP;
	.reg .f32 	%f<676>;
	.reg .pred 	%p<17>;
	.reg .s32 	%r<207>;


	mov.u32 	%SP, __local_depot6;
	ld.param.v4.f32 	{%f388, %f389, %f390, %f391}, [gridInterpolateForce_param_4];
	ld.param.v4.f32 	{%f628, %f629, %f630, %f631}, [gridInterpolateForce_param_3];
	// inline asm
	mov.u32 	%r37, %elwreg3;
	// inline asm
	// inline asm
	mov.u32 	%r38, %ntid.x;
	// inline asm
	// inline asm
	mov.u32 	%r39, %ctaid.x;
	// inline asm
	// inline asm
	mov.u32 	%r40, %tid.x;
	// inline asm
	add.s32 	%r41, %r40, %r37;
	mad.lo.s32 	%r195, %r39, %r38, %r41;
	setp.gt.s32 	%p1, %r195, 23557;
	@%p1 bra 	BB6_9;

	mov.f32 	%f7, 0f3F800000;
	mov.f32 	%f11, 0f40800000;
	mov.f32 	%f15, 0f40000000;
	mov.f32 	%f19, 0f40400000;

BB6_2:
	shl.b32 	%r44, %r195, 3;
	ld.param.u32 	%r194, [gridInterpolateForce_param_5];
	add.s32 	%r45, %r194, %r44;
	ld.global.v2.u32 	{%r189, %r190}, [%r45];
	mov.u32 	%r196, 0;
	shl.b32 	%r46, %r189, 4;
	ld.param.u32 	%r191, [gridInterpolateForce_param_0];
	add.s32 	%r47, %r191, %r46;
	ld.global.v4.f32 	{%f308, %f309, %f310, %f311}, [%r47];
	mul.ftz.f32 	%f24, %f308, %f388;
	// inline asm
	cvt.rmi.f32.f32 	%f23, %f24;
	// inline asm
	neg.f32 	%f32, %f23;
	fma.rn.ftz.f32 	%f33, %f32, %f628, %f308;
	mul.ftz.f32 	%f26, %f309, %f389;
	// inline asm
	cvt.rmi.f32.f32 	%f25, %f26;
	// inline asm
	neg.f32 	%f37, %f25;
	fma.rn.ftz.f32 	%f38, %f37, %f629, %f309;
	mov.u32 	%r202, 2;
	mul.ftz.f32 	%f28, %f310, %f390;
	// inline asm
	cvt.rmi.f32.f32 	%f27, %f28;
	// inline asm
	neg.f32 	%f42, %f27;
	fma.rn.ftz.f32 	%f43, %f42, %f630, %f310;
	mul.ftz.f32 	%f44, %f33, %f388;
	mul.ftz.f32 	%f45, %f44, 0f427C0000;
	mov.f32 	%f46, 0f427C0000;
	mul.ftz.f32 	%f47, %f38, %f389;
	mul.ftz.f32 	%f48, %f47, 0f427C0000;
	mul.ftz.f32 	%f49, %f43, %f390;
	mul.ftz.f32 	%f50, %f49, 0f427C0000;
	cvt.rzi.ftz.s32.f32 	%r48, %f45;
	mul.hi.s32 	%r49, %r48, -2113396605;
	add.s32 	%r50, %r49, %r48;
	shr.u32 	%r51, %r50, 31;
	shr.s32 	%r52, %r50, 5;
	add.s32 	%r53, %r52, %r51;
	mul.lo.s32 	%r54, %r53, 63;
	sub.s32 	%r9, %r48, %r54;
	cvt.rzi.ftz.s32.f32 	%r55, %f48;
	mul.hi.s32 	%r56, %r55, -2113396605;
	add.s32 	%r57, %r56, %r55;
	shr.u32 	%r58, %r57, 31;
	shr.s32 	%r59, %r57, 5;
	add.s32 	%r60, %r59, %r58;
	mul.lo.s32 	%r61, %r60, 63;
	sub.s32 	%r10, %r55, %r61;
	cvt.rzi.ftz.s32.f32 	%r62, %f50;
	mul.hi.s32 	%r63, %r62, -2113396605;
	add.s32 	%r64, %r63, %r62;
	shr.u32 	%r65, %r64, 31;
	shr.s32 	%r66, %r64, 5;
	add.s32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, 63;
	sub.s32 	%r11, %r62, %r68;
	cvt.rn.f32.s32 	%f51, %r48;
	neg.f32 	%f52, %f51;
	fma.rn.ftz.f32 	%f53, %f44, %f46, %f52;
	cvt.rn.f32.s32 	%f54, %r55;
	neg.f32 	%f55, %f54;
	fma.rn.ftz.f32 	%f56, %f47, %f46, %f55;
	cvt.rn.f32.s32 	%f57, %r62;
	neg.f32 	%f58, %f57;
	fma.rn.ftz.f32 	%f59, %f49, %f46, %f58;
	mov.f32 	%f60, 0f00000000;
	add.u32 	%r205, %SP, 0;
	st.local.v4.f32 	[%SP+64], {%f60, %f60, %f60, %f60};
	add.s32 	%r199, %r205, 16;
	st.local.v4.f32 	[%SP+16], {%f53, %f56, %f59, %f60};
	sub.ftz.f32 	%f544, %f7, %f53;
	sub.ftz.f32 	%f545, %f7, %f56;
	sub.ftz.f32 	%f546, %f7, %f59;
	sub.ftz.f32 	%f547, %f7, %f60;
	st.local.v4.f32 	[%SP+0], {%f544, %f545, %f546, %f547};
	neg.ftz.f32 	%f588, %f53;
	neg.ftz.f32 	%f589, %f56;
	neg.ftz.f32 	%f590, %f59;
	neg.ftz.f32 	%f591, %f60;

BB6_3:
	mov.u32 	%r200, %r202;
	mov.u32 	%r13, %r200;
	mov.u32 	%r197, %r199;
	mov.u32 	%r12, %r197;
	mov.u32 	%r14, %r196;
	add.s32 	%r15, %r14, 2;
	add.s32 	%r16, %r14, 1;
	mov.u32 	%r203, 1;
	shl.b32 	%r71, %r16, 4;
	add.s32 	%r73, %r14, 3;
	cvt.rn.f32.s32 	%f64, %r73;
	add.ftz.f32 	%f63, %f64, 0fBF800000;
	// inline asm
	div.approx.f32 	%f62, 1.0, %f63;
	// inline asm
	mul.ftz.f32 	%f616, %f62, %f53;
	mul.ftz.f32 	%f617, %f62, %f56;
	mul.ftz.f32 	%f618, %f62, %f59;
	mul.ftz.f32 	%f619, %f62, %f60;
	add.s32 	%r74, %r205, %r71;
	ld.local.v4.f32 	{%f620, %f621, %f622, %f623}, [%r74];
	mul.ftz.f32 	%f624, %f616, %f620;
	mul.ftz.f32 	%f625, %f617, %f621;
	mul.ftz.f32 	%f626, %f618, %f622;
	mul.ftz.f32 	%f627, %f619, %f623;
	st.local.v4.f32 	[%r74+16], {%f624, %f625, %f626, %f627};
	mov.u32 	%r198, %r12;
	mov.u32 	%r201, %r13;

BB6_4:
	mov.u32 	%r18, %r201;
	mov.u32 	%r17, %r198;
	cvt.rn.f32.s32 	%f68, %r203;
	add.ftz.f32 	%f564, %f53, %f68;
	add.ftz.f32 	%f565, %f56, %f68;
	add.ftz.f32 	%f566, %f59, %f68;
	add.ftz.f32 	%f567, %f60, %f68;
	add.s32 	%r21, %r17, -16;
	ld.local.v4.f32 	{%f568, %f569, %f570, %f571}, [%r17+-16];
	cvt.rn.f32.s32 	%f72, %r18;
	add.ftz.f32 	%f584, %f588, %f72;
	add.ftz.f32 	%f585, %f589, %f72;
	add.ftz.f32 	%f586, %f590, %f72;
	add.ftz.f32 	%f587, %f591, %f72;
	ld.local.v4.f32 	{%f592, %f593, %f594, %f595}, [%r17];
	mul.ftz.f32 	%f596, %f584, %f592;
	mul.ftz.f32 	%f597, %f585, %f593;
	mul.ftz.f32 	%f598, %f586, %f594;
	mul.ftz.f32 	%f599, %f587, %f595;
	fma.rn.ftz.f32 	%f600, %f564, %f568, %f596;
	fma.rn.ftz.f32 	%f601, %f565, %f569, %f597;
	fma.rn.ftz.f32 	%f602, %f566, %f570, %f598;
	fma.rn.ftz.f32 	%f603, %f567, %f571, %f599;
	mul.ftz.f32 	%f604, %f62, %f600;
	mul.ftz.f32 	%f605, %f62, %f601;
	mul.ftz.f32 	%f606, %f62, %f602;
	mul.ftz.f32 	%f607, %f62, %f603;
	st.local.v4.f32 	[%r17], {%f604, %f605, %f606, %f607};
	add.s32 	%r20, %r18, -1;
	add.s32 	%r203, %r203, 1;
	setp.lt.s32 	%p2, %r203, %r15;
	mov.u32 	%r198, %r21;
	mov.u32 	%r201, %r20;
	@%p2 bra 	BB6_4;

	mul.ftz.f32 	%f536, %f62, %f544;
	mul.ftz.f32 	%f537, %f62, %f545;
	mul.ftz.f32 	%f538, %f62, %f546;
	mul.ftz.f32 	%f539, %f62, %f547;
	ld.local.v4.f32 	{%f548, %f549, %f550, %f551}, [%SP+0];
	mul.ftz.f32 	%f392, %f536, %f548;
	mul.ftz.f32 	%f393, %f537, %f549;
	mul.ftz.f32 	%f394, %f538, %f550;
	mul.ftz.f32 	%f395, %f539, %f551;
	st.local.v4.f32 	[%SP+0], {%f392, %f393, %f394, %f395};
	add.s32 	%r23, %r13, 1;
	add.s32 	%r24, %r12, 16;
	setp.ne.s32 	%p3, %r16, 2;
	mov.u32 	%r196, %r16;
	mov.u32 	%r199, %r24;
	mov.u32 	%r202, %r23;
	@%p3 bra 	BB6_3;

	add.u32 	%r204, %SP, 80;
	neg.ftz.f32 	%f344, %f392;
	neg.ftz.f32 	%f345, %f393;
	neg.ftz.f32 	%f346, %f394;
	neg.ftz.f32 	%f347, %f395;
	st.local.v4.f32 	[%SP+80], {%f344, %f345, %f346, %f347};
	ld.local.v4.f32 	{%f396, %f397, %f398, %f399}, [%SP+16];
	sub.ftz.f32 	%f400, %f392, %f396;
	sub.ftz.f32 	%f401, %f393, %f397;
	sub.ftz.f32 	%f402, %f394, %f398;
	sub.ftz.f32 	%f403, %f395, %f399;
	st.local.v4.f32 	[%SP+96], {%f400, %f401, %f402, %f403};
	ld.local.v4.f32 	{%f404, %f405, %f406, %f407}, [%SP+32];
	sub.ftz.f32 	%f408, %f396, %f404;
	sub.ftz.f32 	%f409, %f397, %f405;
	sub.ftz.f32 	%f410, %f398, %f406;
	sub.ftz.f32 	%f411, %f399, %f407;
	st.local.v4.f32 	[%SP+112], {%f408, %f409, %f410, %f411};
	ld.local.v4.f32 	{%f412, %f413, %f414, %f415}, [%SP+48];
	sub.ftz.f32 	%f416, %f404, %f412;
	sub.ftz.f32 	%f417, %f405, %f413;
	sub.ftz.f32 	%f418, %f406, %f414;
	sub.ftz.f32 	%f419, %f407, %f415;
	st.local.v4.f32 	[%SP+128], {%f416, %f417, %f418, %f419};
	ld.local.v4.f32 	{%f420, %f421, %f422, %f423}, [%SP+64];
	sub.ftz.f32 	%f424, %f412, %f420;
	sub.ftz.f32 	%f425, %f413, %f421;
	sub.ftz.f32 	%f426, %f414, %f422;
	sub.ftz.f32 	%f427, %f415, %f423;
	st.local.v4.f32 	[%SP+144], {%f424, %f425, %f426, %f427};
	ld.local.v4.f32 	{%f428, %f429, %f430, %f431}, [%SP+48];
	mov.f32 	%f76, 0f3E800000;
	mul.ftz.f32 	%f436, %f53, %f76;
	mul.ftz.f32 	%f437, %f56, %f76;
	mul.ftz.f32 	%f438, %f59, %f76;
	mul.ftz.f32 	%f439, %f60, %f76;
	mul.ftz.f32 	%f372, %f436, %f428;
	mul.ftz.f32 	%f373, %f437, %f429;
	mul.ftz.f32 	%f374, %f438, %f430;
	mul.ftz.f32 	%f375, %f439, %f431;
	st.local.v4.f32 	[%SP+64], {%f372, %f373, %f374, %f375};
	ld.local.v4.f32 	{%f444, %f445, %f446, %f447}, [%SP+32];
	add.ftz.f32 	%f448, %f53, %f7;
	add.ftz.f32 	%f449, %f56, %f7;
	add.ftz.f32 	%f450, %f59, %f7;
	add.ftz.f32 	%f451, %f60, %f7;
	sub.ftz.f32 	%f456, %f11, %f53;
	sub.ftz.f32 	%f457, %f11, %f56;
	sub.ftz.f32 	%f458, %f11, %f59;
	sub.ftz.f32 	%f459, %f11, %f60;
	mul.ftz.f32 	%f464, %f456, %f428;
	mul.ftz.f32 	%f465, %f457, %f429;
	mul.ftz.f32 	%f466, %f458, %f430;
	mul.ftz.f32 	%f467, %f459, %f431;
	fma.rn.ftz.f32 	%f468, %f448, %f444, %f464;
	fma.rn.ftz.f32 	%f469, %f449, %f445, %f465;
	fma.rn.ftz.f32 	%f470, %f450, %f446, %f466;
	fma.rn.ftz.f32 	%f471, %f451, %f447, %f467;
	mul.ftz.f32 	%f364, %f468, %f76;
	mul.ftz.f32 	%f365, %f469, %f76;
	mul.ftz.f32 	%f366, %f470, %f76;
	mul.ftz.f32 	%f367, %f471, %f76;
	st.local.v4.f32 	[%SP+48], {%f364, %f365, %f366, %f367};
	ld.local.v4.f32 	{%f472, %f473, %f474, %f475}, [%SP+16];
	add.ftz.f32 	%f476, %f53, %f15;
	add.ftz.f32 	%f477, %f56, %f15;
	add.ftz.f32 	%f478, %f59, %f15;
	add.ftz.f32 	%f479, %f60, %f15;
	sub.ftz.f32 	%f484, %f19, %f53;
	sub.ftz.f32 	%f485, %f19, %f56;
	sub.ftz.f32 	%f486, %f19, %f59;
	sub.ftz.f32 	%f487, %f19, %f60;
	mul.ftz.f32 	%f492, %f484, %f444;
	mul.ftz.f32 	%f493, %f485, %f445;
	mul.ftz.f32 	%f494, %f486, %f446;
	mul.ftz.f32 	%f495, %f487, %f447;
	fma.rn.ftz.f32 	%f496, %f476, %f472, %f492;
	fma.rn.ftz.f32 	%f497, %f477, %f473, %f493;
	fma.rn.ftz.f32 	%f498, %f478, %f474, %f494;
	fma.rn.ftz.f32 	%f499, %f479, %f475, %f495;
	mul.ftz.f32 	%f500, %f496, %f76;
	mul.ftz.f32 	%f501, %f497, %f76;
	mul.ftz.f32 	%f502, %f498, %f76;
	mul.ftz.f32 	%f503, %f499, %f76;
	st.local.v4.f32 	[%SP+32], {%f500, %f501, %f502, %f503};
	add.ftz.f32 	%f504, %f53, %f19;
	add.ftz.f32 	%f505, %f56, %f19;
	add.ftz.f32 	%f506, %f59, %f19;
	add.ftz.f32 	%f507, %f60, %f19;
	sub.ftz.f32 	%f508, %f15, %f53;
	sub.ftz.f32 	%f509, %f15, %f56;
	sub.ftz.f32 	%f510, %f15, %f59;
	sub.ftz.f32 	%f511, %f15, %f60;
	mul.ftz.f32 	%f512, %f508, %f472;
	mul.ftz.f32 	%f513, %f509, %f473;
	mul.ftz.f32 	%f514, %f510, %f474;
	mul.ftz.f32 	%f515, %f511, %f475;
	fma.rn.ftz.f32 	%f516, %f504, %f392, %f512;
	fma.rn.ftz.f32 	%f517, %f505, %f393, %f513;
	fma.rn.ftz.f32 	%f518, %f506, %f394, %f514;
	fma.rn.ftz.f32 	%f519, %f507, %f395, %f515;
	mul.ftz.f32 	%f520, %f516, %f76;
	mul.ftz.f32 	%f521, %f517, %f76;
	mul.ftz.f32 	%f522, %f518, %f76;
	mul.ftz.f32 	%f523, %f519, %f76;
	st.local.v4.f32 	[%SP+16], {%f520, %f521, %f522, %f523};
	mul.ftz.f32 	%f532, %f544, %f76;
	mul.ftz.f32 	%f533, %f545, %f76;
	mul.ftz.f32 	%f534, %f546, %f76;
	mul.ftz.f32 	%f535, %f547, %f76;
	mul.ftz.f32 	%f340, %f532, %f392;
	mul.ftz.f32 	%f341, %f533, %f393;
	mul.ftz.f32 	%f342, %f534, %f394;
	mul.ftz.f32 	%f343, %f535, %f395;
	st.local.v4.f32 	[%SP+0], {%f340, %f341, %f342, %f343};
	setp.gt.s32 	%p4, %r10, 62;
	selp.b32 	%r78, 63, 0, %p4;
	mov.u32 	%r206, 0;
	sub.s32 	%r79, %r10, %r78;
	mul.lo.s32 	%r25, %r79, 63;
	add.s32 	%r80, %r10, 1;
	setp.gt.s32 	%p5, %r80, 62;
	selp.b32 	%r81, 63, 0, %p5;
	sub.s32 	%r82, %r80, %r81;
	mul.lo.s32 	%r26, %r82, 63;
	add.s32 	%r83, %r10, 2;
	setp.gt.s32 	%p6, %r83, 62;
	selp.b32 	%r84, 63, 0, %p6;
	sub.s32 	%r85, %r83, %r84;
	mul.lo.s32 	%r27, %r85, 63;
	add.s32 	%r86, %r10, 3;
	setp.gt.s32 	%p7, %r86, 62;
	selp.b32 	%r87, 63, 0, %p7;
	sub.s32 	%r88, %r86, %r87;
	mul.lo.s32 	%r28, %r88, 63;
	add.s32 	%r89, %r10, 4;
	setp.gt.s32 	%p8, %r89, 62;
	selp.b32 	%r90, 63, 0, %p8;
	sub.s32 	%r91, %r89, %r90;
	mul.lo.s32 	%r29, %r91, 63;
	mov.f32 	%f672, %f60;
	mov.f32 	%f673, %f60;
	mov.f32 	%f674, %f60;
	mov.f32 	%f675, %f60;

BB6_7:
	add.s32 	%r92, %r9, %r206;
	setp.gt.s32 	%p9, %r92, 62;
	selp.b32 	%r93, 63, 0, %p9;
	sub.s32 	%r94, %r92, %r93;
	mad.lo.s32 	%r95, %r94, 3969, %r11;
	ld.local.f32 	%f80, [%r204];
	mul.ftz.f32 	%f81, %f80, %f341;
	ld.local.f32 	%f83, [%r205];
	mul.ftz.f32 	%f84, %f83, %f345;
	mul.ftz.f32 	%f85, %f83, %f341;
	add.s32 	%r96, %r95, %r25;
	setp.gt.s32 	%p10, %r11, 62;
	selp.b32 	%r97, -63, 0, %p10;
	add.s32 	%r98, %r97, %r96;
	shl.b32 	%r99, %r98, 3;
	ld.param.u32 	%r193, [gridInterpolateForce_param_2];
	add.s32 	%r100, %r193, %r99;
	mul.ftz.f32 	%f87, %f81, %f342;
	ld.global.f32 	%f89, [%r100];
	fma.rn.ftz.f32 	%f90, %f87, %f89, %f672;
	mul.ftz.f32 	%f91, %f84, %f342;
	fma.rn.ftz.f32 	%f93, %f91, %f89, %f673;
	mul.ftz.f32 	%f95, %f85, %f346;
	fma.rn.ftz.f32 	%f97, %f95, %f89, %f674;
	add.s32 	%r101, %r11, 1;
	setp.gt.s32 	%p11, %r101, 62;
	selp.b32 	%r102, -63, 0, %p11;
	ld.local.v4.f32 	{%f348, %f349, %f350, %f351}, [%SP+16];
	mul.ftz.f32 	%f99, %f81, %f350;
	add.s32 	%r103, %r96, %r102;
	shl.b32 	%r104, %r103, 3;
	add.s32 	%r105, %r104, %r193;
	ld.global.f32 	%f100, [%r105+8];
	fma.rn.ftz.f32 	%f101, %f99, %f100, %f90;
	mul.ftz.f32 	%f102, %f84, %f350;
	fma.rn.ftz.f32 	%f103, %f102, %f100, %f93;
	ld.local.v4.f32 	{%f352, %f353, %f354, %f355}, [%SP+96];
	mul.ftz.f32 	%f105, %f85, %f354;
	fma.rn.ftz.f32 	%f106, %f105, %f100, %f97;
	add.s32 	%r106, %r11, 2;
	setp.gt.s32 	%p12, %r106, 62;
	selp.b32 	%r107, -63, 0, %p12;
	ld.local.v4.f32 	{%f356, %f357, %f358, %f359}, [%SP+32];
	mul.ftz.f32 	%f108, %f81, %f358;
	add.s32 	%r108, %r96, %r107;
	shl.b32 	%r109, %r108, 3;
	add.s32 	%r110, %r109, %r193;
	ld.global.f32 	%f109, [%r110+16];
	fma.rn.ftz.f32 	%f110, %f108, %f109, %f101;
	mul.ftz.f32 	%f111, %f84, %f358;
	fma.rn.ftz.f32 	%f112, %f111, %f109, %f103;
	ld.local.v4.f32 	{%f360, %f361, %f362, %f363}, [%SP+112];
	mul.ftz.f32 	%f114, %f85, %f362;
	fma.rn.ftz.f32 	%f115, %f114, %f109, %f106;
	add.s32 	%r111, %r11, 3;
	setp.gt.s32 	%p13, %r111, 62;
	selp.b32 	%r112, -63, 0, %p13;
	mul.ftz.f32 	%f117, %f81, %f366;
	add.s32 	%r113, %r96, %r112;
	shl.b32 	%r114, %r113, 3;
	add.s32 	%r115, %r114, %r193;
	ld.global.f32 	%f118, [%r115+24];
	fma.rn.ftz.f32 	%f119, %f117, %f118, %f110;
	mul.ftz.f32 	%f120, %f84, %f366;
	fma.rn.ftz.f32 	%f121, %f120, %f118, %f112;
	ld.local.v4.f32 	{%f368, %f369, %f370, %f371}, [%SP+128];
	mul.ftz.f32 	%f123, %f85, %f370;
	fma.rn.ftz.f32 	%f124, %f123, %f118, %f115;
	add.s32 	%r116, %r11, 4;
	setp.gt.s32 	%p14, %r116, 62;
	selp.b32 	%r117, -63, 0, %p14;
	mul.ftz.f32 	%f126, %f81, %f374;
	add.s32 	%r118, %r96, %r117;
	shl.b32 	%r119, %r118, 3;
	add.s32 	%r120, %r119, %r193;
	ld.global.f32 	%f127, [%r120+32];
	fma.rn.ftz.f32 	%f128, %f126, %f127, %f119;
	mul.ftz.f32 	%f129, %f84, %f374;
	fma.rn.ftz.f32 	%f130, %f129, %f127, %f121;
	ld.local.v4.f32 	{%f376, %f377, %f378, %f379}, [%SP+144];
	mul.ftz.f32 	%f132, %f85, %f378;
	fma.rn.ftz.f32 	%f133, %f132, %f127, %f124;
	mul.ftz.f32 	%f135, %f80, %f349;
	mul.ftz.f32 	%f137, %f83, %f353;
	mul.ftz.f32 	%f138, %f83, %f349;
	add.s32 	%r121, %r95, %r26;
	add.s32 	%r122, %r97, %r121;
	shl.b32 	%r123, %r122, 3;
	add.s32 	%r124, %r193, %r123;
	mul.ftz.f32 	%f139, %f135, %f342;
	ld.global.f32 	%f140, [%r124];
	fma.rn.ftz.f32 	%f141, %f139, %f140, %f128;
	mul.ftz.f32 	%f142, %f137, %f342;
	fma.rn.ftz.f32 	%f143, %f142, %f140, %f130;
	mul.ftz.f32 	%f144, %f138, %f346;
	fma.rn.ftz.f32 	%f145, %f144, %f140, %f133;
	mul.ftz.f32 	%f146, %f135, %f350;
	add.s32 	%r125, %r121, %r102;
	shl.b32 	%r126, %r125, 3;
	add.s32 	%r127, %r126, %r193;
	ld.global.f32 	%f147, [%r127+8];
	fma.rn.ftz.f32 	%f148, %f146, %f147, %f141;
	mul.ftz.f32 	%f149, %f137, %f350;
	fma.rn.ftz.f32 	%f150, %f149, %f147, %f143;
	mul.ftz.f32 	%f151, %f138, %f354;
	fma.rn.ftz.f32 	%f152, %f151, %f147, %f145;
	mul.ftz.f32 	%f153, %f135, %f358;
	add.s32 	%r128, %r121, %r107;
	shl.b32 	%r129, %r128, 3;
	add.s32 	%r130, %r129, %r193;
	ld.global.f32 	%f154, [%r130+16];
	fma.rn.ftz.f32 	%f155, %f153, %f154, %f148;
	mul.ftz.f32 	%f156, %f137, %f358;
	fma.rn.ftz.f32 	%f157, %f156, %f154, %f150;
	mul.ftz.f32 	%f158, %f138, %f362;
	fma.rn.ftz.f32 	%f159, %f158, %f154, %f152;
	mul.ftz.f32 	%f160, %f135, %f366;
	add.s32 	%r131, %r121, %r112;
	shl.b32 	%r132, %r131, 3;
	add.s32 	%r133, %r132, %r193;
	ld.global.f32 	%f161, [%r133+24];
	fma.rn.ftz.f32 	%f162, %f160, %f161, %f155;
	mul.ftz.f32 	%f163, %f137, %f366;
	fma.rn.ftz.f32 	%f164, %f163, %f161, %f157;
	mul.ftz.f32 	%f165, %f138, %f370;
	fma.rn.ftz.f32 	%f166, %f165, %f161, %f159;
	mul.ftz.f32 	%f167, %f135, %f374;
	add.s32 	%r134, %r121, %r117;
	shl.b32 	%r135, %r134, 3;
	add.s32 	%r136, %r135, %r193;
	ld.global.f32 	%f168, [%r136+32];
	fma.rn.ftz.f32 	%f169, %f167, %f168, %f162;
	mul.ftz.f32 	%f170, %f137, %f374;
	fma.rn.ftz.f32 	%f171, %f170, %f168, %f164;
	mul.ftz.f32 	%f172, %f138, %f378;
	fma.rn.ftz.f32 	%f173, %f172, %f168, %f166;
	mul.ftz.f32 	%f175, %f80, %f357;
	mul.ftz.f32 	%f177, %f83, %f361;
	mul.ftz.f32 	%f178, %f83, %f357;
	add.s32 	%r137, %r95, %r27;
	add.s32 	%r138, %r97, %r137;
	shl.b32 	%r139, %r138, 3;
	add.s32 	%r140, %r193, %r139;
	mul.ftz.f32 	%f179, %f175, %f342;
	ld.global.f32 	%f180, [%r140];
	fma.rn.ftz.f32 	%f181, %f179, %f180, %f169;
	mul.ftz.f32 	%f182, %f177, %f342;
	fma.rn.ftz.f32 	%f183, %f182, %f180, %f171;
	mul.ftz.f32 	%f184, %f178, %f346;
	fma.rn.ftz.f32 	%f185, %f184, %f180, %f173;
	mul.ftz.f32 	%f186, %f175, %f350;
	add.s32 	%r141, %r137, %r102;
	shl.b32 	%r142, %r141, 3;
	add.s32 	%r143, %r142, %r193;
	ld.global.f32 	%f187, [%r143+8];
	fma.rn.ftz.f32 	%f188, %f186, %f187, %f181;
	mul.ftz.f32 	%f189, %f177, %f350;
	fma.rn.ftz.f32 	%f190, %f189, %f187, %f183;
	mul.ftz.f32 	%f191, %f178, %f354;
	fma.rn.ftz.f32 	%f192, %f191, %f187, %f185;
	mul.ftz.f32 	%f193, %f175, %f358;
	add.s32 	%r144, %r137, %r107;
	shl.b32 	%r145, %r144, 3;
	add.s32 	%r146, %r145, %r193;
	ld.global.f32 	%f194, [%r146+16];
	fma.rn.ftz.f32 	%f195, %f193, %f194, %f188;
	mul.ftz.f32 	%f196, %f177, %f358;
	fma.rn.ftz.f32 	%f197, %f196, %f194, %f190;
	mul.ftz.f32 	%f198, %f178, %f362;
	fma.rn.ftz.f32 	%f199, %f198, %f194, %f192;
	mul.ftz.f32 	%f200, %f175, %f366;
	add.s32 	%r147, %r137, %r112;
	shl.b32 	%r148, %r147, 3;
	add.s32 	%r149, %r148, %r193;
	ld.global.f32 	%f201, [%r149+24];
	fma.rn.ftz.f32 	%f202, %f200, %f201, %f195;
	mul.ftz.f32 	%f203, %f177, %f366;
	fma.rn.ftz.f32 	%f204, %f203, %f201, %f197;
	mul.ftz.f32 	%f205, %f178, %f370;
	fma.rn.ftz.f32 	%f206, %f205, %f201, %f199;
	mul.ftz.f32 	%f207, %f175, %f374;
	add.s32 	%r150, %r137, %r117;
	shl.b32 	%r151, %r150, 3;
	add.s32 	%r152, %r151, %r193;
	ld.global.f32 	%f208, [%r152+32];
	fma.rn.ftz.f32 	%f209, %f207, %f208, %f202;
	mul.ftz.f32 	%f210, %f177, %f374;
	fma.rn.ftz.f32 	%f211, %f210, %f208, %f204;
	mul.ftz.f32 	%f212, %f178, %f378;
	fma.rn.ftz.f32 	%f213, %f212, %f208, %f206;
	mul.ftz.f32 	%f215, %f80, %f365;
	mul.ftz.f32 	%f217, %f83, %f369;
	mul.ftz.f32 	%f218, %f83, %f365;
	add.s32 	%r153, %r95, %r28;
	add.s32 	%r154, %r97, %r153;
	shl.b32 	%r155, %r154, 3;
	add.s32 	%r156, %r193, %r155;
	mul.ftz.f32 	%f219, %f215, %f342;
	ld.global.f32 	%f220, [%r156];
	fma.rn.ftz.f32 	%f221, %f219, %f220, %f209;
	mul.ftz.f32 	%f222, %f217, %f342;
	fma.rn.ftz.f32 	%f223, %f222, %f220, %f211;
	mul.ftz.f32 	%f224, %f218, %f346;
	fma.rn.ftz.f32 	%f225, %f224, %f220, %f213;
	mul.ftz.f32 	%f226, %f215, %f350;
	add.s32 	%r157, %r153, %r102;
	shl.b32 	%r158, %r157, 3;
	add.s32 	%r159, %r158, %r193;
	ld.global.f32 	%f227, [%r159+8];
	fma.rn.ftz.f32 	%f228, %f226, %f227, %f221;
	mul.ftz.f32 	%f229, %f217, %f350;
	fma.rn.ftz.f32 	%f230, %f229, %f227, %f223;
	mul.ftz.f32 	%f231, %f218, %f354;
	fma.rn.ftz.f32 	%f232, %f231, %f227, %f225;
	mul.ftz.f32 	%f233, %f215, %f358;
	add.s32 	%r160, %r153, %r107;
	shl.b32 	%r161, %r160, 3;
	add.s32 	%r162, %r161, %r193;
	ld.global.f32 	%f234, [%r162+16];
	fma.rn.ftz.f32 	%f235, %f233, %f234, %f228;
	mul.ftz.f32 	%f236, %f217, %f358;
	fma.rn.ftz.f32 	%f237, %f236, %f234, %f230;
	mul.ftz.f32 	%f238, %f218, %f362;
	fma.rn.ftz.f32 	%f239, %f238, %f234, %f232;
	mul.ftz.f32 	%f240, %f215, %f366;
	add.s32 	%r163, %r153, %r112;
	shl.b32 	%r164, %r163, 3;
	add.s32 	%r165, %r164, %r193;
	ld.global.f32 	%f241, [%r165+24];
	fma.rn.ftz.f32 	%f242, %f240, %f241, %f235;
	mul.ftz.f32 	%f243, %f217, %f366;
	fma.rn.ftz.f32 	%f244, %f243, %f241, %f237;
	mul.ftz.f32 	%f245, %f218, %f370;
	fma.rn.ftz.f32 	%f246, %f245, %f241, %f239;
	mul.ftz.f32 	%f247, %f215, %f374;
	add.s32 	%r166, %r153, %r117;
	shl.b32 	%r167, %r166, 3;
	add.s32 	%r168, %r167, %r193;
	ld.global.f32 	%f248, [%r168+32];
	fma.rn.ftz.f32 	%f249, %f247, %f248, %f242;
	mul.ftz.f32 	%f250, %f217, %f374;
	fma.rn.ftz.f32 	%f251, %f250, %f248, %f244;
	mul.ftz.f32 	%f252, %f218, %f378;
	fma.rn.ftz.f32 	%f253, %f252, %f248, %f246;
	mul.ftz.f32 	%f255, %f80, %f373;
	mul.ftz.f32 	%f257, %f83, %f377;
	mul.ftz.f32 	%f258, %f83, %f373;
	add.s32 	%r169, %r95, %r29;
	add.s32 	%r170, %r97, %r169;
	shl.b32 	%r171, %r170, 3;
	add.s32 	%r172, %r193, %r171;
	mul.ftz.f32 	%f259, %f255, %f342;
	ld.global.f32 	%f260, [%r172];
	fma.rn.ftz.f32 	%f261, %f259, %f260, %f249;
	mul.ftz.f32 	%f262, %f257, %f342;
	fma.rn.ftz.f32 	%f263, %f262, %f260, %f251;
	mul.ftz.f32 	%f264, %f258, %f346;
	fma.rn.ftz.f32 	%f265, %f264, %f260, %f253;
	mul.ftz.f32 	%f266, %f255, %f350;
	add.s32 	%r173, %r169, %r102;
	shl.b32 	%r174, %r173, 3;
	add.s32 	%r175, %r174, %r193;
	ld.global.f32 	%f267, [%r175+8];
	fma.rn.ftz.f32 	%f268, %f266, %f267, %f261;
	mul.ftz.f32 	%f269, %f257, %f350;
	fma.rn.ftz.f32 	%f270, %f269, %f267, %f263;
	mul.ftz.f32 	%f271, %f258, %f354;
	fma.rn.ftz.f32 	%f272, %f271, %f267, %f265;
	mul.ftz.f32 	%f273, %f255, %f358;
	add.s32 	%r176, %r169, %r107;
	shl.b32 	%r177, %r176, 3;
	add.s32 	%r178, %r177, %r193;
	ld.global.f32 	%f274, [%r178+16];
	fma.rn.ftz.f32 	%f275, %f273, %f274, %f268;
	mul.ftz.f32 	%f276, %f257, %f358;
	fma.rn.ftz.f32 	%f277, %f276, %f274, %f270;
	mul.ftz.f32 	%f278, %f258, %f362;
	fma.rn.ftz.f32 	%f279, %f278, %f274, %f272;
	mul.ftz.f32 	%f280, %f255, %f366;
	add.s32 	%r179, %r169, %r112;
	shl.b32 	%r180, %r179, 3;
	add.s32 	%r181, %r180, %r193;
	ld.global.f32 	%f281, [%r181+24];
	fma.rn.ftz.f32 	%f282, %f280, %f281, %f275;
	mul.ftz.f32 	%f283, %f257, %f366;
	fma.rn.ftz.f32 	%f284, %f283, %f281, %f277;
	mul.ftz.f32 	%f285, %f258, %f370;
	fma.rn.ftz.f32 	%f286, %f285, %f281, %f279;
	mul.ftz.f32 	%f287, %f255, %f374;
	add.s32 	%r182, %r169, %r117;
	shl.b32 	%r183, %r182, 3;
	add.s32 	%r184, %r183, %r193;
	ld.global.f32 	%f288, [%r184+32];
	fma.rn.ftz.f32 	%f1, %f287, %f288, %f282;
	mul.ftz.f32 	%f289, %f257, %f374;
	fma.rn.ftz.f32 	%f2, %f289, %f288, %f284;
	mul.ftz.f32 	%f290, %f258, %f378;
	fma.rn.ftz.f32 	%f3, %f290, %f288, %f286;
	mov.f32 	%f672, %f1;
	mov.f32 	%f673, %f2;
	mov.f32 	%f674, %f3;
	mov.f32 	%f675, %f675;
	add.s32 	%r205, %r205, 16;
	add.s32 	%r204, %r204, 16;
	add.s32 	%r206, %r206, 1;
	setp.ne.s32 	%p15, %r206, 5;
	@%p15 bra 	BB6_7;

	ld.param.u32 	%r192, [gridInterpolateForce_param_1];
	add.s32 	%r188, %r192, %r46;
	mul.ftz.f32 	%f292, %f311, 0f413C97EA;
	mul.ftz.f32 	%f293, %f292, %f1;
	mul.ftz.f32 	%f294, %f293, 0f427C0000;
	ld.global.v4.f32 	{%f312, %f313, %f314, %f315}, [%r188];
	neg.f32 	%f296, %f294;
	fma.rn.ftz.f32 	%f297, %f296, %f388, %f312;
	mul.ftz.f32 	%f298, %f292, %f2;
	mul.ftz.f32 	%f299, %f298, 0f427C0000;
	neg.f32 	%f301, %f299;
	fma.rn.ftz.f32 	%f302, %f301, %f389, %f313;
	mul.ftz.f32 	%f303, %f292, %f3;
	mul.ftz.f32 	%f304, %f303, 0f427C0000;
	neg.f32 	%f306, %f304;
	fma.rn.ftz.f32 	%f307, %f306, %f390, %f314;
	st.global.v4.f32 	[%r188], {%f297, %f302, %f307, %f315};
	// inline asm
	mov.u32 	%r185, %elwreg6;
	// inline asm
	// inline asm
	mov.u32 	%r186, %ntid.x;
	// inline asm
	mad.lo.s32 	%r195, %r186, %r185, %r195;
	setp.lt.s32 	%p16, %r195, 23558;
	@%p16 bra 	BB6_2;

BB6_9:
	ret;
}



