//
// Generated by LWPU LWVM Compiler
//
// Compiler Build ID: CL-18995850
// Lwca compilation tools, release 7.0, V7.0.0
// Based on LLVM 3.4svn
//

.version 4.2
.target sm_53
.address_size 64

	// .weak	lwdaMalloc
.global .texref image;

.weak .func  (.param .b32 func_retval0) lwdaMalloc(
	.param .b64 lwdaMalloc_param_0,
	.param .b64 lwdaMalloc_param_1
)
{
	.reg .s32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	lwdaFuncGetAttributes
.weak .func  (.param .b32 func_retval0) lwdaFuncGetAttributes(
	.param .b64 lwdaFuncGetAttributes_param_0,
	.param .b64 lwdaFuncGetAttributes_param_1
)
{
	.reg .s32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .globl	_Z7GetHighRKi
.visible .func  (.param .b32 func_retval0) _Z7GetHighRKi(
	.param .b64 _Z7GetHighRKi_param_0
)
{
	.reg .s16 	%rs<2>;
	.reg .s32 	%r<3>;
	.reg .s64 	%rd<2>;


	ld.param.u64 	%rd1, [_Z7GetHighRKi_param_0];
	ld.u32 	%r1, [%rd1];
	// inline asm
	{ .reg .f16 low,high;
  mov.b32 {low,high}, %r1;
  mov.b16 %rs1,high;}
	// inline asm
	cvt.u32.u16	%r2, %rs1;
	st.param.b32	[func_retval0+0], %r2;
	ret;
}

	// .globl	_Z6GetLowRKi
.visible .func  (.param .b32 func_retval0) _Z6GetLowRKi(
	.param .b64 _Z6GetLowRKi_param_0
)
{
	.reg .s16 	%rs<2>;
	.reg .s32 	%r<3>;
	.reg .s64 	%rd<2>;


	ld.param.u64 	%rd1, [_Z6GetLowRKi_param_0];
	ld.u32 	%r1, [%rd1];
	// inline asm
	{ .reg .f16 low,high;
  mov.b32 {low,high}, %r1;
  mov.b16 %rs1,low;}
	// inline asm
	cvt.u32.u16	%r2, %rs1;
	st.param.b32	[func_retval0+0], %r2;
	ret;
}

	// .globl	_Z6HFMAA2RiRKiS1_
.visible .func _Z6HFMAA2RiRKiS1_(
	.param .b64 _Z6HFMAA2RiRKiS1__param_0,
	.param .b64 _Z6HFMAA2RiRKiS1__param_1,
	.param .b64 _Z6HFMAA2RiRKiS1__param_2
)
{
	.reg .s32 	%r<5>;
	.reg .s64 	%rd<4>;


	ld.param.u64 	%rd1, [_Z6HFMAA2RiRKiS1__param_0];
	ld.param.u64 	%rd2, [_Z6HFMAA2RiRKiS1__param_1];
	ld.param.u64 	%rd3, [_Z6HFMAA2RiRKiS1__param_2];
	ld.u32 	%r4, [%rd1];
	ld.u32 	%r2, [%rd2];
	ld.u32 	%r3, [%rd3];
	mov.u32 	%r1, %r4;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r2;
mov.b32 b,%r3;
mov.b32 c,%r1;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1,d;
}
	// inline asm
	st.u32 	[%rd1], %r1;
	ret;
}

	// .globl	_Z12HFMAA2_bH0H0RiRKiS1_
.visible .func _Z12HFMAA2_bH0H0RiRKiS1_(
	.param .b64 _Z12HFMAA2_bH0H0RiRKiS1__param_0,
	.param .b64 _Z12HFMAA2_bH0H0RiRKiS1__param_1,
	.param .b64 _Z12HFMAA2_bH0H0RiRKiS1__param_2
)
{
	.reg .s32 	%r<5>;
	.reg .s64 	%rd<4>;


	ld.param.u64 	%rd1, [_Z12HFMAA2_bH0H0RiRKiS1__param_0];
	ld.param.u64 	%rd2, [_Z12HFMAA2_bH0H0RiRKiS1__param_1];
	ld.param.u64 	%rd3, [_Z12HFMAA2_bH0H0RiRKiS1__param_2];
	ld.u32 	%r4, [%rd1];
	ld.u32 	%r2, [%rd2];
	ld.u32 	%r3, [%rd3];
	mov.u32 	%r1, %r4;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r2;
mov.b32 {lowb,highb},%r3;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r1;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1,d;
}
	// inline asm
	st.u32 	[%rd1], %r1;
	ret;
}

	// .globl	_Z12HFMAA2_bH1H1RiRKiS1_
.visible .func _Z12HFMAA2_bH1H1RiRKiS1_(
	.param .b64 _Z12HFMAA2_bH1H1RiRKiS1__param_0,
	.param .b64 _Z12HFMAA2_bH1H1RiRKiS1__param_1,
	.param .b64 _Z12HFMAA2_bH1H1RiRKiS1__param_2
)
{
	.reg .s32 	%r<5>;
	.reg .s64 	%rd<4>;


	ld.param.u64 	%rd1, [_Z12HFMAA2_bH1H1RiRKiS1__param_0];
	ld.param.u64 	%rd2, [_Z12HFMAA2_bH1H1RiRKiS1__param_1];
	ld.param.u64 	%rd3, [_Z12HFMAA2_bH1H1RiRKiS1__param_2];
	ld.u32 	%r4, [%rd1];
	ld.u32 	%r2, [%rd2];
	ld.u32 	%r3, [%rd3];
	mov.u32 	%r1, %r4;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r2;
mov.b32 {lowb,highb},%r3;
mov.b32 temp,{highb,highb};
mov.b32 c,%r1;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1,d;
}
	// inline asm
	st.u32 	[%rd1], %r1;
	ret;
}

	// .globl	_Z15TexFetchF16Packyii
.visible .func  (.param .b32 func_retval0) _Z15TexFetchF16Packyii(
	.param .b64 _Z15TexFetchF16Packyii_param_0,
	.param .b32 _Z15TexFetchF16Packyii_param_1,
	.param .b32 _Z15TexFetchF16Packyii_param_2
)
{
	.reg .s32 	%r<5>;
	.reg .s64 	%rd<2>;


	ld.param.u64 	%rd1, [_Z15TexFetchF16Packyii_param_0];
	ld.param.u32 	%r3, [_Z15TexFetchF16Packyii_param_1];
	ld.param.u32 	%r4, [_Z15TexFetchF16Packyii_param_2];
	// inline asm
	{ .reg .b32 p0;
.reg .b32 p1;
tex.2d.v2.f16x2.s32 {p0,p1},[%rd1,{%r3,%r4}];
mov.b32 %r1,p0;
mov.b32 %r2,p1;
}
	// inline asm
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .globl	_Z10det_fp16x2iii
.visible .func  (.param .b32 func_retval0) _Z10det_fp16x2iii(
	.param .b32 _Z10det_fp16x2iii_param_0,
	.param .b32 _Z10det_fp16x2iii_param_1,
	.param .b32 _Z10det_fp16x2iii_param_2
)
{
	.reg .s32 	%r<13>;


	ld.param.u32 	%r6, [_Z10det_fp16x2iii_param_0];
	ld.param.u32 	%r2, [_Z10det_fp16x2iii_param_1];
	ld.param.u32 	%r7, [_Z10det_fp16x2iii_param_2];
	mov.u32 	%r3, -1140802560;
	mov.u32 	%r8, 0;
	mov.u32 	%r1, %r8;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r2;
mov.b32 b,%r3;
mov.b32 c,%r1;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1,d;
}
	// inline asm
	mov.u32 	%r5, %r8;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r6;
mov.b32 b,%r7;
mov.b32 c,%r5;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r5,d;
}
	// inline asm
	mov.u32 	%r9, %r5;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r2;
mov.b32 b,%r1;
mov.b32 c,%r9;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r9,d;
}
	// inline asm
	st.param.b32	[func_retval0+0], %r9;
	ret;
}

	// .globl	_Z12trace_fp16x2ii
.visible .func  (.param .b32 func_retval0) _Z12trace_fp16x2ii(
	.param .b32 _Z12trace_fp16x2ii_param_0,
	.param .b32 _Z12trace_fp16x2ii_param_1
)
{
	.reg .s32 	%r<5>;


	ld.param.u32 	%r4, [_Z12trace_fp16x2ii_param_0];
	ld.param.u32 	%r2, [_Z12trace_fp16x2ii_param_1];
	mov.u32 	%r3, 1006648320;
	mov.u32 	%r1, %r4;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r2;
mov.b32 b,%r3;
mov.b32 c,%r1;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1,d;
}
	// inline asm
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .globl	_Z12score_fp16x2iii
.visible .func  (.param .b32 func_retval0) _Z12score_fp16x2iii(
	.param .b32 _Z12score_fp16x2iii_param_0,
	.param .b32 _Z12score_fp16x2iii_param_1,
	.param .b32 _Z12score_fp16x2iii_param_2
)
{
	.reg .s32 	%r<9>;


	ld.param.u32 	%r8, [_Z12score_fp16x2iii_param_0];
	ld.param.u32 	%r2, [_Z12score_fp16x2iii_param_1];
	ld.param.u32 	%r7, [_Z12score_fp16x2iii_param_2];
	mov.u32 	%r4, 0;
	mov.u32 	%r1, %r4;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r2;
mov.b32 b,%r2;
mov.b32 c,%r1;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1,d;
}
	// inline asm
	mov.u32 	%r5, %r8;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1;
mov.b32 b,%r7;
mov.b32 c,%r5;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r5,d;
}
	// inline asm
	st.param.b32	[func_retval0+0], %r5;
	ret;
}

	// .globl	_Z4dx_cf
.visible .func  (.param .b32 func_retval0) _Z4dx_cf(
	.param .b32 _Z4dx_cf_param_0
)
{
	.reg .f32 	%f<8>;
	.reg .s32 	%r<5>;


	ld.param.f32 	%f2, [_Z4dx_cf_param_0];
	mov.u32 	%r3, 1;
	mov.u32 	%r2, 0;
	// inline asm
	shfl.up.b32 %f1, %f2, %r3, %r2;
	// inline asm
	mul.ftz.f32 	%f5, %f1, 0f40400000;
	fma.rn.ftz.f32 	%f6, %f2, 0f41200000, %f5;
	mov.u32 	%r4, 31;
	// inline asm
	shfl.down.b32 %f3, %f2, %r3, %r4;
	// inline asm
	fma.rn.ftz.f32 	%f7, %f3, 0f40400000, %f6;
	st.param.f32	[func_retval0+0], %f7;
	ret;
}

	// .globl	_Z11dx_c_fp16x2i
.visible .func  (.param .b32 func_retval0) _Z11dx_c_fp16x2i(
	.param .b32 _Z11dx_c_fp16x2i_param_0
)
{
	.reg .s32 	%r<25>;


	ld.param.u32 	%r2, [_Z11dx_c_fp16x2i_param_0];
	mov.u32 	%r7, 1;
	mov.u32 	%r12, 0;
	// inline asm
	shfl.up.b32 %r1, %r2, %r7, %r12;
	// inline asm
	mov.u32 	%r8, 31;
	// inline asm
	shfl.down.b32 %r5, %r2, %r7, %r8;
	// inline asm
	mov.u32 	%r10, 16896;
	mov.u32 	%r9, %r12;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r10;
mov.b32 {lowb,highb},%r1;
mov.b32 temp,{highb,highb};
mov.b32 c,%r9;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r9,d;
}
	// inline asm
	mov.u32 	%r14, 1107314944;
	mov.u32 	%r13, %r9;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r14;
mov.b32 {lowb,highb},%r2;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r13;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r13,d;
}
	// inline asm
	mov.u32 	%r18, 1224753664;
	mov.u32 	%r17, %r13;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r18;
mov.b32 {lowb,highb},%r2;
mov.b32 temp,{highb,highb};
mov.b32 c,%r17;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r17,d;
}
	// inline asm
	mov.u32 	%r22, 1107296256;
	mov.u32 	%r21, %r17;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r22;
mov.b32 {lowb,highb},%r5;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r21;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r21,d;
}
	// inline asm
	st.param.b32	[func_retval0+0], %r21;
	ret;
}

	// .globl	_Z11dy_c_fp16x2iii
.visible .func  (.param .b32 func_retval0) _Z11dy_c_fp16x2iii(
	.param .b32 _Z11dy_c_fp16x2iii_param_0,
	.param .b32 _Z11dy_c_fp16x2iii_param_1,
	.param .b32 _Z11dy_c_fp16x2iii_param_2
)
{
	.reg .s32 	%r<13>;


	ld.param.u32 	%r2, [_Z11dy_c_fp16x2iii_param_0];
	ld.param.u32 	%r6, [_Z11dy_c_fp16x2iii_param_1];
	ld.param.u32 	%r10, [_Z11dy_c_fp16x2iii_param_2];
	mov.u32 	%r11, 1107313152;
	mov.u32 	%r4, 0;
	mov.u32 	%r1, %r4;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r2;
mov.b32 b,%r11;
mov.b32 c,%r1;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1,d;
}
	// inline asm
	mov.u32 	%r7, 1224755456;
	mov.u32 	%r5, %r1;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r6;
mov.b32 b,%r7;
mov.b32 c,%r5;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r5,d;
}
	// inline asm
	mov.u32 	%r9, %r5;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r10;
mov.b32 b,%r11;
mov.b32 c,%r9;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r9,d;
}
	// inline asm
	st.param.b32	[func_retval0+0], %r9;
	ret;
}

	// .globl	_Z9dx_fp16x2i
.visible .func  (.param .b32 func_retval0) _Z9dx_fp16x2i(
	.param .b32 _Z9dx_fp16x2i_param_0
)
{
	.reg .s32 	%r<25>;


	ld.param.u32 	%r2, [_Z9dx_fp16x2i_param_0];
	mov.u32 	%r7, 1;
	mov.u32 	%r4, 31;
	// inline asm
	shfl.down.b32 %r1, %r2, %r7, %r4;
	// inline asm
	mov.u32 	%r12, 0;
	// inline asm
	shfl.up.b32 %r5, %r2, %r7, %r12;
	// inline asm
	mov.u32 	%r10, 48128;
	mov.u32 	%r9, %r12;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r10;
mov.b32 {lowb,highb},%r5;
mov.b32 temp,{highb,highb};
mov.b32 c,%r9;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r9,d;
}
	// inline asm
	mov.u32 	%r14, -1140850688;
	mov.u32 	%r13, %r9;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r14;
mov.b32 {lowb,highb},%r2;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r13;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r13,d;
}
	// inline asm
	mov.u32 	%r18, 15360;
	mov.u32 	%r17, %r13;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r18;
mov.b32 {lowb,highb},%r2;
mov.b32 temp,{highb,highb};
mov.b32 c,%r17;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r17,d;
}
	// inline asm
	mov.u32 	%r22, 1006632960;
	mov.u32 	%r21, %r17;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r22;
mov.b32 {lowb,highb},%r1;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r21;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r21,d;
}
	// inline asm
	st.param.b32	[func_retval0+0], %r21;
	ret;
}

	// .globl	_Z9dy_fp16x2ii
.visible .func  (.param .b32 func_retval0) _Z9dy_fp16x2ii(
	.param .b32 _Z9dy_fp16x2ii_param_0,
	.param .b32 _Z9dy_fp16x2ii_param_1
)
{
	.reg .s32 	%r<5>;


	ld.param.u32 	%r2, [_Z9dy_fp16x2ii_param_0];
	ld.param.u32 	%r4, [_Z9dy_fp16x2ii_param_1];
	mov.u32 	%r3, -1140802560;
	mov.u32 	%r1, %r4;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r2;
mov.b32 b,%r3;
mov.b32 c,%r1;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1,d;
}
	// inline asm
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .globl	_Z12acc_x_fp16x2i
.visible .func  (.param .b32 func_retval0) _Z12acc_x_fp16x2i(
	.param .b32 _Z12acc_x_fp16x2i_param_0
)
{
	.reg .s32 	%r<17>;


	ld.param.u32 	%r2, [_Z12acc_x_fp16x2i_param_0];
	mov.u32 	%r7, 1;
	mov.u32 	%r4, 0;
	// inline asm
	shfl.up.b32 %r1, %r2, %r7, %r4;
	// inline asm
	mov.u32 	%r8, 31;
	// inline asm
	shfl.down.b32 %r5, %r2, %r7, %r8;
	// inline asm
	mov.u32 	%r11, 1006632960;
	mov.u32 	%r9, %r2;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1;
mov.b32 b,%r11;
mov.b32 c,%r9;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r9,d;
}
	// inline asm
	mov.u32 	%r15, 15360;
	mov.u32 	%r13, %r9;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r5;
mov.b32 b,%r15;
mov.b32 c,%r13;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r13,d;
}
	// inline asm
	st.param.b32	[func_retval0+0], %r13;
	ret;
}

	// .globl	_Z22harris3x3Kernel_fp16x2Pjifiiy
.visible .entry _Z22harris3x3Kernel_fp16x2Pjifiiy(
	.param .u64 _Z22harris3x3Kernel_fp16x2Pjifiiy_param_0,
	.param .u32 _Z22harris3x3Kernel_fp16x2Pjifiiy_param_1,
	.param .f32 _Z22harris3x3Kernel_fp16x2Pjifiiy_param_2,
	.param .u32 _Z22harris3x3Kernel_fp16x2Pjifiiy_param_3,
	.param .u32 _Z22harris3x3Kernel_fp16x2Pjifiiy_param_4,
	.param .u64 _Z22harris3x3Kernel_fp16x2Pjifiiy_param_5
)
{
	.reg .pred 	%p<21>;
	.reg .s16 	%rs<17>;
	.reg .f32 	%f<50>;
	.reg .s32 	%r<1924>;
	.reg .s64 	%rd<31>;


	ld.param.u64 	%rd14, [_Z22harris3x3Kernel_fp16x2Pjifiiy_param_0];
	ld.param.u32 	%r71, [_Z22harris3x3Kernel_fp16x2Pjifiiy_param_1];
	ld.param.f32 	%f9, [_Z22harris3x3Kernel_fp16x2Pjifiiy_param_2];
	ld.param.u32 	%r504, [_Z22harris3x3Kernel_fp16x2Pjifiiy_param_3];
	ld.param.u64 	%rd2, [_Z22harris3x3Kernel_fp16x2Pjifiiy_param_5];
	mov.u32 	%r505, %ctaid.x;
	mov.u32 	%r506, %tid.x;
	mad.lo.s32 	%r507, %r505, 30, %r506;
	add.s32 	%r74, %r507, 4;
	mov.u32 	%r508, %ctaid.y;
	shl.b32 	%r509, %r508, 5;
	mov.u32 	%r510, %tid.y;
	shl.b32 	%r511, %r510, 3;
	add.s32 	%r79, %r511, %r509;
	add.s32 	%r75, %r79, -1;
	// inline asm
	{ .reg .b32 p0;
.reg .b32 p1;
tex.2d.v2.f16x2.s32 {p0,p1},[%rd2,{%r74,%r75}];
mov.b32 %r72,p0;
mov.b32 %r73,p1;
}
	// inline asm
	// inline asm
	{ .reg .b32 p0;
.reg .b32 p1;
tex.2d.v2.f16x2.s32 {p0,p1},[%rd2,{%r74,%r79}];
mov.b32 %r76,p0;
mov.b32 %r77,p1;
}
	// inline asm
	add.s32 	%r83, %r79, 1;
	// inline asm
	{ .reg .b32 p0;
.reg .b32 p1;
tex.2d.v2.f16x2.s32 {p0,p1},[%rd2,{%r74,%r83}];
mov.b32 %r80,p0;
mov.b32 %r81,p1;
}
	// inline asm
	add.s32 	%r87, %r79, 2;
	// inline asm
	{ .reg .b32 p0;
.reg .b32 p1;
tex.2d.v2.f16x2.s32 {p0,p1},[%rd2,{%r74,%r87}];
mov.b32 %r84,p0;
mov.b32 %r85,p1;
}
	// inline asm
	add.s32 	%r91, %r79, 3;
	// inline asm
	{ .reg .b32 p0;
.reg .b32 p1;
tex.2d.v2.f16x2.s32 {p0,p1},[%rd2,{%r74,%r91}];
mov.b32 %r88,p0;
mov.b32 %r89,p1;
}
	// inline asm
	add.s32 	%r95, %r79, 4;
	// inline asm
	{ .reg .b32 p0;
.reg .b32 p1;
tex.2d.v2.f16x2.s32 {p0,p1},[%rd2,{%r74,%r95}];
mov.b32 %r92,p0;
mov.b32 %r93,p1;
}
	// inline asm
	add.s32 	%r99, %r79, 5;
	// inline asm
	{ .reg .b32 p0;
.reg .b32 p1;
tex.2d.v2.f16x2.s32 {p0,p1},[%rd2,{%r74,%r99}];
mov.b32 %r96,p0;
mov.b32 %r97,p1;
}
	// inline asm
	add.s32 	%r103, %r79, 6;
	// inline asm
	{ .reg .b32 p0;
.reg .b32 p1;
tex.2d.v2.f16x2.s32 {p0,p1},[%rd2,{%r74,%r103}];
mov.b32 %r100,p0;
mov.b32 %r101,p1;
}
	// inline asm
	add.s32 	%r107, %r79, 7;
	// inline asm
	{ .reg .b32 p0;
.reg .b32 p1;
tex.2d.v2.f16x2.s32 {p0,p1},[%rd2,{%r74,%r107}];
mov.b32 %r104,p0;
mov.b32 %r105,p1;
}
	// inline asm
	add.s32 	%r111, %r79, 8;
	// inline asm
	{ .reg .b32 p0;
.reg .b32 p1;
tex.2d.v2.f16x2.s32 {p0,p1},[%rd2,{%r74,%r111}];
mov.b32 %r108,p0;
mov.b32 %r109,p1;
}
	// inline asm
	add.s32 	%r115, %r79, 9;
	// inline asm
	{ .reg .b32 p0;
.reg .b32 p1;
tex.2d.v2.f16x2.s32 {p0,p1},[%rd2,{%r74,%r115}];
mov.b32 %r112,p0;
mov.b32 %r113,p1;
}
	// inline asm
	add.s32 	%r119, %r79, 10;
	// inline asm
	{ .reg .b32 p0;
.reg .b32 p1;
tex.2d.v2.f16x2.s32 {p0,p1},[%rd2,{%r74,%r119}];
mov.b32 %r116,p0;
mov.b32 %r117,p1;
}
	// inline asm
	cvta.to.global.u64 	%rd1, %rd14;
	mov.u32 	%r470, 1;
	mov.u32 	%r499, 0;
	// inline asm
	shfl.up.b32 %r120, %r72, %r470, %r499;
	// inline asm
	mov.u32 	%r471, 31;
	// inline asm
	shfl.down.b32 %r124, %r72, %r470, %r471;
	// inline asm
	mov.u32 	%r341, 16896;
	mov.u32 	%r128, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r341;
mov.b32 {lowb,highb},%r120;
mov.b32 temp,{highb,highb};
mov.b32 c,%r128;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r128,d;
}
	// inline asm
	mov.u32 	%r345, 1107314944;
	mov.u32 	%r132, %r128;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r345;
mov.b32 {lowb,highb},%r72;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r132;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r132,d;
}
	// inline asm
	mov.u32 	%r349, 1224753664;
	mov.u32 	%r136, %r132;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r349;
mov.b32 {lowb,highb},%r72;
mov.b32 temp,{highb,highb};
mov.b32 c,%r136;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r136,d;
}
	// inline asm
	mov.u32 	%r353, 1107296256;
	mov.u32 	%r140, %r136;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r353;
mov.b32 {lowb,highb},%r124;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r140;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r140,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r144, %r76, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r148, %r76, %r470, %r471;
	// inline asm
	mov.u32 	%r152, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r341;
mov.b32 {lowb,highb},%r144;
mov.b32 temp,{highb,highb};
mov.b32 c,%r152;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r152,d;
}
	// inline asm
	mov.u32 	%r156, %r152;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r345;
mov.b32 {lowb,highb},%r76;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r156;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r156,d;
}
	// inline asm
	mov.u32 	%r160, %r156;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r349;
mov.b32 {lowb,highb},%r76;
mov.b32 temp,{highb,highb};
mov.b32 c,%r160;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r160,d;
}
	// inline asm
	mov.u32 	%r164, %r160;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r353;
mov.b32 {lowb,highb},%r148;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r164;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r164,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r168, %r80, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r172, %r80, %r470, %r471;
	// inline asm
	mov.u32 	%r176, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r341;
mov.b32 {lowb,highb},%r168;
mov.b32 temp,{highb,highb};
mov.b32 c,%r176;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r176,d;
}
	// inline asm
	mov.u32 	%r180, %r176;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r345;
mov.b32 {lowb,highb},%r80;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r180;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r180,d;
}
	// inline asm
	mov.u32 	%r184, %r180;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r349;
mov.b32 {lowb,highb},%r80;
mov.b32 temp,{highb,highb};
mov.b32 c,%r184;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r184,d;
}
	// inline asm
	mov.u32 	%r188, %r184;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r353;
mov.b32 {lowb,highb},%r172;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r188;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r188,d;
}
	// inline asm
	mov.u32 	%r366, 1107313152;
	mov.u32 	%r192, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r72;
mov.b32 b,%r366;
mov.b32 c,%r192;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r192,d;
}
	// inline asm
	mov.u32 	%r362, 1224755456;
	mov.u32 	%r196, %r192;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r76;
mov.b32 b,%r362;
mov.b32 c,%r196;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r196,d;
}
	// inline asm
	mov.u32 	%r200, %r196;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r80;
mov.b32 b,%r366;
mov.b32 c,%r200;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r200,d;
}
	// inline asm
	// inline asm
	shfl.down.b32 %r204, %r200, %r470, %r471;
	// inline asm
	// inline asm
	shfl.up.b32 %r208, %r200, %r470, %r499;
	// inline asm
	mov.u32 	%r377, 48128;
	mov.u32 	%r212, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r377;
mov.b32 {lowb,highb},%r208;
mov.b32 temp,{highb,highb};
mov.b32 c,%r212;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r212,d;
}
	// inline asm
	mov.u32 	%r381, -1140850688;
	mov.u32 	%r216, %r212;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r381;
mov.b32 {lowb,highb},%r200;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r216;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r216,d;
}
	// inline asm
	mov.u32 	%r478, 15360;
	mov.u32 	%r220, %r216;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r478;
mov.b32 {lowb,highb},%r200;
mov.b32 temp,{highb,highb};
mov.b32 c,%r220;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r220,d;
}
	// inline asm
	mov.u32 	%r474, 1006632960;
	mov.u32 	%r224, %r220;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r474;
mov.b32 {lowb,highb},%r204;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r224;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r224,d;
}
	// inline asm
	mov.u32 	%r482, -1140802560;
	mov.u32 	%r228, %r188;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r140;
mov.b32 b,%r482;
mov.b32 c,%r228;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r228,d;
}
	// inline asm
	mov.u32 	%r232, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r224;
mov.b32 b,%r224;
mov.b32 c,%r232;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r232,d;
}
	// inline asm
	mov.u32 	%r236, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r224;
mov.b32 b,%r228;
mov.b32 c,%r236;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r236,d;
}
	// inline asm
	mov.u32 	%r240, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r228;
mov.b32 b,%r228;
mov.b32 c,%r240;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r240,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r244, %r84, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r248, %r84, %r470, %r471;
	// inline asm
	mov.u32 	%r252, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r341;
mov.b32 {lowb,highb},%r244;
mov.b32 temp,{highb,highb};
mov.b32 c,%r252;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r252,d;
}
	// inline asm
	mov.u32 	%r256, %r252;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r345;
mov.b32 {lowb,highb},%r84;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r256;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r256,d;
}
	// inline asm
	mov.u32 	%r260, %r256;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r349;
mov.b32 {lowb,highb},%r84;
mov.b32 temp,{highb,highb};
mov.b32 c,%r260;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r260,d;
}
	// inline asm
	mov.u32 	%r264, %r260;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r353;
mov.b32 {lowb,highb},%r248;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r264;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r264,d;
}
	// inline asm
	mov.u32 	%r268, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r76;
mov.b32 b,%r366;
mov.b32 c,%r268;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r268,d;
}
	// inline asm
	mov.u32 	%r272, %r268;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r80;
mov.b32 b,%r362;
mov.b32 c,%r272;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r272,d;
}
	// inline asm
	mov.u32 	%r276, %r272;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r84;
mov.b32 b,%r366;
mov.b32 c,%r276;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r276,d;
}
	// inline asm
	// inline asm
	shfl.down.b32 %r280, %r276, %r470, %r471;
	// inline asm
	// inline asm
	shfl.up.b32 %r284, %r276, %r470, %r499;
	// inline asm
	mov.u32 	%r288, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r377;
mov.b32 {lowb,highb},%r284;
mov.b32 temp,{highb,highb};
mov.b32 c,%r288;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r288,d;
}
	// inline asm
	mov.u32 	%r292, %r288;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r381;
mov.b32 {lowb,highb},%r276;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r292;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r292,d;
}
	// inline asm
	mov.u32 	%r296, %r292;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r478;
mov.b32 {lowb,highb},%r276;
mov.b32 temp,{highb,highb};
mov.b32 c,%r296;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r296,d;
}
	// inline asm
	mov.u32 	%r300, %r296;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r474;
mov.b32 {lowb,highb},%r280;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r300;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r300,d;
}
	// inline asm
	mov.u32 	%r304, %r264;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r164;
mov.b32 b,%r482;
mov.b32 c,%r304;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r304,d;
}
	// inline asm
	mov.u32 	%r308, %r232;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r300;
mov.b32 b,%r300;
mov.b32 c,%r308;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r308,d;
}
	// inline asm
	mov.u32 	%r312, %r236;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r300;
mov.b32 b,%r304;
mov.b32 c,%r312;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r312,d;
}
	// inline asm
	mov.u32 	%r316, %r240;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r304;
mov.b32 b,%r304;
mov.b32 c,%r316;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r316,d;
}
	// inline asm
	mov.u32 	%r320, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r300;
mov.b32 b,%r300;
mov.b32 c,%r320;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r320,d;
}
	// inline asm
	mov.u32 	%r324, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r300;
mov.b32 b,%r304;
mov.b32 c,%r324;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r324,d;
}
	// inline asm
	mov.u32 	%r328, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r304;
mov.b32 b,%r304;
mov.b32 c,%r328;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r328,d;
}
	// inline asm
	setp.lt.u32	%p9, %r506, 31;
	setp.ne.s32	%p10, %r506, 0;
	and.pred  	%p1, %p9, %p10;
	shl.b32 	%r12, %r74, 1;
	add.s32 	%r512, %r504, 7;
	shr.s32 	%r513, %r512, 31;
	shr.u32 	%r514, %r513, 29;
	add.s32 	%r515, %r512, %r514;
	shr.s32 	%r13, %r515, 3;
	// inline asm
	shfl.up.b32 %r332, %r88, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r336, %r88, %r470, %r471;
	// inline asm
	mov.u32 	%r340, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r341;
mov.b32 {lowb,highb},%r332;
mov.b32 temp,{highb,highb};
mov.b32 c,%r340;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r340,d;
}
	// inline asm
	mov.u32 	%r344, %r340;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r345;
mov.b32 {lowb,highb},%r88;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r344;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r344,d;
}
	// inline asm
	mov.u32 	%r348, %r344;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r349;
mov.b32 {lowb,highb},%r88;
mov.b32 temp,{highb,highb};
mov.b32 c,%r348;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r348,d;
}
	// inline asm
	mov.u32 	%r352, %r348;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r353;
mov.b32 {lowb,highb},%r336;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r352;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r352,d;
}
	// inline asm
	mov.u32 	%r356, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r80;
mov.b32 b,%r366;
mov.b32 c,%r356;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r356,d;
}
	// inline asm
	mov.u32 	%r360, %r356;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r84;
mov.b32 b,%r362;
mov.b32 c,%r360;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r360,d;
}
	// inline asm
	mov.u32 	%r364, %r360;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r88;
mov.b32 b,%r366;
mov.b32 c,%r364;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r364,d;
}
	// inline asm
	// inline asm
	shfl.down.b32 %r368, %r364, %r470, %r471;
	// inline asm
	// inline asm
	shfl.up.b32 %r372, %r364, %r470, %r499;
	// inline asm
	mov.u32 	%r376, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r377;
mov.b32 {lowb,highb},%r372;
mov.b32 temp,{highb,highb};
mov.b32 c,%r376;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r376,d;
}
	// inline asm
	mov.u32 	%r380, %r376;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r381;
mov.b32 {lowb,highb},%r364;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r380;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r380,d;
}
	// inline asm
	mov.u32 	%r384, %r380;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r478;
mov.b32 {lowb,highb},%r364;
mov.b32 temp,{highb,highb};
mov.b32 c,%r384;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r384,d;
}
	// inline asm
	mov.u32 	%r388, %r384;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r474;
mov.b32 {lowb,highb},%r368;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r388;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r388,d;
}
	// inline asm
	mov.u32 	%r392, %r352;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r188;
mov.b32 b,%r482;
mov.b32 c,%r392;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r392,d;
}
	// inline asm
	mov.u32 	%r396, %r308;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r388;
mov.b32 b,%r388;
mov.b32 c,%r396;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r396,d;
}
	// inline asm
	mov.u32 	%r400, %r312;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r388;
mov.b32 b,%r392;
mov.b32 c,%r400;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r400,d;
}
	// inline asm
	mov.u32 	%r404, %r316;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r392;
mov.b32 b,%r392;
mov.b32 c,%r404;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r404,d;
}
	// inline asm
	mov.u32 	%r408, %r320;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r388;
mov.b32 b,%r388;
mov.b32 c,%r408;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r408,d;
}
	// inline asm
	mov.u32 	%r412, %r324;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r388;
mov.b32 b,%r392;
mov.b32 c,%r412;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r412,d;
}
	// inline asm
	mov.u32 	%r416, %r328;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r392;
mov.b32 b,%r392;
mov.b32 c,%r416;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r416,d;
}
	// inline asm
	mov.u32 	%r420, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r388;
mov.b32 b,%r388;
mov.b32 c,%r420;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r420,d;
}
	// inline asm
	mov.u32 	%r424, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r388;
mov.b32 b,%r392;
mov.b32 c,%r424;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r424,d;
}
	// inline asm
	mov.u32 	%r428, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r392;
mov.b32 b,%r392;
mov.b32 c,%r428;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r428,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r432, %r396, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r436, %r396, %r470, %r471;
	// inline asm
	mov.u32 	%r440, %r396;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r432;
mov.b32 b,%r474;
mov.b32 c,%r440;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r440,d;
}
	// inline asm
	mov.u32 	%r444, %r440;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r436;
mov.b32 b,%r478;
mov.b32 c,%r444;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r444,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r448, %r400, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r452, %r400, %r470, %r471;
	// inline asm
	mov.u32 	%r456, %r400;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r448;
mov.b32 b,%r474;
mov.b32 c,%r456;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r456,d;
}
	// inline asm
	mov.u32 	%r460, %r456;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r452;
mov.b32 b,%r478;
mov.b32 c,%r460;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r460,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r464, %r404, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r468, %r404, %r470, %r471;
	// inline asm
	mov.u32 	%r472, %r404;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r464;
mov.b32 b,%r474;
mov.b32 c,%r472;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r472,d;
}
	// inline asm
	mov.u32 	%r476, %r472;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r468;
mov.b32 b,%r478;
mov.b32 c,%r476;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r476,d;
}
	// inline asm
	mov.u32 	%r480, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r460;
mov.b32 b,%r482;
mov.b32 c,%r480;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r480,d;
}
	// inline asm
	mov.u32 	%r484, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r444;
mov.b32 b,%r476;
mov.b32 c,%r484;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r484,d;
}
	// inline asm
	mov.u32 	%r488, %r484;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r460;
mov.b32 b,%r480;
mov.b32 c,%r488;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r488,d;
}
	// inline asm
	mov.u32 	%r494, 1006648320;
	mov.u32 	%r492, %r444;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r476;
mov.b32 b,%r494;
mov.b32 c,%r492;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r492,d;
}
	// inline asm
	mov.u32 	%r496, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r492;
mov.b32 b,%r492;
mov.b32 c,%r496;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r496,d;
}
	// inline asm
	mov.u32 	%r500, %r488;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r496;
mov.b32 b,%r71;
mov.b32 c,%r500;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r500,d;
}
	// inline asm
	@!%p1 bra 	BB17_3;
	bra.uni 	BB17_1;

BB17_1:
	// inline asm
	{ .reg .f16 low,high;
  mov.b32 {low,high}, %r500;
  mov.b16 %rs1,high;}
	// inline asm
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs1;
	cvt.f32.f16 	%f10, %temp;
	}
	// inline asm
	{ .reg .f16 low,high;
  mov.b32 {low,high}, %r500;
  mov.b16 %rs2,low;}
	// inline asm
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs2;
	cvt.f32.f16 	%f11, %temp;
	}
	setp.gt.ftz.f32	%p2, %f10, %f11;
	selp.f32	%f1, %f10, %f11, %p2;
	setp.ltu.ftz.f32	%p11, %f1, %f9;
	@%p11 bra 	BB17_3;

	selp.u32	%r518, 1, 0, %p2;
	xor.b32  	%r519, %r518, 1;
	add.s32 	%r520, %r519, %r12;
	sub.ftz.f32 	%f12, %f1, %f9;
	mov.f32 	%f13, 0f457A0000;
	min.ftz.f32 	%f14, %f13, %f12;
	cvt.rzi.ftz.s32.f32	%r521, %f14;
	shr.s32 	%r522, %r520, 31;
	shr.u32 	%r523, %r522, 29;
	add.s32 	%r524, %r520, %r523;
	shr.s32 	%r525, %r524, 3;
	and.b32  	%r526, %r524, -8;
	sub.s32 	%r527, %r520, %r526;
	shr.s32 	%r528, %r79, 31;
	shr.u32 	%r529, %r528, 29;
	add.s32 	%r530, %r79, %r529;
	shr.s32 	%r531, %r530, 3;
	and.b32  	%r532, %r530, -8;
	sub.s32 	%r533, %r79, %r532;
	mad.lo.s32 	%r534, %r531, %r13, %r525;
	shl.b32 	%r535, %r533, 3;
	add.s32 	%r536, %r527, %r535;
	shl.b32 	%r537, %r521, 20;
	or.b32  	%r538, %r536, %r537;
	mul.wide.s32 	%rd15, %r534, 4;
	add.s64 	%rd16, %rd1, %rd15;
	atom.global.max.u32 	%r539, [%rd16], %r538;

BB17_3:
	// inline asm
	shfl.up.b32 %r540, %r92, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r544, %r92, %r470, %r471;
	// inline asm
	mov.u32 	%r548, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r341;
mov.b32 {lowb,highb},%r540;
mov.b32 temp,{highb,highb};
mov.b32 c,%r548;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r548,d;
}
	// inline asm
	mov.u32 	%r552, %r548;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r345;
mov.b32 {lowb,highb},%r92;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r552;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r552,d;
}
	// inline asm
	mov.u32 	%r556, %r552;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r349;
mov.b32 {lowb,highb},%r92;
mov.b32 temp,{highb,highb};
mov.b32 c,%r556;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r556,d;
}
	// inline asm
	mov.u32 	%r560, %r556;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r353;
mov.b32 {lowb,highb},%r544;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r560;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r560,d;
}
	// inline asm
	mov.u32 	%r564, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r84;
mov.b32 b,%r366;
mov.b32 c,%r564;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r564,d;
}
	// inline asm
	mov.u32 	%r568, %r564;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r88;
mov.b32 b,%r362;
mov.b32 c,%r568;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r568,d;
}
	// inline asm
	mov.u32 	%r572, %r568;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r92;
mov.b32 b,%r366;
mov.b32 c,%r572;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r572,d;
}
	// inline asm
	// inline asm
	shfl.down.b32 %r576, %r572, %r470, %r471;
	// inline asm
	// inline asm
	shfl.up.b32 %r580, %r572, %r470, %r499;
	// inline asm
	mov.u32 	%r584, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r377;
mov.b32 {lowb,highb},%r580;
mov.b32 temp,{highb,highb};
mov.b32 c,%r584;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r584,d;
}
	// inline asm
	mov.u32 	%r588, %r584;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r381;
mov.b32 {lowb,highb},%r572;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r588;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r588,d;
}
	// inline asm
	mov.u32 	%r592, %r588;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r478;
mov.b32 {lowb,highb},%r572;
mov.b32 temp,{highb,highb};
mov.b32 c,%r592;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r592,d;
}
	// inline asm
	mov.u32 	%r596, %r592;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r474;
mov.b32 {lowb,highb},%r576;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r596;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r596,d;
}
	// inline asm
	mov.u32 	%r600, %r560;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r264;
mov.b32 b,%r482;
mov.b32 c,%r600;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r600,d;
}
	// inline asm
	mov.u32 	%r604, %r408;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r596;
mov.b32 b,%r596;
mov.b32 c,%r604;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r604,d;
}
	// inline asm
	mov.u32 	%r608, %r412;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r596;
mov.b32 b,%r600;
mov.b32 c,%r608;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r608,d;
}
	// inline asm
	mov.u32 	%r612, %r416;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r600;
mov.b32 b,%r600;
mov.b32 c,%r612;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r612,d;
}
	// inline asm
	mov.u32 	%r616, %r420;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r596;
mov.b32 b,%r596;
mov.b32 c,%r616;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r616,d;
}
	// inline asm
	mov.u32 	%r620, %r424;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r596;
mov.b32 b,%r600;
mov.b32 c,%r620;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r620,d;
}
	// inline asm
	mov.u32 	%r624, %r428;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r600;
mov.b32 b,%r600;
mov.b32 c,%r624;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r624,d;
}
	// inline asm
	mov.u32 	%r628, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r596;
mov.b32 b,%r596;
mov.b32 c,%r628;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r628,d;
}
	// inline asm
	mov.u32 	%r632, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r596;
mov.b32 b,%r600;
mov.b32 c,%r632;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r632,d;
}
	// inline asm
	mov.u32 	%r636, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r600;
mov.b32 b,%r600;
mov.b32 c,%r636;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r636,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r640, %r604, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r644, %r604, %r470, %r471;
	// inline asm
	mov.u32 	%r648, %r604;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r640;
mov.b32 b,%r474;
mov.b32 c,%r648;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r648,d;
}
	// inline asm
	mov.u32 	%r652, %r648;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r644;
mov.b32 b,%r478;
mov.b32 c,%r652;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r652,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r656, %r608, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r660, %r608, %r470, %r471;
	// inline asm
	mov.u32 	%r664, %r608;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r656;
mov.b32 b,%r474;
mov.b32 c,%r664;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r664,d;
}
	// inline asm
	mov.u32 	%r668, %r664;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r660;
mov.b32 b,%r478;
mov.b32 c,%r668;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r668,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r672, %r612, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r676, %r612, %r470, %r471;
	// inline asm
	mov.u32 	%r680, %r612;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r672;
mov.b32 b,%r474;
mov.b32 c,%r680;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r680,d;
}
	// inline asm
	mov.u32 	%r684, %r680;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r676;
mov.b32 b,%r478;
mov.b32 c,%r684;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r684,d;
}
	// inline asm
	mov.u32 	%r688, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r668;
mov.b32 b,%r482;
mov.b32 c,%r688;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r688,d;
}
	// inline asm
	mov.u32 	%r692, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r652;
mov.b32 b,%r684;
mov.b32 c,%r692;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r692,d;
}
	// inline asm
	mov.u32 	%r696, %r692;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r668;
mov.b32 b,%r688;
mov.b32 c,%r696;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r696,d;
}
	// inline asm
	mov.u32 	%r700, %r652;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r684;
mov.b32 b,%r494;
mov.b32 c,%r700;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r700,d;
}
	// inline asm
	mov.u32 	%r704, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r700;
mov.b32 b,%r700;
mov.b32 c,%r704;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r704,d;
}
	// inline asm
	mov.u32 	%r708, %r696;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r704;
mov.b32 b,%r71;
mov.b32 c,%r708;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r708,d;
}
	// inline asm
	@!%p1 bra 	BB17_6;
	bra.uni 	BB17_4;

BB17_4:
	// inline asm
	{ .reg .f16 low,high;
  mov.b32 {low,high}, %r708;
  mov.b16 %rs3,high;}
	// inline asm
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs3;
	cvt.f32.f16 	%f15, %temp;
	}
	// inline asm
	{ .reg .f16 low,high;
  mov.b32 {low,high}, %r708;
  mov.b16 %rs4,low;}
	// inline asm
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs4;
	cvt.f32.f16 	%f16, %temp;
	}
	setp.gt.ftz.f32	%p3, %f15, %f16;
	selp.f32	%f2, %f15, %f16, %p3;
	setp.ltu.ftz.f32	%p12, %f2, %f9;
	@%p12 bra 	BB17_6;

	add.s32 	%r1923, %r79, 1;
	selp.u32	%r714, 1, 0, %p3;
	xor.b32  	%r715, %r714, 1;
	add.s32 	%r716, %r715, %r12;
	sub.ftz.f32 	%f17, %f2, %f9;
	mov.f32 	%f18, 0f457A0000;
	min.ftz.f32 	%f19, %f18, %f17;
	cvt.rzi.ftz.s32.f32	%r717, %f19;
	shr.s32 	%r719, %r1923, 31;
	shr.u32 	%r720, %r719, 29;
	add.s32 	%r721, %r1923, %r720;
	shr.s32 	%r722, %r721, 3;
	shr.s32 	%r723, %r716, 31;
	shr.u32 	%r724, %r723, 29;
	add.s32 	%r725, %r716, %r724;
	shr.s32 	%r726, %r725, 3;
	and.b32  	%r727, %r725, -8;
	sub.s32 	%r728, %r716, %r727;
	and.b32  	%r729, %r721, -8;
	sub.s32 	%r730, %r1923, %r729;
	mad.lo.s32 	%r731, %r722, %r13, %r726;
	shl.b32 	%r732, %r730, 3;
	add.s32 	%r733, %r728, %r732;
	shl.b32 	%r734, %r717, 20;
	or.b32  	%r735, %r733, %r734;
	mul.wide.s32 	%rd17, %r731, 4;
	add.s64 	%rd18, %rd1, %rd17;
	atom.global.max.u32 	%r736, [%rd18], %r735;

BB17_6:
	// inline asm
	shfl.up.b32 %r737, %r96, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r741, %r96, %r470, %r471;
	// inline asm
	mov.u32 	%r745, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r341;
mov.b32 {lowb,highb},%r737;
mov.b32 temp,{highb,highb};
mov.b32 c,%r745;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r745,d;
}
	// inline asm
	mov.u32 	%r749, %r745;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r345;
mov.b32 {lowb,highb},%r96;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r749;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r749,d;
}
	// inline asm
	mov.u32 	%r753, %r749;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r349;
mov.b32 {lowb,highb},%r96;
mov.b32 temp,{highb,highb};
mov.b32 c,%r753;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r753,d;
}
	// inline asm
	mov.u32 	%r757, %r753;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r353;
mov.b32 {lowb,highb},%r741;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r757;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r757,d;
}
	// inline asm
	mov.u32 	%r761, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r88;
mov.b32 b,%r366;
mov.b32 c,%r761;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r761,d;
}
	// inline asm
	mov.u32 	%r765, %r761;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r92;
mov.b32 b,%r362;
mov.b32 c,%r765;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r765,d;
}
	// inline asm
	mov.u32 	%r769, %r765;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r96;
mov.b32 b,%r366;
mov.b32 c,%r769;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r769,d;
}
	// inline asm
	// inline asm
	shfl.down.b32 %r773, %r769, %r470, %r471;
	// inline asm
	// inline asm
	shfl.up.b32 %r777, %r769, %r470, %r499;
	// inline asm
	mov.u32 	%r781, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r377;
mov.b32 {lowb,highb},%r777;
mov.b32 temp,{highb,highb};
mov.b32 c,%r781;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r781,d;
}
	// inline asm
	mov.u32 	%r785, %r781;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r381;
mov.b32 {lowb,highb},%r769;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r785;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r785,d;
}
	// inline asm
	mov.u32 	%r789, %r785;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r478;
mov.b32 {lowb,highb},%r769;
mov.b32 temp,{highb,highb};
mov.b32 c,%r789;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r789,d;
}
	// inline asm
	mov.u32 	%r793, %r789;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r474;
mov.b32 {lowb,highb},%r773;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r793;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r793,d;
}
	// inline asm
	mov.u32 	%r797, %r757;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r352;
mov.b32 b,%r482;
mov.b32 c,%r797;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r797,d;
}
	// inline asm
	mov.u32 	%r801, %r616;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r793;
mov.b32 b,%r793;
mov.b32 c,%r801;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r801,d;
}
	// inline asm
	mov.u32 	%r805, %r620;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r793;
mov.b32 b,%r797;
mov.b32 c,%r805;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r805,d;
}
	// inline asm
	mov.u32 	%r809, %r624;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r797;
mov.b32 b,%r797;
mov.b32 c,%r809;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r809,d;
}
	// inline asm
	mov.u32 	%r813, %r628;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r793;
mov.b32 b,%r793;
mov.b32 c,%r813;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r813,d;
}
	// inline asm
	mov.u32 	%r817, %r632;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r793;
mov.b32 b,%r797;
mov.b32 c,%r817;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r817,d;
}
	// inline asm
	mov.u32 	%r821, %r636;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r797;
mov.b32 b,%r797;
mov.b32 c,%r821;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r821,d;
}
	// inline asm
	mov.u32 	%r825, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r793;
mov.b32 b,%r793;
mov.b32 c,%r825;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r825,d;
}
	// inline asm
	mov.u32 	%r829, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r793;
mov.b32 b,%r797;
mov.b32 c,%r829;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r829,d;
}
	// inline asm
	mov.u32 	%r833, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r797;
mov.b32 b,%r797;
mov.b32 c,%r833;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r833,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r837, %r801, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r841, %r801, %r470, %r471;
	// inline asm
	mov.u32 	%r845, %r801;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r837;
mov.b32 b,%r474;
mov.b32 c,%r845;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r845,d;
}
	// inline asm
	mov.u32 	%r849, %r845;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r841;
mov.b32 b,%r478;
mov.b32 c,%r849;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r849,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r853, %r805, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r857, %r805, %r470, %r471;
	// inline asm
	mov.u32 	%r861, %r805;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r853;
mov.b32 b,%r474;
mov.b32 c,%r861;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r861,d;
}
	// inline asm
	mov.u32 	%r865, %r861;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r857;
mov.b32 b,%r478;
mov.b32 c,%r865;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r865,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r869, %r809, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r873, %r809, %r470, %r471;
	// inline asm
	mov.u32 	%r877, %r809;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r869;
mov.b32 b,%r474;
mov.b32 c,%r877;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r877,d;
}
	// inline asm
	mov.u32 	%r881, %r877;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r873;
mov.b32 b,%r478;
mov.b32 c,%r881;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r881,d;
}
	// inline asm
	mov.u32 	%r885, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r865;
mov.b32 b,%r482;
mov.b32 c,%r885;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r885,d;
}
	// inline asm
	mov.u32 	%r889, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r849;
mov.b32 b,%r881;
mov.b32 c,%r889;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r889,d;
}
	// inline asm
	mov.u32 	%r893, %r889;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r865;
mov.b32 b,%r885;
mov.b32 c,%r893;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r893,d;
}
	// inline asm
	mov.u32 	%r897, %r849;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r881;
mov.b32 b,%r494;
mov.b32 c,%r897;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r897,d;
}
	// inline asm
	mov.u32 	%r901, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r897;
mov.b32 b,%r897;
mov.b32 c,%r901;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r901,d;
}
	// inline asm
	mov.u32 	%r905, %r893;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r901;
mov.b32 b,%r71;
mov.b32 c,%r905;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r905,d;
}
	// inline asm
	@!%p1 bra 	BB17_9;
	bra.uni 	BB17_7;

BB17_7:
	// inline asm
	{ .reg .f16 low,high;
  mov.b32 {low,high}, %r905;
  mov.b16 %rs5,high;}
	// inline asm
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs5;
	cvt.f32.f16 	%f20, %temp;
	}
	// inline asm
	{ .reg .f16 low,high;
  mov.b32 {low,high}, %r905;
  mov.b16 %rs6,low;}
	// inline asm
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs6;
	cvt.f32.f16 	%f21, %temp;
	}
	setp.gt.ftz.f32	%p4, %f20, %f21;
	selp.f32	%f3, %f20, %f21, %p4;
	setp.ltu.ftz.f32	%p13, %f3, %f9;
	@%p13 bra 	BB17_9;

	add.s32 	%r1922, %r79, 2;
	selp.u32	%r911, 1, 0, %p4;
	xor.b32  	%r912, %r911, 1;
	add.s32 	%r913, %r912, %r12;
	sub.ftz.f32 	%f22, %f3, %f9;
	mov.f32 	%f23, 0f457A0000;
	min.ftz.f32 	%f24, %f23, %f22;
	cvt.rzi.ftz.s32.f32	%r914, %f24;
	shr.s32 	%r916, %r1922, 31;
	shr.u32 	%r917, %r916, 29;
	add.s32 	%r918, %r1922, %r917;
	shr.s32 	%r919, %r918, 3;
	shr.s32 	%r920, %r913, 31;
	shr.u32 	%r921, %r920, 29;
	add.s32 	%r922, %r913, %r921;
	shr.s32 	%r923, %r922, 3;
	and.b32  	%r924, %r922, -8;
	sub.s32 	%r925, %r913, %r924;
	and.b32  	%r926, %r918, -8;
	sub.s32 	%r927, %r1922, %r926;
	mad.lo.s32 	%r928, %r919, %r13, %r923;
	shl.b32 	%r929, %r927, 3;
	add.s32 	%r930, %r925, %r929;
	shl.b32 	%r931, %r914, 20;
	or.b32  	%r932, %r930, %r931;
	mul.wide.s32 	%rd19, %r928, 4;
	add.s64 	%rd20, %rd1, %rd19;
	atom.global.max.u32 	%r933, [%rd20], %r932;

BB17_9:
	// inline asm
	shfl.up.b32 %r934, %r100, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r938, %r100, %r470, %r471;
	// inline asm
	mov.u32 	%r942, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r341;
mov.b32 {lowb,highb},%r934;
mov.b32 temp,{highb,highb};
mov.b32 c,%r942;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r942,d;
}
	// inline asm
	mov.u32 	%r946, %r942;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r345;
mov.b32 {lowb,highb},%r100;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r946;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r946,d;
}
	// inline asm
	mov.u32 	%r950, %r946;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r349;
mov.b32 {lowb,highb},%r100;
mov.b32 temp,{highb,highb};
mov.b32 c,%r950;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r950,d;
}
	// inline asm
	mov.u32 	%r954, %r950;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r353;
mov.b32 {lowb,highb},%r938;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r954;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r954,d;
}
	// inline asm
	mov.u32 	%r958, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r92;
mov.b32 b,%r366;
mov.b32 c,%r958;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r958,d;
}
	// inline asm
	mov.u32 	%r962, %r958;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r96;
mov.b32 b,%r362;
mov.b32 c,%r962;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r962,d;
}
	// inline asm
	mov.u32 	%r966, %r962;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r100;
mov.b32 b,%r366;
mov.b32 c,%r966;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r966,d;
}
	// inline asm
	// inline asm
	shfl.down.b32 %r970, %r966, %r470, %r471;
	// inline asm
	// inline asm
	shfl.up.b32 %r974, %r966, %r470, %r499;
	// inline asm
	mov.u32 	%r978, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r377;
mov.b32 {lowb,highb},%r974;
mov.b32 temp,{highb,highb};
mov.b32 c,%r978;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r978,d;
}
	// inline asm
	mov.u32 	%r982, %r978;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r381;
mov.b32 {lowb,highb},%r966;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r982;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r982,d;
}
	// inline asm
	mov.u32 	%r986, %r982;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r478;
mov.b32 {lowb,highb},%r966;
mov.b32 temp,{highb,highb};
mov.b32 c,%r986;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r986,d;
}
	// inline asm
	mov.u32 	%r990, %r986;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r474;
mov.b32 {lowb,highb},%r970;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r990;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r990,d;
}
	// inline asm
	mov.u32 	%r994, %r954;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r560;
mov.b32 b,%r482;
mov.b32 c,%r994;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r994,d;
}
	// inline asm
	mov.u32 	%r998, %r813;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r990;
mov.b32 b,%r990;
mov.b32 c,%r998;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r998,d;
}
	// inline asm
	mov.u32 	%r1002, %r817;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r990;
mov.b32 b,%r994;
mov.b32 c,%r1002;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1002,d;
}
	// inline asm
	mov.u32 	%r1006, %r821;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r994;
mov.b32 b,%r994;
mov.b32 c,%r1006;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1006,d;
}
	// inline asm
	mov.u32 	%r1010, %r825;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r990;
mov.b32 b,%r990;
mov.b32 c,%r1010;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1010,d;
}
	// inline asm
	mov.u32 	%r1014, %r829;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r990;
mov.b32 b,%r994;
mov.b32 c,%r1014;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1014,d;
}
	// inline asm
	mov.u32 	%r1018, %r833;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r994;
mov.b32 b,%r994;
mov.b32 c,%r1018;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1018,d;
}
	// inline asm
	mov.u32 	%r1022, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r990;
mov.b32 b,%r990;
mov.b32 c,%r1022;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1022,d;
}
	// inline asm
	mov.u32 	%r1026, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r990;
mov.b32 b,%r994;
mov.b32 c,%r1026;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1026,d;
}
	// inline asm
	mov.u32 	%r1030, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r994;
mov.b32 b,%r994;
mov.b32 c,%r1030;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1030,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r1034, %r998, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r1038, %r998, %r470, %r471;
	// inline asm
	mov.u32 	%r1042, %r998;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1034;
mov.b32 b,%r474;
mov.b32 c,%r1042;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1042,d;
}
	// inline asm
	mov.u32 	%r1046, %r1042;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1038;
mov.b32 b,%r478;
mov.b32 c,%r1046;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1046,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r1050, %r1002, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r1054, %r1002, %r470, %r471;
	// inline asm
	mov.u32 	%r1058, %r1002;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1050;
mov.b32 b,%r474;
mov.b32 c,%r1058;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1058,d;
}
	// inline asm
	mov.u32 	%r1062, %r1058;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1054;
mov.b32 b,%r478;
mov.b32 c,%r1062;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1062,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r1066, %r1006, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r1070, %r1006, %r470, %r471;
	// inline asm
	mov.u32 	%r1074, %r1006;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1066;
mov.b32 b,%r474;
mov.b32 c,%r1074;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1074,d;
}
	// inline asm
	mov.u32 	%r1078, %r1074;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1070;
mov.b32 b,%r478;
mov.b32 c,%r1078;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1078,d;
}
	// inline asm
	mov.u32 	%r1082, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1062;
mov.b32 b,%r482;
mov.b32 c,%r1082;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1082,d;
}
	// inline asm
	mov.u32 	%r1086, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1046;
mov.b32 b,%r1078;
mov.b32 c,%r1086;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1086,d;
}
	// inline asm
	mov.u32 	%r1090, %r1086;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1062;
mov.b32 b,%r1082;
mov.b32 c,%r1090;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1090,d;
}
	// inline asm
	mov.u32 	%r1094, %r1046;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1078;
mov.b32 b,%r494;
mov.b32 c,%r1094;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1094,d;
}
	// inline asm
	mov.u32 	%r1098, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1094;
mov.b32 b,%r1094;
mov.b32 c,%r1098;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1098,d;
}
	// inline asm
	mov.u32 	%r1102, %r1090;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1098;
mov.b32 b,%r71;
mov.b32 c,%r1102;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1102,d;
}
	// inline asm
	@!%p1 bra 	BB17_12;
	bra.uni 	BB17_10;

BB17_10:
	// inline asm
	{ .reg .f16 low,high;
  mov.b32 {low,high}, %r1102;
  mov.b16 %rs7,high;}
	// inline asm
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs7;
	cvt.f32.f16 	%f25, %temp;
	}
	// inline asm
	{ .reg .f16 low,high;
  mov.b32 {low,high}, %r1102;
  mov.b16 %rs8,low;}
	// inline asm
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs8;
	cvt.f32.f16 	%f26, %temp;
	}
	setp.gt.ftz.f32	%p5, %f25, %f26;
	selp.f32	%f4, %f25, %f26, %p5;
	setp.ltu.ftz.f32	%p14, %f4, %f9;
	@%p14 bra 	BB17_12;

	add.s32 	%r1921, %r79, 3;
	selp.u32	%r1108, 1, 0, %p5;
	xor.b32  	%r1109, %r1108, 1;
	add.s32 	%r1110, %r1109, %r12;
	sub.ftz.f32 	%f27, %f4, %f9;
	mov.f32 	%f28, 0f457A0000;
	min.ftz.f32 	%f29, %f28, %f27;
	cvt.rzi.ftz.s32.f32	%r1111, %f29;
	shr.s32 	%r1113, %r1921, 31;
	shr.u32 	%r1114, %r1113, 29;
	add.s32 	%r1115, %r1921, %r1114;
	shr.s32 	%r1116, %r1115, 3;
	shr.s32 	%r1117, %r1110, 31;
	shr.u32 	%r1118, %r1117, 29;
	add.s32 	%r1119, %r1110, %r1118;
	shr.s32 	%r1120, %r1119, 3;
	and.b32  	%r1121, %r1119, -8;
	sub.s32 	%r1122, %r1110, %r1121;
	and.b32  	%r1123, %r1115, -8;
	sub.s32 	%r1124, %r1921, %r1123;
	mad.lo.s32 	%r1125, %r1116, %r13, %r1120;
	shl.b32 	%r1126, %r1124, 3;
	add.s32 	%r1127, %r1122, %r1126;
	shl.b32 	%r1128, %r1111, 20;
	or.b32  	%r1129, %r1127, %r1128;
	mul.wide.s32 	%rd21, %r1125, 4;
	add.s64 	%rd22, %rd1, %rd21;
	atom.global.max.u32 	%r1130, [%rd22], %r1129;

BB17_12:
	// inline asm
	shfl.up.b32 %r1131, %r104, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r1135, %r104, %r470, %r471;
	// inline asm
	mov.u32 	%r1139, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r341;
mov.b32 {lowb,highb},%r1131;
mov.b32 temp,{highb,highb};
mov.b32 c,%r1139;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1139,d;
}
	// inline asm
	mov.u32 	%r1143, %r1139;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r345;
mov.b32 {lowb,highb},%r104;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r1143;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1143,d;
}
	// inline asm
	mov.u32 	%r1147, %r1143;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r349;
mov.b32 {lowb,highb},%r104;
mov.b32 temp,{highb,highb};
mov.b32 c,%r1147;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1147,d;
}
	// inline asm
	mov.u32 	%r1151, %r1147;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r353;
mov.b32 {lowb,highb},%r1135;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r1151;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1151,d;
}
	// inline asm
	mov.u32 	%r1155, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r96;
mov.b32 b,%r366;
mov.b32 c,%r1155;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1155,d;
}
	// inline asm
	mov.u32 	%r1159, %r1155;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r100;
mov.b32 b,%r362;
mov.b32 c,%r1159;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1159,d;
}
	// inline asm
	mov.u32 	%r1163, %r1159;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r104;
mov.b32 b,%r366;
mov.b32 c,%r1163;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1163,d;
}
	// inline asm
	// inline asm
	shfl.down.b32 %r1167, %r1163, %r470, %r471;
	// inline asm
	// inline asm
	shfl.up.b32 %r1171, %r1163, %r470, %r499;
	// inline asm
	mov.u32 	%r1175, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r377;
mov.b32 {lowb,highb},%r1171;
mov.b32 temp,{highb,highb};
mov.b32 c,%r1175;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1175,d;
}
	// inline asm
	mov.u32 	%r1179, %r1175;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r381;
mov.b32 {lowb,highb},%r1163;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r1179;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1179,d;
}
	// inline asm
	mov.u32 	%r1183, %r1179;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r478;
mov.b32 {lowb,highb},%r1163;
mov.b32 temp,{highb,highb};
mov.b32 c,%r1183;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1183,d;
}
	// inline asm
	mov.u32 	%r1187, %r1183;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r474;
mov.b32 {lowb,highb},%r1167;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r1187;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1187,d;
}
	// inline asm
	mov.u32 	%r1191, %r1151;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r757;
mov.b32 b,%r482;
mov.b32 c,%r1191;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1191,d;
}
	// inline asm
	mov.u32 	%r1195, %r1010;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1187;
mov.b32 b,%r1187;
mov.b32 c,%r1195;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1195,d;
}
	// inline asm
	mov.u32 	%r1199, %r1014;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1187;
mov.b32 b,%r1191;
mov.b32 c,%r1199;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1199,d;
}
	// inline asm
	mov.u32 	%r1203, %r1018;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1191;
mov.b32 b,%r1191;
mov.b32 c,%r1203;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1203,d;
}
	// inline asm
	mov.u32 	%r1207, %r1022;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1187;
mov.b32 b,%r1187;
mov.b32 c,%r1207;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1207,d;
}
	// inline asm
	mov.u32 	%r1211, %r1026;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1187;
mov.b32 b,%r1191;
mov.b32 c,%r1211;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1211,d;
}
	// inline asm
	mov.u32 	%r1215, %r1030;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1191;
mov.b32 b,%r1191;
mov.b32 c,%r1215;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1215,d;
}
	// inline asm
	mov.u32 	%r1219, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1187;
mov.b32 b,%r1187;
mov.b32 c,%r1219;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1219,d;
}
	// inline asm
	mov.u32 	%r1223, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1187;
mov.b32 b,%r1191;
mov.b32 c,%r1223;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1223,d;
}
	// inline asm
	mov.u32 	%r1227, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1191;
mov.b32 b,%r1191;
mov.b32 c,%r1227;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1227,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r1231, %r1195, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r1235, %r1195, %r470, %r471;
	// inline asm
	mov.u32 	%r1239, %r1195;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1231;
mov.b32 b,%r474;
mov.b32 c,%r1239;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1239,d;
}
	// inline asm
	mov.u32 	%r1243, %r1239;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1235;
mov.b32 b,%r478;
mov.b32 c,%r1243;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1243,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r1247, %r1199, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r1251, %r1199, %r470, %r471;
	// inline asm
	mov.u32 	%r1255, %r1199;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1247;
mov.b32 b,%r474;
mov.b32 c,%r1255;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1255,d;
}
	// inline asm
	mov.u32 	%r1259, %r1255;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1251;
mov.b32 b,%r478;
mov.b32 c,%r1259;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1259,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r1263, %r1203, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r1267, %r1203, %r470, %r471;
	// inline asm
	mov.u32 	%r1271, %r1203;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1263;
mov.b32 b,%r474;
mov.b32 c,%r1271;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1271,d;
}
	// inline asm
	mov.u32 	%r1275, %r1271;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1267;
mov.b32 b,%r478;
mov.b32 c,%r1275;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1275,d;
}
	// inline asm
	mov.u32 	%r1279, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1259;
mov.b32 b,%r482;
mov.b32 c,%r1279;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1279,d;
}
	// inline asm
	mov.u32 	%r1283, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1243;
mov.b32 b,%r1275;
mov.b32 c,%r1283;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1283,d;
}
	// inline asm
	mov.u32 	%r1287, %r1283;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1259;
mov.b32 b,%r1279;
mov.b32 c,%r1287;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1287,d;
}
	// inline asm
	mov.u32 	%r1291, %r1243;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1275;
mov.b32 b,%r494;
mov.b32 c,%r1291;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1291,d;
}
	// inline asm
	mov.u32 	%r1295, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1291;
mov.b32 b,%r1291;
mov.b32 c,%r1295;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1295,d;
}
	// inline asm
	mov.u32 	%r1299, %r1287;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1295;
mov.b32 b,%r71;
mov.b32 c,%r1299;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1299,d;
}
	// inline asm
	@!%p1 bra 	BB17_15;
	bra.uni 	BB17_13;

BB17_13:
	// inline asm
	{ .reg .f16 low,high;
  mov.b32 {low,high}, %r1299;
  mov.b16 %rs9,high;}
	// inline asm
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs9;
	cvt.f32.f16 	%f30, %temp;
	}
	// inline asm
	{ .reg .f16 low,high;
  mov.b32 {low,high}, %r1299;
  mov.b16 %rs10,low;}
	// inline asm
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs10;
	cvt.f32.f16 	%f31, %temp;
	}
	setp.gt.ftz.f32	%p6, %f30, %f31;
	selp.f32	%f5, %f30, %f31, %p6;
	setp.ltu.ftz.f32	%p15, %f5, %f9;
	@%p15 bra 	BB17_15;

	add.s32 	%r1920, %r79, 4;
	selp.u32	%r1305, 1, 0, %p6;
	xor.b32  	%r1306, %r1305, 1;
	add.s32 	%r1307, %r1306, %r12;
	sub.ftz.f32 	%f32, %f5, %f9;
	mov.f32 	%f33, 0f457A0000;
	min.ftz.f32 	%f34, %f33, %f32;
	cvt.rzi.ftz.s32.f32	%r1308, %f34;
	shr.s32 	%r1310, %r1920, 31;
	shr.u32 	%r1311, %r1310, 29;
	add.s32 	%r1312, %r1920, %r1311;
	shr.s32 	%r1313, %r1312, 3;
	shr.s32 	%r1314, %r1307, 31;
	shr.u32 	%r1315, %r1314, 29;
	add.s32 	%r1316, %r1307, %r1315;
	shr.s32 	%r1317, %r1316, 3;
	and.b32  	%r1318, %r1316, -8;
	sub.s32 	%r1319, %r1307, %r1318;
	and.b32  	%r1320, %r1312, -8;
	sub.s32 	%r1321, %r1920, %r1320;
	mad.lo.s32 	%r1322, %r1313, %r13, %r1317;
	shl.b32 	%r1323, %r1321, 3;
	add.s32 	%r1324, %r1319, %r1323;
	shl.b32 	%r1325, %r1308, 20;
	or.b32  	%r1326, %r1324, %r1325;
	mul.wide.s32 	%rd23, %r1322, 4;
	add.s64 	%rd24, %rd1, %rd23;
	atom.global.max.u32 	%r1327, [%rd24], %r1326;

BB17_15:
	// inline asm
	shfl.up.b32 %r1328, %r108, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r1332, %r108, %r470, %r471;
	// inline asm
	mov.u32 	%r1336, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r341;
mov.b32 {lowb,highb},%r1328;
mov.b32 temp,{highb,highb};
mov.b32 c,%r1336;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1336,d;
}
	// inline asm
	mov.u32 	%r1340, %r1336;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r345;
mov.b32 {lowb,highb},%r108;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r1340;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1340,d;
}
	// inline asm
	mov.u32 	%r1344, %r1340;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r349;
mov.b32 {lowb,highb},%r108;
mov.b32 temp,{highb,highb};
mov.b32 c,%r1344;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1344,d;
}
	// inline asm
	mov.u32 	%r1348, %r1344;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r353;
mov.b32 {lowb,highb},%r1332;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r1348;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1348,d;
}
	// inline asm
	mov.u32 	%r1352, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r100;
mov.b32 b,%r366;
mov.b32 c,%r1352;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1352,d;
}
	// inline asm
	mov.u32 	%r1356, %r1352;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r104;
mov.b32 b,%r362;
mov.b32 c,%r1356;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1356,d;
}
	// inline asm
	mov.u32 	%r1360, %r1356;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r108;
mov.b32 b,%r366;
mov.b32 c,%r1360;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1360,d;
}
	// inline asm
	// inline asm
	shfl.down.b32 %r1364, %r1360, %r470, %r471;
	// inline asm
	// inline asm
	shfl.up.b32 %r1368, %r1360, %r470, %r499;
	// inline asm
	mov.u32 	%r1372, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r377;
mov.b32 {lowb,highb},%r1368;
mov.b32 temp,{highb,highb};
mov.b32 c,%r1372;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1372,d;
}
	// inline asm
	mov.u32 	%r1376, %r1372;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r381;
mov.b32 {lowb,highb},%r1360;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r1376;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1376,d;
}
	// inline asm
	mov.u32 	%r1380, %r1376;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r478;
mov.b32 {lowb,highb},%r1360;
mov.b32 temp,{highb,highb};
mov.b32 c,%r1380;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1380,d;
}
	// inline asm
	mov.u32 	%r1384, %r1380;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r474;
mov.b32 {lowb,highb},%r1364;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r1384;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1384,d;
}
	// inline asm
	mov.u32 	%r1388, %r1348;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r954;
mov.b32 b,%r482;
mov.b32 c,%r1388;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1388,d;
}
	// inline asm
	mov.u32 	%r1392, %r1207;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1384;
mov.b32 b,%r1384;
mov.b32 c,%r1392;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1392,d;
}
	// inline asm
	mov.u32 	%r1396, %r1211;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1384;
mov.b32 b,%r1388;
mov.b32 c,%r1396;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1396,d;
}
	// inline asm
	mov.u32 	%r1400, %r1215;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1388;
mov.b32 b,%r1388;
mov.b32 c,%r1400;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1400,d;
}
	// inline asm
	mov.u32 	%r1404, %r1219;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1384;
mov.b32 b,%r1384;
mov.b32 c,%r1404;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1404,d;
}
	// inline asm
	mov.u32 	%r1408, %r1223;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1384;
mov.b32 b,%r1388;
mov.b32 c,%r1408;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1408,d;
}
	// inline asm
	mov.u32 	%r1412, %r1227;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1388;
mov.b32 b,%r1388;
mov.b32 c,%r1412;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1412,d;
}
	// inline asm
	mov.u32 	%r1416, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1384;
mov.b32 b,%r1384;
mov.b32 c,%r1416;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1416,d;
}
	// inline asm
	mov.u32 	%r1420, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1384;
mov.b32 b,%r1388;
mov.b32 c,%r1420;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1420,d;
}
	// inline asm
	mov.u32 	%r1424, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1388;
mov.b32 b,%r1388;
mov.b32 c,%r1424;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1424,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r1428, %r1392, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r1432, %r1392, %r470, %r471;
	// inline asm
	mov.u32 	%r1436, %r1392;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1428;
mov.b32 b,%r474;
mov.b32 c,%r1436;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1436,d;
}
	// inline asm
	mov.u32 	%r1440, %r1436;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1432;
mov.b32 b,%r478;
mov.b32 c,%r1440;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1440,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r1444, %r1396, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r1448, %r1396, %r470, %r471;
	// inline asm
	mov.u32 	%r1452, %r1396;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1444;
mov.b32 b,%r474;
mov.b32 c,%r1452;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1452,d;
}
	// inline asm
	mov.u32 	%r1456, %r1452;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1448;
mov.b32 b,%r478;
mov.b32 c,%r1456;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1456,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r1460, %r1400, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r1464, %r1400, %r470, %r471;
	// inline asm
	mov.u32 	%r1468, %r1400;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1460;
mov.b32 b,%r474;
mov.b32 c,%r1468;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1468,d;
}
	// inline asm
	mov.u32 	%r1472, %r1468;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1464;
mov.b32 b,%r478;
mov.b32 c,%r1472;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1472,d;
}
	// inline asm
	mov.u32 	%r1476, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1456;
mov.b32 b,%r482;
mov.b32 c,%r1476;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1476,d;
}
	// inline asm
	mov.u32 	%r1480, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1440;
mov.b32 b,%r1472;
mov.b32 c,%r1480;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1480,d;
}
	// inline asm
	mov.u32 	%r1484, %r1480;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1456;
mov.b32 b,%r1476;
mov.b32 c,%r1484;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1484,d;
}
	// inline asm
	mov.u32 	%r1488, %r1440;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1472;
mov.b32 b,%r494;
mov.b32 c,%r1488;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1488,d;
}
	// inline asm
	mov.u32 	%r1492, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1488;
mov.b32 b,%r1488;
mov.b32 c,%r1492;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1492,d;
}
	// inline asm
	mov.u32 	%r1496, %r1484;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1492;
mov.b32 b,%r71;
mov.b32 c,%r1496;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1496,d;
}
	// inline asm
	@!%p1 bra 	BB17_18;
	bra.uni 	BB17_16;

BB17_16:
	// inline asm
	{ .reg .f16 low,high;
  mov.b32 {low,high}, %r1496;
  mov.b16 %rs11,high;}
	// inline asm
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs11;
	cvt.f32.f16 	%f35, %temp;
	}
	// inline asm
	{ .reg .f16 low,high;
  mov.b32 {low,high}, %r1496;
  mov.b16 %rs12,low;}
	// inline asm
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs12;
	cvt.f32.f16 	%f36, %temp;
	}
	setp.gt.ftz.f32	%p7, %f35, %f36;
	selp.f32	%f6, %f35, %f36, %p7;
	setp.ltu.ftz.f32	%p16, %f6, %f9;
	@%p16 bra 	BB17_18;

	add.s32 	%r1919, %r79, 5;
	selp.u32	%r1502, 1, 0, %p7;
	xor.b32  	%r1503, %r1502, 1;
	add.s32 	%r1504, %r1503, %r12;
	sub.ftz.f32 	%f37, %f6, %f9;
	mov.f32 	%f38, 0f457A0000;
	min.ftz.f32 	%f39, %f38, %f37;
	cvt.rzi.ftz.s32.f32	%r1505, %f39;
	shr.s32 	%r1507, %r1919, 31;
	shr.u32 	%r1508, %r1507, 29;
	add.s32 	%r1509, %r1919, %r1508;
	shr.s32 	%r1510, %r1509, 3;
	shr.s32 	%r1511, %r1504, 31;
	shr.u32 	%r1512, %r1511, 29;
	add.s32 	%r1513, %r1504, %r1512;
	shr.s32 	%r1514, %r1513, 3;
	and.b32  	%r1515, %r1513, -8;
	sub.s32 	%r1516, %r1504, %r1515;
	and.b32  	%r1517, %r1509, -8;
	sub.s32 	%r1518, %r1919, %r1517;
	mad.lo.s32 	%r1519, %r1510, %r13, %r1514;
	shl.b32 	%r1520, %r1518, 3;
	add.s32 	%r1521, %r1516, %r1520;
	shl.b32 	%r1522, %r1505, 20;
	or.b32  	%r1523, %r1521, %r1522;
	mul.wide.s32 	%rd25, %r1519, 4;
	add.s64 	%rd26, %rd1, %rd25;
	atom.global.max.u32 	%r1524, [%rd26], %r1523;

BB17_18:
	// inline asm
	shfl.up.b32 %r1525, %r112, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r1529, %r112, %r470, %r471;
	// inline asm
	mov.u32 	%r1533, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r341;
mov.b32 {lowb,highb},%r1525;
mov.b32 temp,{highb,highb};
mov.b32 c,%r1533;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1533,d;
}
	// inline asm
	mov.u32 	%r1537, %r1533;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r345;
mov.b32 {lowb,highb},%r112;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r1537;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1537,d;
}
	// inline asm
	mov.u32 	%r1541, %r1537;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r349;
mov.b32 {lowb,highb},%r112;
mov.b32 temp,{highb,highb};
mov.b32 c,%r1541;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1541,d;
}
	// inline asm
	mov.u32 	%r1545, %r1541;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r353;
mov.b32 {lowb,highb},%r1529;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r1545;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1545,d;
}
	// inline asm
	mov.u32 	%r1549, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r104;
mov.b32 b,%r366;
mov.b32 c,%r1549;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1549,d;
}
	// inline asm
	mov.u32 	%r1553, %r1549;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r108;
mov.b32 b,%r362;
mov.b32 c,%r1553;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1553,d;
}
	// inline asm
	mov.u32 	%r1557, %r1553;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r112;
mov.b32 b,%r366;
mov.b32 c,%r1557;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1557,d;
}
	// inline asm
	// inline asm
	shfl.down.b32 %r1561, %r1557, %r470, %r471;
	// inline asm
	// inline asm
	shfl.up.b32 %r1565, %r1557, %r470, %r499;
	// inline asm
	mov.u32 	%r1569, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r377;
mov.b32 {lowb,highb},%r1565;
mov.b32 temp,{highb,highb};
mov.b32 c,%r1569;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1569,d;
}
	// inline asm
	mov.u32 	%r1573, %r1569;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r381;
mov.b32 {lowb,highb},%r1557;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r1573;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1573,d;
}
	// inline asm
	mov.u32 	%r1577, %r1573;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r478;
mov.b32 {lowb,highb},%r1557;
mov.b32 temp,{highb,highb};
mov.b32 c,%r1577;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1577,d;
}
	// inline asm
	mov.u32 	%r1581, %r1577;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r474;
mov.b32 {lowb,highb},%r1561;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r1581;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1581,d;
}
	// inline asm
	mov.u32 	%r1585, %r1545;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1151;
mov.b32 b,%r482;
mov.b32 c,%r1585;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1585,d;
}
	// inline asm
	mov.u32 	%r1589, %r1404;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1581;
mov.b32 b,%r1581;
mov.b32 c,%r1589;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1589,d;
}
	// inline asm
	mov.u32 	%r1593, %r1408;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1581;
mov.b32 b,%r1585;
mov.b32 c,%r1593;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1593,d;
}
	// inline asm
	mov.u32 	%r1597, %r1412;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1585;
mov.b32 b,%r1585;
mov.b32 c,%r1597;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1597,d;
}
	// inline asm
	mov.u32 	%r1601, %r1416;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1581;
mov.b32 b,%r1581;
mov.b32 c,%r1601;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1601,d;
}
	// inline asm
	mov.u32 	%r1605, %r1420;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1581;
mov.b32 b,%r1585;
mov.b32 c,%r1605;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1605,d;
}
	// inline asm
	mov.u32 	%r1609, %r1424;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1585;
mov.b32 b,%r1585;
mov.b32 c,%r1609;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1609,d;
}
	// inline asm
	mov.u32 	%r1613, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1581;
mov.b32 b,%r1581;
mov.b32 c,%r1613;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1613,d;
}
	// inline asm
	mov.u32 	%r1617, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1581;
mov.b32 b,%r1585;
mov.b32 c,%r1617;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1617,d;
}
	// inline asm
	mov.u32 	%r1621, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1585;
mov.b32 b,%r1585;
mov.b32 c,%r1621;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1621,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r1625, %r1589, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r1629, %r1589, %r470, %r471;
	// inline asm
	mov.u32 	%r1633, %r1589;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1625;
mov.b32 b,%r474;
mov.b32 c,%r1633;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1633,d;
}
	// inline asm
	mov.u32 	%r1637, %r1633;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1629;
mov.b32 b,%r478;
mov.b32 c,%r1637;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1637,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r1641, %r1593, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r1645, %r1593, %r470, %r471;
	// inline asm
	mov.u32 	%r1649, %r1593;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1641;
mov.b32 b,%r474;
mov.b32 c,%r1649;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1649,d;
}
	// inline asm
	mov.u32 	%r1653, %r1649;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1645;
mov.b32 b,%r478;
mov.b32 c,%r1653;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1653,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r1657, %r1597, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r1661, %r1597, %r470, %r471;
	// inline asm
	mov.u32 	%r1665, %r1597;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1657;
mov.b32 b,%r474;
mov.b32 c,%r1665;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1665,d;
}
	// inline asm
	mov.u32 	%r1669, %r1665;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1661;
mov.b32 b,%r478;
mov.b32 c,%r1669;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1669,d;
}
	// inline asm
	mov.u32 	%r1673, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1653;
mov.b32 b,%r482;
mov.b32 c,%r1673;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1673,d;
}
	// inline asm
	mov.u32 	%r1677, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1637;
mov.b32 b,%r1669;
mov.b32 c,%r1677;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1677,d;
}
	// inline asm
	mov.u32 	%r1681, %r1677;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1653;
mov.b32 b,%r1673;
mov.b32 c,%r1681;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1681,d;
}
	// inline asm
	mov.u32 	%r1685, %r1637;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1669;
mov.b32 b,%r494;
mov.b32 c,%r1685;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1685,d;
}
	// inline asm
	mov.u32 	%r1689, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1685;
mov.b32 b,%r1685;
mov.b32 c,%r1689;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1689,d;
}
	// inline asm
	mov.u32 	%r1693, %r1681;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1689;
mov.b32 b,%r71;
mov.b32 c,%r1693;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1693,d;
}
	// inline asm
	@!%p1 bra 	BB17_21;
	bra.uni 	BB17_19;

BB17_19:
	// inline asm
	{ .reg .f16 low,high;
  mov.b32 {low,high}, %r1693;
  mov.b16 %rs13,high;}
	// inline asm
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs13;
	cvt.f32.f16 	%f40, %temp;
	}
	// inline asm
	{ .reg .f16 low,high;
  mov.b32 {low,high}, %r1693;
  mov.b16 %rs14,low;}
	// inline asm
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs14;
	cvt.f32.f16 	%f41, %temp;
	}
	setp.gt.ftz.f32	%p8, %f40, %f41;
	selp.f32	%f7, %f40, %f41, %p8;
	setp.ltu.ftz.f32	%p17, %f7, %f9;
	@%p17 bra 	BB17_21;

	add.s32 	%r1918, %r79, 6;
	selp.u32	%r1699, 1, 0, %p8;
	xor.b32  	%r1700, %r1699, 1;
	add.s32 	%r1701, %r1700, %r12;
	sub.ftz.f32 	%f42, %f7, %f9;
	mov.f32 	%f43, 0f457A0000;
	min.ftz.f32 	%f44, %f43, %f42;
	cvt.rzi.ftz.s32.f32	%r1702, %f44;
	shr.s32 	%r1704, %r1918, 31;
	shr.u32 	%r1705, %r1704, 29;
	add.s32 	%r1706, %r1918, %r1705;
	shr.s32 	%r1707, %r1706, 3;
	shr.s32 	%r1708, %r1701, 31;
	shr.u32 	%r1709, %r1708, 29;
	add.s32 	%r1710, %r1701, %r1709;
	shr.s32 	%r1711, %r1710, 3;
	and.b32  	%r1712, %r1710, -8;
	sub.s32 	%r1713, %r1701, %r1712;
	and.b32  	%r1714, %r1706, -8;
	sub.s32 	%r1715, %r1918, %r1714;
	mad.lo.s32 	%r1716, %r1707, %r13, %r1711;
	shl.b32 	%r1717, %r1715, 3;
	add.s32 	%r1718, %r1713, %r1717;
	shl.b32 	%r1719, %r1702, 20;
	or.b32  	%r1720, %r1718, %r1719;
	mul.wide.s32 	%rd27, %r1716, 4;
	add.s64 	%rd28, %rd1, %rd27;
	atom.global.max.u32 	%r1721, [%rd28], %r1720;

BB17_21:
	// inline asm
	shfl.up.b32 %r1722, %r116, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r1726, %r116, %r470, %r471;
	// inline asm
	mov.u32 	%r1730, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r341;
mov.b32 {lowb,highb},%r1722;
mov.b32 temp,{highb,highb};
mov.b32 c,%r1730;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1730,d;
}
	// inline asm
	mov.u32 	%r1734, %r1730;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r345;
mov.b32 {lowb,highb},%r116;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r1734;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1734,d;
}
	// inline asm
	mov.u32 	%r1738, %r1734;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r349;
mov.b32 {lowb,highb},%r116;
mov.b32 temp,{highb,highb};
mov.b32 c,%r1738;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1738,d;
}
	// inline asm
	mov.u32 	%r1742, %r1738;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r353;
mov.b32 {lowb,highb},%r1726;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r1742;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1742,d;
}
	// inline asm
	mov.u32 	%r1746, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r108;
mov.b32 b,%r366;
mov.b32 c,%r1746;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1746,d;
}
	// inline asm
	mov.u32 	%r1750, %r1746;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r112;
mov.b32 b,%r362;
mov.b32 c,%r1750;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1750,d;
}
	// inline asm
	mov.u32 	%r1754, %r1750;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r116;
mov.b32 b,%r366;
mov.b32 c,%r1754;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1754,d;
}
	// inline asm
	// inline asm
	shfl.down.b32 %r1758, %r1754, %r470, %r471;
	// inline asm
	// inline asm
	shfl.up.b32 %r1762, %r1754, %r470, %r499;
	// inline asm
	mov.u32 	%r1766, %r499;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r377;
mov.b32 {lowb,highb},%r1762;
mov.b32 temp,{highb,highb};
mov.b32 c,%r1766;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1766,d;
}
	// inline asm
	mov.u32 	%r1770, %r1766;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r381;
mov.b32 {lowb,highb},%r1754;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r1770;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1770,d;
}
	// inline asm
	mov.u32 	%r1774, %r1770;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r478;
mov.b32 {lowb,highb},%r1754;
mov.b32 temp,{highb,highb};
mov.b32 c,%r1774;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1774,d;
}
	// inline asm
	mov.u32 	%r1778, %r1774;
	// inline asm
	{.reg .f32 a,c,d,temp;
.reg .f16 lowb,highb;
mov.b32 a,%r474;
mov.b32 {lowb,highb},%r1758;
mov.b32 temp,{lowb,lowb};
mov.b32 c,%r1778;
fma.rn.f16x2 d,a,temp,c;
mov.b32 %r1778,d;
}
	// inline asm
	mov.u32 	%r1782, %r1742;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1348;
mov.b32 b,%r482;
mov.b32 c,%r1782;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1782,d;
}
	// inline asm
	mov.u32 	%r1786, %r1601;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1778;
mov.b32 b,%r1778;
mov.b32 c,%r1786;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1786,d;
}
	// inline asm
	mov.u32 	%r1790, %r1605;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1778;
mov.b32 b,%r1782;
mov.b32 c,%r1790;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1790,d;
}
	// inline asm
	mov.u32 	%r1794, %r1609;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1782;
mov.b32 b,%r1782;
mov.b32 c,%r1794;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1794,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r1822, %r1786, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r1826, %r1786, %r470, %r471;
	// inline asm
	mov.u32 	%r1830, %r1786;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1822;
mov.b32 b,%r474;
mov.b32 c,%r1830;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1830,d;
}
	// inline asm
	mov.u32 	%r1834, %r1830;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1826;
mov.b32 b,%r478;
mov.b32 c,%r1834;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1834,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r1838, %r1790, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r1842, %r1790, %r470, %r471;
	// inline asm
	mov.u32 	%r1846, %r1790;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1838;
mov.b32 b,%r474;
mov.b32 c,%r1846;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1846,d;
}
	// inline asm
	mov.u32 	%r1850, %r1846;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1842;
mov.b32 b,%r478;
mov.b32 c,%r1850;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1850,d;
}
	// inline asm
	// inline asm
	shfl.up.b32 %r1854, %r1794, %r470, %r499;
	// inline asm
	// inline asm
	shfl.down.b32 %r1858, %r1794, %r470, %r471;
	// inline asm
	mov.u32 	%r1862, %r1794;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1854;
mov.b32 b,%r474;
mov.b32 c,%r1862;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1862,d;
}
	// inline asm
	mov.u32 	%r1866, %r1862;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1858;
mov.b32 b,%r478;
mov.b32 c,%r1866;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1866,d;
}
	// inline asm
	mov.u32 	%r1870, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1850;
mov.b32 b,%r482;
mov.b32 c,%r1870;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1870,d;
}
	// inline asm
	mov.u32 	%r1874, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1834;
mov.b32 b,%r1866;
mov.b32 c,%r1874;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1874,d;
}
	// inline asm
	mov.u32 	%r1878, %r1874;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1850;
mov.b32 b,%r1870;
mov.b32 c,%r1878;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1878,d;
}
	// inline asm
	mov.u32 	%r1882, %r1834;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1866;
mov.b32 b,%r494;
mov.b32 c,%r1882;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1882,d;
}
	// inline asm
	mov.u32 	%r1886, %r499;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1882;
mov.b32 b,%r1882;
mov.b32 c,%r1886;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1886,d;
}
	// inline asm
	mov.u32 	%r1890, %r1878;
	// inline asm
	{.reg .f32 a,b,c,d;
mov.b32 a,%r1886;
mov.b32 b,%r71;
mov.b32 c,%r1890;
fma.rn.f16x2 d,a,b,c;
mov.b32 %r1890,d;
}
	// inline asm
	@!%p1 bra 	BB17_24;
	bra.uni 	BB17_22;

BB17_22:
	// inline asm
	{ .reg .f16 low,high;
  mov.b32 {low,high}, %r1890;
  mov.b16 %rs15,high;}
	// inline asm
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs15;
	cvt.f32.f16 	%f45, %temp;
	}
	// inline asm
	{ .reg .f16 low,high;
  mov.b32 {low,high}, %r1890;
  mov.b16 %rs16,low;}
	// inline asm
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs16;
	cvt.f32.f16 	%f46, %temp;
	}
	setp.gt.ftz.f32	%p18, %f45, %f46;
	selp.f32	%f8, %f45, %f46, %p18;
	setp.leu.ftz.f32	%p19, %f45, %f46;
	selp.u32	%r1896, 1, 0, %p19;
	add.s32 	%r70, %r1896, %r12;
	setp.ltu.ftz.f32	%p20, %f8, %f9;
	@%p20 bra 	BB17_24;

	add.s32 	%r1917, %r79, 7;
	sub.ftz.f32 	%f47, %f8, %f9;
	mov.f32 	%f48, 0f457A0000;
	min.ftz.f32 	%f49, %f48, %f47;
	cvt.rzi.ftz.s32.f32	%r1897, %f49;
	shr.s32 	%r1899, %r1917, 31;
	shr.u32 	%r1900, %r1899, 29;
	add.s32 	%r1901, %r1917, %r1900;
	shr.s32 	%r1902, %r1901, 3;
	shr.s32 	%r1903, %r70, 31;
	shr.u32 	%r1904, %r1903, 29;
	add.s32 	%r1905, %r70, %r1904;
	shr.s32 	%r1906, %r1905, 3;
	and.b32  	%r1907, %r1905, -8;
	sub.s32 	%r1908, %r70, %r1907;
	and.b32  	%r1909, %r1901, -8;
	sub.s32 	%r1910, %r1917, %r1909;
	mad.lo.s32 	%r1911, %r1902, %r13, %r1906;
	shl.b32 	%r1912, %r1910, 3;
	add.s32 	%r1913, %r1908, %r1912;
	shl.b32 	%r1914, %r1897, 20;
	or.b32  	%r1915, %r1913, %r1914;
	mul.wide.s32 	%rd29, %r1911, 4;
	add.s64 	%rd30, %rd1, %rd29;
	atom.global.max.u32 	%r1916, [%rd30], %r1915;

BB17_24:
	ret;
}


